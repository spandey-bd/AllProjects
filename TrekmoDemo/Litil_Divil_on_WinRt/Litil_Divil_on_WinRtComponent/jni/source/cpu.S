//=============================================================================
// cpu.s
//
// This file is the main emulator core source module. It has one public function
// "run(bool run)" which begins executing the x86 program from current CS:IP
// address. If the parameter is true, the function returns only if there was
// an error (unsupported opcode) when running the emulation. If the parameter
// is false, the core executes only one opcode and then returns immediately.
// This is mainly used when tracing the x86 program in the built-in debugger.
//
// This file is part of the x86 emulation core written in ARM Assembly, originally
// from the DSx86 Nintendo DS DOS Emulator. See http://dsx86.patrickaalto.com
//
// At the start are various debugging-related defines that can be used when
// hunting for bugs or compatibility problems in the core.
//
//	DISALLOW_ZERO_CODE	If 1, two adjacent "add [bx+si],al" opcodes (0x00, 0x00)
//						are not allowed, as that usually means the core is
//						executing empty data instead of code.
//	DEBUGTRAP			If 1, call external "bool DebugTrap()" C function before
//						executing any opcode. This causes a major performance
//						hit, but the C function can be used for all kinds of
//						debugging purposes. If the C function returns false,
//						the core quits.
//	PROFILER			If 1, uses Nintendo DS -specific timers to calculate the
//						number of ARM cycles each opcode takes, and calls external
//						"Profiler(int opcode, int cycles)" C function to store
//						the cycle data (to memory, file, etc).
//	DEBUGMEMWATCH		If 1, before executing each opcode a code is run that
//						compares the given memory location contents with the
//						previous contents. If they differ, the core quits.
//						The actual checking code can be changed as needed.
//	DEBUGREGWATCH		If 1, before executing each opcode a code is run that
//						checks for a certain value in a certain ARM register.
//						The actual checking code can be changed as needed.
//	CSIPTRACE			If 1, the last 32 physical CS:EIP addresses are stored
//						into a ring buffer "eiptrace". This buffer can be used
//						by the calling code to determine the address where the
//						core encountered an unsupported opcode or crashed.
//
// Copyright (c) 2009-2013 Patrick "Pate" Aalto
//	
// Redistribution and use in source or binary form, with or without modifications,
// is NOT permitted without specific prior written permission from the author.
//
// THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR IMPLIED
// WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
// AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
// DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
// EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//=============================================================================

#if defined(RPi)
	.arch armv6
#elif defined(Roku)
	.cpu arm1176jzf-s
#else
	.arch armv7-a
#endif	
	.file	"cpu.s"

// ===============================================================

#include "defines.inc"

#define	DISALLOW_ZERO_CODE	0
#define DEBUGTRAP			0
#define PROFILER			0
#define	DEBUGMEMWATCH		0
#define	DEBUGREGWATCH		0
#define CSIPTRACE			0
#define	SAVE_HACK			0
#define	S2TEST				0
#define	FULLTRACE			0

// ===============================================================
// Register save, 8 registers AX, CX, DX, BX, SP, BP, SI, DI, PC, Flags, ES, CS, SS, DS, FS, GS, CurF3Tbl, ScreenSEG, VRAMBase
//							 r4, r5, r6, r7, r8, r9, r10, r11,r12,  cpsr
//
	.data
	.align 2
	.global registers
registers:
	.space	4*20				// We save/load them as words instead of halfwords

// ===============================================================
// run( bool r0 )
// Input: r0 == run/trace flag, if == 0, trace a single opcode and then return.
// Output: Nothing
//
// Register usage:
// 	r0  = On input: Are we Running instead of Tracing, in use: Next opcode / temp register
//	r1  = Jump address / temp register
//	r2  = Segment Override (physical segment start address for memory operations) / temp register
//	r3  = Memory address size mask (0x0000FFFF/0xFFFFFFFF) / temp register
//	r4  = EAX
//	r5  = ECX
//	r6  = EDX
//	r7  = EBX
//	r8  = ESP
//	r9  = EBP
//	r10 = ESI
//	r11 = EDI
//	r12 = CS:IP (physical address)
//	sp = stack pointer (internal)
//	lr  = SS:0000 (physical address of current stack segment)
//	r15 = program counter (internal)
//

#include "macros.inc"

.macro	handle_profiling cnt		// No content if profiling is not defined on!
	mrc		p15, 0, r0, c15, c12, 1	// r0 = cycle count value
	push	{r2-r12, lr}			// Push used registers
	mrs		r5,cpsr					// Put flags to r5
	mov		r1, r12					// r1 = pointer to next instruction to execute
	bl		Profiler				// Call the external profiler function
	msr		cpsr_f,r5				// Restore flags from r5
	pop		{r2-r12, lr}			// Pop used registers
	mov		r0, #(1|4)				// Enable all counters, clear cycle counter value
	mcr		p15, 0, r0, c15, c12, 0
.endm


	.text
	.align	2
	.code	32
	.arm
	
	//-------
	// x86 emulator enry point
	//-------
	.type	run_core, %function
	.global	run_core
run_core:
	push	{r4-r12, lr}						// Push used registers
	//-------
	// Clear the BreakReason pointer
	//-------
	ldr		r4,=BreakReason
	mov		r5, #0
	str		r5, [r4]
#if EXTERNAL_TLB
	push	{r1}								// Save the address of the external TLB table to SP_TLBTABLE
#else	
	//-------
	// Push the XMS memory addresses to stack.
	// The address is always ((u32)XMS_Start_Aligned - 0x100000)>>4.
	// We are to push (XMS_Total/16)-4 words.
	//-------
	ldr		r2, =XMS_Start_Aligned
	ldr		r3, =XMS_Total
	ldr		r2, [r2]							// r2 = (u32)XMS_Start_Aligned
	ldr		r3, [r3]
	sub		r2, #0x100000						// r2 = (u32)XMS_Start_Aligned - 0x100000
	lsr		r2, #4								// r2 = ((u32)XMS_Start_Aligned - 0x100000)>>4
	lsr		r3, #4
	sub		r3, #4
1:	push	{r2}
	subs	r3, #1
	bne		1b
	//-------
	// Copy the EMSPageStatic table to stack (to keep it in TCM)
	//-------
	mov		r1, #(64/8)
	ldr		r2,=EMSPageStatic
	add		r2,#(68*4)							// r0 points to the end of the EMSPage table
1:	ldmdb	r2!,{r5-r12}						// 8 registers = 8 words at a time
	push	{r5-r12}
	subs	r1, #1
	bne		1b
	//-------
	// Push the remaining 4 words (for the wrap-around segment).
	//-------
	ldmdb	r2!,{r5-r8}							// 4 registers = 4 words
	push	{r5-r8}
	ldr		r1,=EMSPageTable
	str		sp, [r1]							// Fix the EMSPageTable pointer, we use the table in stack
#endif	
	//-------
	// Save the (first) input parameter to r9
	//-------
	mov		r9, r0								// r9 = input parameter: 0 = not running, 1 = running
	//-------
	// Store 16-bit mask and protected mode -related stack values
	//-------
	sub		sp, #(4*16)							// Make room for the temp variables (SP_FREE1..SP_R11SAVE) on stack
	ldr		r3, =cpu_cr0
	ldr		r5, =cpu_cpl
	ldr		r2, =cpu_big
	ldrb	r3, [r3]							// r3 = lowest byte of cpu_cr0 value (lowest bits tells whether we are in prot mode)
	ldrb	r5, [r5]
	ldrb	r2, [r2]
	ldr		r4, =stack_mask
	orr		r3, r2, lsl #16						// r3 = third byte tells cpu_big value
	orr		r3, r5, lsl #8						// r3 second byte tells cpu_cpl value
	ldr		r4, [r4]							// r4 = stack_mask value, either 0x0000FFFF or 0xFFFFFFFF
	ldr		r2, =0x0000FFFF						// r2 = SP_MASK_16
	push	{r2-r7}								// r5,r6,r7 = temporary variable locations
	//-------
	// Store the logical segment registers to stack
	// SP_ES_BASE, SP_CS_BASE, SP_SS_BASE, SP_DS_BASE, SP_FS_BASE, SP_GS_BASE
	//-------
	ldr		r6,REG_ES 							// Point r5 to ES register save
	ldmia	r6, {r0-r5}							// Get ES, CS, SS, DS, FS, GS
	push	{r0-r5}								// Save them to SP_ES_VALUE, SP_CS_VALUE, SP_SS_VALUE, SP_DS_VALUE, SP_FS_VALUE, SP_GS_VALUE
	mov		r0, r0, lsl #REAL_SEGMENT_SHIFT
	mov		r1, r1, lsl #REAL_SEGMENT_SHIFT
	mov		r2, r2, lsl #REAL_SEGMENT_SHIFT
	mov		r3, r3, lsl #REAL_SEGMENT_SHIFT
	mov		r4, r4, lsl #REAL_SEGMENT_SHIFT
	mov		r5, r5, lsl #REAL_SEGMENT_SHIFT
	push	{r0-r5}								// Save them to SP_ES_BASE, SP_CS_BASE, SP_SS_BASE, SP_DS_BASE, SP_FS_BASE, SP_GS_BASE
	sub		sp, #(6*4)							// Make room in stack for SP_IRQFLAG .. SP_PHYS_CS
#if LDMIA_LOOP
	str		r2, [sp, #(2*4)]					// SP_SS_BASE
	str		r3, [sp, #(1*4)]					// SP_DS_BASE
#endif
	//-------
	// Tell interrupts are now OK if we are indeed running (r0 != 0)
	//-------
	ldr		r2, REG_FLAGS
	ldr		r1, [r2]
	str		r1, [sp, #(3*4)]					// SP_FLAGS
	//-------
	// Set the IRQFlag
	//-------
	ldr		r1, =IRQ_OFF
	ldr		r2, =cpu_big
	//-------
	// Store the current IRQ flag value to stack
	//-------
	str		r1, [sp]							// SP_IRQFLAG
	ldr		r1,=IRQFlagAddr
	cmp		r9, #0								// Are we running?
	streq	r9,[r1]								// Not running, set IRQFlagAddr = NULL
	strne	sp,[r1]								// Running, save the address of the SP_IRQFLAG to IRQFlagAddr
	//-------
	// Copy the main opcode table to stack (to keep it in TCM)
	//-------
	ldrb	r2, [r2]							// r2 = cpu_big value
	mov		r1, #(256/8)
	cmp		r2, #0								// Is cpu_big on?
	ldreq	r2,=opcodetable_16_16				// We are in USE16 segment
	ldrne	r2,=opcodetable_32_32				// We are in USE32 segment
	add		r2,#(256*4)							// r2 points to the end of the opcode table
1:	ldmdb	r2!,{r5-r12}						// 8 registers = 8 words at a time
	push	{r5-r12}
	subs	r1, #1
	bne		1b
	//-------
	// If we are in protected mode, go calculate the proper segment base addresses
	//-------
	ldrb	r2, [sp, #SP_CPU_CR0]
	tst		r2, #1								// Are we in protected mode?
	bne		init_prot_segments					// in "cpu_prot.s"
	//=======
	// REAL-MODE startup code, calculate physical CS and SS addresses
	//=======
	ldr		r2, [sp, #SP_CS_BASE]
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_CS]				// Store new physical CS into stack
	ldr		r2, [sp, #SP_SS_BASE]
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_SS]				// Store new physical SS into stack
	//-------
	// Setup the break point opcode handler if BreakOffs has a value.
	//-------
	ldr		r4, =BreakOffs
	ldr		r4, [r4]
	cmp		r4, #0
	beq		prot_start_cont
	ldr		r4, =BreakValue
	ldr		r5, =GoToUSE16ROpcode
	ldrb	r4, [r4]
	str		r5, [sp, r4, lsl #2]				// Change the opcode handler to be the break point handler.
	//-------
	// Load emulation registers
	//-------
	.global	prot_start_cont
prot_start_cont:
	ldr		r4,=IRQFlagAddr
	ldr		r1,=registers
	mov		r5, #1								// Default return value = 1 = true
	str		r5, [r1, #4*16]						// Save the default return value to registers[16]
	ldr		r0, [r4]							// r0 == 0 if we are not running
	ldmia	r1!,{r4-r12}						// Load emulation registers from global memory
#if CSIPTRACE
	mov		r2, #0								
	str		r2, [sp, #SP_FREE4]					// Clear the eiptrace table index
#endif	
	cmp		r0, #0								// Are we not running (r0 == 0 means we are tracing)?
	ldr		r0, [r1]							// Get the flags from global memory
	beq		trace_one_opcode					// Jump if we are not running
	popped_flags_to_ARM r0						// Convert the x86 flags to ARM flags in r0
	msr		cpsr_f,r0							// Set the processor flags
	//-------
	// Go start the code
	//-------
	b		loop
trace_one_opcode:
	ldr		r1, =IRQ_ON
	str		r1, [sp, #SP_IRQFLAG]				// Make the normal opcode handler jump to IRQStart
	popped_flags_to_ARM r0						// Convert the x86 flags to ARM flags in r0
	msr		cpsr_f,r0							// Set the processor flags
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	ldr		lr, [sp, #SP_SS_BASE]				// Get the default segment base for BP-relative addressing
	ldr		r2, [sp, #SP_DS_BASE]				// r2 = logical DS segment
	str		r12, [sp, #SP_EX_CSIP]				// Remember where this opcode started, for division-by-zero and exception handling
	ldr		pc,[sp, r0, lsl #2]					// Jump to the opcode handler

.ltorg											// Dump the current literal pool here

	//------ Complement the carry flag after CMP and SUB instructions (ARM -> x86 convention)
op_f5:											// Opcode F5 = CMC (Complement Carry)
	.global complement_carry
complement_carry:
	mrs		r0,cpsr
	eor		r0, r0, #ARM_CARRY
	.global restore_flags_from_r0
restore_flags_from_r0:							// Many functions jump here to restore flags and continue loop
	msr		cpsr_f,r0
	//------ Start the opcode decoder loop
	.global loop
loop:
#if FULLTRACE
	add		r0, sp, #SP_ES_VALUE
	ldr		r1,=registers
	stmia	r1,{r4-r12}							// Save emulation registers to global memory
	ldr		r4, [sp, #SP_PHYS_CS]
	mov		r8, r1
	str		r4, [r1, #4*18]						// registers[18] = PHYS_CS
	ldr		r1, REG_ES
	ldmia	r0, {r2-r7}							// Get current ES,CS,SS,DS,FS,GS
	stmia	r1, {r2-r7}							// Save current ES,CS,SS,DS,FS,GS
	mrs		r4,cpsr								// Save flags
	bl		RegDebug							// Call the external debug trap function
	msr		cpsr_f, r4							// Restore flags
	ldmia	r8,{r4-r12}							// Restore emulation registers from global memory
#endif
#if CSIPTRACE
	ldr		r0, =eiptrace
	ldr		r1, [sp, #SP_FREE4]					// Index
	ldr		r2, [sp, #SP_EX_CSIP]
	add		r1, #4
	and		r1, #4*32-1
	str		r1, [sp, #SP_FREE4]					// Index
	str		r2, [r0, r1]						// Save ex csip to table
#endif
#if DEBUGREGWATCH
	ldr		r2, =0xFFFD6BC4
	mrs		r0,cpsr								// Save flags to r0
	cmp		edx, r2
	bne		debug_trap_continue					// No break, continue running
	ldr		r1, =BRMemWatch
	ldr		r2, =BreakReason
	str		r1, [r2]							// Tell the reason for breaking was a user request
	msr		cpsr_f,r0
	b		.unknown
debug_trap_continue:	
	msr		cpsr_f,r0							// Restore flags from r0
#endif
#if	DEBUGMEMWATCH
	//-------
	// These operations determine the memory location to watch
	//-------
#if 0
	ldr		r1, [sp, #SP_CS_VALUE]
	ldr		r2, [sp, #SP_PHYS_CS]
	sub		r2, r12, r2
	mrs		r0,cpsr								// Save flags to r0
	cmp		r1, #0x80
	bne		debug_trap_continue					// No break, continue running
	ldr		r1, =0x5142
	cmp		r2, r1
#else
	ldr		r2, =EMM_Start_Aligned
	ldr		r1, =0x2DDC
	ldr		r2, [r2]
	add		r2, r1
	ldr		r1,[r2]
	ldr		r2, =0x5BE900C8
	mrs		r0,cpsr								// Save flags to r0
	cmp		r1, r2
#endif	
	//-------
	// Continue or break depending on the comparison
	//-------
	bne		debug_trap_continue					// No break, continue running
	ldr		r2,=TestData
	str		r1,[r2]
	ldr		r1, =BRMemWatch
	ldr		r2, =BreakReason
	str		r1, [r2]							// Tell the reason for breaking was a user request
	msr		cpsr_f,r0
	b		.unknown
debug_trap_continue:	
	msr		cpsr_f,r0							// Restore flags from r0
#endif	
#if DEBUGTRAP
	mrs		r1,cpsr								// Put flags to r1
	push	{r1-r12, lr}						// Push used registers
	ldr		r1,=registers
	stmia	r1!,{r4-r12}						// Save emulation registers to global memory
	mrs		r2, cpsr
	str		r2, [r1]							// Save flags to global memory
	bl		DebugTrap							// Call the external debug trap function
	pop		{r1-r12, lr}						// Pop used registers
	cmp		r0, #0								// Are we allowed to continue running?
	beq		debug_trap_false					// Nope, return to UI
	b		debug_trap_continue					// Yep, continue
debug_trap_continue:	
	msr		cpsr_f,r1							// Get flags from r1
#endif
#if PROFILER
	handle_profiling 0x1000000
#endif	
	//-------
	// Use internal IRQ handling.
	//-------
	ldrb	r0, [r12], #1						// 2 Load opcode byte to r0, increment r12 by 1
	ldr		r1, [sp, #SP_IRQFLAG]				// 2 Load IRQ_ON / IRQ_OFF mask to r1
	ldr		lr, [sp, #SP_SS_BASE]				// 2 Get the default segment base for BP-relative addressing
	ldr		r2, [sp, #SP_DS_BASE]				// 2 r2 = logical DS segment
	str		r12, [sp, #SP_EX_CSIP]				// 2 Remember where this opcode started, for division-by-zero and exception handling
	and		r1, r0								// 1 Mask the opcode with IRQ_ON / IRQ_OFF value
	ldr		pc, [sp, r1, lsl #2]				// 9 Jump to the opcode handler (or opcode 0 if r1 == 0 == IRQ_ON)
	//=======

	.ltorg

	.text
	.align	2

.exit_restoring_flags:
	msr		cpsr_f,r0							// Restore flags from r0
	//------ End of the opcode decoder loop
	.global .unknown_back2
.unknown_back2:									// Unknown but we need to rewind by 3 bytes
	.global .unknown_back1
.unknown_back1:									// Unknown but we need to rewind by 2 bytes	
	.global .unknown
.unknown:
	ldr		r12, [sp, #SP_EX_CSIP]				// rewind the CSEIP back to the beginning of this opcode.
	ldr		r1,=registers
	mov		r0, #0
	sub		r12, #1
	str		r0, [r1, #4*16]						// Save return value 0 = false
#if CSIPTRACE	
	ldr		r3, [sp, #SP_FREE4]
	str		r3, [r1, #4*19]
#endif	
	.global debug_trap_false
debug_trap_false:	
program_exit:
	ldr		r1,=registers
#if 0
	ldr		r3, [sp, #SP_FREE5]
	str		r3, [r1, #4*18]
	ldr		r3, [sp, #SP_SS_BASE]
	str		r3, [r1, #4*19]
#endif	
	//------ Save emulation registers
	stmia	r1!,{r4-r12}						// Save emulation registers to main memory
	ldr		r2,[sp, #SP_FLAGS]					// Get the current X86 FLAGS from stack
	join_ARM_to_X86_flags r2					// Update the X86 flags with the current ARM flags
	str		r2, [r1]							// Save the complete flags to main memory
	// ----- Tell we are not running any more
	ldr		r2,=IRQFlagAddr
	mov		r1, #0
	str		r1, [r2]							// Set IRQFlagAddr = NULL (= not running)
	//-------
	// Save the logical segment registers
	//-------
	add		r0, sp, #SP_ES_VALUE
	ldr		r1, REG_ES
	ldmia	r0, {r2-r7}							// Get current ES,CS,SS,DS,FS,GS
	stmia	r1!, {r2-r7}						// Save current ES,CS,SS,DS,FS,GS
	//-------
	// Save CPU_BIG, CPU_CPL and CPU_CR0
	//-------
	ldr		r2, =cpu_big
	ldr		r3, =cpu_cpl
	ldr		r4, =cpu_cr0
	ldrb	r5, [sp, #SP_CPU_BIG]
	ldrb	r6, [sp, #SP_CPU_CPL]
	ldrb	r7, [sp, #SP_CPU_CR0]
	strb	r5, [r2]
	strb	r6, [r3]
	strb	r7, [r4]
	//-------
	// Clean up the stack (remove the opcode table etc)
	//-------
	add		sp, #(256*4)						// Pop the opcode table from stack
	add		sp, #(SP_TLBTABLE-SP_IRQFLAG)		// Pop the extra local variables from stack
	//-------
	// Get the return value from registers[16]
	//-------
	ldr		r0, [r1]
#if EXTERNAL_TLB
	add		sp, #4								// Pop the SP_TLBTABLE pointer
#else	
	//-------
	// Restore the EMSPageStatic table from stack
	//-------
	mov		r1, #(64/8)
	ldr		r2,=EMSPageStatic
1:	pop		{r5-r12}							// 8 registers = 8 words at a time
	stmia	r2!, {r5-r12}
	subs	r1, #1
	bne		1b
	//-------
	// Restore the wrap-around segment
	//-------
	pop		{r5-r8}								// 4 registers = 4 words
	stmia	r2!, {r5-r8}
	//-------
	// Pop the XMS memory addresses from stack
	//-------
	ldr		r3, =XMS_Total
	ldr		r3, [r3]
	lsr		r3, #(4-2)
	sub		r3, #(4*4)
	add		sp, r3
	//-------
	// Fix the EMSPageTable pointer, the table is now in main RAM.
	//-------
	ldr		r1,=EMSPageTable
	ldr		r2,=EMSPageStatic
	str		r2, [r1]
#endif	
	//-------
	// Pop the used registers and return
	//-------
	pop		{r4-r12, lr}						// Pop used registers
	bx		lr									// Return

bad_EGA_opcode_2:
	add		r12, #1
bad_EGA_opcode_1:
	add		r12, #1
	.global	bad_EGA_opcode
bad_EGA_opcode:
	ldr		r0, =BRUnsEGA
	ldr		r1, =BreakReason
	str		r0, [r1]							// ... tell we break because of an unsupported EGA opcode
	b		debug_trap_false

bad_MODEX_opcode_2:
	add		r12, #1
bad_MODEX_opcode_1:
	add		r12, #1
	.global	bad_MODEX_opcode
bad_MODEX_opcode:
	ldr		r0, =BRUnsMODEX
	ldr		r1, =BreakReason
	str		r0, [r1]							// ... tell we break because of an unsupported MODEX opcode
	b		debug_trap_false

	//------
	// Subroutines for breaking into the debugger when a certain opcode is
	// encountered at a certain CS:IP address.
	//------
	.global	GoToUSE16ROpcode
GoToUSE16ROpcode:
	//-------
	// Check for the correct IP value
	//-------
	ldr		r2, =BreakOffs
	ldr		r1, [sp, #SP_PHYS_CS]				// Get current physical CS from stack
	ldr		r2, [r2]
	sub		r1, r12, r1							// r1 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	mrs		r0,cpsr								// Save flags to r0
	cmp		r1, r2
	bne		1f									// Not the correct IP address, call original handler
	//-------
	// Check for the correct segment value
	//-------
	ldr		r2, =BreakSeg
	ldr		r1, [sp, #SP_CS_VALUE]
	ldr		r2, [r2]
	cmp		r1, r2
	beq		.exit_restoring_flags				// Correct CS:IP, break into the debugger!
	//-------
	// Call the original handler.
	//-------
1:	ldr		r1, =OrigUSE16RHandler
	msr		cpsr_f,r0							// Restore flags from r0
	ldrb	r0, [r12, #-1]						// 2 Load opcode byte to r0, increment r12 by 1
	ldr		r2, [sp, #SP_DS_BASE]				// 2 r2 = logical DS segment
	ldr		pc, [r1]							// 9 Jump to the original opcode handler

.ltorg											// Dump the current literal pool here
	
// ------------------- 00 = ADD r/m8, r8 -------------------------------
//
// All modrm variations supported!
//
//
	.global	op_00
op_00:
	//-------
	// Check if we are to handle an interrupt instead of op_00
	//-------
	mrs		r1,cpsr								// Save flags to r1. We don't need to restore them if not an IRQ
	cmp		r0, #0								// Do we really need to handle opcode 00 instead of an IRQ?
	bne		IRQStart_r1							// Nope, we need to handle an IRQ instead.
	//-------
	// Handle opcode 00.
	//-------
	modrm_jump_16
// 0
	.word add_bxsi_al, add_bxdi_al, add_bpsi_al, add_bpdi_al, add_siidx_al, add_diidx_al, add_disp16_al, add_bxidx_al
	.word add_bxsi_cl, add_bxdi_cl, add_bpsi_cl, add_bpdi_cl, add_siidx_cl, add_diidx_cl, add_disp16_cl, add_bxidx_cl
	.word add_bxsi_dl, add_bxdi_dl, add_bpsi_dl, add_bpdi_dl, add_siidx_dl, add_diidx_dl, add_disp16_dl, add_bxidx_dl
	.word add_bxsi_bl, add_bxdi_bl, add_bpsi_bl, add_bpdi_bl, add_siidx_bl, add_diidx_bl, add_disp16_bl, add_bxidx_bl
	.word add_bxsi_ah, add_bxdi_ah, add_bpsi_ah, add_bpdi_ah, add_siidx_ah, add_diidx_ah, add_disp16_ah, add_bxidx_ah
	.word add_bxsi_ch, add_bxdi_ch, add_bpsi_ch, add_bpdi_ch, add_siidx_ch, add_diidx_ch, add_disp16_ch, add_bxidx_ch
	.word add_bxsi_dh, add_bxdi_dh, add_bpsi_dh, add_bpdi_dh, add_siidx_dh, add_diidx_dh, add_disp16_dh, add_bxidx_dh
	.word add_bxsi_bh, add_bxdi_bh, add_bpsi_bh, add_bpdi_bh, add_siidx_bh, add_diidx_bh, add_disp16_bh, add_bxidx_bh
//0x40
	.word add_bxsid8_al, add_bxdid8_al, add_bpsid8_al, add_bpdid8_al, add_sidisp8_al, add_didisp8_al, add_bpdisp8_al, add_bxdisp8_al
	.word add_bxsid8_cl, add_bxdid8_cl, add_bpsid8_cl, add_bpdid8_cl, add_sidisp8_cl, add_didisp8_cl, add_bpdisp8_cl, add_bxdisp8_cl
	.word add_bxsid8_dl, add_bxdid8_dl, add_bpsid8_dl, add_bpdid8_dl, add_sidisp8_dl, add_didisp8_dl, add_bpdisp8_dl, add_bxdisp8_dl
	.word add_bxsid8_bl, add_bxdid8_bl, add_bpsid8_bl, add_bpdid8_bl, add_sidisp8_bl, add_didisp8_bl, add_bpdisp8_bl, add_bxdisp8_bl
	.word add_bxsid8_ah, add_bxdid8_ah, add_bpsid8_ah, add_bpdid8_ah, add_sidisp8_ah, add_didisp8_ah, add_bpdisp8_ah, add_bxdisp8_ah
	.word add_bxsid8_ch, add_bxdid8_ch, add_bpsid8_ch, add_bpdid8_ch, add_sidisp8_ch, add_didisp8_ch, add_bpdisp8_ch, add_bxdisp8_ch
	.word add_bxsid8_dh, add_bxdid8_dh, add_bpsid8_dh, add_bpdid8_dh, add_sidisp8_dh, add_didisp8_dh, add_bpdisp8_dh, add_bxdisp8_dh
	.word add_bxsid8_bh, add_bxdid8_bh, add_bpsid8_bh, add_bpdid8_bh, add_sidisp8_bh, add_didisp8_bh, add_bpdisp8_bh, add_bxdisp8_bh
//0x80
	.word add_bxsid16_al, add_bxdid16_al, add_bpsid16_al, add_bpdid16_al, add_sidisp16_al, add_didisp16_al, add_bpdisp16_al, add_bxdisp16_al
	.word add_bxsid16_cl, add_bxdid16_cl, add_bpsid16_cl, add_bpdid16_cl, add_sidisp16_cl, add_didisp16_cl, add_bpdisp16_cl, add_bxdisp16_cl
	.word add_bxsid16_dl, add_bxdid16_dl, add_bpsid16_dl, add_bpdid16_dl, add_sidisp16_dl, add_didisp16_dl, add_bpdisp16_dl, add_bxdisp16_dl
	.word add_bxsid16_bl, add_bxdid16_bl, add_bpsid16_bl, add_bpdid16_bl, add_sidisp16_bl, add_didisp16_bl, add_bpdisp16_bl, add_bxdisp16_bl
	.word add_bxsid16_ah, add_bxdid16_ah, add_bpsid16_ah, add_bpdid16_ah, add_sidisp16_ah, add_didisp16_ah, add_bpdisp16_ah, add_bxdisp16_ah
	.word add_bxsid16_ch, add_bxdid16_ch, add_bpsid16_ch, add_bpdid16_ch, add_sidisp16_ch, add_didisp16_ch, add_bpdisp16_ch, add_bxdisp16_ch
	.word add_bxsid16_dh, add_bxdid16_dh, add_bpsid16_dh, add_bpdid16_dh, add_sidisp16_dh, add_didisp16_dh, add_bpdisp16_dh, add_bxdisp16_dh
	.word add_bxsid16_bh, add_bxdid16_bh, add_bpsid16_bh, add_bpdid16_bh, add_sidisp16_bh, add_didisp16_bh, add_bpdisp16_bh, add_bxdisp16_bh
// 0xC0 = two register operands
	.word add_al_al, add_cl_al, add_dl_al, add_bl_al, add_ah_al, add_ch_al, add_dh_al, add_bh_al
	.word add_al_cl, add_cl_cl, add_dl_cl, add_bl_cl, add_ah_cl, add_ch_cl, add_dh_cl, add_bh_cl
	.word add_al_dl, add_cl_dl, add_dl_dl, add_bl_dl, add_ah_dl, add_ch_dl, add_dh_dl, add_bh_dl
	.word add_al_bl, add_cl_bl, add_dl_bl, add_bl_bl, add_ah_bl, add_ch_bl, add_dh_bl, add_bh_bl
	.word add_al_ah, add_cl_ah, add_dl_ah, add_bl_ah, add_ah_ah, add_ch_ah, add_dh_ah, add_bh_ah
	.word add_al_ch, add_cl_ch, add_dl_ch, add_bl_ch, add_ah_ch, add_ch_ch, add_dh_ch, add_bh_ch
	.word add_al_dh, add_cl_dh, add_dl_dh, add_bl_dh, add_ah_dh, add_ch_dh, add_dh_dh, add_bh_dh
	.word add_al_bh, add_cl_bh, add_dl_bh, add_bl_bh, add_ah_bh, add_ch_bh, add_dh_bh, add_bh_bh

// These are called from "cpu_386.s":

	.global	add_siidx_al, add_siidx_cl, add_siidx_dl, add_siidx_bl, add_siidx_ah, add_siidx_ch, add_siidx_dh, add_siidx_bh
	.global	add_diidx_al, add_diidx_cl, add_diidx_dl, add_diidx_bl, add_diidx_ah, add_diidx_ch, add_diidx_dh, add_diidx_bh
	.global	add_bxidx_al, add_bxidx_cl, add_bxidx_dl, add_bxidx_bl, add_bxidx_ah, add_bxidx_ch, add_bxidx_dh, add_bxidx_bh
	.global	add_sidisp8_al, add_sidisp8_cl, add_sidisp8_dl, add_sidisp8_bl, add_sidisp8_ah, add_sidisp8_ch, add_sidisp8_dh, add_sidisp8_bh
	.global	add_didisp8_al, add_didisp8_cl, add_didisp8_dl, add_didisp8_bl, add_didisp8_ah, add_didisp8_ch, add_didisp8_dh, add_didisp8_bh
	.global	add_bpdisp8_al, add_bpdisp8_cl, add_bpdisp8_dl, add_bpdisp8_bl, add_bpdisp8_ah, add_bpdisp8_ch, add_bpdisp8_dh, add_bpdisp8_bh
	.global	add_bxdisp8_al, add_bxdisp8_cl, add_bxdisp8_dl, add_bxdisp8_bl, add_bxdisp8_ah, add_bxdisp8_ch, add_bxdisp8_dh, add_bxdisp8_bh
 
.macro add_r0_reg8l reg
	.global	add_r0_r8l_bp_\reg
add_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	add_r0_r8l_\reg
add_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_00_RAM_l_\reg op_00_EGA_l_\reg op_00_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_00_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	adds	r0, r1, r0, lsl #24		// r0 = [RAM] + reg in highest byte
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to [physical segment + disp16]
	b		loop
.endm
.macro add_r0_reg8h reg
	.global	add_r0_r8h_bp_\reg
add_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	add_r0_r8h_\reg
add_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_00_RAM_h_\reg op_00_EGA_h_\reg op_00_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_00_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0x0000FF00
	lsl		r1, #16
	adds	r0, r1, r0, lsl #24		// r0 = [RAM] + reg in highest byte
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to RAM
	b		loop
.endm

	add_r0_reg8l r4
	add_r0_reg8l r5
	add_r0_reg8l r6
	add_r0_reg8l r7
	add_r0_reg8h r4
	add_r0_reg8h r5
	add_r0_reg8h r6
	add_r0_reg8h r7

	.ltorg

// --- [idx] ---

.macro add_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		add_r0_r8l_\reg
.endm
.macro add_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		add_r0_r8h_\reg
.endm

add_bxsi_al:
#if DISALLOW_ZERO_CODE
	//-------
	// This is opcode 00 00. Make sure the next opcode is not 00 00 as well.
	// If it is, we seem to have gotten into non-code memory area.
	//-------
	ldrb	r0, [r12]
	cmp		r0, #0
	ldreqb	r0, [r12, #1]
	cmpeq	r0, #0
	beq		.unknown_back1
#endif	
	add_bxidx_reg8l r10 r4
add_bxsi_cl:
	add_bxidx_reg8l r10 r5
add_bxsi_dl:
	add_bxidx_reg8l r10 r6
add_bxsi_bl:
	add_bxidx_reg8l r10 r7
add_bxsi_ah:
	add_bxidx_reg8h r10 r4
add_bxsi_ch:
	add_bxidx_reg8h r10 r5
add_bxsi_dh:
	add_bxidx_reg8h r10 r6
add_bxsi_bh:
	add_bxidx_reg8h r10 r7

add_bxdi_al:
	add_bxidx_reg8l r11 r4
add_bxdi_cl:
	add_bxidx_reg8l r11 r5
add_bxdi_dl:
	add_bxidx_reg8l r11 r6
add_bxdi_bl:
	add_bxidx_reg8l r11 r7
add_bxdi_ah:
	add_bxidx_reg8h r11 r4
add_bxdi_ch:
	add_bxidx_reg8h r11 r5
add_bxdi_dh:
	add_bxidx_reg8h r11 r6
add_bxdi_bh:
	add_bxidx_reg8h r11 r7

.macro add_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		add_r0_r8l_bp_\reg
.endm
.macro add_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		add_r0_r8h_bp_\reg
.endm

add_bpsi_al:
	add_bpidx_reg8l r10 r4
add_bpsi_cl:
	add_bpidx_reg8l r10 r5
add_bpsi_dl:
	add_bpidx_reg8l r10 r6
add_bpsi_bl:
	add_bpidx_reg8l r10 r7
add_bpsi_ah:
	add_bpidx_reg8h r10 r4
add_bpsi_ch:
	add_bpidx_reg8h r10 r5
add_bpsi_dh:
	add_bpidx_reg8h r10 r6
add_bpsi_bh:
	add_bpidx_reg8h r10 r7

add_bpdi_al:
	add_bpidx_reg8l r11 r4
add_bpdi_cl:
	add_bpidx_reg8l r11 r5
add_bpdi_dl:
	add_bpidx_reg8l r11 r6
add_bpdi_bl:
	add_bpidx_reg8l r11 r7
add_bpdi_ah:
	add_bpidx_reg8h r11 r4
add_bpdi_ch:
	add_bpidx_reg8h r11 r5
add_bpdi_dh:
	add_bpidx_reg8h r11 r6
add_bpdi_bh:
	add_bpidx_reg8h r11 r7

.macro add_idx_reg8l idx reg
	mov		r0, \idx				// r0 = idx register value
	b		add_r0_r8l_\reg
.endm
.macro add_idx_reg8h idx reg
	mov		r0, \idx				// r0 = idx register value
	b		add_r0_r8h_\reg
.endm

add_siidx_al:
	add_idx_reg8l r10 r4
add_siidx_cl:
	add_idx_reg8l r10 r5
add_siidx_dl:
	add_idx_reg8l r10 r6
add_siidx_bl:
	add_idx_reg8l r10 r7
add_siidx_ah:
	add_idx_reg8h r10 r4
add_siidx_ch:
	add_idx_reg8h r10 r5
add_siidx_dh:
	add_idx_reg8h r10 r6
add_siidx_bh:
	add_idx_reg8h r10 r7

add_diidx_al:
	add_idx_reg8l r11 r4
add_diidx_cl:
	add_idx_reg8l r11 r5
add_diidx_dl:
	add_idx_reg8l r11 r6
add_diidx_bl:
	add_idx_reg8l r11 r7
add_diidx_ah:
	add_idx_reg8h r11 r4
add_diidx_ch:
	add_idx_reg8h r11 r5
add_diidx_dh:
	add_idx_reg8h r11 r6
add_diidx_bh:
	add_idx_reg8h r11 r7

add_bxidx_al:
	add_idx_reg8l r7 r4
add_bxidx_cl:
	add_idx_reg8l r7 r5
add_bxidx_dl:
	add_idx_reg8l r7 r6
add_bxidx_bl:
	add_idx_reg8l r7 r7
add_bxidx_ah:
	add_idx_reg8h r7 r4
add_bxidx_ch:
	add_idx_reg8h r7 r5
add_bxidx_dh:
	add_idx_reg8h r7 r6
add_bxidx_bh:
	add_idx_reg8h r7 r7
	
.macro add_disp16_reg8l reg
	r0_from_disp16
	b		add_r0_r8l_\reg
.endm

.macro add_disp16_reg8h reg
	r0_from_disp16
	b		add_r0_r8h_\reg
.endm

add_disp16_al:
	add_disp16_reg8l r4
add_disp16_cl:
	add_disp16_reg8l r5
add_disp16_dl:
	add_disp16_reg8l r6
add_disp16_bl:
	add_disp16_reg8l r7
add_disp16_ah:
	add_disp16_reg8h r4
add_disp16_ch:
	add_disp16_reg8h r5
add_disp16_dh:
	add_disp16_reg8h r6
add_disp16_bh:
	add_disp16_reg8h r7

// --- [idx+disp8] ---

.macro add_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		add_r0_r8l_\reg
.endm
.macro add_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		add_r0_r8h_\reg
.endm

add_bxsid8_al:
	add_bxidxd8_reg8l r10 r4
add_bxsid8_cl:
	add_bxidxd8_reg8l r10 r5
add_bxsid8_dl:
	add_bxidxd8_reg8l r10 r6
add_bxsid8_bl:
	add_bxidxd8_reg8l r10 r7
add_bxsid8_ah:
	add_bxidxd8_reg8h r10 r4
add_bxsid8_ch:
	add_bxidxd8_reg8h r10 r5
add_bxsid8_dh:
	add_bxidxd8_reg8h r10 r6
add_bxsid8_bh:
	add_bxidxd8_reg8h r10 r7

add_bxdid8_al:
	add_bxidxd8_reg8l r11 r4
add_bxdid8_cl:
	add_bxidxd8_reg8l r11 r5
add_bxdid8_dl:
	add_bxidxd8_reg8l r11 r6
add_bxdid8_bl:
	add_bxidxd8_reg8l r11 r7
add_bxdid8_ah:
	add_bxidxd8_reg8h r11 r4
add_bxdid8_ch:
	add_bxidxd8_reg8h r11 r5
add_bxdid8_dh:
	add_bxidxd8_reg8h r11 r6
add_bxdid8_bh:
	add_bxidxd8_reg8h r11 r7

.macro add_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		add_r0_r8l_bp_\reg
.endm
.macro add_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		add_r0_r8h_bp_\reg
.endm

add_bpsid8_al:
	add_bpidxd8_reg8l r10 r4
add_bpsid8_cl:
	add_bpidxd8_reg8l r10 r5
add_bpsid8_dl:
	add_bpidxd8_reg8l r10 r6
add_bpsid8_bl:
	add_bpidxd8_reg8l r10 r7
add_bpsid8_ah:
	add_bpidxd8_reg8h r10 r4
add_bpsid8_ch:
	add_bpidxd8_reg8h r10 r5
add_bpsid8_dh:
	add_bpidxd8_reg8h r10 r6
add_bpsid8_bh:
	add_bpidxd8_reg8h r10 r7

add_bpdid8_al:
	add_bpidxd8_reg8l r11 r4
add_bpdid8_cl:
	add_bpidxd8_reg8l r11 r5
add_bpdid8_dl:
	add_bpidxd8_reg8l r11 r6
add_bpdid8_bl:
	add_bpidxd8_reg8l r11 r7
add_bpdid8_ah:
	add_bpidxd8_reg8h r11 r4
add_bpdid8_ch:
	add_bpidxd8_reg8h r11 r5
add_bpdid8_dh:
	add_bpidxd8_reg8h r11 r6
add_bpdid8_bh:
	add_bpidxd8_reg8h r11 r7

.macro add_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		add_r0_r8l_\reg
.endm
.macro add_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		add_r0_r8h_\reg
.endm

add_sidisp8_al:
	add_idxdisp8_reg8l r10 r4
add_sidisp8_cl:
	add_idxdisp8_reg8l r10 r5
add_sidisp8_dl:
	add_idxdisp8_reg8l r10 r6
add_sidisp8_bl:
	add_idxdisp8_reg8l r10 r7
add_sidisp8_ah:
	add_idxdisp8_reg8h r10 r4
add_sidisp8_ch:
	add_idxdisp8_reg8h r10 r5
add_sidisp8_dh:
	add_idxdisp8_reg8h r10 r6
add_sidisp8_bh:
	add_idxdisp8_reg8h r10 r7

add_didisp8_al:
	add_idxdisp8_reg8l r11 r4
add_didisp8_cl:
	add_idxdisp8_reg8l r11 r5
add_didisp8_dl:
	add_idxdisp8_reg8l r11 r6
add_didisp8_bl:
	add_idxdisp8_reg8l r11 r7
add_didisp8_ah:
	add_idxdisp8_reg8h r11 r4
add_didisp8_ch:
	add_idxdisp8_reg8h r11 r5
add_didisp8_dh:
	add_idxdisp8_reg8h r11 r6
add_didisp8_bh:
	add_idxdisp8_reg8h r11 r7

add_bxdisp8_al:
	add_idxdisp8_reg8l r7 r4
add_bxdisp8_cl:
	add_idxdisp8_reg8l r7 r5
add_bxdisp8_dl:
	add_idxdisp8_reg8l r7 r6
add_bxdisp8_bl:
	add_idxdisp8_reg8l r7 r7
add_bxdisp8_ah:
	add_idxdisp8_reg8h r7 r4
add_bxdisp8_ch:
	add_idxdisp8_reg8h r7 r5
add_bxdisp8_dh:
	add_idxdisp8_reg8h r7 r6
add_bxdisp8_bh:
	add_idxdisp8_reg8h r7 r7

.macro add_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		add_r0_r8l_bp_\reg
.endm
.macro add_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		add_r0_r8h_bp_\reg
.endm

add_bpdisp8_al:
	add_bpdisp8_reg8l r4
add_bpdisp8_cl:
	add_bpdisp8_reg8l r5
add_bpdisp8_dl:
	add_bpdisp8_reg8l r6
add_bpdisp8_bl:
	add_bpdisp8_reg8l r7
add_bpdisp8_ah:
	add_bpdisp8_reg8h r4
add_bpdisp8_ch:
	add_bpdisp8_reg8h r5
add_bpdisp8_dh:
	add_bpdisp8_reg8h r6
add_bpdisp8_bh:
	add_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro add_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		add_r0_r8l_\reg
.endm
.macro add_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		add_r0_r8h_\reg
.endm

add_bxsid16_al:
	add_bxidxdisp16_reg8l r10 r4
add_bxsid16_cl:
	add_bxidxdisp16_reg8l r10 r5
add_bxsid16_dl:
	add_bxidxdisp16_reg8l r10 r6
add_bxsid16_bl:
	add_bxidxdisp16_reg8l r10 r7
add_bxsid16_ah:
	add_bxidxdisp16_reg8h r10 r4
add_bxsid16_ch:
	add_bxidxdisp16_reg8h r10 r5
add_bxsid16_dh:
	add_bxidxdisp16_reg8h r10 r6
add_bxsid16_bh:
	add_bxidxdisp16_reg8h r10 r7

add_bxdid16_al:
	add_bxidxdisp16_reg8l r11 r4
add_bxdid16_cl:
	add_bxidxdisp16_reg8l r11 r5
add_bxdid16_dl:
	add_bxidxdisp16_reg8l r11 r6
add_bxdid16_bl:
	add_bxidxdisp16_reg8l r11 r7
add_bxdid16_ah:
	add_bxidxdisp16_reg8h r11 r4
add_bxdid16_ch:
	add_bxidxdisp16_reg8h r11 r5
add_bxdid16_dh:
	add_bxidxdisp16_reg8h r11 r6
add_bxdid16_bh:
	add_bxidxdisp16_reg8h r11 r7

.macro add_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		add_r0_r8l_bp_\reg
.endm
.macro add_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		add_r0_r8h_bp_\reg
.endm

add_bpsid16_al:
	add_bpidxd16_reg8l r10 r4
add_bpsid16_cl:
	add_bpidxd16_reg8l r10 r5
add_bpsid16_dl:
	add_bpidxd16_reg8l r10 r6
add_bpsid16_bl:
	add_bpidxd16_reg8l r10 r7
add_bpsid16_ah:
	add_bpidxd16_reg8h r10 r4
add_bpsid16_ch:
	add_bpidxd16_reg8h r10 r5
add_bpsid16_dh:
	add_bpidxd16_reg8h r10 r6
add_bpsid16_bh:
	add_bpidxd16_reg8h r10 r7

add_bpdid16_al:
	add_bpidxd16_reg8l r11 r4
add_bpdid16_cl:
	add_bpidxd16_reg8l r11 r5
add_bpdid16_dl:
	add_bpidxd16_reg8l r11 r6
add_bpdid16_bl:
	add_bpidxd16_reg8l r11 r7
add_bpdid16_ah:
	add_bpidxd16_reg8h r11 r4
add_bpdid16_ch:
	add_bpidxd16_reg8h r11 r5
add_bpdid16_dh:
	add_bpidxd16_reg8h r11 r6
add_bpdid16_bh:
	add_bpidxd16_reg8h r11 r7

.macro add_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		add_r0_r8l_\reg
.endm
.macro add_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		add_r0_r8h_\reg
.endm

add_sidisp16_al:
	add_idxdisp16_reg8l r10 r4
add_sidisp16_cl:
	add_idxdisp16_reg8l r10 r5
add_sidisp16_dl:
	add_idxdisp16_reg8l r10 r6
add_sidisp16_bl:
	add_idxdisp16_reg8l r10 r7
add_sidisp16_ah:
	add_idxdisp16_reg8h r10 r4
add_sidisp16_ch:
	add_idxdisp16_reg8h r10 r5
add_sidisp16_dh:
	add_idxdisp16_reg8h r10 r6
add_sidisp16_bh:
	add_idxdisp16_reg8h r10 r7

add_didisp16_al:
	add_idxdisp16_reg8l r11 r4
add_didisp16_cl:
	add_idxdisp16_reg8l r11 r5
add_didisp16_dl:
	add_idxdisp16_reg8l r11 r6
add_didisp16_bl:
	add_idxdisp16_reg8l r11 r7
add_didisp16_ah:
	add_idxdisp16_reg8h r11 r4
add_didisp16_ch:
	add_idxdisp16_reg8h r11 r5
add_didisp16_dh:
	add_idxdisp16_reg8h r11 r6
add_didisp16_bh:
	add_idxdisp16_reg8h r11 r7

add_bxdisp16_al:
	add_idxdisp16_reg8l r7 r4
add_bxdisp16_cl:
	add_idxdisp16_reg8l r7 r5
add_bxdisp16_dl:
	add_idxdisp16_reg8l r7 r6
add_bxdisp16_bl:
	add_idxdisp16_reg8l r7 r7
add_bxdisp16_ah:
	add_idxdisp16_reg8h r7 r4
add_bxdisp16_ch:
	add_idxdisp16_reg8h r7 r5
add_bxdisp16_dh:
	add_idxdisp16_reg8h r7 r6
add_bxdisp16_bh:
	add_idxdisp16_reg8h r7 r7

.macro add_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		add_r0_r8l_bp_\reg
.endm
.macro add_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		add_r0_r8h_bp_\reg
.endm

add_bpdisp16_al:
	add_bpdisp16_reg8l r4
add_bpdisp16_cl:
	add_bpdisp16_reg8l r5
add_bpdisp16_dl:
	add_bpdisp16_reg8l r6
add_bpdisp16_bl:
	add_bpdisp16_reg8l r7
add_bpdisp16_ah:
	add_bpdisp16_reg8h r4
add_bpdisp16_ch:
	add_bpdisp16_reg8h r5
add_bpdisp16_dh:
	add_bpdisp16_reg8h r6
add_bpdisp16_bh:
	add_bpdisp16_reg8h r7


// ------------------- 01 = ADD r/m16, r16 -----------------------------
//
// All modrm variations supported!
//
//
	.global	op_01
op_01:
	modrm_jump_16
// 0
	.word add_bxsi_ax, add_bxdi_ax, add_bpsi_ax, add_bpdi_ax, add_siidx_ax, add_diidx_ax, add_disp16_ax, add_bxidx_ax
	.word add_bxsi_cx, add_bxdi_cx, add_bpsi_cx, add_bpdi_cx, add_siidx_cx, add_diidx_cx, add_disp16_cx, add_bxidx_cx
	.word add_bxsi_dx, add_bxdi_dx, add_bpsi_dx, add_bpdi_dx, add_siidx_dx, add_diidx_dx, add_disp16_dx, add_bxidx_dx
	.word add_bxsi_bx, add_bxdi_bx, add_bpsi_bx, add_bpdi_bx, add_siidx_bx, add_diidx_bx, add_disp16_bx, add_bxidx_bx
	.word add_bxsi_sp, add_bxdi_sp, add_bpsi_sp, add_bpdi_sp, add_siidx_sp, add_diidx_sp, add_disp16_sp, add_bxidx_sp
	.word add_bxsi_bp, add_bxdi_bp, add_bpsi_bp, add_bpdi_bp, add_siidx_bp, add_diidx_bp, add_disp16_bp, add_bxidx_bp
	.word add_bxsi_si, add_bxdi_si, add_bpsi_si, add_bpdi_si, add_siidx_si, add_diidx_si, add_disp16_si, add_bxidx_si
	.word add_bxsi_di, add_bxdi_di, add_bpsi_di, add_bpdi_di, add_siidx_di, add_diidx_di, add_disp16_di, add_bxidx_di
//0x40
	.word add_bxsid8_ax, add_bxdid8_ax, add_bpsid8_ax, add_bpdid8_ax, add_sidisp8_ax, add_didisp8_ax, add_bpdisp8_ax, add_bxdisp8_ax
	.word add_bxsid8_cx, add_bxdid8_cx, add_bpsid8_cx, add_bpdid8_cx, add_sidisp8_cx, add_didisp8_cx, add_bpdisp8_cx, add_bxdisp8_cx
	.word add_bxsid8_dx, add_bxdid8_dx, add_bpsid8_dx, add_bpdid8_dx, add_sidisp8_dx, add_didisp8_dx, add_bpdisp8_dx, add_bxdisp8_dx
	.word add_bxsid8_bx, add_bxdid8_bx, add_bpsid8_bx, add_bpdid8_bx, add_sidisp8_bx, add_didisp8_bx, add_bpdisp8_bx, add_bxdisp8_bx
	.word add_bxsid8_sp, add_bxdid8_sp, add_bpsid8_sp, add_bpdid8_sp, add_sidisp8_sp, add_didisp8_sp, add_bpdisp8_sp, add_bxdisp8_sp
	.word add_bxsid8_bp, add_bxdid8_bp, add_bpsid8_bp, add_bpdid8_bp, add_sidisp8_bp, add_didisp8_bp, add_bpdisp8_bp, add_bxdisp8_bp
	.word add_bxsid8_si, add_bxdid8_si, add_bpsid8_si, add_bpdid8_si, add_sidisp8_si, add_didisp8_si, add_bpdisp8_si, add_bxdisp8_si
	.word add_bxsid8_di, add_bxdid8_di, add_bpsid8_di, add_bpdid8_di, add_sidisp8_di, add_didisp8_di, add_bpdisp8_di, add_bxdisp8_di
//0x80
	.word add_bxsid16_ax, add_bxdid16_ax, add_bpsid16_ax, add_bpdid16_ax, add_sidisp16_ax, add_didisp16_ax, add_bpdisp16_ax, add_bxdisp16_ax
	.word add_bxsid16_cx, add_bxdid16_cx, add_bpsid16_cx, add_bpdid16_cx, add_sidisp16_cx, add_didisp16_cx, add_bpdisp16_cx, add_bxdisp16_cx
	.word add_bxsid16_dx, add_bxdid16_dx, add_bpsid16_dx, add_bpdid16_dx, add_sidisp16_dx, add_didisp16_dx, add_bpdisp16_dx, add_bxdisp16_dx
	.word add_bxsid16_bx, add_bxdid16_bx, add_bpsid16_bx, add_bpdid16_bx, add_sidisp16_bx, add_didisp16_bx, add_bpdisp16_bx, add_bxdisp16_bx
	.word add_bxsid16_sp, add_bxdid16_sp, add_bpsid16_sp, add_bpdid16_sp, add_sidisp16_sp, add_didisp16_sp, add_bpdisp16_sp, add_bxdisp16_sp
	.word add_bxsid16_bp, add_bxdid16_bp, add_bpsid16_bp, add_bpdid16_bp, add_sidisp16_bp, add_didisp16_bp, add_bpdisp16_bp, add_bxdisp16_bp
	.word add_bxsid16_si, add_bxdid16_si, add_bpsid16_si, add_bpdid16_si, add_sidisp16_si, add_didisp16_si, add_bpdisp16_si, add_bxdisp16_si
	.word add_bxsid16_di, add_bxdid16_di, add_bpsid16_di, add_bpdid16_di, add_sidisp16_di, add_didisp16_di, add_bpdisp16_di, add_bxdisp16_di
// 0xC0 = two register operands
	.word add_ax_ax, add_cx_ax, add_dx_ax, add_bx_ax, add_sp_ax, add_bp_ax, add_si_ax, add_di_ax
	.word add_ax_cx, add_cx_cx, add_dx_cx, add_bx_cx, add_sp_cx, add_bp_cx, add_si_cx, add_di_cx
	.word add_ax_dx, add_cx_dx, add_dx_dx, add_bx_dx, add_sp_dx, add_bp_dx, add_si_dx, add_di_dx
	.word add_ax_bx, add_cx_bx, add_dx_bx, add_bx_bx, add_sp_bx, add_bp_bx, add_si_bx, add_di_bx
	.word add_ax_sp, add_cx_sp, add_dx_sp, add_bx_sp, add_sp_sp, add_bp_sp, add_si_sp, add_di_sp
	.word add_ax_bp, add_cx_bp, add_dx_bp, add_bx_bp, add_sp_bp, add_bp_bp, add_si_bp, add_di_bp
	.word add_ax_si, add_cx_si, add_dx_si, add_bx_si, add_sp_si, add_bp_si, add_si_si, add_di_si
	.word add_ax_di, add_cx_di, add_dx_di, add_bx_di, add_sp_di, add_bp_di, add_si_di, add_di_di

// These are called from "cpu_67.s":

	.global add_siidx_ax, add_diidx_ax, add_bxidx_ax
	.global add_siidx_cx, add_diidx_cx, add_bxidx_cx
	.global add_siidx_dx, add_diidx_dx, add_bxidx_dx
	.global add_siidx_bx, add_diidx_bx, add_bxidx_bx
	.global add_siidx_sp, add_diidx_sp, add_bxidx_sp
	.global add_siidx_bp, add_diidx_bp, add_bxidx_bp
	.global add_siidx_si, add_diidx_si, add_bxidx_si
	.global add_siidx_di, add_diidx_di, add_bxidx_di
	.global add_sidisp8_ax, add_didisp8_ax, add_bpdisp8_ax, add_bxdisp8_ax
	.global add_sidisp8_cx, add_didisp8_cx, add_bpdisp8_cx, add_bxdisp8_cx
	.global add_sidisp8_dx, add_didisp8_dx, add_bpdisp8_dx, add_bxdisp8_dx
	.global add_sidisp8_bx, add_didisp8_bx, add_bpdisp8_bx, add_bxdisp8_bx
	.global add_sidisp8_sp, add_didisp8_sp, add_bpdisp8_sp, add_bxdisp8_sp
	.global add_sidisp8_bp, add_didisp8_bp, add_bpdisp8_bp, add_bxdisp8_bp
	.global add_sidisp8_si, add_didisp8_si, add_bpdisp8_si, add_bxdisp8_si
	.global add_sidisp8_di, add_didisp8_di, add_bpdisp8_di, add_bxdisp8_di
	.global add_ax_ax, add_cx_ax, add_dx_ax, add_bx_ax, add_sp_ax, add_bp_ax, add_si_ax, add_di_ax
	.global add_ax_cx, add_cx_cx, add_dx_cx, add_bx_cx, add_sp_cx, add_bp_cx, add_si_cx, add_di_cx
	.global add_ax_dx, add_cx_dx, add_dx_dx, add_bx_dx, add_sp_dx, add_bp_dx, add_si_dx, add_di_dx
	.global add_ax_bx, add_cx_bx, add_dx_bx, add_bx_bx, add_sp_bx, add_bp_bx, add_si_bx, add_di_bx
	.global add_ax_sp, add_cx_sp, add_dx_sp, add_bx_sp, add_sp_sp, add_bp_sp, add_si_sp, add_di_sp
	.global add_ax_bp, add_cx_bp, add_dx_bp, add_bx_bp, add_sp_bp, add_bp_bp, add_si_bp, add_di_bp
	.global add_ax_si, add_cx_si, add_dx_si, add_bx_si, add_sp_si, add_bp_si, add_si_si, add_di_si
	.global add_ax_di, add_cx_di, add_dx_di, add_bx_di, add_sp_di, add_bp_di, add_si_di, add_di_di
	.global	add_r0_r16_bp_r4, add_r0_r16_bp_r5, add_r0_r16_bp_r6, add_r0_r16_bp_r7, add_r0_r16_bp_r8, add_r0_r16_bp_r9, add_r0_r16_bp_r10, add_r0_r16_bp_r11, add_r0_r16_bp_r4
	.global	add_r0_r16_r4, add_r0_r16_r5, add_r0_r16_r6, add_r0_r16_r7, add_r0_r16_r8, add_r0_r16_r9, add_r0_r16_r10, add_r0_r16_r11, add_r0_r16_r4


.macro add_r0_r16_reg reg
add_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
add_r0_r16_\reg:
	//-------
	// Indexing by the current effective segment.
	//-------
	mem_handler_jump_r0r3 .op_01_RAM_\reg op_01_EGA_r2_\reg bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_01_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	lsl		r0, #16
	orr		r0, r1, lsl #24			// r0 = low byte | (high byte << 8)
	adds	r0, \reg, lsl #16		// r0 = [RAM] + reg
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		loop
.endm

	add_r0_r16_reg r4
	add_r0_r16_reg r5
	add_r0_r16_reg r6
	add_r0_r16_reg r7
	add_r0_r16_reg r8
	add_r0_r16_reg r9
	add_r0_r16_reg r10
	add_r0_r16_reg r11

	.ltorg

// --- [idx] ----

.macro add_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		add_r0_r16_\reg
.endm

add_bxsi_ax:
	add_bxidx_reg16 r10 r4
add_bxsi_cx:
	add_bxidx_reg16 r10 r5
add_bxsi_dx:
	add_bxidx_reg16 r10 r6
add_bxsi_bx:
	add_bxidx_reg16 r10 r7
add_bxsi_sp:
	add_bxidx_reg16 r10 r8
add_bxsi_bp:
	add_bxidx_reg16 r10 r9
add_bxsi_si:
	add_bxidx_reg16 r10 r10
add_bxsi_di:
	add_bxidx_reg16 r10 r11

add_bxdi_ax:
	add_bxidx_reg16 r11 r4
add_bxdi_cx:
	add_bxidx_reg16 r11 r5
add_bxdi_dx:
	add_bxidx_reg16 r11 r6
add_bxdi_bx:
	add_bxidx_reg16 r11 r7
add_bxdi_sp:
	add_bxidx_reg16 r11 r8
add_bxdi_bp:
	add_bxidx_reg16 r11 r9
add_bxdi_si:
	add_bxidx_reg16 r11 r10
add_bxdi_di:
	add_bxidx_reg16 r11 r11

.macro add_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		add_r0_r16_bp_\reg
.endm

add_bpsi_ax:
	add_bpidx_reg16 r10 r4
add_bpsi_cx:
	add_bpidx_reg16 r10 r5
add_bpsi_dx:
	add_bpidx_reg16 r10 r6
add_bpsi_bx:
	add_bpidx_reg16 r10 r7
add_bpsi_sp:
	add_bpidx_reg16 r10 r8
add_bpsi_bp:
	add_bpidx_reg16 r10 r9
add_bpsi_si:
	add_bpidx_reg16 r10 r10
add_bpsi_di:
	add_bpidx_reg16 r10 r11

add_bpdi_ax:
	add_bpidx_reg16 r11 r4
add_bpdi_cx:
	add_bpidx_reg16 r11 r5
add_bpdi_dx:
	add_bpidx_reg16 r11 r6
add_bpdi_bx:
	add_bpidx_reg16 r11 r7
add_bpdi_sp:
	add_bpidx_reg16 r11 r8
add_bpdi_bp:
	add_bpidx_reg16 r11 r9
add_bpdi_si:
	add_bpidx_reg16 r11 r10
add_bpdi_di:
	add_bpidx_reg16 r11 r11

.macro add_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		add_r0_r16_\reg
.endm

add_siidx_ax:
	add_idx_reg16 r10 r4
add_siidx_cx:
	add_idx_reg16 r10 r5
add_siidx_dx:
	add_idx_reg16 r10 r6
add_siidx_bx:
	add_idx_reg16 r10 r7
add_siidx_sp:
	add_idx_reg16 r10 r8
add_siidx_bp:
	add_idx_reg16 r10 r9
add_siidx_si:
	add_idx_reg16 r10 r10
add_siidx_di:
	add_idx_reg16 r10 r11

add_diidx_ax:
	add_idx_reg16 r11 r4
add_diidx_cx:
	add_idx_reg16 r11 r5
add_diidx_dx:
	add_idx_reg16 r11 r6
add_diidx_bx:
	add_idx_reg16 r11 r7
add_diidx_sp:
	add_idx_reg16 r11 r8
add_diidx_bp:
	add_idx_reg16 r11 r9
add_diidx_si:
	add_idx_reg16 r11 r10
add_diidx_di:
	add_idx_reg16 r11 r11

add_bxidx_ax:
	add_idx_reg16 r7 r4
add_bxidx_cx:
	add_idx_reg16 r7 r5
add_bxidx_dx:
	add_idx_reg16 r7 r6
add_bxidx_bx:
	add_idx_reg16 r7 r7
add_bxidx_sp:
	add_idx_reg16 r7 r8
add_bxidx_bp:
	add_idx_reg16 r7 r9
add_bxidx_si:
	add_idx_reg16 r7 r10
add_bxidx_di:
	add_idx_reg16 r7 r11
	
.macro add_disp16_reg16 reg
	r0_from_disp16
	b		add_r0_r16_\reg
.endm

add_disp16_ax:
	add_disp16_reg16 r4
add_disp16_cx:
	add_disp16_reg16 r5
add_disp16_dx:
	add_disp16_reg16 r6
add_disp16_bx:
	add_disp16_reg16 r7
add_disp16_sp:
	add_disp16_reg16 r8
add_disp16_bp:
	add_disp16_reg16 r9
add_disp16_si:
	add_disp16_reg16 r10
add_disp16_di:
	add_disp16_reg16 r11

// --- [idx+disp8] ----

.macro add_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		add_r0_r16_\reg
.endm

add_bxsid8_ax:
	add_bxidxd8_reg16 r10 r4
add_bxsid8_cx:
	add_bxidxd8_reg16 r10 r5
add_bxsid8_dx:
	add_bxidxd8_reg16 r10 r6
add_bxsid8_bx:
	add_bxidxd8_reg16 r10 r7
add_bxsid8_sp:
	add_bxidxd8_reg16 r10 r8
add_bxsid8_bp:
	add_bxidxd8_reg16 r10 r9
add_bxsid8_si:
	add_bxidxd8_reg16 r10 r10
add_bxsid8_di:
	add_bxidxd8_reg16 r10 r11

add_bxdid8_ax:
	add_bxidxd8_reg16 r11 r4
add_bxdid8_cx:
	add_bxidxd8_reg16 r11 r5
add_bxdid8_dx:
	add_bxidxd8_reg16 r11 r6
add_bxdid8_bx:
	add_bxidxd8_reg16 r11 r7
add_bxdid8_sp:
	add_bxidxd8_reg16 r11 r8
add_bxdid8_bp:
	add_bxidxd8_reg16 r11 r9
add_bxdid8_si:
	add_bxidxd8_reg16 r11 r10
add_bxdid8_di:
	add_bxidxd8_reg16 r11 r11

.macro add_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		add_r0_r16_bp_\reg
.endm

add_bpsid8_ax:
	add_bpidxd8_reg16 r10 r4
add_bpsid8_cx:
	add_bpidxd8_reg16 r10 r5
add_bpsid8_dx:
	add_bpidxd8_reg16 r10 r6
add_bpsid8_bx:
	add_bpidxd8_reg16 r10 r7
add_bpsid8_sp:
	add_bpidxd8_reg16 r10 r8
add_bpsid8_bp:
	add_bpidxd8_reg16 r10 r9
add_bpsid8_si:
	add_bpidxd8_reg16 r10 r10
add_bpsid8_di:
	add_bpidxd8_reg16 r10 r11

add_bpdid8_ax:
	add_bpidxd8_reg16 r11 r4
add_bpdid8_cx:
	add_bpidxd8_reg16 r11 r5
add_bpdid8_dx:
	add_bpidxd8_reg16 r11 r6
add_bpdid8_bx:
	add_bpidxd8_reg16 r11 r7
add_bpdid8_sp:
	add_bpidxd8_reg16 r11 r8
add_bpdid8_bp:
	add_bpidxd8_reg16 r11 r9
add_bpdid8_si:
	add_bpidxd8_reg16 r11 r10
add_bpdid8_di:
	add_bpidxd8_reg16 r11 r11

.macro add_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		add_r0_r16_\reg
.endm

add_sidisp8_ax:
	add_idxdisp8_reg16 r10 r4
add_sidisp8_cx:
	add_idxdisp8_reg16 r10 r5
add_sidisp8_dx:
	add_idxdisp8_reg16 r10 r6
add_sidisp8_bx:
	add_idxdisp8_reg16 r10 r7
add_sidisp8_sp:
	add_idxdisp8_reg16 r10 r8
add_sidisp8_bp:
	add_idxdisp8_reg16 r10 r9
add_sidisp8_si:
	add_idxdisp8_reg16 r10 r10
add_sidisp8_di:
	add_idxdisp8_reg16 r10 r11

add_didisp8_ax:
	add_idxdisp8_reg16 r11 r4
add_didisp8_cx:
	add_idxdisp8_reg16 r11 r5
add_didisp8_dx:
	add_idxdisp8_reg16 r11 r6
add_didisp8_bx:
	add_idxdisp8_reg16 r11 r7
add_didisp8_sp:
	add_idxdisp8_reg16 r11 r8
add_didisp8_bp:
	add_idxdisp8_reg16 r11 r9
add_didisp8_si:
	add_idxdisp8_reg16 r11 r10
add_didisp8_di:
	add_idxdisp8_reg16 r11 r11

add_bxdisp8_ax:
	add_idxdisp8_reg16 r7 r4
add_bxdisp8_cx:
	add_idxdisp8_reg16 r7 r5
add_bxdisp8_dx:
	add_idxdisp8_reg16 r7 r6
add_bxdisp8_bx:
	add_idxdisp8_reg16 r7 r7
add_bxdisp8_sp:
	add_idxdisp8_reg16 r7 r8
add_bxdisp8_bp:
	add_idxdisp8_reg16 r7 r9
add_bxdisp8_si:
	add_idxdisp8_reg16 r7 r10
add_bxdisp8_di:
	add_idxdisp8_reg16 r7 r11
	
.macro add_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		add_r0_r16_bp_\reg
.endm
	
add_bpdisp8_ax:
	add_bpdisp8_reg16 r4
add_bpdisp8_cx:
	add_bpdisp8_reg16 r5
add_bpdisp8_dx:
	add_bpdisp8_reg16 r6
add_bpdisp8_bx:
	add_bpdisp8_reg16 r7
add_bpdisp8_sp:
	add_bpdisp8_reg16 r8
add_bpdisp8_bp:
	add_bpdisp8_reg16 r9
add_bpdisp8_si:
	add_bpdisp8_reg16 r10
add_bpdisp8_di:
	add_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro add_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		add_r0_r16_\reg
.endm

add_bxsid16_ax:
	add_bxidxd16_reg16 r10 r4
add_bxsid16_cx:
	add_bxidxd16_reg16 r10 r5
add_bxsid16_dx:
	add_bxidxd16_reg16 r10 r6
add_bxsid16_bx:
	add_bxidxd16_reg16 r10 r7
add_bxsid16_sp:
	add_bxidxd16_reg16 r10 r8
add_bxsid16_bp:
	add_bxidxd16_reg16 r10 r9
add_bxsid16_si:
	add_bxidxd16_reg16 r10 r10
add_bxsid16_di:
	add_bxidxd16_reg16 r10 r11

add_bxdid16_ax:
	add_bxidxd16_reg16 r11 r4
add_bxdid16_cx:
	add_bxidxd16_reg16 r11 r5
add_bxdid16_dx:
	add_bxidxd16_reg16 r11 r6
add_bxdid16_bx:
	add_bxidxd16_reg16 r11 r7
add_bxdid16_sp:
	add_bxidxd16_reg16 r11 r8
add_bxdid16_bp:
	add_bxidxd16_reg16 r11 r9
add_bxdid16_si:
	add_bxidxd16_reg16 r11 r10
add_bxdid16_di:
	add_bxidxd16_reg16 r11 r11

.macro add_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		add_r0_r16_bp_\reg
.endm

add_bpsid16_ax:
	add_bpidxd16_reg16 r10 r4
add_bpsid16_cx:
	add_bpidxd16_reg16 r10 r5
add_bpsid16_dx:
	add_bpidxd16_reg16 r10 r6
add_bpsid16_bx:
	add_bpidxd16_reg16 r10 r7
add_bpsid16_sp:
	add_bpidxd16_reg16 r10 r8
add_bpsid16_bp:
	add_bpidxd16_reg16 r10 r9
add_bpsid16_si:
	add_bpidxd16_reg16 r10 r10
add_bpsid16_di:
	add_bpidxd16_reg16 r10 r11

add_bpdid16_ax:
	add_bpidxd16_reg16 r11 r4
add_bpdid16_cx:
	add_bpidxd16_reg16 r11 r5
add_bpdid16_dx:
	add_bpidxd16_reg16 r11 r6
add_bpdid16_bx:
	add_bpidxd16_reg16 r11 r7
add_bpdid16_sp:
	add_bpidxd16_reg16 r11 r8
add_bpdid16_bp:
	add_bpidxd16_reg16 r11 r9
add_bpdid16_si:
	add_bpidxd16_reg16 r11 r10
add_bpdid16_di:
	add_bpidxd16_reg16 r11 r11

.macro add_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		add_r0_r16_\reg
.endm

add_sidisp16_ax:
	add_idxdisp16_reg16 r10 r4
add_sidisp16_cx:
	add_idxdisp16_reg16 r10 r5
add_sidisp16_dx:
	add_idxdisp16_reg16 r10 r6
add_sidisp16_bx:
	add_idxdisp16_reg16 r10 r7
add_sidisp16_sp:
	add_idxdisp16_reg16 r10 r8
add_sidisp16_bp:
	add_idxdisp16_reg16 r10 r9
add_sidisp16_si:
	add_idxdisp16_reg16 r10 r10
add_sidisp16_di:
	add_idxdisp16_reg16 r10 r11

add_didisp16_ax:
	add_idxdisp16_reg16 r11 r4
add_didisp16_cx:
	add_idxdisp16_reg16 r11 r5
add_didisp16_dx:
	add_idxdisp16_reg16 r11 r6
add_didisp16_bx:
	add_idxdisp16_reg16 r11 r7
add_didisp16_sp:
	add_idxdisp16_reg16 r11 r8
add_didisp16_bp:
	add_idxdisp16_reg16 r11 r9
add_didisp16_si:
	add_idxdisp16_reg16 r11 r10
add_didisp16_di:
	add_idxdisp16_reg16 r11 r11

add_bxdisp16_ax:
	add_idxdisp16_reg16 r7 r4
add_bxdisp16_cx:
	add_idxdisp16_reg16 r7 r5
add_bxdisp16_dx:
	add_idxdisp16_reg16 r7 r6
add_bxdisp16_bx:
	add_idxdisp16_reg16 r7 r7
add_bxdisp16_sp:
	add_idxdisp16_reg16 r7 r8
add_bxdisp16_bp:
	add_idxdisp16_reg16 r7 r9
add_bxdisp16_si:
	add_idxdisp16_reg16 r7 r10
add_bxdisp16_di:
	add_idxdisp16_reg16 r7 r11

.macro add_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		add_r0_r16_bp_\reg
.endm

add_bpdisp16_ax:
	add_bpdisp16_reg16 r4
add_bpdisp16_cx:
	add_bpdisp16_reg16 r5
add_bpdisp16_dx:
	add_bpdisp16_reg16 r6
add_bpdisp16_bx:
	add_bpdisp16_reg16 r7
add_bpdisp16_sp:
	add_bpdisp16_reg16 r8
add_bpdisp16_bp:
	add_bpdisp16_reg16 r9
add_bpdisp16_si:
	add_bpdisp16_reg16 r10
add_bpdisp16_di:
	add_bpdisp16_reg16 r11


// ------------------- 02 = ADD r8, r/m8 -------------------------------
//
// All modrm variations supported!
//
//
op_02:
	modrm_jump_16
// 0
	.word add_al_bxsi, add_al_bxdi, add_al_bpsi, add_al_bpdi, add_al_siidx, add_al_diidx, add_al_disp16, add_al_bxidx
	.word add_cl_bxsi, add_cl_bxdi, add_cl_bpsi, add_cl_bpdi, add_cl_siidx, add_cl_diidx, add_cl_disp16, add_cl_bxidx
	.word add_dl_bxsi, add_dl_bxdi, add_dl_bpsi, add_dl_bpdi, add_dl_siidx, add_dl_diidx, add_dl_disp16, add_dl_bxidx
	.word add_bl_bxsi, add_bl_bxdi, add_bl_bpsi, add_bl_bpdi, add_bl_siidx, add_bl_diidx, add_bl_disp16, add_bl_bxidx
	.word add_ah_bxsi, add_ah_bxdi, add_ah_bpsi, add_ah_bpdi, add_ah_siidx, add_ah_diidx, add_ah_disp16, add_ah_bxidx
	.word add_ch_bxsi, add_ch_bxdi, add_ch_bpsi, add_ch_bpdi, add_ch_siidx, add_ch_diidx, add_ch_disp16, add_ch_bxidx
	.word add_dh_bxsi, add_dh_bxdi, add_dh_bpsi, add_dh_bpdi, add_dh_siidx, add_dh_diidx, add_dh_disp16, add_dh_bxidx
	.word add_bh_bxsi, add_bh_bxdi, add_bh_bpsi, add_bh_bpdi, add_bh_siidx, add_bh_diidx, add_bh_disp16, add_bh_bxidx
//0x40
	.word add_al_bxsid8, add_al_bxdid8, add_al_bpsid8, add_al_bpdid8, add_al_sidisp8, add_al_didisp8, add_al_bpdisp8, add_al_bxdisp8
	.word add_cl_bxsid8, add_cl_bxdid8, add_cl_bpsid8, add_cl_bpdid8, add_cl_sidisp8, add_cl_didisp8, add_cl_bpdisp8, add_cl_bxdisp8
	.word add_dl_bxsid8, add_dl_bxdid8, add_dl_bpsid8, add_dl_bpdid8, add_dl_sidisp8, add_dl_didisp8, add_dl_bpdisp8, add_dl_bxdisp8
	.word add_bl_bxsid8, add_bl_bxdid8, add_bl_bpsid8, add_bl_bpdid8, add_bl_sidisp8, add_bl_didisp8, add_bl_bpdisp8, add_bl_bxdisp8
	.word add_ah_bxsid8, add_ah_bxdid8, add_ah_bpsid8, add_ah_bpdid8, add_ah_sidisp8, add_ah_didisp8, add_ah_bpdisp8, add_ah_bxdisp8
	.word add_ch_bxsid8, add_ch_bxdid8, add_ch_bpsid8, add_ch_bpdid8, add_ch_sidisp8, add_ch_didisp8, add_ch_bpdisp8, add_ch_bxdisp8
	.word add_dh_bxsid8, add_dh_bxdid8, add_dh_bpsid8, add_dh_bpdid8, add_dh_sidisp8, add_dh_didisp8, add_dh_bpdisp8, add_dh_bxdisp8
	.word add_bh_bxsid8, add_bh_bxdid8, add_bh_bpsid8, add_bh_bpdid8, add_bh_sidisp8, add_bh_didisp8, add_bh_bpdisp8, add_bh_bxdisp8
//0x80
	.word add_al_bxsid16, add_al_bxdid16, add_al_bpsid16, add_al_bpdid16, add_al_sidisp16, add_al_didisp16, add_al_bpdisp16, add_al_bxdisp16
	.word add_cl_bxsid16, add_cl_bxdid16, add_cl_bpsid16, add_cl_bpdid16, add_cl_sidisp16, add_cl_didisp16, add_cl_bpdisp16, add_cl_bxdisp16
	.word add_dl_bxsid16, add_dl_bxdid16, add_dl_bpsid16, add_dl_bpdid16, add_dl_sidisp16, add_dl_didisp16, add_dl_bpdisp16, add_dl_bxdisp16
	.word add_bl_bxsid16, add_bl_bxdid16, add_bl_bpsid16, add_bl_bpdid16, add_bl_sidisp16, add_bl_didisp16, add_bl_bpdisp16, add_bl_bxdisp16
	.word add_ah_bxsid16, add_ah_bxdid16, add_ah_bpsid16, add_ah_bpdid16, add_ah_sidisp16, add_ah_didisp16, add_ah_bpdisp16, add_ah_bxdisp16
	.word add_ch_bxsid16, add_ch_bxdid16, add_ch_bpsid16, add_ch_bpdid16, add_ch_sidisp16, add_ch_didisp16, add_ch_bpdisp16, add_ch_bxdisp16
	.word add_dh_bxsid16, add_dh_bxdid16, add_dh_bpsid16, add_dh_bpdid16, add_dh_sidisp16, add_dh_didisp16, add_dh_bpdisp16, add_dh_bxdisp16
	.word add_bh_bxsid16, add_bh_bxdid16, add_bh_bpsid16, add_bh_bpdid16, add_bh_sidisp16, add_bh_didisp16, add_bh_bpdisp16, add_bh_bxdisp16
// 0xC0 = two register operands
	.word add_al_al, add_al_cl, add_al_dl, add_al_bl, add_al_ah, add_al_ch, add_al_dh, add_al_bh
	.word add_cl_al, add_cl_cl, add_cl_dl, add_cl_bl, add_cl_ah, add_cl_ch, add_cl_dh, add_cl_bh
	.word add_dl_al, add_dl_cl, add_dl_dl, add_dl_bl, add_dl_ah, add_dl_ch, add_dl_dh, add_dl_bh
	.word add_bl_al, add_bl_cl, add_bl_dl, add_bl_bl, add_bl_ah, add_bl_ch, add_bl_dh, add_bl_bh
	.word add_ah_al, add_ah_cl, add_ah_dl, add_ah_bl, add_ah_ah, add_ah_ch, add_ah_dh, add_ah_bh
	.word add_ch_al, add_ch_cl, add_ch_dl, add_ch_bl, add_ch_ah, add_ch_ch, add_ch_dh, add_ch_bh
	.word add_dh_al, add_dh_cl, add_dh_dl, add_dh_bl, add_dh_ah, add_dh_ch, add_dh_dh, add_dh_bh
	.word add_bh_al, add_bh_cl, add_bh_dl, add_bh_bl, add_bh_ah, add_bh_ch, add_bh_dh, add_bh_bh

// These are called from "cpu_386.s":

	.global add_al_siidx, add_cl_siidx, add_dl_siidx, add_bl_siidx, add_ah_siidx, add_ch_siidx, add_dh_siidx, add_bh_siidx
	.global add_al_diidx, add_cl_diidx, add_dl_diidx, add_bl_diidx, add_ah_diidx, add_ch_diidx, add_dh_diidx, add_bh_diidx
	.global add_al_bxidx, add_cl_bxidx, add_dl_bxidx, add_bl_bxidx, add_ah_bxidx, add_ch_bxidx, add_dh_bxidx, add_bh_bxidx
	.global add_al_sidisp8, add_al_didisp8, add_al_bpdisp8, add_al_bxdisp8
	.global add_cl_sidisp8, add_cl_didisp8, add_cl_bpdisp8, add_cl_bxdisp8
	.global add_dl_sidisp8, add_dl_didisp8, add_dl_bpdisp8, add_dl_bxdisp8
	.global add_bl_sidisp8, add_bl_didisp8, add_bl_bpdisp8, add_bl_bxdisp8
	.global add_ah_sidisp8, add_ah_didisp8, add_ah_bpdisp8, add_ah_bxdisp8
	.global add_ch_sidisp8, add_ch_didisp8, add_ch_bpdisp8, add_ch_bxdisp8
	.global add_dh_sidisp8, add_dh_didisp8, add_dh_bpdisp8, add_dh_bxdisp8
	.global add_bh_sidisp8, add_bh_didisp8, add_bh_bpdisp8, add_bh_bxdisp8
	.global add_al_al, add_cl_al, add_dl_al, add_bl_al, add_ah_al, add_ch_al, add_dh_al, add_bh_al
	.global add_al_cl, add_cl_cl, add_dl_cl, add_bl_cl, add_ah_cl, add_ch_cl, add_dh_cl, add_bh_cl
	.global add_al_dl, add_cl_dl, add_dl_dl, add_bl_dl, add_ah_dl, add_ch_dl, add_dh_dl, add_bh_dl
	.global add_al_bl, add_cl_bl, add_dl_bl, add_bl_bl, add_ah_bl, add_ch_bl, add_dh_bl, add_bh_bl
	.global add_al_ah, add_cl_ah, add_dl_ah, add_bl_ah, add_ah_ah, add_ch_ah, add_dh_ah, add_bh_ah
	.global add_al_ch, add_cl_ch, add_dl_ch, add_bl_ch, add_ah_ch, add_ch_ch, add_dh_ch, add_bh_ch
	.global add_al_dh, add_cl_dh, add_dl_dh, add_bl_dh, add_ah_dh, add_ch_dh, add_dh_dh, add_bh_dh
	.global add_al_bh, add_cl_bh, add_dl_bh, add_bl_bh, add_ah_bh, add_ch_bh, add_dh_bh, add_bh_bh

.macro add_reg8l_r0high reg
	.global	add_r8l_r0_bp_\reg
add_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	add_r8l_r0_\reg
add_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_02_RAM_l_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_02_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1,\reg, lsl #24
	adds	r1, r0, lsl #24			// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1, lsr #24		// Put the result to the lowest byte of the left register
	b		loop
.endm
.macro add_reg8h_r0high reg
	.global	add_r8h_r0_bp_\reg
add_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	add_r8h_r0_\reg
add_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_02_RAM_h_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_02_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r1, #16
	adds	r1, r0, lsl #24			// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsr #16
	b		loop
.endm

	add_reg8l_r0high r4
	add_reg8l_r0high r5
	add_reg8l_r0high r6
	add_reg8l_r0high r7
	add_reg8h_r0high r4
	add_reg8h_r0high r5
	add_reg8h_r0high r6
	add_reg8h_r0high r7

	.ltorg

// --- [idx] ---

.macro add_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		add_r8l_r0_\reg
.endm
.macro add_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		add_r8h_r0_\reg
.endm

add_al_bxsi:
	add_reg8l_bxidx r4 r10
add_cl_bxsi:
	add_reg8l_bxidx r5 r10
add_dl_bxsi:
	add_reg8l_bxidx r6 r10
add_bl_bxsi:
	add_reg8l_bxidx r7 r10
add_ah_bxsi:
	add_reg8h_bxidx r4 r10
add_ch_bxsi:
	add_reg8h_bxidx r5 r10
add_dh_bxsi:
	add_reg8h_bxidx r6 r10
add_bh_bxsi:
	add_reg8h_bxidx r7 r10

add_al_bxdi:
	add_reg8l_bxidx r4 r11
add_cl_bxdi:
	add_reg8l_bxidx r5 r11
add_dl_bxdi:
	add_reg8l_bxidx r6 r11
add_bl_bxdi:
	add_reg8l_bxidx r7 r11
add_ah_bxdi:
	add_reg8h_bxidx r4 r11
add_ch_bxdi:
	add_reg8h_bxidx r5 r11
add_dh_bxdi:
	add_reg8h_bxidx r6 r11
add_bh_bxdi:
	add_reg8h_bxidx r7 r11

.macro add_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		add_r8l_r0_bp_\reg
.endm
.macro add_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		add_r8h_r0_bp_\reg
.endm

add_al_bpsi:
	add_reg8l_bpidx r4 r10
add_cl_bpsi:
	add_reg8l_bpidx r5 r10
add_dl_bpsi:
	add_reg8l_bpidx r6 r10
add_bl_bpsi:
	add_reg8l_bpidx r7 r10
add_ah_bpsi:
	add_reg8h_bpidx r4 r10
add_ch_bpsi:
	add_reg8h_bpidx r5 r10
add_dh_bpsi:
	add_reg8h_bpidx r6 r10
add_bh_bpsi:
	add_reg8h_bpidx r7 r10

add_al_bpdi:
	add_reg8l_bpidx r4 r11
add_cl_bpdi:
	add_reg8l_bpidx r5 r11
add_dl_bpdi:
	add_reg8l_bpidx r6 r11
add_bl_bpdi:
	add_reg8l_bpidx r7 r11
add_ah_bpdi:
	add_reg8h_bpidx r4 r11
add_ch_bpdi:
	add_reg8h_bpidx r5 r11
add_dh_bpdi:
	add_reg8h_bpidx r6 r11
add_bh_bpdi:
	add_reg8h_bpidx r7 r11

.macro add_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		add_r8l_r0_\reg
.endm
.macro add_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		add_r8h_r0_\reg
.endm

add_al_siidx:
	add_reg8l_idx r4 r10
add_cl_siidx:
	add_reg8l_idx r5 r10
add_dl_siidx:
	add_reg8l_idx r6 r10
add_bl_siidx:
	add_reg8l_idx r7 r10
add_ah_siidx:
	add_reg8h_idx r4 r10
add_ch_siidx:
	add_reg8h_idx r5 r10
add_dh_siidx:
	add_reg8h_idx r6 r10
add_bh_siidx:
	add_reg8h_idx r7 r10

add_al_diidx:
	add_reg8l_idx r4 r11
add_cl_diidx:
	add_reg8l_idx r5 r11
add_dl_diidx:
	add_reg8l_idx r6 r11
add_bl_diidx:
	add_reg8l_idx r7 r11
add_ah_diidx:
	add_reg8h_idx r4 r11
add_ch_diidx:
	add_reg8h_idx r5 r11
add_dh_diidx:
	add_reg8h_idx r6 r11
add_bh_diidx:
	add_reg8h_idx r7 r11

add_al_bxidx:
	add_reg8l_idx r4 r7
add_cl_bxidx:
	add_reg8l_idx r5 r7
add_dl_bxidx:
	add_reg8l_idx r6 r7
add_bl_bxidx:
	add_reg8l_idx r7 r7
add_ah_bxidx:
	add_reg8h_idx r4 r7
add_ch_bxidx:
	add_reg8h_idx r5 r7
add_dh_bxidx:
	add_reg8h_idx r6 r7
add_bh_bxidx:
	add_reg8h_idx r7 r7

.macro add_reg8l_disp16 reg
	r0_from_disp16
	b		add_r8l_r0_\reg
.endm
.macro add_reg8h_disp16 reg
	r0_from_disp16
	b		add_r8h_r0_\reg
.endm

add_al_disp16:
	add_reg8l_disp16 r4
add_cl_disp16:
	add_reg8l_disp16 r5
add_dl_disp16:
	add_reg8l_disp16 r6
add_bl_disp16:
	add_reg8l_disp16 r7
add_ah_disp16:
	add_reg8h_disp16 r4
add_ch_disp16:
	add_reg8h_disp16 r5
add_dh_disp16:
	add_reg8h_disp16 r6
add_bh_disp16:
	add_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro add_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		add_r8l_r0_\reg
.endm
.macro add_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		add_r8h_r0_\reg
.endm

add_al_bxsid8:
	add_reg8l_bxidxd8 r4 r10
add_cl_bxsid8:
	add_reg8l_bxidxd8 r5 r10
add_dl_bxsid8:
	add_reg8l_bxidxd8 r6 r10
add_bl_bxsid8:
	add_reg8l_bxidxd8 r7 r10
add_ah_bxsid8:
	add_reg8h_bxidxd8 r4 r10
add_ch_bxsid8:
	add_reg8h_bxidxd8 r5 r10
add_dh_bxsid8:
	add_reg8h_bxidxd8 r6 r10
add_bh_bxsid8:
	add_reg8h_bxidxd8 r7 r10

add_al_bxdid8:
	add_reg8l_bxidxd8 r4 r11
add_cl_bxdid8:
	add_reg8l_bxidxd8 r5 r11
add_dl_bxdid8:
	add_reg8l_bxidxd8 r6 r11
add_bl_bxdid8:
	add_reg8l_bxidxd8 r7 r11
add_ah_bxdid8:
	add_reg8h_bxidxd8 r4 r11
add_ch_bxdid8:
	add_reg8h_bxidxd8 r5 r11
add_dh_bxdid8:
	add_reg8h_bxidxd8 r6 r11
add_bh_bxdid8:
	add_reg8h_bxidxd8 r7 r11

.macro add_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		add_r8l_r0_bp_\reg
.endm
.macro add_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		add_r8h_r0_bp_\reg
.endm

add_al_bpsid8:
	add_reg8l_bpidxd8 r4 r10
add_cl_bpsid8:
	add_reg8l_bpidxd8 r5 r10
add_dl_bpsid8:
	add_reg8l_bpidxd8 r6 r10
add_bl_bpsid8:
	add_reg8l_bpidxd8 r7 r10
add_ah_bpsid8:
	add_reg8h_bpidxd8 r4 r10
add_ch_bpsid8:
	add_reg8h_bpidxd8 r5 r10
add_dh_bpsid8:
	add_reg8h_bpidxd8 r6 r10
add_bh_bpsid8:
	add_reg8h_bpidxd8 r7 r10

add_al_bpdid8:
	add_reg8l_bpidxd8 r4 r11
add_cl_bpdid8:
	add_reg8l_bpidxd8 r5 r11
add_dl_bpdid8:
	add_reg8l_bpidxd8 r6 r11
add_bl_bpdid8:
	add_reg8l_bpidxd8 r7 r11
add_ah_bpdid8:
	add_reg8h_bpidxd8 r4 r11
add_ch_bpdid8:
	add_reg8h_bpidxd8 r5 r11
add_dh_bpdid8:
	add_reg8h_bpidxd8 r6 r11
add_bh_bpdid8:
	add_reg8h_bpidxd8 r7 r11

.macro add_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		add_r8l_r0_\reg
.endm
.macro add_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		add_r8h_r0_\reg
.endm

add_al_sidisp8:
	add_reg8l_idxdisp8 r4 r10
add_cl_sidisp8:
	add_reg8l_idxdisp8 r5 r10
add_dl_sidisp8:
	add_reg8l_idxdisp8 r6 r10
add_bl_sidisp8:
	add_reg8l_idxdisp8 r7 r10
add_ah_sidisp8:
	add_reg8h_idxdisp8 r4 r10
add_ch_sidisp8:
	add_reg8h_idxdisp8 r5 r10
add_dh_sidisp8:
	add_reg8h_idxdisp8 r6 r10
add_bh_sidisp8:
	add_reg8h_idxdisp8 r7 r10
	
add_al_didisp8:
	add_reg8l_idxdisp8 r4 r11
add_cl_didisp8:
	add_reg8l_idxdisp8 r5 r11
add_dl_didisp8:
	add_reg8l_idxdisp8 r6 r11
add_bl_didisp8:
	add_reg8l_idxdisp8 r7 r11
add_ah_didisp8:
	add_reg8h_idxdisp8 r4 r11
add_ch_didisp8:
	add_reg8h_idxdisp8 r5 r11
add_dh_didisp8:
	add_reg8h_idxdisp8 r6 r11
add_bh_didisp8:
	add_reg8h_idxdisp8 r7 r11

add_al_bxdisp8:
	add_reg8l_idxdisp8 r4 r7
add_cl_bxdisp8:
	add_reg8l_idxdisp8 r5 r7
add_dl_bxdisp8:
	add_reg8l_idxdisp8 r6 r7
add_bl_bxdisp8:
	add_reg8l_idxdisp8 r7 r7
add_ah_bxdisp8:
	add_reg8h_idxdisp8 r4 r7
add_ch_bxdisp8:
	add_reg8h_idxdisp8 r5 r7
add_dh_bxdisp8:
	add_reg8h_idxdisp8 r6 r7
add_bh_bxdisp8:
	add_reg8h_idxdisp8 r7 r7

.macro add_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		add_r8l_r0_bp_\reg
.endm
.macro add_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		add_r8h_r0_bp_\reg
.endm

add_al_bpdisp8:
	add_reg8l_bpdisp8 r4
add_cl_bpdisp8:
	add_reg8l_bpdisp8 r5
add_dl_bpdisp8:
	add_reg8l_bpdisp8 r6
add_bl_bpdisp8:
	add_reg8l_bpdisp8 r7
add_ah_bpdisp8:
	add_reg8h_bpdisp8 r4
add_ch_bpdisp8:
	add_reg8h_bpdisp8 r5
add_dh_bpdisp8:
	add_reg8h_bpdisp8 r6
add_bh_bpdisp8:
	add_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro add_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		add_r8l_r0_\reg
.endm
.macro add_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		add_r8h_r0_\reg
.endm

add_al_bxsid16:
	add_reg8l_bxidxd16 r4 r10
add_cl_bxsid16:
	add_reg8l_bxidxd16 r5 r10
add_dl_bxsid16:
	add_reg8l_bxidxd16 r6 r10
add_bl_bxsid16:
	add_reg8l_bxidxd16 r7 r10
add_ah_bxsid16:
	add_reg8h_bxidxd16 r4 r10
add_ch_bxsid16:
	add_reg8h_bxidxd16 r5 r10
add_dh_bxsid16:
	add_reg8h_bxidxd16 r6 r10
add_bh_bxsid16:
	add_reg8h_bxidxd16 r7 r10

add_al_bxdid16:
	add_reg8l_bxidxd16 r4 r11
add_cl_bxdid16:
	add_reg8l_bxidxd16 r5 r11
add_dl_bxdid16:
	add_reg8l_bxidxd16 r6 r11
add_bl_bxdid16:
	add_reg8l_bxidxd16 r7 r11
add_ah_bxdid16:
	add_reg8h_bxidxd16 r4 r11
add_ch_bxdid16:
	add_reg8h_bxidxd16 r5 r11
add_dh_bxdid16:
	add_reg8h_bxidxd16 r6 r11
add_bh_bxdid16:
	add_reg8h_bxidxd16 r7 r11

.macro add_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		add_r8l_r0_bp_\reg
.endm
.macro add_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		add_r8h_r0_bp_\reg
.endm

add_al_bpsid16:
	add_reg8l_bpidxd16 r4 r10
add_cl_bpsid16:
	add_reg8l_bpidxd16 r5 r10
add_dl_bpsid16:
	add_reg8l_bpidxd16 r6 r10
add_bl_bpsid16:
	add_reg8l_bpidxd16 r7 r10
add_ah_bpsid16:
	add_reg8h_bpidxd16 r4 r10
add_ch_bpsid16:
	add_reg8h_bpidxd16 r5 r10
add_dh_bpsid16:
	add_reg8h_bpidxd16 r6 r10
add_bh_bpsid16:
	add_reg8h_bpidxd16 r7 r10

add_al_bpdid16:
	add_reg8l_bpidxd16 r4 r11
add_cl_bpdid16:
	add_reg8l_bpidxd16 r5 r11
add_dl_bpdid16:
	add_reg8l_bpidxd16 r6 r11
add_bl_bpdid16:
	add_reg8l_bpidxd16 r7 r11
add_ah_bpdid16:
	add_reg8h_bpidxd16 r4 r11
add_ch_bpdid16:
	add_reg8h_bpidxd16 r5 r11
add_dh_bpdid16:
	add_reg8h_bpidxd16 r6 r11
add_bh_bpdid16:
	add_reg8h_bpidxd16 r7 r11

.macro add_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		add_r8l_r0_\reg
.endm
.macro add_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		add_r8h_r0_\reg
.endm

add_al_sidisp16:
	add_reg8l_idxdisp16 r4 r10
add_cl_sidisp16:
	add_reg8l_idxdisp16 r5 r10
add_dl_sidisp16:
	add_reg8l_idxdisp16 r6 r10
add_bl_sidisp16:
	add_reg8l_idxdisp16 r7 r10
add_ah_sidisp16:
	add_reg8h_idxdisp16 r4 r10
add_ch_sidisp16:
	add_reg8h_idxdisp16 r5 r10
add_dh_sidisp16:
	add_reg8h_idxdisp16 r6 r10
add_bh_sidisp16:
	add_reg8h_idxdisp16 r7 r10

add_al_didisp16:
	add_reg8l_idxdisp16 r4 r11
add_cl_didisp16:
	add_reg8l_idxdisp16 r5 r11
add_dl_didisp16:
	add_reg8l_idxdisp16 r6 r11
add_bl_didisp16:
	add_reg8l_idxdisp16 r7 r11
add_ah_didisp16:
	add_reg8h_idxdisp16 r4 r11
add_ch_didisp16:
	add_reg8h_idxdisp16 r5 r11
add_dh_didisp16:
	add_reg8h_idxdisp16 r6 r11
add_bh_didisp16:
	add_reg8h_idxdisp16 r7 r11

add_al_bxdisp16:
	add_reg8l_idxdisp16 r4 r7
add_cl_bxdisp16:
	add_reg8l_idxdisp16 r5 r7
add_dl_bxdisp16:
	add_reg8l_idxdisp16 r6 r7
add_bl_bxdisp16:
	add_reg8l_idxdisp16 r7 r7
add_ah_bxdisp16:
	add_reg8h_idxdisp16 r4 r7
add_ch_bxdisp16:
	add_reg8h_idxdisp16 r5 r7
add_dh_bxdisp16:
	add_reg8h_idxdisp16 r6 r7
add_bh_bxdisp16:
	add_reg8h_idxdisp16 r7 r7
	
.macro add_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		add_r8l_r0_bp_\reg
.endm
.macro add_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		add_r8h_r0_bp_\reg
.endm

add_al_bpdisp16:
	add_reg8l_bpdisp16 r4 
add_cl_bpdisp16:
	add_reg8l_bpdisp16 r5 
add_dl_bpdisp16:
	add_reg8l_bpdisp16 r6 
add_bl_bpdisp16:
	add_reg8l_bpdisp16 r7 
add_ah_bpdisp16:
	add_reg8h_bpdisp16 r4 
add_ch_bpdisp16:
	add_reg8h_bpdisp16 r5 
add_dh_bpdisp16:
	add_reg8h_bpdisp16 r6 
add_bh_bpdisp16:
	add_reg8h_bpdisp16 r7 


// --- Register operands ---

.macro add_reg8l_reg8l rl rr
	mov		r0,\rl, lsl #24
	adds	r0, \rr, lsl #24		// Perform the addition using the highest bytes to get the correct flags
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// Put the result to the lowest byte of the left register
	b		loop
.endm
.macro add_reg8l_reg8h rl rr
	and		r1, \rr, #0xFF00
	lsl		r1, #16
	adds	r0, r1, \rl, lsl #24	// Perform the addition using the highest bytes to get the correct flags
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// Put the result to the lowest byte of the left register
	b		loop
.endm
.macro add_reg8h_reg8l rl rr
	and		r0, \rl, #0xFF00
	lsl		r0, #16
	adds	r0, \rr, lsl #24		// Perform the addition using the highest bytes to get the correct flags
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16
	b		loop
.endm
.macro add_reg8h_reg8h rl rr
	and		r0, \rl, #0xFF00
	lsl		r0, #16
	and		r1, \rr, #0xFF00
	adds	r0, r1, lsl #16			// Perform the addition using the highest bytes to get the correct flags
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16
	b		loop
.endm

add_al_al:
	add_reg8l_reg8l r4 r4
add_al_cl:
	add_reg8l_reg8l r4 r5
add_al_dl:
	add_reg8l_reg8l r4 r6
add_al_bl:
	add_reg8l_reg8l r4 r7
add_al_ah:
	add_reg8l_reg8h r4 r4
add_al_ch:
	add_reg8l_reg8h r4 r5
add_al_dh:
	add_reg8l_reg8h r4 r6
add_al_bh:
	add_reg8l_reg8h r4 r7

add_cl_al:
	add_reg8l_reg8l r5 r4
add_cl_cl:
	add_reg8l_reg8l r5 r5
add_cl_dl:
	add_reg8l_reg8l r5 r6
add_cl_bl:
	add_reg8l_reg8l r5 r7
add_cl_ah:
	add_reg8l_reg8h r5 r4
add_cl_ch:
	add_reg8l_reg8h r5 r5
add_cl_dh:
	add_reg8l_reg8h r5 r6
add_cl_bh:
	add_reg8l_reg8h r5 r7

add_dl_al:
	add_reg8l_reg8l r6 r4
add_dl_cl:
	add_reg8l_reg8l r6 r5
add_dl_dl:
	add_reg8l_reg8l r6 r6
add_dl_bl:
	add_reg8l_reg8l r6 r7
add_dl_ah:
	add_reg8l_reg8h r6 r4
add_dl_ch:
	add_reg8l_reg8h r6 r5
add_dl_dh:
	add_reg8l_reg8h r6 r6
add_dl_bh:
	add_reg8l_reg8h r6 r7

add_bl_al:
	add_reg8l_reg8l r7 r4
add_bl_cl:
	add_reg8l_reg8l r7 r5
add_bl_dl:
	add_reg8l_reg8l r7 r6
add_bl_bl:
	add_reg8l_reg8l r7 r7
add_bl_ah:
	add_reg8l_reg8h r7 r4
add_bl_ch:
	add_reg8l_reg8h r7 r5
add_bl_dh:
	add_reg8l_reg8h r7 r6
add_bl_bh:
	add_reg8l_reg8h r7 r7

add_ah_al:
	add_reg8h_reg8l r4 r4
add_ah_cl:
	add_reg8h_reg8l r4 r5
add_ah_dl:
	add_reg8h_reg8l r4 r6
add_ah_bl:
	add_reg8h_reg8l r4 r7
add_ah_ah:
	add_reg8h_reg8h r4 r4
add_ah_ch:
	add_reg8h_reg8h r4 r5
add_ah_dh:
	add_reg8h_reg8h r4 r6
add_ah_bh:
	add_reg8h_reg8h r4 r7

add_ch_al:
	add_reg8h_reg8l r5 r4
add_ch_cl:
	add_reg8h_reg8l r5 r5
add_ch_dl:
	add_reg8h_reg8l r5 r6
add_ch_bl:
	add_reg8h_reg8l r5 r7
add_ch_ah:
	add_reg8h_reg8h r5 r4
add_ch_ch:
	add_reg8h_reg8h r5 r5
add_ch_dh:
	add_reg8h_reg8h r5 r6
add_ch_bh:
	add_reg8h_reg8h r5 r7

add_dh_al:
	add_reg8h_reg8l r6 r4
add_dh_cl:
	add_reg8h_reg8l r6 r5
add_dh_dl:
	add_reg8h_reg8l r6 r6
add_dh_bl:
	add_reg8h_reg8l r6 r7
add_dh_ah:
	add_reg8h_reg8h r6 r4
add_dh_ch:
	add_reg8h_reg8h r6 r5
add_dh_dh:
	add_reg8h_reg8h r6 r6
add_dh_bh:
	add_reg8h_reg8h r6 r7

add_bh_al:
	add_reg8h_reg8l r7 r4
add_bh_cl:
	add_reg8h_reg8l r7 r5
add_bh_dl:
	add_reg8h_reg8l r7 r6
add_bh_bl:
	add_reg8h_reg8l r7 r7
add_bh_ah:
	add_reg8h_reg8h r7 r4
add_bh_ch:
	add_reg8h_reg8h r7 r5
add_bh_dh:
	add_reg8h_reg8h r7 r6
add_bh_bh:
	add_reg8h_reg8h r7 r7

// ------------------- 03 = ADD r16, r/m16 ------------------------------
//
// All modrm variations supported!
//
//
op_03:
	modrm_jump_16
// 0
	.word add_ax_bxsi, add_ax_bxdi, add_ax_bpsi, add_ax_bpdi, add_ax_siidx, add_ax_diidx, add_ax_disp16, add_ax_bxidx
	.word add_cx_bxsi, add_cx_bxdi, add_cx_bpsi, add_cx_bpdi, add_cx_siidx, add_cx_diidx, add_cx_disp16, add_cx_bxidx
	.word add_dx_bxsi, add_dx_bxdi, add_dx_bpsi, add_dx_bpdi, add_dx_siidx, add_dx_diidx, add_dx_disp16, add_dx_bxidx
	.word add_bx_bxsi, add_bx_bxdi, add_bx_bpsi, add_bx_bpdi, add_bx_siidx, add_bx_diidx, add_bx_disp16, add_bx_bxidx
	.word add_sp_bxsi, add_sp_bxdi, add_sp_bpsi, add_sp_bpdi, add_sp_siidx, add_sp_diidx, add_sp_disp16, add_sp_bxidx
	.word add_bp_bxsi, add_bp_bxdi, add_bp_bpsi, add_bp_bpdi, add_bp_siidx, add_bp_diidx, add_bp_disp16, add_bp_bxidx
	.word add_si_bxsi, add_si_bxdi, add_si_bpsi, add_si_bpdi, add_si_siidx, add_si_diidx, add_si_disp16, add_si_bxidx
	.word add_di_bxsi, add_di_bxdi, add_di_bpsi, add_di_bpdi, add_di_siidx, add_di_diidx, add_di_disp16, add_di_bxidx
//0x40
	.word add_ax_bxsid8, add_ax_bxdid8, add_ax_bpsid8, add_ax_bpdid8, add_ax_sidisp8, add_ax_didisp8, add_ax_bpdisp8, add_ax_bxdisp8
	.word add_cx_bxsid8, add_cx_bxdid8, add_cx_bpsid8, add_cx_bpdid8, add_cx_sidisp8, add_cx_didisp8, add_cx_bpdisp8, add_cx_bxdisp8
	.word add_dx_bxsid8, add_dx_bxdid8, add_dx_bpsid8, add_dx_bpdid8, add_dx_sidisp8, add_dx_didisp8, add_dx_bpdisp8, add_dx_bxdisp8
	.word add_bx_bxsid8, add_bx_bxdid8, add_bx_bpsid8, add_bx_bpdid8, add_bx_sidisp8, add_bx_didisp8, add_bx_bpdisp8, add_bx_bxdisp8
	.word add_sp_bxsid8, add_sp_bxdid8, add_sp_bpsid8, add_sp_bpdid8, add_sp_sidisp8, add_sp_didisp8, add_sp_bpdisp8, add_sp_bxdisp8
	.word add_bp_bxsid8, add_bp_bxdid8, add_bp_bpsid8, add_bp_bpdid8, add_bp_sidisp8, add_bp_didisp8, add_bp_bpdisp8, add_bp_bxdisp8
	.word add_si_bxsid8, add_si_bxdid8, add_si_bpsid8, add_si_bpdid8, add_si_sidisp8, add_si_didisp8, add_si_bpdisp8, add_si_bxdisp8
	.word add_di_bxsid8, add_di_bxdid8, add_di_bpsid8, add_di_bpdid8, add_di_sidisp8, add_di_didisp8, add_di_bpdisp8, add_di_bxdisp8
//0x80
	.word add_ax_bxsid16, add_ax_bxdid16, add_ax_bpsid16, add_ax_bpdid16, add_ax_sidisp16, add_ax_didisp16, add_ax_bpdisp16, add_ax_bxdisp16
	.word add_cx_bxsid16, add_cx_bxdid16, add_cx_bpsid16, add_cx_bpdid16, add_cx_sidisp16, add_cx_didisp16, add_cx_bpdisp16, add_cx_bxdisp16
	.word add_dx_bxsid16, add_dx_bxdid16, add_dx_bpsid16, add_dx_bpdid16, add_dx_sidisp16, add_dx_didisp16, add_dx_bpdisp16, add_dx_bxdisp16
	.word add_bx_bxsid16, add_bx_bxdid16, add_bx_bpsid16, add_bx_bpdid16, add_bx_sidisp16, add_bx_didisp16, add_bx_bpdisp16, add_bx_bxdisp16
	.word add_sp_bxsid16, add_sp_bxdid16, add_sp_bpsid16, add_sp_bpdid16, add_sp_sidisp16, add_sp_didisp16, add_sp_bpdisp16, add_sp_bxdisp16
	.word add_bp_bxsid16, add_bp_bxdid16, add_bp_bpsid16, add_bp_bpdid16, add_bp_sidisp16, add_bp_didisp16, add_bp_bpdisp16, add_bp_bxdisp16
	.word add_si_bxsid16, add_si_bxdid16, add_si_bpsid16, add_si_bpdid16, add_si_sidisp16, add_si_didisp16, add_si_bpdisp16, add_si_bxdisp16
	.word add_di_bxsid16, add_di_bxdid16, add_di_bpsid16, add_di_bpdid16, add_di_sidisp16, add_di_didisp16, add_di_bpdisp16, add_di_bxdisp16
// 0xC0 = two register operands
	.word add_ax_ax, add_ax_cx, add_ax_dx, add_ax_bx, add_ax_sp, add_ax_bp, add_ax_si, add_ax_di
	.word add_cx_ax, add_cx_cx, add_cx_dx, add_cx_bx, add_cx_sp, add_cx_bp, add_cx_si, add_cx_di
	.word add_dx_ax, add_dx_cx, add_dx_dx, add_dx_bx, add_dx_sp, add_dx_bp, add_dx_si, add_dx_di
	.word add_bx_ax, add_bx_cx, add_bx_dx, add_bx_bx, add_bx_sp, add_bx_bp, add_bx_si, add_bx_di
	.word add_sp_ax, add_sp_cx, add_sp_dx, add_sp_bx, add_sp_sp, add_sp_bp, add_sp_si, add_sp_di
	.word add_bp_ax, add_bp_cx, add_bp_dx, add_bp_bx, add_bp_sp, add_bp_bp, add_bp_si, add_bp_di
	.word add_si_ax, add_si_cx, add_si_dx, add_si_bx, add_si_sp, add_si_bp, add_si_si, add_si_di
	.word add_di_ax, add_di_cx, add_di_dx, add_di_bx, add_di_sp, add_di_bp, add_di_si, add_di_di

// These are called from "cpu_67.s":

	.global add_ax_siidx, add_ax_diidx, add_ax_bxidx
	.global add_cx_siidx, add_cx_diidx, add_cx_bxidx
	.global add_dx_siidx, add_dx_diidx, add_dx_bxidx
	.global add_bx_siidx, add_bx_diidx, add_bx_bxidx
	.global add_sp_siidx, add_sp_diidx, add_sp_bxidx
	.global add_bp_siidx, add_bp_diidx, add_bp_bxidx
	.global add_si_siidx, add_si_diidx, add_si_bxidx
	.global add_di_siidx, add_di_diidx, add_di_bxidx
	.global add_ax_sidisp8, add_ax_didisp8, add_ax_bpdisp8, add_ax_bxdisp8
	.global add_cx_sidisp8, add_cx_didisp8, add_cx_bpdisp8, add_cx_bxdisp8
	.global add_dx_sidisp8, add_dx_didisp8, add_dx_bpdisp8, add_dx_bxdisp8
	.global add_bx_sidisp8, add_bx_didisp8, add_bx_bpdisp8, add_bx_bxdisp8
	.global add_sp_sidisp8, add_sp_didisp8, add_sp_bpdisp8, add_sp_bxdisp8
	.global add_bp_sidisp8, add_bp_didisp8, add_bp_bpdisp8, add_bp_bxdisp8
	.global add_si_sidisp8, add_si_didisp8, add_si_bpdisp8, add_si_bxdisp8
	.global add_di_sidisp8, add_di_didisp8, add_di_bpdisp8, add_di_bxdisp8
	.global	add_r16_r0_bp_r4, add_r16_r0_bp_r5, add_r16_r0_bp_r6, add_r16_r0_bp_r7, add_r16_r0_bp_r8, add_r16_r0_bp_r9, add_r16_r0_bp_r10, add_r16_r0_bp_r11
	.global	add_r16_r0_r4, add_r16_r0_r5, add_r16_r0_r6, add_r16_r0_r7, add_r16_r0_r8, add_r16_r0_r9, add_r16_r0_r10, add_r16_r0_r11

.macro add_reg16_r0high reg
add_r16_r0_bp_\reg:
	//-------
	// Indexing by BP register, so use SS unless a segment override is in effect.
	//-------
	mem_handler_bp
add_r16_r0_\reg:
	//-------
	// Indexing by the current effective segment.
	//-------
	mem_handler_jump_r0r3 .op_03_RAM_\reg op_03_EGA_\reg bad_MODEX_opcode
.op_03_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	adds	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

	add_reg16_r0high r4
	add_reg16_r0high r5
	add_reg16_r0high r6
	add_reg16_r0high r7
	add_reg16_r0high r8
	add_reg16_r0high r9
	add_reg16_r0high r10
	add_reg16_r0high r11

	.ltorg

// --- [idx] ---

.macro add_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		add_r16_r0_\reg
.endm

add_ax_bxsi:
	add_reg16_bxidx r4 r10
add_cx_bxsi:
	add_reg16_bxidx r5 r10
add_dx_bxsi:
	add_reg16_bxidx r6 r10
add_bx_bxsi:
	add_reg16_bxidx r7 r10
add_bp_bxsi:
	add_reg16_bxidx r9 r10
add_sp_bxsi:
	add_reg16_bxidx r8 r10
add_si_bxsi:
	add_reg16_bxidx r10 r10
add_di_bxsi:
	add_reg16_bxidx r11 r10

add_ax_bxdi:
	add_reg16_bxidx r4 r11
add_cx_bxdi:
	add_reg16_bxidx r5 r11
add_dx_bxdi:
	add_reg16_bxidx r6 r11
add_bx_bxdi:
	add_reg16_bxidx r7 r11
add_sp_bxdi:
	add_reg16_bxidx r8 r11
add_bp_bxdi:
	add_reg16_bxidx r9 r11
add_si_bxdi:
	add_reg16_bxidx r10 r11
add_di_bxdi:
	add_reg16_bxidx r11 r11

.macro add_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		add_r16_r0_bp_\reg
.endm

add_ax_bpsi:
	add_reg16_bpidx r4 r10
add_cx_bpsi:
	add_reg16_bpidx r5 r10
add_dx_bpsi:
	add_reg16_bpidx r6 r10
add_bx_bpsi:
	add_reg16_bpidx r7 r10
add_sp_bpsi:
	add_reg16_bpidx r8 r10
add_bp_bpsi:
	add_reg16_bpidx r9 r10
add_si_bpsi:
	add_reg16_bpidx r10 r10
add_di_bpsi:
	add_reg16_bpidx r11 r10

add_ax_bpdi:
	add_reg16_bpidx r4 r11
add_cx_bpdi:
	add_reg16_bpidx r5 r11
add_dx_bpdi:
	add_reg16_bpidx r6 r11
add_bx_bpdi:
	add_reg16_bpidx r7 r11
add_sp_bpdi:
	add_reg16_bpidx r8 r11
add_bp_bpdi:
	add_reg16_bpidx r9 r11
add_si_bpdi:
	add_reg16_bpidx r10 r11
add_di_bpdi:
	add_reg16_bpidx r11 r11

.macro add_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		add_r16_r0_\reg
.endm

add_ax_siidx:
	add_reg16_idx r4 r10
add_cx_siidx:
	add_reg16_idx r5 r10
add_dx_siidx:
	add_reg16_idx r6 r10
add_bx_siidx:
	add_reg16_idx r7 r10
add_sp_siidx:
	add_reg16_idx r8 r10
add_bp_siidx:
	add_reg16_idx r9 r10
add_si_siidx:
	add_reg16_idx r10 r10
add_di_siidx:
	add_reg16_idx r11 r10

add_ax_diidx:
	add_reg16_idx r4 r11
add_cx_diidx:
	add_reg16_idx r5 r11
add_dx_diidx:
	add_reg16_idx r6 r11
add_bx_diidx:
	add_reg16_idx r7 r11
add_sp_diidx:
	add_reg16_idx r8 r11
add_bp_diidx:
	add_reg16_idx r9 r11
add_si_diidx:
	add_reg16_idx r10 r11
add_di_diidx:
	add_reg16_idx r11 r11

add_ax_bxidx:
	add_reg16_idx r4 r7
add_cx_bxidx:
	add_reg16_idx r5 r7
add_dx_bxidx:
	add_reg16_idx r6 r7
add_bx_bxidx:
	add_reg16_idx r7 r7
add_sp_bxidx:
	add_reg16_idx r8 r7
add_bp_bxidx:
	add_reg16_idx r9 r7
add_si_bxidx:
	add_reg16_idx r10 r7
add_di_bxidx:
	add_reg16_idx r11 r7

.macro add_reg16_disp16 reg
	r0_from_disp16
	b		add_r16_r0_\reg
.endm

add_ax_disp16:
	add_reg16_disp16 r4
add_cx_disp16:
	add_reg16_disp16 r5
add_dx_disp16:
	add_reg16_disp16 r6
add_bx_disp16:
	add_reg16_disp16 r7
add_sp_disp16:
	add_reg16_disp16 r8
add_bp_disp16:
	add_reg16_disp16 r9
add_si_disp16:
	add_reg16_disp16 r10
add_di_disp16:
	add_reg16_disp16 r11

// --- [idx+disp8] ---

.macro add_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		add_r16_r0_\reg
.endm

add_ax_bxsid8:
	add_reg16_bxidxdisp8 r4 r10
add_cx_bxsid8:
	add_reg16_bxidxdisp8 r5 r10
add_dx_bxsid8:
	add_reg16_bxidxdisp8 r6 r10
add_bx_bxsid8:
	add_reg16_bxidxdisp8 r7 r10
add_sp_bxsid8:
	add_reg16_bxidxdisp8 r8 r10
add_bp_bxsid8:
	add_reg16_bxidxdisp8 r9 r10
add_si_bxsid8:
	add_reg16_bxidxdisp8 r10 r10
add_di_bxsid8:
	add_reg16_bxidxdisp8 r11 r10

add_ax_bxdid8:
	add_reg16_bxidxdisp8 r4 r11
add_cx_bxdid8:
	add_reg16_bxidxdisp8 r5 r11
add_dx_bxdid8:
	add_reg16_bxidxdisp8 r6 r11
add_bx_bxdid8:
	add_reg16_bxidxdisp8 r7 r11
add_sp_bxdid8:
	add_reg16_bxidxdisp8 r8 r11
add_bp_bxdid8:
	add_reg16_bxidxdisp8 r9 r11
add_si_bxdid8:
	add_reg16_bxidxdisp8 r10 r11
add_di_bxdid8:
	add_reg16_bxidxdisp8 r11 r11

.macro add_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		add_r16_r0_bp_\reg
.endm

add_ax_bpsid8:
	add_reg16_bpidxdisp8 r4 r10
add_cx_bpsid8:
	add_reg16_bpidxdisp8 r5 r10
add_dx_bpsid8:
	add_reg16_bpidxdisp8 r6 r10
add_bx_bpsid8:
	add_reg16_bpidxdisp8 r7 r10
add_sp_bpsid8:
	add_reg16_bpidxdisp8 r8 r10
add_bp_bpsid8:
	add_reg16_bpidxdisp8 r9 r10
add_si_bpsid8:
	add_reg16_bpidxdisp8 r10 r10
add_di_bpsid8:
	add_reg16_bpidxdisp8 r11 r10

add_ax_bpdid8:
	add_reg16_bpidxdisp8 r4 r11
add_cx_bpdid8:
	add_reg16_bpidxdisp8 r5 r11
add_dx_bpdid8:
	add_reg16_bpidxdisp8 r6 r11
add_bx_bpdid8:
	add_reg16_bpidxdisp8 r7 r11
add_sp_bpdid8:
	add_reg16_bpidxdisp8 r8 r11
add_bp_bpdid8:
	add_reg16_bpidxdisp8 r9 r11
add_si_bpdid8:
	add_reg16_bpidxdisp8 r10 r11
add_di_bpdid8:
	add_reg16_bpidxdisp8 r11 r11

.macro add_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		add_r16_r0_\reg
.endm

add_ax_sidisp8:
	add_reg16_idxdisp8 r4 r10
add_cx_sidisp8:
	add_reg16_idxdisp8 r5 r10
add_dx_sidisp8:
	add_reg16_idxdisp8 r6 r10
add_bx_sidisp8:
	add_reg16_idxdisp8 r7 r10
add_sp_sidisp8:
	add_reg16_idxdisp8 r8 r10
add_bp_sidisp8:
	add_reg16_idxdisp8 r9 r10
add_si_sidisp8:
	add_reg16_idxdisp8 r10 r10
add_di_sidisp8:
	add_reg16_idxdisp8 r11 r10

add_ax_didisp8:
	add_reg16_idxdisp8 r4 r11
add_cx_didisp8:
	add_reg16_idxdisp8 r5 r11
add_dx_didisp8:
	add_reg16_idxdisp8 r6 r11
add_bx_didisp8:
	add_reg16_idxdisp8 r7 r11
add_sp_didisp8:
	add_reg16_idxdisp8 r8 r11
add_bp_didisp8:
	add_reg16_idxdisp8 r9 r11
add_si_didisp8:
	add_reg16_idxdisp8 r10 r11
add_di_didisp8:
	add_reg16_idxdisp8 r11 r11

add_ax_bxdisp8:
	add_reg16_idxdisp8 r4 r7
add_cx_bxdisp8:
	add_reg16_idxdisp8 r5 r7
add_dx_bxdisp8:
	add_reg16_idxdisp8 r6 r7
add_bx_bxdisp8:
	add_reg16_idxdisp8 r7 r7
add_sp_bxdisp8:
	add_reg16_idxdisp8 r8 r7
add_bp_bxdisp8:
	add_reg16_idxdisp8 r9 r7
add_si_bxdisp8:
	add_reg16_idxdisp8 r10 r7
add_di_bxdisp8:
	add_reg16_idxdisp8 r11 r7

.macro add_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		add_r16_r0_bp_\reg
.endm

add_ax_bpdisp8:
	add_reg16_bpdisp8 r4
add_cx_bpdisp8:
	add_reg16_bpdisp8 r5
add_dx_bpdisp8:
	add_reg16_bpdisp8 r6
add_bx_bpdisp8:
	add_reg16_bpdisp8 r7
add_sp_bpdisp8:
	add_reg16_bpdisp8 r8
add_bp_bpdisp8:
	add_reg16_bpdisp8 r9
add_si_bpdisp8:
	add_reg16_bpdisp8 r10
add_di_bpdisp8:
	add_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro add_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		add_r16_r0_\reg
.endm

add_ax_bxsid16:
	add_reg16_bxidxdisp16 r4 r10
add_cx_bxsid16:
	add_reg16_bxidxdisp16 r5 r10
add_dx_bxsid16:
	add_reg16_bxidxdisp16 r6 r10
add_bx_bxsid16:
	add_reg16_bxidxdisp16 r7 r10
add_sp_bxsid16:
	add_reg16_bxidxdisp16 r8 r10
add_bp_bxsid16:
	add_reg16_bxidxdisp16 r9 r10
add_si_bxsid16:
	add_reg16_bxidxdisp16 r10 r10
add_di_bxsid16:
	add_reg16_bxidxdisp16 r11 r10

add_ax_bxdid16:
	add_reg16_bxidxdisp16 r4 r11
add_cx_bxdid16:
	add_reg16_bxidxdisp16 r5 r11
add_dx_bxdid16:
	add_reg16_bxidxdisp16 r6 r11
add_bx_bxdid16:
	add_reg16_bxidxdisp16 r7 r11
add_sp_bxdid16:
	add_reg16_bxidxdisp16 r8 r11
add_bp_bxdid16:
	add_reg16_bxidxdisp16 r9 r11
add_si_bxdid16:
	add_reg16_bxidxdisp16 r10 r11
add_di_bxdid16:
	add_reg16_bxidxdisp16 r11 r11

.macro add_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		add_r16_r0_bp_\reg
.endm

add_ax_bpsid16:
	add_reg16_bpidxdisp16 r4 r10
add_cx_bpsid16:
	add_reg16_bpidxdisp16 r5 r10
add_dx_bpsid16:
	add_reg16_bpidxdisp16 r6 r10
add_bx_bpsid16:
	add_reg16_bpidxdisp16 r7 r10
add_sp_bpsid16:
	add_reg16_bpidxdisp16 r8 r10
add_bp_bpsid16:
	add_reg16_bpidxdisp16 r9 r10
add_si_bpsid16:
	add_reg16_bpidxdisp16 r10 r10
add_di_bpsid16:
	add_reg16_bpidxdisp16 r11 r10

add_ax_bpdid16:
	add_reg16_bpidxdisp16 r4 r11
add_cx_bpdid16:
	add_reg16_bpidxdisp16 r5 r11
add_dx_bpdid16:
	add_reg16_bpidxdisp16 r6 r11
add_bx_bpdid16:
	add_reg16_bpidxdisp16 r7 r11
add_sp_bpdid16:
	add_reg16_bpidxdisp16 r8 r11
add_bp_bpdid16:
	add_reg16_bpidxdisp16 r9 r11
add_si_bpdid16:
	add_reg16_bpidxdisp16 r10 r11
add_di_bpdid16:
	add_reg16_bpidxdisp16 r11 r11

.macro add_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		add_r16_r0_\reg
.endm

add_ax_sidisp16:
	add_reg16_idxdisp16 r4 r10
add_cx_sidisp16:
	add_reg16_idxdisp16 r5 r10
add_dx_sidisp16:
	add_reg16_idxdisp16 r6 r10
add_bx_sidisp16:
	add_reg16_idxdisp16 r7 r10
add_sp_sidisp16:
	add_reg16_idxdisp16 r8 r10
add_bp_sidisp16:
	add_reg16_idxdisp16 r9 r10
add_si_sidisp16:
	add_reg16_idxdisp16 r10 r10
add_di_sidisp16:
	add_reg16_idxdisp16 r11 r10

add_ax_didisp16:
	add_reg16_idxdisp16 r4 r11
add_cx_didisp16:
	add_reg16_idxdisp16 r5 r11
add_dx_didisp16:
	add_reg16_idxdisp16 r6 r11
add_bx_didisp16:
	add_reg16_idxdisp16 r7 r11
add_sp_didisp16:
	add_reg16_idxdisp16 r8 r11
add_bp_didisp16:
	add_reg16_idxdisp16 r9 r11
add_si_didisp16:
	add_reg16_idxdisp16 r10 r11
add_di_didisp16:
	add_reg16_idxdisp16 r11 r11

add_ax_bxdisp16:
	add_reg16_idxdisp16 r4 r7
add_cx_bxdisp16:
	add_reg16_idxdisp16 r5 r7
add_dx_bxdisp16:
	add_reg16_idxdisp16 r6 r7
add_bx_bxdisp16:
	add_reg16_idxdisp16 r7 r7
add_sp_bxdisp16:
	add_reg16_idxdisp16 r8 r7
add_bp_bxdisp16:
	add_reg16_idxdisp16 r9 r7
add_si_bxdisp16:
	add_reg16_idxdisp16 r10 r7
add_di_bxdisp16:
	add_reg16_idxdisp16 r11 r7

.macro add_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		add_r16_r0_bp_\reg
.endm

add_ax_bpdisp16:
	add_reg16_bpdisp16 r4
add_cx_bpdisp16:
	add_reg16_bpdisp16 r5
add_dx_bpdisp16:
	add_reg16_bpdisp16 r6
add_bx_bpdisp16:
	add_reg16_bpdisp16 r7
add_sp_bpdisp16:
	add_reg16_bpdisp16 r8
add_bp_bpdisp16:
	add_reg16_bpdisp16 r9
add_si_bpdisp16:
	add_reg16_bpdisp16 r10
add_di_bpdisp16:
	add_reg16_bpdisp16 r11


// --- registers ---

.macro add_reg16_reg16 rl rr
	mov		r1, \rl, lsl #16					// Put the 16-bit register value to high halfword of r1
	adds	r0, r1, \rr, lsl #16				// Perform the operation, put result to r0
	eor		\rl, r1, lsr #16					// Clear the left 16-bit register value
	orr		\rl, r0, lsr #16					// Put the result into the left 16-bit register.
	b		loop
.endm

add_ax_ax:
shl_reg16_1_r4:
	add_reg16_reg16		r4 r4
add_ax_cx:
	add_reg16_reg16		r4 r5
add_ax_dx:
	add_reg16_reg16		r4 r6
add_ax_bx:
	add_reg16_reg16		r4 r7
add_ax_sp:
	add_reg16_reg16		r4 r8
add_ax_bp:
	add_reg16_reg16		r4 r9
add_ax_si:
	add_reg16_reg16		r4 r10
add_ax_di:
	add_reg16_reg16		r4 r11
add_cx_ax:
	add_reg16_reg16		r5 r4
add_cx_cx:
shl_reg16_1_r5:
	add_reg16_reg16		r5 r5
add_cx_dx:
	add_reg16_reg16		r5 r6
add_cx_bx:
	add_reg16_reg16		r5 r7
add_cx_sp:
	add_reg16_reg16		r5 r8
add_cx_bp:
	add_reg16_reg16		r5 r9
add_cx_si:
	add_reg16_reg16		r5 r10
add_cx_di:
	add_reg16_reg16		r5 r11
add_dx_ax:
	add_reg16_reg16		r6 r4
add_dx_cx:
	add_reg16_reg16		r6 r5
add_dx_dx:
shl_reg16_1_r6:
	add_reg16_reg16		r6 r6
add_dx_bx:
	add_reg16_reg16		r6 r7
add_dx_sp:
	add_reg16_reg16		r6 r8
add_dx_bp:
	add_reg16_reg16		r6 r9
add_dx_si:
	add_reg16_reg16		r6 r10
add_dx_di:
	add_reg16_reg16		r6 r11
add_bx_ax:
	add_reg16_reg16		r7 r4
add_bx_cx:
	add_reg16_reg16		r7 r5
add_bx_dx:
	add_reg16_reg16		r7 r6
add_bx_bx:
shl_reg16_1_r7:
	add_reg16_reg16		r7 r7
add_bx_sp:
	add_reg16_reg16		r7 r8
add_bx_bp:
	add_reg16_reg16		r7 r9
add_bx_si:
	add_reg16_reg16		r7 r10
add_bx_di:
	add_reg16_reg16		r7 r11
add_sp_ax:
	add_reg16_reg16		r8 r4
add_sp_cx:
	add_reg16_reg16		r8 r5
add_sp_dx:
	add_reg16_reg16		r8 r6
add_sp_bx:
	add_reg16_reg16		r8 r7
add_sp_sp:
shl_reg16_1_r8:
	add_reg16_reg16		r8 r8
add_sp_bp:
	add_reg16_reg16		r8 r9
add_sp_si:
	add_reg16_reg16		r8 r10
add_sp_di:
	add_reg16_reg16		r8 r11
add_bp_ax:
	add_reg16_reg16		r9 r4
add_bp_cx:
	add_reg16_reg16		r9 r5
add_bp_dx:
	add_reg16_reg16		r9 r6
add_bp_bx:
	add_reg16_reg16		r9 r7
add_bp_sp:
	add_reg16_reg16		r9 r8
add_bp_bp:
shl_reg16_1_r9:
	add_reg16_reg16		r9 r9
add_bp_si:
	add_reg16_reg16		r9 r10
add_bp_di:
	add_reg16_reg16		r9 r11
add_si_ax:
	add_reg16_reg16		r10 r4
add_si_cx:
	add_reg16_reg16		r10 r5
add_si_dx:
	add_reg16_reg16		r10 r6
add_si_bx:
	add_reg16_reg16		r10 r7
add_si_sp:
	add_reg16_reg16		r10 r8
add_si_bp:
	add_reg16_reg16		r10 r9
add_si_si:
shl_reg16_1_r10:
	add_reg16_reg16		r10 r10
add_si_di:
	add_reg16_reg16		r10 r11
add_di_ax:
	add_reg16_reg16		r11 r4
add_di_cx:
	add_reg16_reg16		r11 r5
add_di_dx:
	add_reg16_reg16		r11 r6
add_di_bx:
	add_reg16_reg16		r11 r7
add_di_sp:
	add_reg16_reg16		r11 r8
add_di_bp:
	add_reg16_reg16		r11 r9
add_di_si:
	add_reg16_reg16		r11 r10
add_di_di:
shl_reg16_1_r11:
	add_reg16_reg16		r11 r11


// ------------------- 04 = ADD AL,imm8 --------------------------------
op_04:
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r1, eax, lsl #24
	adds	r1, r0, lsl #24
	bic		eax, #0xFF
	orr		eax, r1, lsr #24
	b		loop
	
// ------------------- 05 = ADD AX,imm16 -------------------------------
op_05:
	ldrb	r1,[r12],#1				// Load byte to r1, increment r12 by 1
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r2, eax, lsl #16
	eor		eax, r2, lsr #16
	orr		r1, r0, lsl #8			// r1 = low byte | (high byte << 8)
	adds	r0, r2, r1, lsl #16
	orr		eax, r0, lsr #16
	b		loop

// ------------------- 06 = PUSH ES ------------------------------------
op_06:
	ldr		r1, [sp, #SP_ES_VALUE]	
	push_hword r1 r0 r2
	b		loop

// ------------------- 07 = POP ES -------------------------------------
// Profiler: 4027, 18, 51.37, 206885, 0.1%
//
op_07:
	pop_reg_low_tmp r2 r1
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]				// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr							// Save current flags to r0
	tst		r3, #1								// Are we in protected mode (or in VM mode)?
	bne		mov_es_r0r2_prot					// Yes we are, go handle protected mode version!
	//-------
	// We are in real mode, so use the simple handling.
	//-------
	mov		r1, r2, lsl #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_ES_VALUE]
	str		r1, [sp, #SP_ES_BASE]
	b		restore_flags_from_r0				// Go back to the opcode loop, restoring flags

.ltorg								// Dump the current literal pool here


	.text
	.align	2

// ------------------- 08 = OR r/m8,r8 -------------------------------
//
// All modrm variations supported!
//
//
	.global	op_08
op_08:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word or_bxsi_al, or_bxdi_al, or_bpsi_al, or_bpdi_al, or_siidx_al, or_diidx_al, or_disp16_al, or_bxidx_al
	.word or_bxsi_cl, or_bxdi_cl, or_bpsi_cl, or_bpdi_cl, or_siidx_cl, or_diidx_cl, or_disp16_cl, or_bxidx_cl
	.word or_bxsi_dl, or_bxdi_dl, or_bpsi_dl, or_bpdi_dl, or_siidx_dl, or_diidx_dl, or_disp16_dl, or_bxidx_dl
	.word or_bxsi_bl, or_bxdi_bl, or_bpsi_bl, or_bpdi_bl, or_siidx_bl, or_diidx_bl, or_disp16_bl, or_bxidx_bl
	.word or_bxsi_ah, or_bxdi_ah, or_bpsi_ah, or_bpdi_ah, or_siidx_ah, or_diidx_ah, or_disp16_ah, or_bxidx_ah
	.word or_bxsi_ch, or_bxdi_ch, or_bpsi_ch, or_bpdi_ch, or_siidx_ch, or_diidx_ch, or_disp16_ch, or_bxidx_ch
	.word or_bxsi_dh, or_bxdi_dh, or_bpsi_dh, or_bpdi_dh, or_siidx_dh, or_diidx_dh, or_disp16_dh, or_bxidx_dh
	.word or_bxsi_bh, or_bxdi_bh, or_bpsi_bh, or_bpdi_bh, or_siidx_bh, or_diidx_bh, or_disp16_bh, or_bxidx_bh
//0x40
	.word or_bxsid8_al, or_bxdid8_al, or_bpsid8_al, or_bpdid8_al, or_sidisp8_al, or_didisp8_al, or_bpdisp8_al, or_bxdisp8_al
	.word or_bxsid8_cl, or_bxdid8_cl, or_bpsid8_cl, or_bpdid8_cl, or_sidisp8_cl, or_didisp8_cl, or_bpdisp8_cl, or_bxdisp8_cl
	.word or_bxsid8_dl, or_bxdid8_dl, or_bpsid8_dl, or_bpdid8_dl, or_sidisp8_dl, or_didisp8_dl, or_bpdisp8_dl, or_bxdisp8_dl
	.word or_bxsid8_bl, or_bxdid8_bl, or_bpsid8_bl, or_bpdid8_bl, or_sidisp8_bl, or_didisp8_bl, or_bpdisp8_bl, or_bxdisp8_bl
	.word or_bxsid8_ah, or_bxdid8_ah, or_bpsid8_ah, or_bpdid8_ah, or_sidisp8_ah, or_didisp8_ah, or_bpdisp8_ah, or_bxdisp8_ah
	.word or_bxsid8_ch, or_bxdid8_ch, or_bpsid8_ch, or_bpdid8_ch, or_sidisp8_ch, or_didisp8_ch, or_bpdisp8_ch, or_bxdisp8_ch
	.word or_bxsid8_dh, or_bxdid8_dh, or_bpsid8_dh, or_bpdid8_dh, or_sidisp8_dh, or_didisp8_dh, or_bpdisp8_dh, or_bxdisp8_dh
	.word or_bxsid8_bh, or_bxdid8_bh, or_bpsid8_bh, or_bpdid8_bh, or_sidisp8_bh, or_didisp8_bh, or_bpdisp8_bh, or_bxdisp8_bh
//0x80
	.word or_bxsid16_al, or_bxdid16_al, or_bpsid16_al, or_bpdid16_al, or_sidisp16_al, or_didisp16_al, or_bpdisp16_al, or_bxdisp16_al
	.word or_bxsid16_cl, or_bxdid16_cl, or_bpsid16_cl, or_bpdid16_cl, or_sidisp16_cl, or_didisp16_cl, or_bpdisp16_cl, or_bxdisp16_cl
	.word or_bxsid16_dl, or_bxdid16_dl, or_bpsid16_dl, or_bpdid16_dl, or_sidisp16_dl, or_didisp16_dl, or_bpdisp16_dl, or_bxdisp16_dl
	.word or_bxsid16_bl, or_bxdid16_bl, or_bpsid16_bl, or_bpdid16_bl, or_sidisp16_bl, or_didisp16_bl, or_bpdisp16_bl, or_bxdisp16_bl
	.word or_bxsid16_ah, or_bxdid16_ah, or_bpsid16_ah, or_bpdid16_ah, or_sidisp16_ah, or_didisp16_ah, or_bpdisp16_ah, or_bxdisp16_ah
	.word or_bxsid16_ch, or_bxdid16_ch, or_bpsid16_ch, or_bpdid16_ch, or_sidisp16_ch, or_didisp16_ch, or_bpdisp16_ch, or_bxdisp16_ch
	.word or_bxsid16_dh, or_bxdid16_dh, or_bpsid16_dh, or_bpdid16_dh, or_sidisp16_dh, or_didisp16_dh, or_bpdisp16_dh, or_bxdisp16_dh
	.word or_bxsid16_bh, or_bxdid16_bh, or_bpsid16_bh, or_bpdid16_bh, or_sidisp16_bh, or_didisp16_bh, or_bpdisp16_bh, or_bxdisp16_bh
// 0xC0 = two register operands
	.word or_al_al, or_cl_al, or_dl_al, or_bl_al, or_ah_al, or_ch_al, or_dh_al, or_bh_al
	.word or_al_cl, or_cl_cl, or_dl_cl, or_bl_cl, or_ah_cl, or_ch_cl, or_dh_cl, or_bh_cl
	.word or_al_dl, or_cl_dl, or_dl_dl, or_bl_dl, or_ah_dl, or_ch_dl, or_dh_dl, or_bh_dl
	.word or_al_bl, or_cl_bl, or_dl_bl, or_bl_bl, or_ah_bl, or_ch_bl, or_dh_bl, or_bh_bl
	.word or_al_ah, or_cl_ah, or_dl_ah, or_bl_ah, or_ah_ah, or_ch_ah, or_dh_ah, or_bh_ah
	.word or_al_ch, or_cl_ch, or_dl_ch, or_bl_ch, or_ah_ch, or_ch_ch, or_dh_ch, or_bh_ch
	.word or_al_dh, or_cl_dh, or_dl_dh, or_bl_dh, or_ah_dh, or_ch_dh, or_dh_dh, or_bh_dh
	.word or_al_bh, or_cl_bh, or_dl_bh, or_bl_bh, or_ah_bh, or_ch_bh, or_dh_bh, or_bh_bh

// These are called from "cpu_386.s":

	.global	or_siidx_al, or_siidx_cl, or_siidx_dl, or_siidx_bl, or_siidx_ah, or_siidx_ch, or_siidx_dh, or_siidx_bh
	.global	or_diidx_al, or_diidx_cl, or_diidx_dl, or_diidx_bl, or_diidx_ah, or_diidx_ch, or_diidx_dh, or_diidx_bh
	.global	or_bxidx_al, or_bxidx_cl, or_bxidx_dl, or_bxidx_bl, or_bxidx_ah, or_bxidx_ch, or_bxidx_dh, or_bxidx_bh
	.global	or_sidisp8_al, or_sidisp8_cl, or_sidisp8_dl, or_sidisp8_bl, or_sidisp8_ah, or_sidisp8_ch, or_sidisp8_dh, or_sidisp8_bh
	.global	or_didisp8_al, or_didisp8_cl, or_didisp8_dl, or_didisp8_bl, or_didisp8_ah, or_didisp8_ch, or_didisp8_dh, or_didisp8_bh
	.global	or_bpdisp8_al, or_bpdisp8_cl, or_bpdisp8_dl, or_bpdisp8_bl, or_bpdisp8_ah, or_bpdisp8_ch, or_bpdisp8_dh, or_bpdisp8_bh
	.global	or_bxdisp8_al, or_bxdisp8_cl, or_bxdisp8_dl, or_bxdisp8_bl, or_bxdisp8_ah, or_bxdisp8_ch, or_bxdisp8_dh, or_bxdisp8_bh

.macro or_r0_reg8l reg
	.global	or_r0_r8l_bp_\reg
or_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	or_r0_r8l_\reg
or_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_08_RAM_l_\reg op_08_EGA_l_\reg op_08_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_08_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	orrs	r0, r1, r0, lsl #24		// Perform the operation using the highest bytes to get the correct flags
	lsr		r0, #24
	strb	r0,[r2]					// Store the byte back
	b		loop
.endm
.macro or_r0_reg8h reg
	.global	or_r0_r8h_bp_\reg
or_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	or_r0_r8h_\reg
or_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_08_RAM_h_\reg op_08_EGA_h_\reg op_08_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_08_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r1, #16
	orrs	r0, r1, r0, lsl #24		// Perform the operation using the highest bytes to get the correct flags
	lsr		r0, #24
	strb	r0,[r2]					// Store the byte back
	b		loop
.endm

	or_r0_reg8l r4
	or_r0_reg8l r5
	or_r0_reg8l r6
	or_r0_reg8l r7
	or_r0_reg8h r4
	or_r0_reg8h r5
	or_r0_reg8h r6
	or_r0_reg8h r7

	.ltorg

// --- [idx] ---

.macro or_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		or_r0_r8l_\reg
.endm
.macro or_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		or_r0_r8h_\reg
.endm

or_bxsi_al:
	or_bxidx_reg8l r10 r4
or_bxsi_cl:
	or_bxidx_reg8l r10 r5
or_bxsi_dl:
	or_bxidx_reg8l r10 r6
or_bxsi_bl:
	or_bxidx_reg8l r10 r7
or_bxsi_ah:
	or_bxidx_reg8h r10 r4
or_bxsi_ch:
	or_bxidx_reg8h r10 r5
or_bxsi_dh:
	or_bxidx_reg8h r10 r6
or_bxsi_bh:
	or_bxidx_reg8h r10 r7

or_bxdi_al:
	or_bxidx_reg8l r11 r4
or_bxdi_cl:
	or_bxidx_reg8l r11 r5
or_bxdi_dl:
	or_bxidx_reg8l r11 r6
or_bxdi_bl:
	or_bxidx_reg8l r11 r7
or_bxdi_ah:
	or_bxidx_reg8h r11 r4
or_bxdi_ch:
	or_bxidx_reg8h r11 r5
or_bxdi_dh:
	or_bxidx_reg8h r11 r6
or_bxdi_bh:
	or_bxidx_reg8h r11 r7

.macro or_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		or_r0_r8l_bp_\reg
.endm
.macro or_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		or_r0_r8h_bp_\reg
.endm

or_bpsi_al:
	or_bpidx_reg8l r10 r4
or_bpsi_cl:
	or_bpidx_reg8l r10 r5
or_bpsi_dl:
	or_bpidx_reg8l r10 r6
or_bpsi_bl:
	or_bpidx_reg8l r10 r7
or_bpsi_ah:
	or_bpidx_reg8h r10 r4
or_bpsi_ch:
	or_bpidx_reg8h r10 r5
or_bpsi_dh:
	or_bpidx_reg8h r10 r6
or_bpsi_bh:
	or_bpidx_reg8h r10 r7

or_bpdi_al:
	or_bpidx_reg8l r11 r4
or_bpdi_cl:
	or_bpidx_reg8l r11 r5
or_bpdi_dl:
	or_bpidx_reg8l r11 r6
or_bpdi_bl:
	or_bpidx_reg8l r11 r7
or_bpdi_ah:
	or_bpidx_reg8h r11 r4
or_bpdi_ch:
	or_bpidx_reg8h r11 r5
or_bpdi_dh:
	or_bpidx_reg8h r11 r6
or_bpdi_bh:
	or_bpidx_reg8h r11 r7

.macro or_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		or_r0_r8l_\reg
.endm
.macro or_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		or_r0_r8h_\reg
.endm

or_siidx_al:
	or_idx_reg8l r10 r4
or_siidx_cl:
	or_idx_reg8l r10 r5
or_siidx_dl:
	or_idx_reg8l r10 r6
or_siidx_bl:
	or_idx_reg8l r10 r7
or_siidx_ah:
	or_idx_reg8h r10 r4
or_siidx_ch:
	or_idx_reg8h r10 r5
or_siidx_dh:
	or_idx_reg8h r10 r6
or_siidx_bh:
	or_idx_reg8h r10 r7

or_diidx_al:
	or_idx_reg8l r11 r4
or_diidx_cl:
	or_idx_reg8l r11 r5
or_diidx_dl:
	or_idx_reg8l r11 r6
or_diidx_bl:
	or_idx_reg8l r11 r7
or_diidx_ah:
	or_idx_reg8h r11 r4
or_diidx_ch:
	or_idx_reg8h r11 r5
or_diidx_dh:
	or_idx_reg8h r11 r6
or_diidx_bh:
	or_idx_reg8h r11 r7

or_bxidx_al:
	or_idx_reg8l r7 r4
or_bxidx_cl:
	or_idx_reg8l r7 r5
or_bxidx_dl:
	or_idx_reg8l r7 r6
or_bxidx_bl:
	or_idx_reg8l r7 r7
or_bxidx_ah:
	or_idx_reg8h r7 r4
or_bxidx_ch:
	or_idx_reg8h r7 r5
or_bxidx_dh:
	or_idx_reg8h r7 r6
or_bxidx_bh:
	or_idx_reg8h r7 r7
	
.macro or_disp16_reg8l reg
	r0_from_disp16
	b		or_r0_r8l_\reg
.endm

.macro or_disp16_reg8h reg
	r0_from_disp16
	b		or_r0_r8h_\reg
.endm

or_disp16_al:
	or_disp16_reg8l r4
or_disp16_cl:
	or_disp16_reg8l r5
or_disp16_dl:
	or_disp16_reg8l r6
or_disp16_bl:
	or_disp16_reg8l r7
or_disp16_ah:
	or_disp16_reg8h r4
or_disp16_ch:
	or_disp16_reg8h r5
or_disp16_dh:
	or_disp16_reg8h r6
or_disp16_bh:
	or_disp16_reg8h r7

// --- [idx+disp8] ---

.macro or_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		or_r0_r8l_\reg
.endm
.macro or_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		or_r0_r8h_\reg
.endm

or_bxsid8_al:
	or_bxidxd8_reg8l r10 r4
or_bxsid8_cl:
	or_bxidxd8_reg8l r10 r5
or_bxsid8_dl:
	or_bxidxd8_reg8l r10 r6
or_bxsid8_bl:
	or_bxidxd8_reg8l r10 r7
or_bxsid8_ah:
	or_bxidxd8_reg8h r10 r4
or_bxsid8_ch:
	or_bxidxd8_reg8h r10 r5
or_bxsid8_dh:
	or_bxidxd8_reg8h r10 r6
or_bxsid8_bh:
	or_bxidxd8_reg8h r10 r7

or_bxdid8_al:
	or_bxidxd8_reg8l r11 r4
or_bxdid8_cl:
	or_bxidxd8_reg8l r11 r5
or_bxdid8_dl:
	or_bxidxd8_reg8l r11 r6
or_bxdid8_bl:
	or_bxidxd8_reg8l r11 r7
or_bxdid8_ah:
	or_bxidxd8_reg8h r11 r4
or_bxdid8_ch:
	or_bxidxd8_reg8h r11 r5
or_bxdid8_dh:
	or_bxidxd8_reg8h r11 r6
or_bxdid8_bh:
	or_bxidxd8_reg8h r11 r7

.macro or_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		or_r0_r8l_bp_\reg
.endm
.macro or_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		or_r0_r8h_bp_\reg
.endm

or_bpsid8_al:
	or_bpidxd8_reg8l r10 r4
or_bpsid8_cl:
	or_bpidxd8_reg8l r10 r5
or_bpsid8_dl:
	or_bpidxd8_reg8l r10 r6
or_bpsid8_bl:
	or_bpidxd8_reg8l r10 r7
or_bpsid8_ah:
	or_bpidxd8_reg8h r10 r4
or_bpsid8_ch:
	or_bpidxd8_reg8h r10 r5
or_bpsid8_dh:
	or_bpidxd8_reg8h r10 r6
or_bpsid8_bh:
	or_bpidxd8_reg8h r10 r7

or_bpdid8_al:
	or_bpidxd8_reg8l r11 r4
or_bpdid8_cl:
	or_bpidxd8_reg8l r11 r5
or_bpdid8_dl:
	or_bpidxd8_reg8l r11 r6
or_bpdid8_bl:
	or_bpidxd8_reg8l r11 r7
or_bpdid8_ah:
	or_bpidxd8_reg8h r11 r4
or_bpdid8_ch:
	or_bpidxd8_reg8h r11 r5
or_bpdid8_dh:
	or_bpidxd8_reg8h r11 r6
or_bpdid8_bh:
	or_bpidxd8_reg8h r11 r7

.macro or_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		or_r0_r8l_\reg
.endm
.macro or_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		or_r0_r8h_\reg
.endm

or_sidisp8_al:
	or_idxdisp8_reg8l r10 r4
or_sidisp8_cl:
	or_idxdisp8_reg8l r10 r5
or_sidisp8_dl:
	or_idxdisp8_reg8l r10 r6
or_sidisp8_bl:
	or_idxdisp8_reg8l r10 r7
or_sidisp8_ah:
	or_idxdisp8_reg8h r10 r4
or_sidisp8_ch:
	or_idxdisp8_reg8h r10 r5
or_sidisp8_dh:
	or_idxdisp8_reg8h r10 r6
or_sidisp8_bh:
	or_idxdisp8_reg8h r10 r7

or_didisp8_al:
	or_idxdisp8_reg8l r11 r4
or_didisp8_cl:
	or_idxdisp8_reg8l r11 r5
or_didisp8_dl:
	or_idxdisp8_reg8l r11 r6
or_didisp8_bl:
	or_idxdisp8_reg8l r11 r7
or_didisp8_ah:
	or_idxdisp8_reg8h r11 r4
or_didisp8_ch:
	or_idxdisp8_reg8h r11 r5
or_didisp8_dh:
	or_idxdisp8_reg8h r11 r6
or_didisp8_bh:
	or_idxdisp8_reg8h r11 r7

or_bxdisp8_al:
	or_idxdisp8_reg8l r7 r4
or_bxdisp8_cl:
	or_idxdisp8_reg8l r7 r5
or_bxdisp8_dl:
	or_idxdisp8_reg8l r7 r6
or_bxdisp8_bl:
	or_idxdisp8_reg8l r7 r7
or_bxdisp8_ah:
	or_idxdisp8_reg8h r7 r4
or_bxdisp8_ch:
	or_idxdisp8_reg8h r7 r5
or_bxdisp8_dh:
	or_idxdisp8_reg8h r7 r6
or_bxdisp8_bh:
	or_idxdisp8_reg8h r7 r7

.macro or_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		or_r0_r8l_bp_\reg
.endm
.macro or_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		or_r0_r8h_bp_\reg
.endm

or_bpdisp8_al:
	or_bpdisp8_reg8l r4
or_bpdisp8_cl:
	or_bpdisp8_reg8l r5
or_bpdisp8_dl:
	or_bpdisp8_reg8l r6
or_bpdisp8_bl:
	or_bpdisp8_reg8l r7
or_bpdisp8_ah:
	or_bpdisp8_reg8h r4
or_bpdisp8_ch:
	or_bpdisp8_reg8h r5
or_bpdisp8_dh:
	or_bpdisp8_reg8h r6
or_bpdisp8_bh:
	or_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro or_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		or_r0_r8l_\reg
.endm
.macro or_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		or_r0_r8h_\reg
.endm

or_bxsid16_al:
	or_bxidxdisp16_reg8l r10 r4
or_bxsid16_cl:
	or_bxidxdisp16_reg8l r10 r5
or_bxsid16_dl:
	or_bxidxdisp16_reg8l r10 r6
or_bxsid16_bl:
	or_bxidxdisp16_reg8l r10 r7
or_bxsid16_ah:
	or_bxidxdisp16_reg8h r10 r4
or_bxsid16_ch:
	or_bxidxdisp16_reg8h r10 r5
or_bxsid16_dh:
	or_bxidxdisp16_reg8h r10 r6
or_bxsid16_bh:
	or_bxidxdisp16_reg8h r10 r7

or_bxdid16_al:
	or_bxidxdisp16_reg8l r11 r4
or_bxdid16_cl:
	or_bxidxdisp16_reg8l r11 r5
or_bxdid16_dl:
	or_bxidxdisp16_reg8l r11 r6
or_bxdid16_bl:
	or_bxidxdisp16_reg8l r11 r7
or_bxdid16_ah:
	or_bxidxdisp16_reg8h r11 r4
or_bxdid16_ch:
	or_bxidxdisp16_reg8h r11 r5
or_bxdid16_dh:
	or_bxidxdisp16_reg8h r11 r6
or_bxdid16_bh:
	or_bxidxdisp16_reg8h r11 r7

.macro or_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		or_r0_r8l_bp_\reg
.endm
.macro or_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		or_r0_r8h_bp_\reg
.endm

or_bpsid16_al:
	or_bpidxd16_reg8l r10 r4
or_bpsid16_cl:
	or_bpidxd16_reg8l r10 r5
or_bpsid16_dl:
	or_bpidxd16_reg8l r10 r6
or_bpsid16_bl:
	or_bpidxd16_reg8l r10 r7
or_bpsid16_ah:
	or_bpidxd16_reg8h r10 r4
or_bpsid16_ch:
	or_bpidxd16_reg8h r10 r5
or_bpsid16_dh:
	or_bpidxd16_reg8h r10 r6
or_bpsid16_bh:
	or_bpidxd16_reg8h r10 r7

or_bpdid16_al:
	or_bpidxd16_reg8l r11 r4
or_bpdid16_cl:
	or_bpidxd16_reg8l r11 r5
or_bpdid16_dl:
	or_bpidxd16_reg8l r11 r6
or_bpdid16_bl:
	or_bpidxd16_reg8l r11 r7
or_bpdid16_ah:
	or_bpidxd16_reg8h r11 r4
or_bpdid16_ch:
	or_bpidxd16_reg8h r11 r5
or_bpdid16_dh:
	or_bpidxd16_reg8h r11 r6
or_bpdid16_bh:
	or_bpidxd16_reg8h r11 r7

.macro or_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		or_r0_r8l_\reg
.endm
.macro or_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		or_r0_r8h_\reg
.endm

or_sidisp16_al:
	or_idxdisp16_reg8l r10 r4
or_sidisp16_cl:
	or_idxdisp16_reg8l r10 r5
or_sidisp16_dl:
	or_idxdisp16_reg8l r10 r6
or_sidisp16_bl:
	or_idxdisp16_reg8l r10 r7
or_sidisp16_ah:
	or_idxdisp16_reg8h r10 r4
or_sidisp16_ch:
	or_idxdisp16_reg8h r10 r5
or_sidisp16_dh:
	or_idxdisp16_reg8h r10 r6
or_sidisp16_bh:
	or_idxdisp16_reg8h r10 r7

or_didisp16_al:
	or_idxdisp16_reg8l r11 r4
or_didisp16_cl:
	or_idxdisp16_reg8l r11 r5
or_didisp16_dl:
	or_idxdisp16_reg8l r11 r6
or_didisp16_bl:
	or_idxdisp16_reg8l r11 r7
or_didisp16_ah:
	or_idxdisp16_reg8h r11 r4
or_didisp16_ch:
	or_idxdisp16_reg8h r11 r5
or_didisp16_dh:
	or_idxdisp16_reg8h r11 r6
or_didisp16_bh:
	or_idxdisp16_reg8h r11 r7

or_bxdisp16_al:
	or_idxdisp16_reg8l r7 r4
or_bxdisp16_cl:
	or_idxdisp16_reg8l r7 r5
or_bxdisp16_dl:
	or_idxdisp16_reg8l r7 r6
or_bxdisp16_bl:
	or_idxdisp16_reg8l r7 r7
or_bxdisp16_ah:
	or_idxdisp16_reg8h r7 r4
or_bxdisp16_ch:
	or_idxdisp16_reg8h r7 r5
or_bxdisp16_dh:
	or_idxdisp16_reg8h r7 r6
or_bxdisp16_bh:
	or_idxdisp16_reg8h r7 r7

.macro or_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		or_r0_r8l_bp_\reg
.endm
.macro or_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		or_r0_r8h_bp_\reg
.endm

or_bpdisp16_al:
	or_bpdisp16_reg8l r4
or_bpdisp16_cl:
	or_bpdisp16_reg8l r5
or_bpdisp16_dl:
	or_bpdisp16_reg8l r6
or_bpdisp16_bl:
	or_bpdisp16_reg8l r7
or_bpdisp16_ah:
	or_bpdisp16_reg8h r4
or_bpdisp16_ch:
	or_bpdisp16_reg8h r5
or_bpdisp16_dh:
	or_bpdisp16_reg8h r6
or_bpdisp16_bh:
	or_bpdisp16_reg8h r7

// ------------------- 09 = OR r/m16,r16 -------------------------------
//
// All modrm variations supported!
//
//
	.global	op_09
op_09:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word or_bxsi_ax, or_bxdi_ax, or_bpsi_ax, or_bpdi_ax, or_siidx_ax, or_diidx_ax, or_disp16_ax, or_bxidx_ax
	.word or_bxsi_cx, or_bxdi_cx, or_bpsi_cx, or_bpdi_cx, or_siidx_cx, or_diidx_cx, or_disp16_cx, or_bxidx_cx
	.word or_bxsi_dx, or_bxdi_dx, or_bpsi_dx, or_bpdi_dx, or_siidx_dx, or_diidx_dx, or_disp16_dx, or_bxidx_dx
	.word or_bxsi_bx, or_bxdi_bx, or_bpsi_bx, or_bpdi_bx, or_siidx_bx, or_diidx_bx, or_disp16_bx, or_bxidx_bx
	.word or_bxsi_sp, or_bxdi_sp, or_bpsi_sp, or_bpdi_sp, or_siidx_sp, or_diidx_sp, or_disp16_sp, or_bxidx_sp
	.word or_bxsi_bp, or_bxdi_bp, or_bpsi_bp, or_bpdi_bp, or_siidx_bp, or_diidx_bp, or_disp16_bp, or_bxidx_bp
	.word or_bxsi_si, or_bxdi_si, or_bpsi_si, or_bpdi_si, or_siidx_si, or_diidx_si, or_disp16_si, or_bxidx_si
	.word or_bxsi_di, or_bxdi_di, or_bpsi_di, or_bpdi_di, or_siidx_di, or_diidx_di, or_disp16_di, or_bxidx_di
//0x40
	.word or_bxsid8_ax, or_bxdid8_ax, or_bpsid8_ax, or_bpdid8_ax, or_sidisp8_ax, or_didisp8_ax, or_bpdisp8_ax, or_bxdisp8_ax
	.word or_bxsid8_cx, or_bxdid8_cx, or_bpsid8_cx, or_bpdid8_cx, or_sidisp8_cx, or_didisp8_cx, or_bpdisp8_cx, or_bxdisp8_cx
	.word or_bxsid8_dx, or_bxdid8_dx, or_bpsid8_dx, or_bpdid8_dx, or_sidisp8_dx, or_didisp8_dx, or_bpdisp8_dx, or_bxdisp8_dx
	.word or_bxsid8_bx, or_bxdid8_bx, or_bpsid8_bx, or_bpdid8_bx, or_sidisp8_bx, or_didisp8_bx, or_bpdisp8_bx, or_bxdisp8_bx
	.word or_bxsid8_sp, or_bxdid8_sp, or_bpsid8_sp, or_bpdid8_sp, or_sidisp8_sp, or_didisp8_sp, or_bpdisp8_sp, or_bxdisp8_sp
	.word or_bxsid8_bp, or_bxdid8_bp, or_bpsid8_bp, or_bpdid8_bp, or_sidisp8_bp, or_didisp8_bp, or_bpdisp8_bp, or_bxdisp8_bp
	.word or_bxsid8_si, or_bxdid8_si, or_bpsid8_si, or_bpdid8_si, or_sidisp8_si, or_didisp8_si, or_bpdisp8_si, or_bxdisp8_si
	.word or_bxsid8_di, or_bxdid8_di, or_bpsid8_di, or_bpdid8_di, or_sidisp8_di, or_didisp8_di, or_bpdisp8_di, or_bxdisp8_di
//0x80
	.word or_bxsid16_ax, or_bxdid16_ax, or_bpsid16_ax, or_bpdid16_ax, or_sidisp16_ax, or_didisp16_ax, or_bpdisp16_ax, or_bxdisp16_ax
	.word or_bxsid16_cx, or_bxdid16_cx, or_bpsid16_cx, or_bpdid16_cx, or_sidisp16_cx, or_didisp16_cx, or_bpdisp16_cx, or_bxdisp16_cx
	.word or_bxsid16_dx, or_bxdid16_dx, or_bpsid16_dx, or_bpdid16_dx, or_sidisp16_dx, or_didisp16_dx, or_bpdisp16_dx, or_bxdisp16_dx
	.word or_bxsid16_bx, or_bxdid16_bx, or_bpsid16_bx, or_bpdid16_bx, or_sidisp16_bx, or_didisp16_bx, or_bpdisp16_bx, or_bxdisp16_bx
	.word or_bxsid16_sp, or_bxdid16_sp, or_bpsid16_sp, or_bpdid16_sp, or_sidisp16_sp, or_didisp16_sp, or_bpdisp16_sp, or_bxdisp16_sp
	.word or_bxsid16_bp, or_bxdid16_bp, or_bpsid16_bp, or_bpdid16_bp, or_sidisp16_bp, or_didisp16_bp, or_bpdisp16_bp, or_bxdisp16_bp
	.word or_bxsid16_si, or_bxdid16_si, or_bpsid16_si, or_bpdid16_si, or_sidisp16_si, or_didisp16_si, or_bpdisp16_si, or_bxdisp16_si
	.word or_bxsid16_di, or_bxdid16_di, or_bpsid16_di, or_bpdid16_di, or_sidisp16_di, or_didisp16_di, or_bpdisp16_di, or_bxdisp16_di
// 0xC0 = two register operands
	.word or_ax_ax, or_cx_ax, or_dx_ax, or_bx_ax, or_sp_ax, or_bp_ax, or_si_ax, or_di_ax
	.word or_ax_cx, or_cx_cx, or_dx_cx, or_bx_cx, or_sp_cx, or_bp_cx, or_si_cx, or_di_cx
	.word or_ax_dx, or_cx_dx, or_dx_dx, or_bx_dx, or_sp_dx, or_bp_dx, or_si_dx, or_di_dx
	.word or_ax_bx, or_cx_bx, or_dx_bx, or_bx_bx, or_sp_bx, or_bp_bx, or_si_bx, or_di_bx
	.word or_ax_sp, or_cx_sp, or_dx_sp, or_bx_sp, or_sp_sp, or_bp_sp, or_si_sp, or_di_sp
	.word or_ax_bp, or_cx_bp, or_dx_bp, or_bx_bp, or_sp_bp, or_bp_bp, or_si_bp, or_di_bp
	.word or_ax_si, or_cx_si, or_dx_si, or_bx_si, or_sp_si, or_bp_si, or_si_si, or_di_si
	.word or_ax_di, or_cx_di, or_dx_di, or_bx_di, or_sp_di, or_bp_di, or_si_di, or_di_di

// These are called from "cpu_67.s":

	.global or_siidx_ax, or_diidx_ax, or_bxidx_ax
	.global or_siidx_cx, or_diidx_cx, or_bxidx_cx
	.global or_siidx_dx, or_diidx_dx, or_bxidx_dx
	.global or_siidx_bx, or_diidx_bx, or_bxidx_bx
	.global or_siidx_sp, or_diidx_sp, or_bxidx_sp
	.global or_siidx_bp, or_diidx_bp, or_bxidx_bp
	.global or_siidx_si, or_diidx_si, or_bxidx_si
	.global or_siidx_di, or_diidx_di, or_bxidx_di
	.global or_sidisp8_ax, or_didisp8_ax, or_bpdisp8_ax, or_bxdisp8_ax
	.global or_sidisp8_cx, or_didisp8_cx, or_bpdisp8_cx, or_bxdisp8_cx
	.global or_sidisp8_dx, or_didisp8_dx, or_bpdisp8_dx, or_bxdisp8_dx
	.global or_sidisp8_bx, or_didisp8_bx, or_bpdisp8_bx, or_bxdisp8_bx
	.global or_sidisp8_sp, or_didisp8_sp, or_bpdisp8_sp, or_bxdisp8_sp
	.global or_sidisp8_bp, or_didisp8_bp, or_bpdisp8_bp, or_bxdisp8_bp
	.global or_sidisp8_si, or_didisp8_si, or_bpdisp8_si, or_bxdisp8_si
	.global or_sidisp8_di, or_didisp8_di, or_bpdisp8_di, or_bxdisp8_di
	.global or_ax_ax, or_cx_ax, or_dx_ax, or_bx_ax, or_sp_ax, or_bp_ax, or_si_ax, or_di_ax
	.global or_ax_cx, or_cx_cx, or_dx_cx, or_bx_cx, or_sp_cx, or_bp_cx, or_si_cx, or_di_cx
	.global or_ax_dx, or_cx_dx, or_dx_dx, or_bx_dx, or_sp_dx, or_bp_dx, or_si_dx, or_di_dx
	.global or_ax_bx, or_cx_bx, or_dx_bx, or_bx_bx, or_sp_bx, or_bp_bx, or_si_bx, or_di_bx
	.global or_ax_sp, or_cx_sp, or_dx_sp, or_bx_sp, or_sp_sp, or_bp_sp, or_si_sp, or_di_sp
	.global or_ax_bp, or_cx_bp, or_dx_bp, or_bx_bp, or_sp_bp, or_bp_bp, or_si_bp, or_di_bp
	.global or_ax_si, or_cx_si, or_dx_si, or_bx_si, or_sp_si, or_bp_si, or_si_si, or_di_si
	.global or_ax_di, or_cx_di, or_dx_di, or_bx_di, or_sp_di, or_bp_di, or_si_di, or_di_di
	.global	or_r0_r16_bp_r4, or_r0_r16_bp_r5, or_r0_r16_bp_r6, or_r0_r16_bp_r7, or_r0_r16_bp_r8, or_r0_r16_bp_r9, or_r0_r16_bp_r10, or_r0_r16_bp_r11, or_r0_r16_bp_r4
	.global	or_r0_r16_r4, or_r0_r16_r5, or_r0_r16_r6, or_r0_r16_r7, or_r0_r16_r8, or_r0_r16_r9, or_r0_r16_r10, or_r0_r16_r11, or_r0_r16_r4


.macro or_r0_r16_reg reg
or_r0_r16_bp_\reg:
	//-------
	// Indexing by BP register, so use SS unless a segment override is in effect.
	//-------
	mem_handler_bp
or_r0_r16_\reg:
	//-------
	// Indexing by the current effective segment.
	//-------
	mem_handler_jump_r0r3 .op_09_RAM_\reg op_09_EGA_r2_\reg bad_MODEX_opcode
.op_09_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r3, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	orrs	r0, r3, r0, lsl #16
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		loop
.endm

	or_r0_r16_reg r4
	or_r0_r16_reg r5
	or_r0_r16_reg r6
	or_r0_r16_reg r7
	or_r0_r16_reg r8
	or_r0_r16_reg r9
	or_r0_r16_reg r10
	or_r0_r16_reg r11

	.ltorg
	
// --- [idx] ----

.macro or_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		or_r0_r16_\reg
.endm

	.global or_bxsi_ax
or_bxsi_ax:
	or_bxidx_reg16 r10 r4
or_bxsi_cx:
	or_bxidx_reg16 r10 r5
or_bxsi_dx:
	or_bxidx_reg16 r10 r6
or_bxsi_bx:
	or_bxidx_reg16 r10 r7
or_bxsi_sp:
	or_bxidx_reg16 r10 r8
or_bxsi_bp:
	or_bxidx_reg16 r10 r9
or_bxsi_si:
	or_bxidx_reg16 r10 r10
or_bxsi_di:
	or_bxidx_reg16 r10 r11

or_bxdi_ax:
	or_bxidx_reg16 r11 r4
or_bxdi_cx:
	or_bxidx_reg16 r11 r5
or_bxdi_dx:
	or_bxidx_reg16 r11 r6
or_bxdi_bx:
	or_bxidx_reg16 r11 r7
or_bxdi_sp:
	or_bxidx_reg16 r11 r8
or_bxdi_bp:
	or_bxidx_reg16 r11 r9
or_bxdi_si:
	or_bxidx_reg16 r11 r10
or_bxdi_di:
	or_bxidx_reg16 r11 r11

.macro or_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		or_r0_r16_bp_\reg
.endm

or_bpsi_ax:
	or_bpidx_reg16 r10 r4
or_bpsi_cx:
	or_bpidx_reg16 r10 r5
or_bpsi_dx:
	or_bpidx_reg16 r10 r6
or_bpsi_bx:
	or_bpidx_reg16 r10 r7
or_bpsi_sp:
	or_bpidx_reg16 r10 r8
or_bpsi_bp:
	or_bpidx_reg16 r10 r9
or_bpsi_si:
	or_bpidx_reg16 r10 r10
or_bpsi_di:
	or_bpidx_reg16 r10 r11

or_bpdi_ax:
	or_bpidx_reg16 r11 r4
or_bpdi_cx:
	or_bpidx_reg16 r11 r5
or_bpdi_dx:
	or_bpidx_reg16 r11 r6
or_bpdi_bx:
	or_bpidx_reg16 r11 r7
or_bpdi_sp:
	or_bpidx_reg16 r11 r8
or_bpdi_bp:
	or_bpidx_reg16 r11 r9
or_bpdi_si:
	or_bpidx_reg16 r11 r10
or_bpdi_di:
	or_bpidx_reg16 r11 r11

.macro or_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		or_r0_r16_\reg
.endm

or_siidx_ax:
	or_idx_reg16 r10 r4
or_siidx_cx:
	or_idx_reg16 r10 r5
or_siidx_dx:
	or_idx_reg16 r10 r6
or_siidx_bx:
	or_idx_reg16 r10 r7
or_siidx_sp:
	or_idx_reg16 r10 r8
or_siidx_bp:
	or_idx_reg16 r10 r9
or_siidx_si:
	or_idx_reg16 r10 r10
or_siidx_di:
	or_idx_reg16 r10 r11

or_diidx_ax:
	or_idx_reg16 r11 r4
or_diidx_cx:
	or_idx_reg16 r11 r5
or_diidx_dx:
	or_idx_reg16 r11 r6
or_diidx_bx:
	or_idx_reg16 r11 r7
or_diidx_sp:
	or_idx_reg16 r11 r8
or_diidx_bp:
	or_idx_reg16 r11 r9
or_diidx_si:
	or_idx_reg16 r11 r10
or_diidx_di:
	or_idx_reg16 r11 r11

or_bxidx_ax:
	or_idx_reg16 r7 r4
or_bxidx_cx:
	or_idx_reg16 r7 r5
or_bxidx_dx:
	or_idx_reg16 r7 r6
or_bxidx_bx:
	or_idx_reg16 r7 r7
or_bxidx_sp:
	or_idx_reg16 r7 r8
or_bxidx_bp:
	or_idx_reg16 r7 r9
or_bxidx_si:
	or_idx_reg16 r7 r10
or_bxidx_di:
	or_idx_reg16 r7 r11
	
.macro or_disp16_reg16 reg
	r0_from_disp16
	b		or_r0_r16_\reg
.endm

or_disp16_ax:
	or_disp16_reg16 r4
or_disp16_cx:
	or_disp16_reg16 r5
or_disp16_dx:
	or_disp16_reg16 r6
or_disp16_bx:
	or_disp16_reg16 r7
or_disp16_sp:
	or_disp16_reg16 r8
or_disp16_bp:
	or_disp16_reg16 r9
or_disp16_si:
	or_disp16_reg16 r10
or_disp16_di:
	or_disp16_reg16 r11

// --- [idx+disp8] ----

.macro or_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		or_r0_r16_\reg
.endm

or_bxsid8_ax:
	or_bxidxd8_reg16 r10 r4
or_bxsid8_cx:
	or_bxidxd8_reg16 r10 r5
or_bxsid8_dx:
	or_bxidxd8_reg16 r10 r6
or_bxsid8_bx:
	or_bxidxd8_reg16 r10 r7
or_bxsid8_sp:
	or_bxidxd8_reg16 r10 r8
or_bxsid8_bp:
	or_bxidxd8_reg16 r10 r9
or_bxsid8_si:
	or_bxidxd8_reg16 r10 r10
or_bxsid8_di:
	or_bxidxd8_reg16 r10 r11

or_bxdid8_ax:
	or_bxidxd8_reg16 r11 r4
or_bxdid8_cx:
	or_bxidxd8_reg16 r11 r5
or_bxdid8_dx:
	or_bxidxd8_reg16 r11 r6
or_bxdid8_bx:
	or_bxidxd8_reg16 r11 r7
or_bxdid8_sp:
	or_bxidxd8_reg16 r11 r8
or_bxdid8_bp:
	or_bxidxd8_reg16 r11 r9
or_bxdid8_si:
	or_bxidxd8_reg16 r11 r10
or_bxdid8_di:
	or_bxidxd8_reg16 r11 r11

.macro or_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		or_r0_r16_bp_\reg
.endm

or_bpsid8_ax:
	or_bpidxd8_reg16 r10 r4
or_bpsid8_cx:
	or_bpidxd8_reg16 r10 r5
or_bpsid8_dx:
	or_bpidxd8_reg16 r10 r6
or_bpsid8_bx:
	or_bpidxd8_reg16 r10 r7
or_bpsid8_sp:
	or_bpidxd8_reg16 r10 r8
or_bpsid8_bp:
	or_bpidxd8_reg16 r10 r9
or_bpsid8_si:
	or_bpidxd8_reg16 r10 r10
or_bpsid8_di:
	or_bpidxd8_reg16 r10 r11

or_bpdid8_ax:
	or_bpidxd8_reg16 r11 r4
or_bpdid8_cx:
	or_bpidxd8_reg16 r11 r5
or_bpdid8_dx:
	or_bpidxd8_reg16 r11 r6
or_bpdid8_bx:
	or_bpidxd8_reg16 r11 r7
or_bpdid8_sp:
	or_bpidxd8_reg16 r11 r8
or_bpdid8_bp:
	or_bpidxd8_reg16 r11 r9
or_bpdid8_si:
	or_bpidxd8_reg16 r11 r10
or_bpdid8_di:
	or_bpidxd8_reg16 r11 r11

.macro or_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		or_r0_r16_\reg
.endm

or_sidisp8_ax:
	or_idxdisp8_reg16 r10 r4
or_sidisp8_cx:
	or_idxdisp8_reg16 r10 r5
or_sidisp8_dx:
	or_idxdisp8_reg16 r10 r6
or_sidisp8_bx:
	or_idxdisp8_reg16 r10 r7
or_sidisp8_sp:
	or_idxdisp8_reg16 r10 r8
or_sidisp8_bp:
	or_idxdisp8_reg16 r10 r9
or_sidisp8_si:
	or_idxdisp8_reg16 r10 r10
or_sidisp8_di:
	or_idxdisp8_reg16 r10 r11

or_didisp8_ax:
	or_idxdisp8_reg16 r11 r4
or_didisp8_cx:
	or_idxdisp8_reg16 r11 r5
or_didisp8_dx:
	or_idxdisp8_reg16 r11 r6
or_didisp8_bx:
	or_idxdisp8_reg16 r11 r7
or_didisp8_sp:
	or_idxdisp8_reg16 r11 r8
or_didisp8_bp:
	or_idxdisp8_reg16 r11 r9
or_didisp8_si:
	or_idxdisp8_reg16 r11 r10
or_didisp8_di:
	or_idxdisp8_reg16 r11 r11

or_bxdisp8_ax:
	or_idxdisp8_reg16 r7 r4
or_bxdisp8_cx:
	or_idxdisp8_reg16 r7 r5
or_bxdisp8_dx:
	or_idxdisp8_reg16 r7 r6
or_bxdisp8_bx:
	or_idxdisp8_reg16 r7 r7
or_bxdisp8_sp:
	or_idxdisp8_reg16 r7 r8
or_bxdisp8_bp:
	or_idxdisp8_reg16 r7 r9
or_bxdisp8_si:
	or_idxdisp8_reg16 r7 r10
or_bxdisp8_di:
	or_idxdisp8_reg16 r7 r11
	
.macro or_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		or_r0_r16_bp_\reg
.endm
	
or_bpdisp8_ax:
	or_bpdisp8_reg16 r4
or_bpdisp8_cx:
	or_bpdisp8_reg16 r5
or_bpdisp8_dx:
	or_bpdisp8_reg16 r6
or_bpdisp8_bx:
	or_bpdisp8_reg16 r7
or_bpdisp8_sp:
	or_bpdisp8_reg16 r8
or_bpdisp8_bp:
	or_bpdisp8_reg16 r9
or_bpdisp8_si:
	or_bpdisp8_reg16 r10
or_bpdisp8_di:
	or_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro or_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		or_r0_r16_\reg
.endm

or_bxsid16_ax:
	or_bxidxd16_reg16 r10 r4
or_bxsid16_cx:
	or_bxidxd16_reg16 r10 r5
or_bxsid16_dx:
	or_bxidxd16_reg16 r10 r6
or_bxsid16_bx:
	or_bxidxd16_reg16 r10 r7
or_bxsid16_sp:
	or_bxidxd16_reg16 r10 r8
or_bxsid16_bp:
	or_bxidxd16_reg16 r10 r9
or_bxsid16_si:
	or_bxidxd16_reg16 r10 r10
or_bxsid16_di:
	or_bxidxd16_reg16 r10 r11

or_bxdid16_ax:
	or_bxidxd16_reg16 r11 r4
or_bxdid16_cx:
	or_bxidxd16_reg16 r11 r5
or_bxdid16_dx:
	or_bxidxd16_reg16 r11 r6
or_bxdid16_bx:
	or_bxidxd16_reg16 r11 r7
or_bxdid16_sp:
	or_bxidxd16_reg16 r11 r8
or_bxdid16_bp:
	or_bxidxd16_reg16 r11 r9
or_bxdid16_si:
	or_bxidxd16_reg16 r11 r10
or_bxdid16_di:
	or_bxidxd16_reg16 r11 r11

.macro or_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		or_r0_r16_bp_\reg
.endm

or_bpsid16_ax:
	or_bpidxd16_reg16 r10 r4
or_bpsid16_cx:
	or_bpidxd16_reg16 r10 r5
or_bpsid16_dx:
	or_bpidxd16_reg16 r10 r6
or_bpsid16_bx:
	or_bpidxd16_reg16 r10 r7
or_bpsid16_sp:
	or_bpidxd16_reg16 r10 r8
or_bpsid16_bp:
	or_bpidxd16_reg16 r10 r9
or_bpsid16_si:
	or_bpidxd16_reg16 r10 r10
or_bpsid16_di:
	or_bpidxd16_reg16 r10 r11

or_bpdid16_ax:
	or_bpidxd16_reg16 r11 r4
or_bpdid16_cx:
	or_bpidxd16_reg16 r11 r5
or_bpdid16_dx:
	or_bpidxd16_reg16 r11 r6
or_bpdid16_bx:
	or_bpidxd16_reg16 r11 r7
or_bpdid16_sp:
	or_bpidxd16_reg16 r11 r8
or_bpdid16_bp:
	or_bpidxd16_reg16 r11 r9
or_bpdid16_si:
	or_bpidxd16_reg16 r11 r10
or_bpdid16_di:
	or_bpidxd16_reg16 r11 r11

.macro or_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		or_r0_r16_\reg
.endm

or_sidisp16_ax:
	or_idxdisp16_reg16 r10 r4
or_sidisp16_cx:
	or_idxdisp16_reg16 r10 r5
or_sidisp16_dx:
	or_idxdisp16_reg16 r10 r6
or_sidisp16_bx:
	or_idxdisp16_reg16 r10 r7
or_sidisp16_sp:
	or_idxdisp16_reg16 r10 r8
or_sidisp16_bp:
	or_idxdisp16_reg16 r10 r9
or_sidisp16_si:
	or_idxdisp16_reg16 r10 r10
or_sidisp16_di:
	or_idxdisp16_reg16 r10 r11

or_didisp16_ax:
	or_idxdisp16_reg16 r11 r4
or_didisp16_cx:
	or_idxdisp16_reg16 r11 r5
or_didisp16_dx:
	or_idxdisp16_reg16 r11 r6
or_didisp16_bx:
	or_idxdisp16_reg16 r11 r7
or_didisp16_sp:
	or_idxdisp16_reg16 r11 r8
or_didisp16_bp:
	or_idxdisp16_reg16 r11 r9
or_didisp16_si:
	or_idxdisp16_reg16 r11 r10
or_didisp16_di:
	or_idxdisp16_reg16 r11 r11

or_bxdisp16_ax:
	or_idxdisp16_reg16 r7 r4
or_bxdisp16_cx:
	or_idxdisp16_reg16 r7 r5
or_bxdisp16_dx:
	or_idxdisp16_reg16 r7 r6
or_bxdisp16_bx:
	or_idxdisp16_reg16 r7 r7
or_bxdisp16_sp:
	or_idxdisp16_reg16 r7 r8
or_bxdisp16_bp:
	or_idxdisp16_reg16 r7 r9
or_bxdisp16_si:
	or_idxdisp16_reg16 r7 r10
or_bxdisp16_di:
	or_idxdisp16_reg16 r7 r11

.macro or_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		or_r0_r16_bp_\reg
.endm

or_bpdisp16_ax:
	or_bpdisp16_reg16 r4
or_bpdisp16_cx:
	or_bpdisp16_reg16 r5
or_bpdisp16_dx:
	or_bpdisp16_reg16 r6
or_bpdisp16_bx:
	or_bpdisp16_reg16 r7
or_bpdisp16_sp:
	or_bpdisp16_reg16 r8
or_bpdisp16_bp:
	or_bpdisp16_reg16 r9
or_bpdisp16_si:
	or_bpdisp16_reg16 r10
or_bpdisp16_di:
	or_bpdisp16_reg16 r11

// ------------------- 0A = OR r8,r/m8 -------------------------------
//
// All modrm variations supported!
//
//
	.global	op_0a
op_0a:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word or_al_bxsi, or_al_bxdi, or_al_bpsi, or_al_bpdi, or_al_siidx, or_al_diidx, or_al_disp16, or_al_bxidx
	.word or_cl_bxsi, or_cl_bxdi, or_cl_bpsi, or_cl_bpdi, or_cl_siidx, or_cl_diidx, or_cl_disp16, or_cl_bxidx
	.word or_dl_bxsi, or_dl_bxdi, or_dl_bpsi, or_dl_bpdi, or_dl_siidx, or_dl_diidx, or_dl_disp16, or_dl_bxidx
	.word or_bl_bxsi, or_bl_bxdi, or_bl_bpsi, or_bl_bpdi, or_bl_siidx, or_bl_diidx, or_bl_disp16, or_bl_bxidx
	.word or_ah_bxsi, or_ah_bxdi, or_ah_bpsi, or_ah_bpdi, or_ah_siidx, or_ah_diidx, or_ah_disp16, or_ah_bxidx
	.word or_ch_bxsi, or_ch_bxdi, or_ch_bpsi, or_ch_bpdi, or_ch_siidx, or_ch_diidx, or_ch_disp16, or_ch_bxidx
	.word or_dh_bxsi, or_dh_bxdi, or_dh_bpsi, or_dh_bpdi, or_dh_siidx, or_dh_diidx, or_dh_disp16, or_dh_bxidx
	.word or_bh_bxsi, or_bh_bxdi, or_bh_bpsi, or_bh_bpdi, or_bh_siidx, or_bh_diidx, or_bh_disp16, or_bh_bxidx
//0x40
	.word or_al_bxsid8, or_al_bxdid8, or_al_bpsid8, or_al_bpdid8, or_al_sidisp8, or_al_didisp8, or_al_bpdisp8, or_al_bxdisp8
	.word or_cl_bxsid8, or_cl_bxdid8, or_cl_bpsid8, or_cl_bpdid8, or_cl_sidisp8, or_cl_didisp8, or_cl_bpdisp8, or_cl_bxdisp8
	.word or_dl_bxsid8, or_dl_bxdid8, or_dl_bpsid8, or_dl_bpdid8, or_dl_sidisp8, or_dl_didisp8, or_dl_bpdisp8, or_dl_bxdisp8
	.word or_bl_bxsid8, or_bl_bxdid8, or_bl_bpsid8, or_bl_bpdid8, or_bl_sidisp8, or_bl_didisp8, or_bl_bpdisp8, or_bl_bxdisp8
	.word or_ah_bxsid8, or_ah_bxdid8, or_ah_bpsid8, or_ah_bpdid8, or_ah_sidisp8, or_ah_didisp8, or_ah_bpdisp8, or_ah_bxdisp8
	.word or_ch_bxsid8, or_ch_bxdid8, or_ch_bpsid8, or_ch_bpdid8, or_ch_sidisp8, or_ch_didisp8, or_ch_bpdisp8, or_ch_bxdisp8
	.word or_dh_bxsid8, or_dh_bxdid8, or_dh_bpsid8, or_dh_bpdid8, or_dh_sidisp8, or_dh_didisp8, or_dh_bpdisp8, or_dh_bxdisp8
	.word or_bh_bxsid8, or_bh_bxdid8, or_bh_bpsid8, or_bh_bpdid8, or_bh_sidisp8, or_bh_didisp8, or_bh_bpdisp8, or_bh_bxdisp8
//0x80
	.word or_al_bxsid16, or_al_bxdid16, or_al_bpsid16, or_al_bpdid16, or_al_sidisp16, or_al_didisp16, or_al_bpdisp16, or_al_bxdisp16
	.word or_cl_bxsid16, or_cl_bxdid16, or_cl_bpsid16, or_cl_bpdid16, or_cl_sidisp16, or_cl_didisp16, or_cl_bpdisp16, or_cl_bxdisp16
	.word or_dl_bxsid16, or_dl_bxdid16, or_dl_bpsid16, or_dl_bpdid16, or_dl_sidisp16, or_dl_didisp16, or_dl_bpdisp16, or_dl_bxdisp16
	.word or_bl_bxsid16, or_bl_bxdid16, or_bl_bpsid16, or_bl_bpdid16, or_bl_sidisp16, or_bl_didisp16, or_bl_bpdisp16, or_bl_bxdisp16
	.word or_ah_bxsid16, or_ah_bxdid16, or_ah_bpsid16, or_ah_bpdid16, or_ah_sidisp16, or_ah_didisp16, or_ah_bpdisp16, or_ah_bxdisp16
	.word or_ch_bxsid16, or_ch_bxdid16, or_ch_bpsid16, or_ch_bpdid16, or_ch_sidisp16, or_ch_didisp16, or_ch_bpdisp16, or_ch_bxdisp16
	.word or_dh_bxsid16, or_dh_bxdid16, or_dh_bpsid16, or_dh_bpdid16, or_dh_sidisp16, or_dh_didisp16, or_dh_bpdisp16, or_dh_bxdisp16
	.word or_bh_bxsid16, or_bh_bxdid16, or_bh_bpsid16, or_bh_bpdid16, or_bh_sidisp16, or_bh_didisp16, or_bh_bpdisp16, or_bh_bxdisp16
// 0xC0 = two register operands
	.word or_al_al, or_al_cl, or_al_dl, or_al_bl, or_al_ah, or_al_ch, or_al_dh, or_al_bh
	.word or_cl_al, or_cl_cl, or_cl_dl, or_cl_bl, or_cl_ah, or_cl_ch, or_cl_dh, or_cl_bh
	.word or_dl_al, or_dl_cl, or_dl_dl, or_dl_bl, or_dl_ah, or_dl_ch, or_dl_dh, or_dl_bh
	.word or_bl_al, or_bl_cl, or_bl_dl, or_bl_bl, or_bl_ah, or_bl_ch, or_bl_dh, or_bl_bh
	.word or_ah_al, or_ah_cl, or_ah_dl, or_ah_bl, or_ah_ah, or_ah_ch, or_ah_dh, or_ah_bh
	.word or_ch_al, or_ch_cl, or_ch_dl, or_ch_bl, or_ch_ah, or_ch_ch, or_ch_dh, or_ch_bh
	.word or_dh_al, or_dh_cl, or_dh_dl, or_dh_bl, or_dh_ah, or_dh_ch, or_dh_dh, or_dh_bh
	.word or_bh_al, or_bh_cl, or_bh_dl, or_bh_bl, or_bh_ah, or_bh_ch, or_bh_dh, or_bh_bh

// These are called from "cpu_386.s":

	.global or_al_siidx, or_cl_siidx, or_dl_siidx, or_bl_siidx, or_ah_siidx, or_ch_siidx, or_dh_siidx, or_bh_siidx
	.global or_al_diidx, or_cl_diidx, or_dl_diidx, or_bl_diidx, or_ah_diidx, or_ch_diidx, or_dh_diidx, or_bh_diidx
	.global or_al_bxidx, or_cl_bxidx, or_dl_bxidx, or_bl_bxidx, or_ah_bxidx, or_ch_bxidx, or_dh_bxidx, or_bh_bxidx
	.global or_al_sidisp8, or_al_didisp8, or_al_bpdisp8, or_al_bxdisp8
	.global or_cl_sidisp8, or_cl_didisp8, or_cl_bpdisp8, or_cl_bxdisp8
	.global or_dl_sidisp8, or_dl_didisp8, or_dl_bpdisp8, or_dl_bxdisp8
	.global or_bl_sidisp8, or_bl_didisp8, or_bl_bpdisp8, or_bl_bxdisp8
	.global or_ah_sidisp8, or_ah_didisp8, or_ah_bpdisp8, or_ah_bxdisp8
	.global or_ch_sidisp8, or_ch_didisp8, or_ch_bpdisp8, or_ch_bxdisp8
	.global or_dh_sidisp8, or_dh_didisp8, or_dh_bpdisp8, or_dh_bxdisp8
	.global or_bh_sidisp8, or_bh_didisp8, or_bh_bpdisp8, or_bh_bxdisp8
	.global or_al_al, or_cl_al, or_dl_al, or_bl_al, or_ah_al, or_ch_al, or_dh_al, or_bh_al
	.global or_al_cl, or_cl_cl, or_dl_cl, or_bl_cl, or_ah_cl, or_ch_cl, or_dh_cl, or_bh_cl
	.global or_al_dl, or_cl_dl, or_dl_dl, or_bl_dl, or_ah_dl, or_ch_dl, or_dh_dl, or_bh_dl
	.global or_al_bl, or_cl_bl, or_dl_bl, or_bl_bl, or_ah_bl, or_ch_bl, or_dh_bl, or_bh_bl
	.global or_al_ah, or_cl_ah, or_dl_ah, or_bl_ah, or_ah_ah, or_ch_ah, or_dh_ah, or_bh_ah
	.global or_al_ch, or_cl_ch, or_dl_ch, or_bl_ch, or_ah_ch, or_ch_ch, or_dh_ch, or_bh_ch
	.global or_al_dh, or_cl_dh, or_dl_dh, or_bl_dh, or_ah_dh, or_ch_dh, or_dh_dh, or_bh_dh
	.global or_al_bh, or_cl_bh, or_dl_bh, or_bl_bh, or_ah_bh, or_ch_bh, or_dh_bh, or_bh_bh

.macro or_reg8l_r0high reg
	.global	or_r8l_r0_bp_\reg
or_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	or_r8l_r0_\reg
or_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_0a_RAM_l_\reg op_0a_EGA_l_\reg op_0a_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_0a_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1,\reg, lsl #24
	orrs	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1, lsr #24		// Put the result to the lowest byte of the left register
	b		loop
.endm
.macro or_reg8h_r0high reg
	.global	or_r8h_r0_bp_\reg
or_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	or_r8h_r0_\reg
or_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_0a_RAM_h_\reg op_0a_EGA_h_\reg op_0a_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_0a_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r1, #16
	orrs	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsr #16
	b		loop
.endm

	or_reg8l_r0high r4
	or_reg8l_r0high r5
	or_reg8l_r0high r6
	or_reg8l_r0high r7
	or_reg8h_r0high r4
	or_reg8h_r0high r5
	or_reg8h_r0high r6
	or_reg8h_r0high r7

	.ltorg


// --- [idx] ---

.macro or_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		or_r8l_r0_\reg
.endm
.macro or_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		or_r8h_r0_\reg
.endm

or_al_bxsi:
	or_reg8l_bxidx r4 r10
or_cl_bxsi:
	or_reg8l_bxidx r5 r10
or_dl_bxsi:
	or_reg8l_bxidx r6 r10
or_bl_bxsi:
	or_reg8l_bxidx r7 r10
or_ah_bxsi:
	or_reg8h_bxidx r4 r10
or_ch_bxsi:
	or_reg8h_bxidx r5 r10
or_dh_bxsi:
	or_reg8h_bxidx r6 r10
or_bh_bxsi:
	or_reg8h_bxidx r7 r10

or_al_bxdi:
	or_reg8l_bxidx r4 r11
or_cl_bxdi:
	or_reg8l_bxidx r5 r11
or_dl_bxdi:
	or_reg8l_bxidx r6 r11
or_bl_bxdi:
	or_reg8l_bxidx r7 r11
or_ah_bxdi:
	or_reg8h_bxidx r4 r11
or_ch_bxdi:
	or_reg8h_bxidx r5 r11
or_dh_bxdi:
	or_reg8h_bxidx r6 r11
or_bh_bxdi:
	or_reg8h_bxidx r7 r11

.macro or_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		or_r8l_r0_bp_\reg
.endm
.macro or_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		or_r8h_r0_bp_\reg
.endm

or_al_bpsi:
	or_reg8l_bpidx r4 r10
or_cl_bpsi:
	or_reg8l_bpidx r5 r10
or_dl_bpsi:
	or_reg8l_bpidx r6 r10
or_bl_bpsi:
	or_reg8l_bpidx r7 r10
or_ah_bpsi:
	or_reg8h_bpidx r4 r10
or_ch_bpsi:
	or_reg8h_bpidx r5 r10
or_dh_bpsi:
	or_reg8h_bpidx r6 r10
or_bh_bpsi:
	or_reg8h_bpidx r7 r10

or_al_bpdi:
	or_reg8l_bpidx r4 r11
or_cl_bpdi:
	or_reg8l_bpidx r5 r11
or_dl_bpdi:
	or_reg8l_bpidx r6 r11
or_bl_bpdi:
	or_reg8l_bpidx r7 r11
or_ah_bpdi:
	or_reg8h_bpidx r4 r11
or_ch_bpdi:
	or_reg8h_bpidx r5 r11
or_dh_bpdi:
	or_reg8h_bpidx r6 r11
or_bh_bpdi:
	or_reg8h_bpidx r7 r11

.macro or_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		or_r8l_r0_\reg
.endm
.macro or_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		or_r8h_r0_\reg
.endm

or_al_siidx:
	or_reg8l_idx r4 r10
or_cl_siidx:
	or_reg8l_idx r5 r10
or_dl_siidx:
	or_reg8l_idx r6 r10
or_bl_siidx:
	or_reg8l_idx r7 r10
or_ah_siidx:
	or_reg8h_idx r4 r10
or_ch_siidx:
	or_reg8h_idx r5 r10
or_dh_siidx:
	or_reg8h_idx r6 r10
or_bh_siidx:
	or_reg8h_idx r7 r10

or_al_diidx:
	or_reg8l_idx r4 r11
or_cl_diidx:
	or_reg8l_idx r5 r11
or_dl_diidx:
	or_reg8l_idx r6 r11
or_bl_diidx:
	or_reg8l_idx r7 r11
or_ah_diidx:
	or_reg8h_idx r4 r11
or_ch_diidx:
	or_reg8h_idx r5 r11
or_dh_diidx:
	or_reg8h_idx r6 r11
or_bh_diidx:
	or_reg8h_idx r7 r11

or_al_bxidx:
	or_reg8l_idx r4 r7
or_cl_bxidx:
	or_reg8l_idx r5 r7
or_dl_bxidx:
	or_reg8l_idx r6 r7
or_bl_bxidx:
	or_reg8l_idx r7 r7
or_ah_bxidx:
	or_reg8h_idx r4 r7
or_ch_bxidx:
	or_reg8h_idx r5 r7
or_dh_bxidx:
	or_reg8h_idx r6 r7
or_bh_bxidx:
	or_reg8h_idx r7 r7

.macro or_reg8l_disp16 reg
	r0_from_disp16
	b		or_r8l_r0_\reg
.endm
.macro or_reg8h_disp16 reg
	r0_from_disp16
	b		or_r8h_r0_\reg
.endm

or_al_disp16:
	or_reg8l_disp16 r4
or_cl_disp16:
	or_reg8l_disp16 r5
or_dl_disp16:
	or_reg8l_disp16 r6
or_bl_disp16:
	or_reg8l_disp16 r7
or_ah_disp16:
	or_reg8h_disp16 r4
or_ch_disp16:
	or_reg8h_disp16 r5
or_dh_disp16:
	or_reg8h_disp16 r6
or_bh_disp16:
	or_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro or_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		or_r8l_r0_\reg
.endm
.macro or_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		or_r8h_r0_\reg
.endm

or_al_bxsid8:
	or_reg8l_bxidxd8 r4 r10
or_cl_bxsid8:
	or_reg8l_bxidxd8 r5 r10
or_dl_bxsid8:
	or_reg8l_bxidxd8 r6 r10
or_bl_bxsid8:
	or_reg8l_bxidxd8 r7 r10
or_ah_bxsid8:
	or_reg8h_bxidxd8 r4 r10
or_ch_bxsid8:
	or_reg8h_bxidxd8 r5 r10
or_dh_bxsid8:
	or_reg8h_bxidxd8 r6 r10
or_bh_bxsid8:
	or_reg8h_bxidxd8 r7 r10

or_al_bxdid8:
	or_reg8l_bxidxd8 r4 r11
or_cl_bxdid8:
	or_reg8l_bxidxd8 r5 r11
or_dl_bxdid8:
	or_reg8l_bxidxd8 r6 r11
or_bl_bxdid8:
	or_reg8l_bxidxd8 r7 r11
or_ah_bxdid8:
	or_reg8h_bxidxd8 r4 r11
or_ch_bxdid8:
	or_reg8h_bxidxd8 r5 r11
or_dh_bxdid8:
	or_reg8h_bxidxd8 r6 r11
or_bh_bxdid8:
	or_reg8h_bxidxd8 r7 r11

.macro or_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		or_r8l_r0_bp_\reg
.endm
.macro or_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		or_r8h_r0_bp_\reg
.endm

or_al_bpsid8:
	or_reg8l_bpidxd8 r4 r10
or_cl_bpsid8:
	or_reg8l_bpidxd8 r5 r10
or_dl_bpsid8:
	or_reg8l_bpidxd8 r6 r10
or_bl_bpsid8:
	or_reg8l_bpidxd8 r7 r10
or_ah_bpsid8:
	or_reg8h_bpidxd8 r4 r10
or_ch_bpsid8:
	or_reg8h_bpidxd8 r5 r10
or_dh_bpsid8:
	or_reg8h_bpidxd8 r6 r10
or_bh_bpsid8:
	or_reg8h_bpidxd8 r7 r10

or_al_bpdid8:
	or_reg8l_bpidxd8 r4 r11
or_cl_bpdid8:
	or_reg8l_bpidxd8 r5 r11
or_dl_bpdid8:
	or_reg8l_bpidxd8 r6 r11
or_bl_bpdid8:
	or_reg8l_bpidxd8 r7 r11
or_ah_bpdid8:
	or_reg8h_bpidxd8 r4 r11
or_ch_bpdid8:
	or_reg8h_bpidxd8 r5 r11
or_dh_bpdid8:
	or_reg8h_bpidxd8 r6 r11
or_bh_bpdid8:
	or_reg8h_bpidxd8 r7 r11

.macro or_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		or_r8l_r0_\reg
.endm
.macro or_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		or_r8h_r0_\reg
.endm

or_al_sidisp8:
	or_reg8l_idxdisp8 r4 r10
or_cl_sidisp8:
	or_reg8l_idxdisp8 r5 r10
or_dl_sidisp8:
	or_reg8l_idxdisp8 r6 r10
or_bl_sidisp8:
	or_reg8l_idxdisp8 r7 r10
or_ah_sidisp8:
	or_reg8h_idxdisp8 r4 r10
or_ch_sidisp8:
	or_reg8h_idxdisp8 r5 r10
or_dh_sidisp8:
	or_reg8h_idxdisp8 r6 r10
or_bh_sidisp8:
	or_reg8h_idxdisp8 r7 r10
	
or_al_didisp8:
	or_reg8l_idxdisp8 r4 r11
or_cl_didisp8:
	or_reg8l_idxdisp8 r5 r11
or_dl_didisp8:
	or_reg8l_idxdisp8 r6 r11
or_bl_didisp8:
	or_reg8l_idxdisp8 r7 r11
or_ah_didisp8:
	or_reg8h_idxdisp8 r4 r11
or_ch_didisp8:
	or_reg8h_idxdisp8 r5 r11
or_dh_didisp8:
	or_reg8h_idxdisp8 r6 r11
or_bh_didisp8:
	or_reg8h_idxdisp8 r7 r11

or_al_bxdisp8:
	or_reg8l_idxdisp8 r4 r7
or_cl_bxdisp8:
	or_reg8l_idxdisp8 r5 r7
or_dl_bxdisp8:
	or_reg8l_idxdisp8 r6 r7
or_bl_bxdisp8:
	or_reg8l_idxdisp8 r7 r7
or_ah_bxdisp8:
	or_reg8h_idxdisp8 r4 r7
or_ch_bxdisp8:
	or_reg8h_idxdisp8 r5 r7
or_dh_bxdisp8:
	or_reg8h_idxdisp8 r6 r7
or_bh_bxdisp8:
	or_reg8h_idxdisp8 r7 r7

.macro or_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		or_r8l_r0_bp_\reg
.endm
.macro or_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		or_r8h_r0_bp_\reg
.endm

or_al_bpdisp8:
	or_reg8l_bpdisp8 r4
or_cl_bpdisp8:
	or_reg8l_bpdisp8 r5
or_dl_bpdisp8:
	or_reg8l_bpdisp8 r6
or_bl_bpdisp8:
	or_reg8l_bpdisp8 r7
or_ah_bpdisp8:
	or_reg8h_bpdisp8 r4
or_ch_bpdisp8:
	or_reg8h_bpdisp8 r5
or_dh_bpdisp8:
	or_reg8h_bpdisp8 r6
or_bh_bpdisp8:
	or_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro or_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		or_r8l_r0_\reg
.endm
.macro or_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		or_r8h_r0_\reg
.endm

or_al_bxsid16:
	or_reg8l_bxidxd16 r4 r10
or_cl_bxsid16:
	or_reg8l_bxidxd16 r5 r10
or_dl_bxsid16:
	or_reg8l_bxidxd16 r6 r10
or_bl_bxsid16:
	or_reg8l_bxidxd16 r7 r10
or_ah_bxsid16:
	or_reg8h_bxidxd16 r4 r10
or_ch_bxsid16:
	or_reg8h_bxidxd16 r5 r10
or_dh_bxsid16:
	or_reg8h_bxidxd16 r6 r10
or_bh_bxsid16:
	or_reg8h_bxidxd16 r7 r10

or_al_bxdid16:
	or_reg8l_bxidxd16 r4 r11
or_cl_bxdid16:
	or_reg8l_bxidxd16 r5 r11
or_dl_bxdid16:
	or_reg8l_bxidxd16 r6 r11
or_bl_bxdid16:
	or_reg8l_bxidxd16 r7 r11
or_ah_bxdid16:
	or_reg8h_bxidxd16 r4 r11
or_ch_bxdid16:
	or_reg8h_bxidxd16 r5 r11
or_dh_bxdid16:
	or_reg8h_bxidxd16 r6 r11
or_bh_bxdid16:
	or_reg8h_bxidxd16 r7 r11

.macro or_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		or_r8l_r0_bp_\reg
.endm
.macro or_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		or_r8h_r0_bp_\reg
.endm

or_al_bpsid16:
	or_reg8l_bpidxd16 r4 r10
or_cl_bpsid16:
	or_reg8l_bpidxd16 r5 r10
or_dl_bpsid16:
	or_reg8l_bpidxd16 r6 r10
or_bl_bpsid16:
	or_reg8l_bpidxd16 r7 r10
or_ah_bpsid16:
	or_reg8h_bpidxd16 r4 r10
or_ch_bpsid16:
	or_reg8h_bpidxd16 r5 r10
or_dh_bpsid16:
	or_reg8h_bpidxd16 r6 r10
or_bh_bpsid16:
	or_reg8h_bpidxd16 r7 r10

or_al_bpdid16:
	or_reg8l_bpidxd16 r4 r11
or_cl_bpdid16:
	or_reg8l_bpidxd16 r5 r11
or_dl_bpdid16:
	or_reg8l_bpidxd16 r6 r11
or_bl_bpdid16:
	or_reg8l_bpidxd16 r7 r11
or_ah_bpdid16:
	or_reg8h_bpidxd16 r4 r11
or_ch_bpdid16:
	or_reg8h_bpidxd16 r5 r11
or_dh_bpdid16:
	or_reg8h_bpidxd16 r6 r11
or_bh_bpdid16:
	or_reg8h_bpidxd16 r7 r11

.macro or_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		or_r8l_r0_\reg
.endm
.macro or_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		or_r8h_r0_\reg
.endm

or_al_sidisp16:
	or_reg8l_idxdisp16 r4 r10
or_cl_sidisp16:
	or_reg8l_idxdisp16 r5 r10
or_dl_sidisp16:
	or_reg8l_idxdisp16 r6 r10
or_bl_sidisp16:
	or_reg8l_idxdisp16 r7 r10
or_ah_sidisp16:
	or_reg8h_idxdisp16 r4 r10
or_ch_sidisp16:
	or_reg8h_idxdisp16 r5 r10
or_dh_sidisp16:
	or_reg8h_idxdisp16 r6 r10
or_bh_sidisp16:
	or_reg8h_idxdisp16 r7 r10

or_al_didisp16:
	or_reg8l_idxdisp16 r4 r11
or_cl_didisp16:
	or_reg8l_idxdisp16 r5 r11
or_dl_didisp16:
	or_reg8l_idxdisp16 r6 r11
or_bl_didisp16:
	or_reg8l_idxdisp16 r7 r11
or_ah_didisp16:
	or_reg8h_idxdisp16 r4 r11
or_ch_didisp16:
	or_reg8h_idxdisp16 r5 r11
or_dh_didisp16:
	or_reg8h_idxdisp16 r6 r11
or_bh_didisp16:
	or_reg8h_idxdisp16 r7 r11

or_al_bxdisp16:
	or_reg8l_idxdisp16 r4 r7
or_cl_bxdisp16:
	or_reg8l_idxdisp16 r5 r7
or_dl_bxdisp16:
	or_reg8l_idxdisp16 r6 r7
or_bl_bxdisp16:
	or_reg8l_idxdisp16 r7 r7
or_ah_bxdisp16:
	or_reg8h_idxdisp16 r4 r7
or_ch_bxdisp16:
	or_reg8h_idxdisp16 r5 r7
or_dh_bxdisp16:
	or_reg8h_idxdisp16 r6 r7
or_bh_bxdisp16:
	or_reg8h_idxdisp16 r7 r7
	
.macro or_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		or_r8l_r0_bp_\reg
.endm
.macro or_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		or_r8h_r0_bp_\reg
.endm

or_al_bpdisp16:
	or_reg8l_bpdisp16 r4 
or_cl_bpdisp16:
	or_reg8l_bpdisp16 r5 
or_dl_bpdisp16:
	or_reg8l_bpdisp16 r6 
or_bl_bpdisp16:
	or_reg8l_bpdisp16 r7 
or_ah_bpdisp16:
	or_reg8h_bpdisp16 r4 
or_ch_bpdisp16:
	or_reg8h_bpdisp16 r5 
or_dh_bpdisp16:
	or_reg8h_bpdisp16 r6 
or_bh_bpdisp16:
	or_reg8h_bpdisp16 r7 

// --- Register operands ---

.macro or_reg8l_reg8l rl rr
	mov		r0, \rl, lsl #24
	mov		r1, \rr, lsl #24
	orrs	r0, r1					// Perform the operation using the highest bytes to get the correct flags
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// Put the result to the lowest byte of the left register
	b		loop
.endm

.macro or_reg8l_reg8h rl rr
	and		r0, \rr, #0xFF00
	lsl		r0, #16
	mov		r1, \rl, lsl #24
	orrs	r0, r1					// Perform the operation using the highest bytes to get the correct flags
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// Put the result to the lowest byte of the left register
	b		loop
.endm

.macro or_reg8h_reg8l rl rr
	and		r0, \rl, #0xFF00
	lsl		r0, #16
	mov		r1, \rr, lsl #24
	orrs	r0, r1					// Perform the operation using the highest bytes to get the correct flags
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16		// Put the result to the proper byte of the left register
	b		loop
.endm

.macro or_reg8h_reg8h rl rr
	and		r0, \rl, #0xFF00		// Left operand already uses just the rightmost byte
	and		r1, \rr, #0xFF00		// Right operand already uses just the rightmost byte
	lsl		r0, #16
	lsl		r1, #16
	orrs	r0, r1					// Perform the operation using the highest bytes to get the correct flags
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16		// Put the result to the proper byte of the left register
	b		loop
.endm

or_al_al:
	or_reg8l_reg8l r4 r4
or_al_cl:
	or_reg8l_reg8l r4 r5
or_al_dl:
	or_reg8l_reg8l r4 r6
or_al_bl:
	or_reg8l_reg8l r4 r7
or_al_ah:
	or_reg8l_reg8h r4 r4
or_al_ch:
	or_reg8l_reg8h r4 r5
or_al_dh:
	or_reg8l_reg8h r4 r6
or_al_bh:
	or_reg8l_reg8h r4 r7
or_cl_al:
	or_reg8l_reg8l r5 r4
or_cl_cl:
	or_reg8l_reg8l r5 r5
or_cl_dl:
	or_reg8l_reg8l r5 r6
or_cl_bl:
	or_reg8l_reg8l r5 r7
or_cl_ah:
	or_reg8l_reg8h r5 r4
or_cl_ch:
	or_reg8l_reg8h r5 r5
or_cl_dh:
	or_reg8l_reg8h r5 r6
or_cl_bh:
	or_reg8l_reg8h r5 r7
or_dl_al:
	or_reg8l_reg8l r6 r4
or_dl_cl:
	or_reg8l_reg8l r6 r5
or_dl_dl:
	or_reg8l_reg8l r6 r6
or_dl_bl:
	or_reg8l_reg8l r6 r7
or_dl_ah:
	or_reg8l_reg8h r6 r4
or_dl_ch:
	or_reg8l_reg8h r6 r5
or_dl_dh:
	or_reg8l_reg8h r6 r6
or_dl_bh:
	or_reg8l_reg8h r6 r7
or_bl_al:
	or_reg8l_reg8l r7 r4
or_bl_cl:
	or_reg8l_reg8l r7 r5
or_bl_dl:
	or_reg8l_reg8l r7 r6
or_bl_bl:
	or_reg8l_reg8l r7 r7
or_bl_ah:
	or_reg8l_reg8h r7 r4
or_bl_ch:
	or_reg8l_reg8h r7 r5
or_bl_dh:
	or_reg8l_reg8h r7 r6
or_bl_bh:
	or_reg8l_reg8h r7 r7

or_ah_al:
	or_reg8h_reg8l r4 r4
or_ah_cl:
	or_reg8h_reg8l r4 r5
or_ah_dl:
	or_reg8h_reg8l r4 r6
or_ah_bl:
	or_reg8h_reg8l r4 r7
or_ah_ah:
	or_reg8h_reg8h r4 r4
or_ah_ch:
	or_reg8h_reg8h r4 r5
or_ah_dh:
	or_reg8h_reg8h r4 r6
or_ah_bh:
	or_reg8h_reg8h r4 r7
or_ch_al:
	or_reg8h_reg8l r5 r4
or_ch_cl:
	or_reg8h_reg8l r5 r5
or_ch_dl:
	or_reg8h_reg8l r5 r6
or_ch_bl:
	or_reg8h_reg8l r5 r7
or_ch_ah:
	or_reg8h_reg8h r5 r4
or_ch_ch:
	or_reg8h_reg8h r5 r5
or_ch_dh:
	or_reg8h_reg8h r5 r6
or_ch_bh:
	or_reg8h_reg8h r5 r7
or_dh_al:
	or_reg8h_reg8l r6 r4
or_dh_cl:
	or_reg8h_reg8l r6 r5
or_dh_dl:
	or_reg8h_reg8l r6 r6
or_dh_bl:
	or_reg8h_reg8l r6 r7
or_dh_ah:
	or_reg8h_reg8h r6 r4
or_dh_ch:
	or_reg8h_reg8h r6 r5
or_dh_dh:
	or_reg8h_reg8h r6 r6
or_dh_bh:
	or_reg8h_reg8h r6 r7
or_bh_al:
	or_reg8h_reg8l r7 r4
or_bh_cl:
	or_reg8h_reg8l r7 r5
or_bh_dl:
	or_reg8h_reg8l r7 r6
or_bh_bl:
	or_reg8h_reg8l r7 r7
or_bh_ah:
	or_reg8h_reg8h r7 r4
or_bh_ch:
	or_reg8h_reg8h r7 r5
or_bh_dh:
	or_reg8h_reg8h r7 r6
or_bh_bh:
	or_reg8h_reg8h r7 r7

// ------------------- 0B = OR r16,r/m16 -------------------------------
//
// All modrm variations supported!
//
//
	.global	op_0b
op_0b:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word or_ax_bxsi, or_ax_bxdi, or_ax_bpsi, or_ax_bpdi, or_ax_siidx, or_ax_diidx, or_ax_disp16, or_ax_bxidx
	.word or_cx_bxsi, or_cx_bxdi, or_cx_bpsi, or_cx_bpdi, or_cx_siidx, or_cx_diidx, or_cx_disp16, or_cx_bxidx
	.word or_dx_bxsi, or_dx_bxdi, or_dx_bpsi, or_dx_bpdi, or_dx_siidx, or_dx_diidx, or_dx_disp16, or_dx_bxidx
	.word or_bx_bxsi, or_bx_bxdi, or_bx_bpsi, or_bx_bpdi, or_bx_siidx, or_bx_diidx, or_bx_disp16, or_bx_bxidx
	.word or_sp_bxsi, or_sp_bxdi, or_sp_bpsi, or_sp_bpdi, or_sp_siidx, or_sp_diidx, or_sp_disp16, or_sp_bxidx
	.word or_bp_bxsi, or_bp_bxdi, or_bp_bpsi, or_bp_bpdi, or_bp_siidx, or_bp_diidx, or_bp_disp16, or_bp_bxidx
	.word or_si_bxsi, or_si_bxdi, or_si_bpsi, or_si_bpdi, or_si_siidx, or_si_diidx, or_si_disp16, or_si_bxidx
	.word or_di_bxsi, or_di_bxdi, or_di_bpsi, or_di_bpdi, or_di_siidx, or_di_diidx, or_di_disp16, or_di_bxidx
//0x40
	.word or_ax_bxsid8, or_ax_bxdid8, or_ax_bpsid8, or_ax_bpdid8, or_ax_sidisp8, or_ax_didisp8, or_ax_bpdisp8, or_ax_bxdisp8
	.word or_cx_bxsid8, or_cx_bxdid8, or_cx_bpsid8, or_cx_bpdid8, or_cx_sidisp8, or_cx_didisp8, or_cx_bpdisp8, or_cx_bxdisp8
	.word or_dx_bxsid8, or_dx_bxdid8, or_dx_bpsid8, or_dx_bpdid8, or_dx_sidisp8, or_dx_didisp8, or_dx_bpdisp8, or_dx_bxdisp8
	.word or_bx_bxsid8, or_bx_bxdid8, or_bx_bpsid8, or_bx_bpdid8, or_bx_sidisp8, or_bx_didisp8, or_bx_bpdisp8, or_bx_bxdisp8
	.word or_sp_bxsid8, or_sp_bxdid8, or_sp_bpsid8, or_sp_bpdid8, or_sp_sidisp8, or_sp_didisp8, or_sp_bpdisp8, or_sp_bxdisp8
	.word or_bp_bxsid8, or_bp_bxdid8, or_bp_bpsid8, or_bp_bpdid8, or_bp_sidisp8, or_bp_didisp8, or_bp_bpdisp8, or_bp_bxdisp8
	.word or_si_bxsid8, or_si_bxdid8, or_si_bpsid8, or_si_bpdid8, or_si_sidisp8, or_si_didisp8, or_si_bpdisp8, or_si_bxdisp8
	.word or_di_bxsid8, or_di_bxdid8, or_di_bpsid8, or_di_bpdid8, or_di_sidisp8, or_di_didisp8, or_di_bpdisp8, or_di_bxdisp8
//0x80
	.word or_ax_bxsid16, or_ax_bxdid16, or_ax_bpsid16, or_ax_bpdid16, or_ax_sidisp16, or_ax_didisp16, or_ax_bpdisp16, or_ax_bxdisp16
	.word or_cx_bxsid16, or_cx_bxdid16, or_cx_bpsid16, or_cx_bpdid16, or_cx_sidisp16, or_cx_didisp16, or_cx_bpdisp16, or_cx_bxdisp16
	.word or_dx_bxsid16, or_dx_bxdid16, or_dx_bpsid16, or_dx_bpdid16, or_dx_sidisp16, or_dx_didisp16, or_dx_bpdisp16, or_dx_bxdisp16
	.word or_bx_bxsid16, or_bx_bxdid16, or_bx_bpsid16, or_bx_bpdid16, or_bx_sidisp16, or_bx_didisp16, or_bx_bpdisp16, or_bx_bxdisp16
	.word or_sp_bxsid16, or_sp_bxdid16, or_sp_bpsid16, or_sp_bpdid16, or_sp_sidisp16, or_sp_didisp16, or_sp_bpdisp16, or_sp_bxdisp16
	.word or_bp_bxsid16, or_bp_bxdid16, or_bp_bpsid16, or_bp_bpdid16, or_bp_sidisp16, or_bp_didisp16, or_bp_bpdisp16, or_bp_bxdisp16
	.word or_si_bxsid16, or_si_bxdid16, or_si_bpsid16, or_si_bpdid16, or_si_sidisp16, or_si_didisp16, or_si_bpdisp16, or_si_bxdisp16
	.word or_di_bxsid16, or_di_bxdid16, or_di_bpsid16, or_di_bpdid16, or_di_sidisp16, or_di_didisp16, or_di_bpdisp16, or_di_bxdisp16
// 0xC0 = two register operands
	.word or_ax_ax, or_ax_cx, or_ax_dx, or_ax_bx, or_ax_sp, or_ax_bp, or_ax_si, or_ax_di
	.word or_cx_ax, or_cx_cx, or_cx_dx, or_cx_bx, or_cx_sp, or_cx_bp, or_cx_si, or_cx_di
	.word or_dx_ax, or_dx_cx, or_dx_dx, or_dx_bx, or_dx_sp, or_dx_bp, or_dx_si, or_dx_di
	.word or_bx_ax, or_bx_cx, or_bx_dx, or_bx_bx, or_bx_sp, or_bx_bp, or_bx_si, or_bx_di
	.word or_sp_ax, or_sp_cx, or_sp_dx, or_sp_bx, or_sp_sp, or_sp_bp, or_sp_si, or_sp_di
	.word or_bp_ax, or_bp_cx, or_bp_dx, or_bp_bx, or_bp_sp, or_bp_bp, or_bp_si, or_bp_di
	.word or_si_ax, or_si_cx, or_si_dx, or_si_bx, or_si_sp, or_si_bp, or_si_si, or_si_di
	.word or_di_ax, or_di_cx, or_di_dx, or_di_bx, or_di_sp, or_di_bp, or_di_si, or_di_di

// These are called from "cpu_67.s":

	.global or_ax_siidx, or_ax_diidx, or_ax_bxidx
	.global or_cx_siidx, or_cx_diidx, or_cx_bxidx
	.global or_dx_siidx, or_dx_diidx, or_dx_bxidx
	.global or_bx_siidx, or_bx_diidx, or_bx_bxidx
	.global or_sp_siidx, or_sp_diidx, or_sp_bxidx
	.global or_bp_siidx, or_bp_diidx, or_bp_bxidx
	.global or_si_siidx, or_si_diidx, or_si_bxidx
	.global or_di_siidx, or_di_diidx, or_di_bxidx
	.global or_ax_sidisp8, or_ax_didisp8, or_ax_bpdisp8, or_ax_bxdisp8
	.global or_cx_sidisp8, or_cx_didisp8, or_cx_bpdisp8, or_cx_bxdisp8
	.global or_dx_sidisp8, or_dx_didisp8, or_dx_bpdisp8, or_dx_bxdisp8
	.global or_bx_sidisp8, or_bx_didisp8, or_bx_bpdisp8, or_bx_bxdisp8
	.global or_sp_sidisp8, or_sp_didisp8, or_sp_bpdisp8, or_sp_bxdisp8
	.global or_bp_sidisp8, or_bp_didisp8, or_bp_bpdisp8, or_bp_bxdisp8
	.global or_si_sidisp8, or_si_didisp8, or_si_bpdisp8, or_si_bxdisp8
	.global or_di_sidisp8, or_di_didisp8, or_di_bpdisp8, or_di_bxdisp8
	.global	or_r16_r0_bp_r4, or_r16_r0_bp_r5, or_r16_r0_bp_r6, or_r16_r0_bp_r7, or_r16_r0_bp_r8, or_r16_r0_bp_r9, or_r16_r0_bp_r10, or_r16_r0_bp_r11
	.global	or_r16_r0_r4, or_r16_r0_r5, or_r16_r0_r6, or_r16_r0_r7, or_r16_r0_r8, or_r16_r0_r9, or_r16_r0_r10, or_r16_r0_r11

.macro or_reg16_r0high reg
or_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
or_r16_r0_\reg:
	//-------
	// Indexing by the current effective segment.
	//-------
	mem_handler_jump_r0r3 .op_0b_RAM_\reg op_0b_EGA_\reg bad_MODEX_opcode
.op_0b_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r3, \reg, lsl #16
	eor		\reg, r3, lsr #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	orrs	r0, r3, r0, lsl #16
	orr		\reg, r0, lsr #16
	b		loop
.endm

	or_reg16_r0high r4
	or_reg16_r0high r5
	or_reg16_r0high r6
	or_reg16_r0high r7
	or_reg16_r0high r8
	or_reg16_r0high r9
	or_reg16_r0high r10
	or_reg16_r0high r11

	.ltorg

// --- [idx] ---

.macro or_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		or_r16_r0_\reg
.endm

or_ax_bxsi:
	or_reg16_bxidx r4 r10
or_cx_bxsi:
	or_reg16_bxidx r5 r10
or_dx_bxsi:
	or_reg16_bxidx r6 r10
or_bx_bxsi:
	or_reg16_bxidx r7 r10
or_bp_bxsi:
	or_reg16_bxidx r9 r10
or_sp_bxsi:
	or_reg16_bxidx r8 r10
or_si_bxsi:
	or_reg16_bxidx r10 r10
or_di_bxsi:
	or_reg16_bxidx r11 r10

or_ax_bxdi:
	or_reg16_bxidx r4 r11
or_cx_bxdi:
	or_reg16_bxidx r5 r11
or_dx_bxdi:
	or_reg16_bxidx r6 r11
or_bx_bxdi:
	or_reg16_bxidx r7 r11
or_sp_bxdi:
	or_reg16_bxidx r8 r11
or_bp_bxdi:
	or_reg16_bxidx r9 r11
or_si_bxdi:
	or_reg16_bxidx r10 r11
or_di_bxdi:
	or_reg16_bxidx r11 r11

.macro or_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		or_r16_r0_bp_\reg
.endm

or_ax_bpsi:
	or_reg16_bpidx r4 r10
or_cx_bpsi:
	or_reg16_bpidx r5 r10
or_dx_bpsi:
	or_reg16_bpidx r6 r10
or_bx_bpsi:
	or_reg16_bpidx r7 r10
or_sp_bpsi:
	or_reg16_bpidx r8 r10
or_bp_bpsi:
	or_reg16_bpidx r9 r10
or_si_bpsi:
	or_reg16_bpidx r10 r10
or_di_bpsi:
	or_reg16_bpidx r11 r10

or_ax_bpdi:
	or_reg16_bpidx r4 r11
or_cx_bpdi:
	or_reg16_bpidx r5 r11
or_dx_bpdi:
	or_reg16_bpidx r6 r11
or_bx_bpdi:
	or_reg16_bpidx r7 r11
or_sp_bpdi:
	or_reg16_bpidx r8 r11
or_bp_bpdi:
	or_reg16_bpidx r9 r11
or_si_bpdi:
	or_reg16_bpidx r10 r11
or_di_bpdi:
	or_reg16_bpidx r11 r11

.macro or_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		or_r16_r0_\reg
.endm

or_ax_siidx:
	or_reg16_idx r4 r10
or_cx_siidx:
	or_reg16_idx r5 r10
or_dx_siidx:
	or_reg16_idx r6 r10
or_bx_siidx:
	or_reg16_idx r7 r10
or_sp_siidx:
	or_reg16_idx r8 r10
or_bp_siidx:
	or_reg16_idx r9 r10
or_si_siidx:
	or_reg16_idx r10 r10
or_di_siidx:
	or_reg16_idx r11 r10

or_ax_diidx:
	or_reg16_idx r4 r11
or_cx_diidx:
	or_reg16_idx r5 r11
or_dx_diidx:
	or_reg16_idx r6 r11
or_bx_diidx:
	or_reg16_idx r7 r11
or_sp_diidx:
	or_reg16_idx r8 r11
or_bp_diidx:
	or_reg16_idx r9 r11
or_si_diidx:
	or_reg16_idx r10 r11
or_di_diidx:
	or_reg16_idx r11 r11

or_ax_bxidx:
	or_reg16_idx r4 r7
or_cx_bxidx:
	or_reg16_idx r5 r7
or_dx_bxidx:
	or_reg16_idx r6 r7
or_bx_bxidx:
	or_reg16_idx r7 r7
or_sp_bxidx:
	or_reg16_idx r8 r7
or_bp_bxidx:
	or_reg16_idx r9 r7
or_si_bxidx:
	or_reg16_idx r10 r7
or_di_bxidx:
	or_reg16_idx r11 r7

.macro or_reg16_disp16 reg
	r0_from_disp16
	b		or_r16_r0_\reg
.endm

or_ax_disp16:
	or_reg16_disp16 r4
or_cx_disp16:
	or_reg16_disp16 r5
or_dx_disp16:
	or_reg16_disp16 r6
or_bx_disp16:
	or_reg16_disp16 r7
or_sp_disp16:
	or_reg16_disp16 r8
or_bp_disp16:
	or_reg16_disp16 r9
or_si_disp16:
	or_reg16_disp16 r10
or_di_disp16:
	or_reg16_disp16 r11

// --- [idx+disp8] ---

.macro or_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		or_r16_r0_\reg
.endm

or_ax_bxsid8:
	or_reg16_bxidxdisp8 r4 r10
or_cx_bxsid8:
	or_reg16_bxidxdisp8 r5 r10
or_dx_bxsid8:
	or_reg16_bxidxdisp8 r6 r10
or_bx_bxsid8:
	or_reg16_bxidxdisp8 r7 r10
or_sp_bxsid8:
	or_reg16_bxidxdisp8 r8 r10
or_bp_bxsid8:
	or_reg16_bxidxdisp8 r9 r10
or_si_bxsid8:
	or_reg16_bxidxdisp8 r10 r10
or_di_bxsid8:
	or_reg16_bxidxdisp8 r11 r10

or_ax_bxdid8:
	or_reg16_bxidxdisp8 r4 r11
or_cx_bxdid8:
	or_reg16_bxidxdisp8 r5 r11
or_dx_bxdid8:
	or_reg16_bxidxdisp8 r6 r11
or_bx_bxdid8:
	or_reg16_bxidxdisp8 r7 r11
or_sp_bxdid8:
	or_reg16_bxidxdisp8 r8 r11
or_bp_bxdid8:
	or_reg16_bxidxdisp8 r9 r11
or_si_bxdid8:
	or_reg16_bxidxdisp8 r10 r11
or_di_bxdid8:
	or_reg16_bxidxdisp8 r11 r11

.macro or_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		or_r16_r0_bp_\reg
.endm

or_ax_bpsid8:
	or_reg16_bpidxdisp8 r4 r10
or_cx_bpsid8:
	or_reg16_bpidxdisp8 r5 r10
or_dx_bpsid8:
	or_reg16_bpidxdisp8 r6 r10
or_bx_bpsid8:
	or_reg16_bpidxdisp8 r7 r10
or_sp_bpsid8:
	or_reg16_bpidxdisp8 r8 r10
or_bp_bpsid8:
	or_reg16_bpidxdisp8 r9 r10
or_si_bpsid8:
	or_reg16_bpidxdisp8 r10 r10
or_di_bpsid8:
	or_reg16_bpidxdisp8 r11 r10

or_ax_bpdid8:
	or_reg16_bpidxdisp8 r4 r11
or_cx_bpdid8:
	or_reg16_bpidxdisp8 r5 r11
or_dx_bpdid8:
	or_reg16_bpidxdisp8 r6 r11
or_bx_bpdid8:
	or_reg16_bpidxdisp8 r7 r11
or_sp_bpdid8:
	or_reg16_bpidxdisp8 r8 r11
or_bp_bpdid8:
	or_reg16_bpidxdisp8 r9 r11
or_si_bpdid8:
	or_reg16_bpidxdisp8 r10 r11
or_di_bpdid8:
	or_reg16_bpidxdisp8 r11 r11

.macro or_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		or_r16_r0_\reg
.endm

or_ax_sidisp8:
	or_reg16_idxdisp8 r4 r10
or_cx_sidisp8:
	or_reg16_idxdisp8 r5 r10
or_dx_sidisp8:
	or_reg16_idxdisp8 r6 r10
or_bx_sidisp8:
	or_reg16_idxdisp8 r7 r10
or_sp_sidisp8:
	or_reg16_idxdisp8 r8 r10
or_bp_sidisp8:
	or_reg16_idxdisp8 r9 r10
or_si_sidisp8:
	or_reg16_idxdisp8 r10 r10
or_di_sidisp8:
	or_reg16_idxdisp8 r11 r10

or_ax_didisp8:
	or_reg16_idxdisp8 r4 r11
or_cx_didisp8:
	or_reg16_idxdisp8 r5 r11
or_dx_didisp8:
	or_reg16_idxdisp8 r6 r11
or_bx_didisp8:
	or_reg16_idxdisp8 r7 r11
or_sp_didisp8:
	or_reg16_idxdisp8 r8 r11
or_bp_didisp8:
	or_reg16_idxdisp8 r9 r11
or_si_didisp8:
	or_reg16_idxdisp8 r10 r11
or_di_didisp8:
	or_reg16_idxdisp8 r11 r11

or_ax_bxdisp8:
	or_reg16_idxdisp8 r4 r7
or_cx_bxdisp8:
	or_reg16_idxdisp8 r5 r7
or_dx_bxdisp8:
	or_reg16_idxdisp8 r6 r7
or_bx_bxdisp8:
	or_reg16_idxdisp8 r7 r7
or_sp_bxdisp8:
	or_reg16_idxdisp8 r8 r7
or_bp_bxdisp8:
	or_reg16_idxdisp8 r9 r7
or_si_bxdisp8:
	or_reg16_idxdisp8 r10 r7
or_di_bxdisp8:
	or_reg16_idxdisp8 r11 r7

.macro or_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		or_r16_r0_bp_\reg
.endm

or_ax_bpdisp8:
	or_reg16_bpdisp8 r4
or_cx_bpdisp8:
	or_reg16_bpdisp8 r5
or_dx_bpdisp8:
	or_reg16_bpdisp8 r6
or_bx_bpdisp8:
	or_reg16_bpdisp8 r7
or_sp_bpdisp8:
	or_reg16_bpdisp8 r8
or_bp_bpdisp8:
	or_reg16_bpdisp8 r9
or_si_bpdisp8:
	or_reg16_bpdisp8 r10
or_di_bpdisp8:
	or_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro or_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		or_r16_r0_\reg
.endm

or_ax_bxsid16:
	or_reg16_bxidxdisp16 r4 r10
or_cx_bxsid16:
	or_reg16_bxidxdisp16 r5 r10
or_dx_bxsid16:
	or_reg16_bxidxdisp16 r6 r10
or_bx_bxsid16:
	or_reg16_bxidxdisp16 r7 r10
or_sp_bxsid16:
	or_reg16_bxidxdisp16 r8 r10
or_bp_bxsid16:
	or_reg16_bxidxdisp16 r9 r10
or_si_bxsid16:
	or_reg16_bxidxdisp16 r10 r10
or_di_bxsid16:
	or_reg16_bxidxdisp16 r11 r10

or_ax_bxdid16:
	or_reg16_bxidxdisp16 r4 r11
or_cx_bxdid16:
	or_reg16_bxidxdisp16 r5 r11
or_dx_bxdid16:
	or_reg16_bxidxdisp16 r6 r11
or_bx_bxdid16:
	or_reg16_bxidxdisp16 r7 r11
or_sp_bxdid16:
	or_reg16_bxidxdisp16 r8 r11
or_bp_bxdid16:
	or_reg16_bxidxdisp16 r9 r11
or_si_bxdid16:
	or_reg16_bxidxdisp16 r10 r11
or_di_bxdid16:
	or_reg16_bxidxdisp16 r11 r11

.macro or_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		or_r16_r0_bp_\reg
.endm

or_ax_bpsid16:
	or_reg16_bpidxdisp16 r4 r10
or_cx_bpsid16:
	or_reg16_bpidxdisp16 r5 r10
or_dx_bpsid16:
	or_reg16_bpidxdisp16 r6 r10
or_bx_bpsid16:
	or_reg16_bpidxdisp16 r7 r10
or_sp_bpsid16:
	or_reg16_bpidxdisp16 r8 r10
or_bp_bpsid16:
	or_reg16_bpidxdisp16 r9 r10
or_si_bpsid16:
	or_reg16_bpidxdisp16 r10 r10
or_di_bpsid16:
	or_reg16_bpidxdisp16 r11 r10

or_ax_bpdid16:
	or_reg16_bpidxdisp16 r4 r11
or_cx_bpdid16:
	or_reg16_bpidxdisp16 r5 r11
or_dx_bpdid16:
	or_reg16_bpidxdisp16 r6 r11
or_bx_bpdid16:
	or_reg16_bpidxdisp16 r7 r11
or_sp_bpdid16:
	or_reg16_bpidxdisp16 r8 r11
or_bp_bpdid16:
	or_reg16_bpidxdisp16 r9 r11
or_si_bpdid16:
	or_reg16_bpidxdisp16 r10 r11
or_di_bpdid16:
	or_reg16_bpidxdisp16 r11 r11

.macro or_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		or_r16_r0_\reg
.endm

or_ax_sidisp16:
	or_reg16_idxdisp16 r4 r10
or_cx_sidisp16:
	or_reg16_idxdisp16 r5 r10
or_dx_sidisp16:
	or_reg16_idxdisp16 r6 r10
or_bx_sidisp16:
	or_reg16_idxdisp16 r7 r10
or_sp_sidisp16:
	or_reg16_idxdisp16 r8 r10
or_bp_sidisp16:
	or_reg16_idxdisp16 r9 r10
or_si_sidisp16:
	or_reg16_idxdisp16 r10 r10
or_di_sidisp16:
	or_reg16_idxdisp16 r11 r10

or_ax_didisp16:
	or_reg16_idxdisp16 r4 r11
or_cx_didisp16:
	or_reg16_idxdisp16 r5 r11
or_dx_didisp16:
	or_reg16_idxdisp16 r6 r11
or_bx_didisp16:
	or_reg16_idxdisp16 r7 r11
or_sp_didisp16:
	or_reg16_idxdisp16 r8 r11
or_bp_didisp16:
	or_reg16_idxdisp16 r9 r11
or_si_didisp16:
	or_reg16_idxdisp16 r10 r11
or_di_didisp16:
	or_reg16_idxdisp16 r11 r11

or_ax_bxdisp16:
	or_reg16_idxdisp16 r4 r7
or_cx_bxdisp16:
	or_reg16_idxdisp16 r5 r7
or_dx_bxdisp16:
	or_reg16_idxdisp16 r6 r7
or_bx_bxdisp16:
	or_reg16_idxdisp16 r7 r7
or_sp_bxdisp16:
	or_reg16_idxdisp16 r8 r7
or_bp_bxdisp16:
	or_reg16_idxdisp16 r9 r7
or_si_bxdisp16:
	or_reg16_idxdisp16 r10 r7
or_di_bxdisp16:
	or_reg16_idxdisp16 r11 r7

.macro or_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		or_r16_r0_bp_\reg
.endm

or_ax_bpdisp16:
	or_reg16_bpdisp16 r4
or_cx_bpdisp16:
	or_reg16_bpdisp16 r5
or_dx_bpdisp16:
	or_reg16_bpdisp16 r6
or_bx_bpdisp16:
	or_reg16_bpdisp16 r7
or_sp_bpdisp16:
	or_reg16_bpdisp16 r8
or_bp_bpdisp16:
	or_reg16_bpdisp16 r9
or_si_bpdisp16:
	or_reg16_bpdisp16 r10
or_di_bpdisp16:
	or_reg16_bpdisp16 r11


// --- OR reg16, reg16 ---

.macro or_reg16_reg16 rl rr
	mov		r0, \rl, lsl #16
	mov		r1, \rr, lsl #16
	eor		\rl, r0, lsr #16
	orrs	r0, r1
	orr		\rl, r0, lsr #16
	b		loop
.endm

or_ax_ax:
	or_reg16_reg16		r4 r4
or_ax_cx:
	or_reg16_reg16		r4 r5
or_ax_dx:
	or_reg16_reg16		r4 r6
or_ax_bx:
	or_reg16_reg16		r4 r7
or_ax_sp:
	or_reg16_reg16		r4 r8
or_ax_bp:
	or_reg16_reg16		r4 r9
or_ax_si:
	or_reg16_reg16		r4 r10
or_ax_di:
	or_reg16_reg16		r4 r11
or_cx_ax:
	or_reg16_reg16		r5 r4
or_cx_cx:
	or_reg16_reg16		r5 r5
or_cx_dx:
	or_reg16_reg16		r5 r6
or_cx_bx:
	or_reg16_reg16		r5 r7
or_cx_sp:
	or_reg16_reg16		r5 r8
or_cx_bp:
	or_reg16_reg16		r5 r9
or_cx_si:
	or_reg16_reg16		r5 r10
or_cx_di:
	or_reg16_reg16		r5 r11
or_dx_ax:
	or_reg16_reg16		r6 r4
or_dx_cx:
	or_reg16_reg16		r6 r5
or_dx_dx:
	or_reg16_reg16		r6 r6
or_dx_bx:
	or_reg16_reg16		r6 r7
or_dx_sp:
	or_reg16_reg16		r6 r8
or_dx_bp:
	or_reg16_reg16		r6 r9
or_dx_si:
	or_reg16_reg16		r6 r10
or_dx_di:
	or_reg16_reg16		r6 r11
or_bx_ax:
	or_reg16_reg16		r7 r4
or_bx_cx:
	or_reg16_reg16		r7 r5
or_bx_dx:
	or_reg16_reg16		r7 r6
or_bx_bx:
	or_reg16_reg16		r7 r7
or_bx_sp:
	or_reg16_reg16		r7 r8
or_bx_bp:
	or_reg16_reg16		r7 r9
or_bx_si:
	or_reg16_reg16		r7 r10
or_bx_di:
	or_reg16_reg16		r7 r11

or_sp_ax:
	or_reg16_reg16		r8 r4
or_sp_cx:
	or_reg16_reg16		r8 r5
or_sp_dx:
	or_reg16_reg16		r8 r6
or_sp_bx:
	or_reg16_reg16		r8 r7
or_sp_sp:
	or_reg16_reg16		r8 r8
or_sp_bp:
	or_reg16_reg16		r8 r9
or_sp_si:
	or_reg16_reg16		r8 r10
or_sp_di:
	or_reg16_reg16		r8 r11

or_bp_ax:
	or_reg16_reg16		r9 r4
or_bp_cx:
	or_reg16_reg16		r9 r5
or_bp_dx:
	or_reg16_reg16		r9 r6
or_bp_bx:
	or_reg16_reg16		r9 r7
or_bp_sp:
	or_reg16_reg16		r9 r8
or_bp_bp:
	or_reg16_reg16		r9 r9
or_bp_si:
	or_reg16_reg16		r9 r10
or_bp_di:
	or_reg16_reg16		r9 r11
or_si_ax:
	or_reg16_reg16		r10 r4
or_si_cx:
	or_reg16_reg16		r10 r5
or_si_dx:
	or_reg16_reg16		r10 r6
or_si_bx:
	or_reg16_reg16		r10 r7
or_si_sp:
	or_reg16_reg16		r10 r8
or_si_bp:
	or_reg16_reg16		r10 r9
or_si_si:
	or_reg16_reg16		r10 r10
or_si_di:
	or_reg16_reg16		r10 r11
or_di_ax:
	or_reg16_reg16		r11 r4
or_di_cx:
	or_reg16_reg16		r11 r5
or_di_dx:
	or_reg16_reg16		r11 r6
or_di_bx:
	or_reg16_reg16		r11 r7
or_di_sp:
	or_reg16_reg16		r11 r8
or_di_bp:
	or_reg16_reg16		r11 r9
or_di_si:
	or_reg16_reg16		r11 r10
or_di_di:
	or_reg16_reg16		r11 r11


#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

// ------------------- 0C = OR AL,imm8 --------------------------------
op_0c:
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	ldrb	r0,[r12],#1				// Load imm8 to r0, increment r12 by 1
	mov		r1, eax, lsl #24
	orrs	r1, r0, lsl #24
	bic		eax, #0xFF
	orr		eax, r1, lsr #24
	b		loop

// ------------------- 0D = OR AX,imm16 --------------------------------
op_0d:
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load high byte to r0, increment r12 by 1
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	lsl		r1, eax, #16
	eor		eax, r1, lsr #16
	orrs	r0, r1, r0, lsl #16
	orr		eax, r0, lsr #16
	b		loop

// ------------------- 0E = PUSH CS ------------------------------------
op_0e:
	ldr		r0, [sp, #SP_CS_VALUE]	// r0 = Current logical CS
	push_hword r0 r1 r2
	b		loop

	.ltorg							// Dump the current literal pool here

	.text
	.align	2

// ------------------- 0F = protected mode opcodes ---------------------
// See "cpu_prot.s"


// ------------------- 10 = ADC r/m8, r8 -------------------------------
//
// All modrm variations supported!
//
//
op_10:
	modrm_jump_16
// 0
	.word adc_bxsi_al, adc_bxdi_al, adc_bpsi_al, adc_bpdi_al, adc_siidx_al, adc_diidx_al, adc_disp16_al, adc_bxidx_al
	.word adc_bxsi_cl, adc_bxdi_cl, adc_bpsi_cl, adc_bpdi_cl, adc_siidx_cl, adc_diidx_cl, adc_disp16_cl, adc_bxidx_cl
	.word adc_bxsi_dl, adc_bxdi_dl, adc_bpsi_dl, adc_bpdi_dl, adc_siidx_dl, adc_diidx_dl, adc_disp16_dl, adc_bxidx_dl
	.word adc_bxsi_bl, adc_bxdi_bl, adc_bpsi_bl, adc_bpdi_bl, adc_siidx_bl, adc_diidx_bl, adc_disp16_bl, adc_bxidx_bl
	.word adc_bxsi_ah, adc_bxdi_ah, adc_bpsi_ah, adc_bpdi_ah, adc_siidx_ah, adc_diidx_ah, adc_disp16_ah, adc_bxidx_ah
	.word adc_bxsi_ch, adc_bxdi_ch, adc_bpsi_ch, adc_bpdi_ch, adc_siidx_ch, adc_diidx_ch, adc_disp16_ch, adc_bxidx_ch
	.word adc_bxsi_dh, adc_bxdi_dh, adc_bpsi_dh, adc_bpdi_dh, adc_siidx_dh, adc_diidx_dh, adc_disp16_dh, adc_bxidx_dh
	.word adc_bxsi_bh, adc_bxdi_bh, adc_bpsi_bh, adc_bpdi_bh, adc_siidx_bh, adc_diidx_bh, adc_disp16_bh, adc_bxidx_bh
//0x40
	.word adc_bxsid8_al, adc_bxdid8_al, adc_bpsid8_al, adc_bpdid8_al, adc_sidisp8_al, adc_didisp8_al, adc_bpdisp8_al, adc_bxdisp8_al
	.word adc_bxsid8_cl, adc_bxdid8_cl, adc_bpsid8_cl, adc_bpdid8_cl, adc_sidisp8_cl, adc_didisp8_cl, adc_bpdisp8_cl, adc_bxdisp8_cl
	.word adc_bxsid8_dl, adc_bxdid8_dl, adc_bpsid8_dl, adc_bpdid8_dl, adc_sidisp8_dl, adc_didisp8_dl, adc_bpdisp8_dl, adc_bxdisp8_dl
	.word adc_bxsid8_bl, adc_bxdid8_bl, adc_bpsid8_bl, adc_bpdid8_bl, adc_sidisp8_bl, adc_didisp8_bl, adc_bpdisp8_bl, adc_bxdisp8_bl
	.word adc_bxsid8_ah, adc_bxdid8_ah, adc_bpsid8_ah, adc_bpdid8_ah, adc_sidisp8_ah, adc_didisp8_ah, adc_bpdisp8_ah, adc_bxdisp8_ah
	.word adc_bxsid8_ch, adc_bxdid8_ch, adc_bpsid8_ch, adc_bpdid8_ch, adc_sidisp8_ch, adc_didisp8_ch, adc_bpdisp8_ch, adc_bxdisp8_ch
	.word adc_bxsid8_dh, adc_bxdid8_dh, adc_bpsid8_dh, adc_bpdid8_dh, adc_sidisp8_dh, adc_didisp8_dh, adc_bpdisp8_dh, adc_bxdisp8_dh
	.word adc_bxsid8_bh, adc_bxdid8_bh, adc_bpsid8_bh, adc_bpdid8_bh, adc_sidisp8_bh, adc_didisp8_bh, adc_bpdisp8_bh, adc_bxdisp8_bh
//0x80
	.word adc_bxsid16_al, adc_bxdid16_al, adc_bpsid16_al, adc_bpdid16_al, adc_sidisp16_al, adc_didisp16_al, adc_bpdisp16_al, adc_bxdisp16_al
	.word adc_bxsid16_cl, adc_bxdid16_cl, adc_bpsid16_cl, adc_bpdid16_cl, adc_sidisp16_cl, adc_didisp16_cl, adc_bpdisp16_cl, adc_bxdisp16_cl
	.word adc_bxsid16_dl, adc_bxdid16_dl, adc_bpsid16_dl, adc_bpdid16_dl, adc_sidisp16_dl, adc_didisp16_dl, adc_bpdisp16_dl, adc_bxdisp16_dl
	.word adc_bxsid16_bl, adc_bxdid16_bl, adc_bpsid16_bl, adc_bpdid16_bl, adc_sidisp16_bl, adc_didisp16_bl, adc_bpdisp16_bl, adc_bxdisp16_bl
	.word adc_bxsid16_ah, adc_bxdid16_ah, adc_bpsid16_ah, adc_bpdid16_ah, adc_sidisp16_ah, adc_didisp16_ah, adc_bpdisp16_ah, adc_bxdisp16_ah
	.word adc_bxsid16_ch, adc_bxdid16_ch, adc_bpsid16_ch, adc_bpdid16_ch, adc_sidisp16_ch, adc_didisp16_ch, adc_bpdisp16_ch, adc_bxdisp16_ch
	.word adc_bxsid16_dh, adc_bxdid16_dh, adc_bpsid16_dh, adc_bpdid16_dh, adc_sidisp16_dh, adc_didisp16_dh, adc_bpdisp16_dh, adc_bxdisp16_dh
	.word adc_bxsid16_bh, adc_bxdid16_bh, adc_bpsid16_bh, adc_bpdid16_bh, adc_sidisp16_bh, adc_didisp16_bh, adc_bpdisp16_bh, adc_bxdisp16_bh
// 0xC0 = two register operands
	.word adc_al_al, adc_cl_al, adc_dl_al, adc_bl_al, adc_ah_al, adc_ch_al, adc_dh_al, adc_bh_al
	.word adc_al_cl, adc_cl_cl, adc_dl_cl, adc_bl_cl, adc_ah_cl, adc_ch_cl, adc_dh_cl, adc_bh_cl
	.word adc_al_dl, adc_cl_dl, adc_dl_dl, adc_bl_dl, adc_ah_dl, adc_ch_dl, adc_dh_dl, adc_bh_dl
	.word adc_al_bl, adc_cl_bl, adc_dl_bl, adc_bl_bl, adc_ah_bl, adc_ch_bl, adc_dh_bl, adc_bh_bl
	.word adc_al_ah, adc_cl_ah, adc_dl_ah, adc_bl_ah, adc_ah_ah, adc_ch_ah, adc_dh_ah, adc_bh_ah
	.word adc_al_ch, adc_cl_ch, adc_dl_ch, adc_bl_ch, adc_ah_ch, adc_ch_ch, adc_dh_ch, adc_bh_ch
	.word adc_al_dh, adc_cl_dh, adc_dl_dh, adc_bl_dh, adc_ah_dh, adc_ch_dh, adc_dh_dh, adc_bh_dh
	.word adc_al_bh, adc_cl_bh, adc_dl_bh, adc_bl_bh, adc_ah_bh, adc_ch_bh, adc_dh_bh, adc_bh_bh

// These are called from "cpu_386.s":

	.global	adc_siidx_al, adc_siidx_cl, adc_siidx_dl, adc_siidx_bl, adc_siidx_ah, adc_siidx_ch, adc_siidx_dh, adc_siidx_bh
	.global	adc_diidx_al, adc_diidx_cl, adc_diidx_dl, adc_diidx_bl, adc_diidx_ah, adc_diidx_ch, adc_diidx_dh, adc_diidx_bh
	.global	adc_bxidx_al, adc_bxidx_cl, adc_bxidx_dl, adc_bxidx_bl, adc_bxidx_ah, adc_bxidx_ch, adc_bxidx_dh, adc_bxidx_bh
	.global	adc_sidisp8_al, adc_sidisp8_cl, adc_sidisp8_dl, adc_sidisp8_bl, adc_sidisp8_ah, adc_sidisp8_ch, adc_sidisp8_dh, adc_sidisp8_bh
	.global	adc_didisp8_al, adc_didisp8_cl, adc_didisp8_dl, adc_didisp8_bl, adc_didisp8_ah, adc_didisp8_ch, adc_didisp8_dh, adc_didisp8_bh
	.global	adc_bpdisp8_al, adc_bpdisp8_cl, adc_bpdisp8_dl, adc_bpdisp8_bl, adc_bpdisp8_ah, adc_bpdisp8_ch, adc_bpdisp8_dh, adc_bpdisp8_bh
	.global	adc_bxdisp8_al, adc_bxdisp8_cl, adc_bxdisp8_dl, adc_bxdisp8_bl, adc_bxdisp8_ah, adc_bxdisp8_ch, adc_bxdisp8_dh, adc_bxdisp8_bh

.macro adc_r0_reg8l reg
	.global	adc_r0_r8l_bp_\reg
adc_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	adc_r0_r8l_\reg
adc_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_10_RAM_l_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory adcress
	//-------
.op_10_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	lsl		r0, #24
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, \reg, lsl #24		// Perform the actual addition, setting the resulting flags.
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to [physical segment + disp16]
	b		loop
.endm
.macro adc_r0_reg8h reg
	.global	adc_r0_r8h_bp_\reg
adc_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	adc_r0_r8h_\reg
adc_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_10_RAM_h_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory adcress
	//-------
.op_10_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r0, #24
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, lsl #16			// Perform the actual addition, setting the resulting flags.
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to RAM
	b		loop
.endm

	adc_r0_reg8l r4
	adc_r0_reg8l r5
	adc_r0_reg8l r6
	adc_r0_reg8l r7
	adc_r0_reg8h r4
	adc_r0_reg8h r5
	adc_r0_reg8h r6
	adc_r0_reg8h r7

	.ltorg

// --- [idx] ---

.macro adc_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		adc_r0_r8l_\reg
.endm
.macro adc_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		adc_r0_r8h_\reg
.endm

adc_bxsi_al:
	adc_bxidx_reg8l r10 r4
adc_bxsi_cl:
	adc_bxidx_reg8l r10 r5
adc_bxsi_dl:
	adc_bxidx_reg8l r10 r6
adc_bxsi_bl:
	adc_bxidx_reg8l r10 r7
adc_bxsi_ah:
	adc_bxidx_reg8h r10 r4
adc_bxsi_ch:
	adc_bxidx_reg8h r10 r5
adc_bxsi_dh:
	adc_bxidx_reg8h r10 r6
adc_bxsi_bh:
	adc_bxidx_reg8h r10 r7

adc_bxdi_al:
	adc_bxidx_reg8l r11 r4
adc_bxdi_cl:
	adc_bxidx_reg8l r11 r5
adc_bxdi_dl:
	adc_bxidx_reg8l r11 r6
adc_bxdi_bl:
	adc_bxidx_reg8l r11 r7
adc_bxdi_ah:
	adc_bxidx_reg8h r11 r4
adc_bxdi_ch:
	adc_bxidx_reg8h r11 r5
adc_bxdi_dh:
	adc_bxidx_reg8h r11 r6
adc_bxdi_bh:
	adc_bxidx_reg8h r11 r7

.macro adc_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		adc_r0_r8l_bp_\reg
.endm
.macro adc_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		adc_r0_r8h_bp_\reg
.endm

adc_bpsi_al:
	adc_bpidx_reg8l r10 r4
adc_bpsi_cl:
	adc_bpidx_reg8l r10 r5
adc_bpsi_dl:
	adc_bpidx_reg8l r10 r6
adc_bpsi_bl:
	adc_bpidx_reg8l r10 r7
adc_bpsi_ah:
	adc_bpidx_reg8h r10 r4
adc_bpsi_ch:
	adc_bpidx_reg8h r10 r5
adc_bpsi_dh:
	adc_bpidx_reg8h r10 r6
adc_bpsi_bh:
	adc_bpidx_reg8h r10 r7

adc_bpdi_al:
	adc_bpidx_reg8l r11 r4
adc_bpdi_cl:
	adc_bpidx_reg8l r11 r5
adc_bpdi_dl:
	adc_bpidx_reg8l r11 r6
adc_bpdi_bl:
	adc_bpidx_reg8l r11 r7
adc_bpdi_ah:
	adc_bpidx_reg8h r11 r4
adc_bpdi_ch:
	adc_bpidx_reg8h r11 r5
adc_bpdi_dh:
	adc_bpidx_reg8h r11 r6
adc_bpdi_bh:
	adc_bpidx_reg8h r11 r7

.macro adc_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		adc_r0_r8l_\reg
.endm
.macro adc_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		adc_r0_r8h_\reg
.endm

adc_siidx_al:
	adc_idx_reg8l r10 r4
adc_siidx_cl:
	adc_idx_reg8l r10 r5
adc_siidx_dl:
	adc_idx_reg8l r10 r6
adc_siidx_bl:
	adc_idx_reg8l r10 r7
adc_siidx_ah:
	adc_idx_reg8h r10 r4
adc_siidx_ch:
	adc_idx_reg8h r10 r5
adc_siidx_dh:
	adc_idx_reg8h r10 r6
adc_siidx_bh:
	adc_idx_reg8h r10 r7

adc_diidx_al:
	adc_idx_reg8l r11 r4
adc_diidx_cl:
	adc_idx_reg8l r11 r5
adc_diidx_dl:
	adc_idx_reg8l r11 r6
adc_diidx_bl:
	adc_idx_reg8l r11 r7
adc_diidx_ah:
	adc_idx_reg8h r11 r4
adc_diidx_ch:
	adc_idx_reg8h r11 r5
adc_diidx_dh:
	adc_idx_reg8h r11 r6
adc_diidx_bh:
	adc_idx_reg8h r11 r7

adc_bxidx_al:
	adc_idx_reg8l r7 r4
adc_bxidx_cl:
	adc_idx_reg8l r7 r5
adc_bxidx_dl:
	adc_idx_reg8l r7 r6
adc_bxidx_bl:
	adc_idx_reg8l r7 r7
adc_bxidx_ah:
	adc_idx_reg8h r7 r4
adc_bxidx_ch:
	adc_idx_reg8h r7 r5
adc_bxidx_dh:
	adc_idx_reg8h r7 r6
adc_bxidx_bh:
	adc_idx_reg8h r7 r7
	
.macro adc_disp16_reg8l reg
	r0_from_disp16
	b		adc_r0_r8l_\reg
.endm

.macro adc_disp16_reg8h reg
	r0_from_disp16
	b		adc_r0_r8h_\reg
.endm

adc_disp16_al:
	adc_disp16_reg8l r4
adc_disp16_cl:
	adc_disp16_reg8l r5
adc_disp16_dl:
	adc_disp16_reg8l r6
adc_disp16_bl:
	adc_disp16_reg8l r7
adc_disp16_ah:
	adc_disp16_reg8h r4
adc_disp16_ch:
	adc_disp16_reg8h r5
adc_disp16_dh:
	adc_disp16_reg8h r6
adc_disp16_bh:
	adc_disp16_reg8h r7

// --- [idx+disp8] ---

.macro adc_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		adc_r0_r8l_\reg
.endm
.macro adc_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		adc_r0_r8h_\reg
.endm

adc_bxsid8_al:
	adc_bxidxd8_reg8l r10 r4
adc_bxsid8_cl:
	adc_bxidxd8_reg8l r10 r5
adc_bxsid8_dl:
	adc_bxidxd8_reg8l r10 r6
adc_bxsid8_bl:
	adc_bxidxd8_reg8l r10 r7
adc_bxsid8_ah:
	adc_bxidxd8_reg8h r10 r4
adc_bxsid8_ch:
	adc_bxidxd8_reg8h r10 r5
adc_bxsid8_dh:
	adc_bxidxd8_reg8h r10 r6
adc_bxsid8_bh:
	adc_bxidxd8_reg8h r10 r7

adc_bxdid8_al:
	adc_bxidxd8_reg8l r11 r4
adc_bxdid8_cl:
	adc_bxidxd8_reg8l r11 r5
adc_bxdid8_dl:
	adc_bxidxd8_reg8l r11 r6
adc_bxdid8_bl:
	adc_bxidxd8_reg8l r11 r7
adc_bxdid8_ah:
	adc_bxidxd8_reg8h r11 r4
adc_bxdid8_ch:
	adc_bxidxd8_reg8h r11 r5
adc_bxdid8_dh:
	adc_bxidxd8_reg8h r11 r6
adc_bxdid8_bh:
	adc_bxidxd8_reg8h r11 r7

.macro adc_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		adc_r0_r8l_bp_\reg
.endm
.macro adc_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		adc_r0_r8h_bp_\reg
.endm

adc_bpsid8_al:
	adc_bpidxd8_reg8l r10 r4
adc_bpsid8_cl:
	adc_bpidxd8_reg8l r10 r5
adc_bpsid8_dl:
	adc_bpidxd8_reg8l r10 r6
adc_bpsid8_bl:
	adc_bpidxd8_reg8l r10 r7
adc_bpsid8_ah:
	adc_bpidxd8_reg8h r10 r4
adc_bpsid8_ch:
	adc_bpidxd8_reg8h r10 r5
adc_bpsid8_dh:
	adc_bpidxd8_reg8h r10 r6
adc_bpsid8_bh:
	adc_bpidxd8_reg8h r10 r7

adc_bpdid8_al:
	adc_bpidxd8_reg8l r11 r4
adc_bpdid8_cl:
	adc_bpidxd8_reg8l r11 r5
adc_bpdid8_dl:
	adc_bpidxd8_reg8l r11 r6
adc_bpdid8_bl:
	adc_bpidxd8_reg8l r11 r7
adc_bpdid8_ah:
	adc_bpidxd8_reg8h r11 r4
adc_bpdid8_ch:
	adc_bpidxd8_reg8h r11 r5
adc_bpdid8_dh:
	adc_bpidxd8_reg8h r11 r6
adc_bpdid8_bh:
	adc_bpidxd8_reg8h r11 r7

.macro adc_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		adc_r0_r8l_\reg
.endm
.macro adc_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		adc_r0_r8h_\reg
.endm

adc_sidisp8_al:
	adc_idxdisp8_reg8l r10 r4
adc_sidisp8_cl:
	adc_idxdisp8_reg8l r10 r5
adc_sidisp8_dl:
	adc_idxdisp8_reg8l r10 r6
adc_sidisp8_bl:
	adc_idxdisp8_reg8l r10 r7
adc_sidisp8_ah:
	adc_idxdisp8_reg8h r10 r4
adc_sidisp8_ch:
	adc_idxdisp8_reg8h r10 r5
adc_sidisp8_dh:
	adc_idxdisp8_reg8h r10 r6
adc_sidisp8_bh:
	adc_idxdisp8_reg8h r10 r7

adc_didisp8_al:
	adc_idxdisp8_reg8l r11 r4
adc_didisp8_cl:
	adc_idxdisp8_reg8l r11 r5
adc_didisp8_dl:
	adc_idxdisp8_reg8l r11 r6
adc_didisp8_bl:
	adc_idxdisp8_reg8l r11 r7
adc_didisp8_ah:
	adc_idxdisp8_reg8h r11 r4
adc_didisp8_ch:
	adc_idxdisp8_reg8h r11 r5
adc_didisp8_dh:
	adc_idxdisp8_reg8h r11 r6
adc_didisp8_bh:
	adc_idxdisp8_reg8h r11 r7

adc_bxdisp8_al:
	adc_idxdisp8_reg8l r7 r4
adc_bxdisp8_cl:
	adc_idxdisp8_reg8l r7 r5
adc_bxdisp8_dl:
	adc_idxdisp8_reg8l r7 r6
adc_bxdisp8_bl:
	adc_idxdisp8_reg8l r7 r7
adc_bxdisp8_ah:
	adc_idxdisp8_reg8h r7 r4
adc_bxdisp8_ch:
	adc_idxdisp8_reg8h r7 r5
adc_bxdisp8_dh:
	adc_idxdisp8_reg8h r7 r6
adc_bxdisp8_bh:
	adc_idxdisp8_reg8h r7 r7

.macro adc_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		adc_r0_r8l_bp_\reg
.endm
.macro adc_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		adc_r0_r8h_bp_\reg
.endm

adc_bpdisp8_al:
	adc_bpdisp8_reg8l r4
adc_bpdisp8_cl:
	adc_bpdisp8_reg8l r5
adc_bpdisp8_dl:
	adc_bpdisp8_reg8l r6
adc_bpdisp8_bl:
	adc_bpdisp8_reg8l r7
adc_bpdisp8_ah:
	adc_bpdisp8_reg8h r4
adc_bpdisp8_ch:
	adc_bpdisp8_reg8h r5
adc_bpdisp8_dh:
	adc_bpdisp8_reg8h r6
adc_bpdisp8_bh:
	adc_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro adc_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		adc_r0_r8l_\reg
.endm
.macro adc_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		adc_r0_r8h_\reg
.endm

adc_bxsid16_al:
	adc_bxidxdisp16_reg8l r10 r4
adc_bxsid16_cl:
	adc_bxidxdisp16_reg8l r10 r5
adc_bxsid16_dl:
	adc_bxidxdisp16_reg8l r10 r6
adc_bxsid16_bl:
	adc_bxidxdisp16_reg8l r10 r7
adc_bxsid16_ah:
	adc_bxidxdisp16_reg8h r10 r4
adc_bxsid16_ch:
	adc_bxidxdisp16_reg8h r10 r5
adc_bxsid16_dh:
	adc_bxidxdisp16_reg8h r10 r6
adc_bxsid16_bh:
	adc_bxidxdisp16_reg8h r10 r7

adc_bxdid16_al:
	adc_bxidxdisp16_reg8l r11 r4
adc_bxdid16_cl:
	adc_bxidxdisp16_reg8l r11 r5
adc_bxdid16_dl:
	adc_bxidxdisp16_reg8l r11 r6
adc_bxdid16_bl:
	adc_bxidxdisp16_reg8l r11 r7
adc_bxdid16_ah:
	adc_bxidxdisp16_reg8h r11 r4
adc_bxdid16_ch:
	adc_bxidxdisp16_reg8h r11 r5
adc_bxdid16_dh:
	adc_bxidxdisp16_reg8h r11 r6
adc_bxdid16_bh:
	adc_bxidxdisp16_reg8h r11 r7

.macro adc_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		adc_r0_r8l_bp_\reg
.endm
.macro adc_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		adc_r0_r8h_bp_\reg
.endm

adc_bpsid16_al:
	adc_bpidxd16_reg8l r10 r4
adc_bpsid16_cl:
	adc_bpidxd16_reg8l r10 r5
adc_bpsid16_dl:
	adc_bpidxd16_reg8l r10 r6
adc_bpsid16_bl:
	adc_bpidxd16_reg8l r10 r7
adc_bpsid16_ah:
	adc_bpidxd16_reg8h r10 r4
adc_bpsid16_ch:
	adc_bpidxd16_reg8h r10 r5
adc_bpsid16_dh:
	adc_bpidxd16_reg8h r10 r6
adc_bpsid16_bh:
	adc_bpidxd16_reg8h r10 r7

adc_bpdid16_al:
	adc_bpidxd16_reg8l r11 r4
adc_bpdid16_cl:
	adc_bpidxd16_reg8l r11 r5
adc_bpdid16_dl:
	adc_bpidxd16_reg8l r11 r6
adc_bpdid16_bl:
	adc_bpidxd16_reg8l r11 r7
adc_bpdid16_ah:
	adc_bpidxd16_reg8h r11 r4
adc_bpdid16_ch:
	adc_bpidxd16_reg8h r11 r5
adc_bpdid16_dh:
	adc_bpidxd16_reg8h r11 r6
adc_bpdid16_bh:
	adc_bpidxd16_reg8h r11 r7

.macro adc_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		adc_r0_r8l_\reg
.endm
.macro adc_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		adc_r0_r8h_\reg
.endm

adc_sidisp16_al:
	adc_idxdisp16_reg8l r10 r4
adc_sidisp16_cl:
	adc_idxdisp16_reg8l r10 r5
adc_sidisp16_dl:
	adc_idxdisp16_reg8l r10 r6
adc_sidisp16_bl:
	adc_idxdisp16_reg8l r10 r7
adc_sidisp16_ah:
	adc_idxdisp16_reg8h r10 r4
adc_sidisp16_ch:
	adc_idxdisp16_reg8h r10 r5
adc_sidisp16_dh:
	adc_idxdisp16_reg8h r10 r6
adc_sidisp16_bh:
	adc_idxdisp16_reg8h r10 r7

adc_didisp16_al:
	adc_idxdisp16_reg8l r11 r4
adc_didisp16_cl:
	adc_idxdisp16_reg8l r11 r5
adc_didisp16_dl:
	adc_idxdisp16_reg8l r11 r6
adc_didisp16_bl:
	adc_idxdisp16_reg8l r11 r7
adc_didisp16_ah:
	adc_idxdisp16_reg8h r11 r4
adc_didisp16_ch:
	adc_idxdisp16_reg8h r11 r5
adc_didisp16_dh:
	adc_idxdisp16_reg8h r11 r6
adc_didisp16_bh:
	adc_idxdisp16_reg8h r11 r7

adc_bxdisp16_al:
	adc_idxdisp16_reg8l r7 r4
adc_bxdisp16_cl:
	adc_idxdisp16_reg8l r7 r5
adc_bxdisp16_dl:
	adc_idxdisp16_reg8l r7 r6
adc_bxdisp16_bl:
	adc_idxdisp16_reg8l r7 r7
adc_bxdisp16_ah:
	adc_idxdisp16_reg8h r7 r4
adc_bxdisp16_ch:
	adc_idxdisp16_reg8h r7 r5
adc_bxdisp16_dh:
	adc_idxdisp16_reg8h r7 r6
adc_bxdisp16_bh:
	adc_idxdisp16_reg8h r7 r7

.macro adc_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		adc_r0_r8l_bp_\reg
.endm
.macro adc_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		adc_r0_r8h_bp_\reg
.endm

adc_bpdisp16_al:
	adc_bpdisp16_reg8l r4
adc_bpdisp16_cl:
	adc_bpdisp16_reg8l r5
adc_bpdisp16_dl:
	adc_bpdisp16_reg8l r6
adc_bpdisp16_bl:
	adc_bpdisp16_reg8l r7
adc_bpdisp16_ah:
	adc_bpdisp16_reg8h r4
adc_bpdisp16_ch:
	adc_bpdisp16_reg8h r5
adc_bpdisp16_dh:
	adc_bpdisp16_reg8h r6
adc_bpdisp16_bh:
	adc_bpdisp16_reg8h r7


// ------------------- 11 = ADC r/m16, r16 -----------------------------
//
// All modrm variations supported!
//
//
op_11:
	modrm_jump_16
// 0
	.word adc_bxsi_ax, adc_bxdi_ax, adc_bpsi_ax, adc_bpdi_ax, adc_siidx_ax, adc_diidx_ax, adc_disp16_ax, adc_bxidx_ax
	.word adc_bxsi_cx, adc_bxdi_cx, adc_bpsi_cx, adc_bpdi_cx, adc_siidx_cx, adc_diidx_cx, adc_disp16_cx, adc_bxidx_cx
	.word adc_bxsi_dx, adc_bxdi_dx, adc_bpsi_dx, adc_bpdi_dx, adc_siidx_dx, adc_diidx_dx, adc_disp16_dx, adc_bxidx_dx
	.word adc_bxsi_bx, adc_bxdi_bx, adc_bpsi_bx, adc_bpdi_bx, adc_siidx_bx, adc_diidx_bx, adc_disp16_bx, adc_bxidx_bx
	.word adc_bxsi_sp, adc_bxdi_sp, adc_bpsi_sp, adc_bpdi_sp, adc_siidx_sp, adc_diidx_sp, adc_disp16_sp, adc_bxidx_sp
	.word adc_bxsi_bp, adc_bxdi_bp, adc_bpsi_bp, adc_bpdi_bp, adc_siidx_bp, adc_diidx_bp, adc_disp16_bp, adc_bxidx_bp
	.word adc_bxsi_si, adc_bxdi_si, adc_bpsi_si, adc_bpdi_si, adc_siidx_si, adc_diidx_si, adc_disp16_si, adc_bxidx_si
	.word adc_bxsi_di, adc_bxdi_di, adc_bpsi_di, adc_bpdi_di, adc_siidx_di, adc_diidx_di, adc_disp16_di, adc_bxidx_di
//0x40
	.word adc_bxsid8_ax, adc_bxdid8_ax, adc_bpsid8_ax, adc_bpdid8_ax, adc_sidisp8_ax, adc_didisp8_ax, adc_bpdisp8_ax, adc_bxdisp8_ax
	.word adc_bxsid8_cx, adc_bxdid8_cx, adc_bpsid8_cx, adc_bpdid8_cx, adc_sidisp8_cx, adc_didisp8_cx, adc_bpdisp8_cx, adc_bxdisp8_cx
	.word adc_bxsid8_dx, adc_bxdid8_dx, adc_bpsid8_dx, adc_bpdid8_dx, adc_sidisp8_dx, adc_didisp8_dx, adc_bpdisp8_dx, adc_bxdisp8_dx
	.word adc_bxsid8_bx, adc_bxdid8_bx, adc_bpsid8_bx, adc_bpdid8_bx, adc_sidisp8_bx, adc_didisp8_bx, adc_bpdisp8_bx, adc_bxdisp8_bx
	.word adc_bxsid8_sp, adc_bxdid8_sp, adc_bpsid8_sp, adc_bpdid8_sp, adc_sidisp8_sp, adc_didisp8_sp, adc_bpdisp8_sp, adc_bxdisp8_sp
	.word adc_bxsid8_bp, adc_bxdid8_bp, adc_bpsid8_bp, adc_bpdid8_bp, adc_sidisp8_bp, adc_didisp8_bp, adc_bpdisp8_bp, adc_bxdisp8_bp
	.word adc_bxsid8_si, adc_bxdid8_si, adc_bpsid8_si, adc_bpdid8_si, adc_sidisp8_si, adc_didisp8_si, adc_bpdisp8_si, adc_bxdisp8_si
	.word adc_bxsid8_di, adc_bxdid8_di, adc_bpsid8_di, adc_bpdid8_di, adc_sidisp8_di, adc_didisp8_di, adc_bpdisp8_di, adc_bxdisp8_di
//0x80
	.word adc_bxsid16_ax, adc_bxdid16_ax, adc_bpsid16_ax, adc_bpdid16_ax, adc_sidisp16_ax, adc_didisp16_ax, adc_bpdisp16_ax, adc_bxdisp16_ax
	.word adc_bxsid16_cx, adc_bxdid16_cx, adc_bpsid16_cx, adc_bpdid16_cx, adc_sidisp16_cx, adc_didisp16_cx, adc_bpdisp16_cx, adc_bxdisp16_cx
	.word adc_bxsid16_dx, adc_bxdid16_dx, adc_bpsid16_dx, adc_bpdid16_dx, adc_sidisp16_dx, adc_didisp16_dx, adc_bpdisp16_dx, adc_bxdisp16_dx
	.word adc_bxsid16_bx, adc_bxdid16_bx, adc_bpsid16_bx, adc_bpdid16_bx, adc_sidisp16_bx, adc_didisp16_bx, adc_bpdisp16_bx, adc_bxdisp16_bx
	.word adc_bxsid16_sp, adc_bxdid16_sp, adc_bpsid16_sp, adc_bpdid16_sp, adc_sidisp16_sp, adc_didisp16_sp, adc_bpdisp16_sp, adc_bxdisp16_sp
	.word adc_bxsid16_bp, adc_bxdid16_bp, adc_bpsid16_bp, adc_bpdid16_bp, adc_sidisp16_bp, adc_didisp16_bp, adc_bpdisp16_bp, adc_bxdisp16_bp
	.word adc_bxsid16_si, adc_bxdid16_si, adc_bpsid16_si, adc_bpdid16_si, adc_sidisp16_si, adc_didisp16_si, adc_bpdisp16_si, adc_bxdisp16_si
	.word adc_bxsid16_di, adc_bxdid16_di, adc_bpsid16_di, adc_bpdid16_di, adc_sidisp16_di, adc_didisp16_di, adc_bpdisp16_di, adc_bxdisp16_di
// 0xC0 = two register operands
	.word adc_ax_ax, adc_cx_ax, adc_dx_ax, adc_bx_ax, adc_sp_ax, adc_bp_ax, adc_si_ax, adc_di_ax
	.word adc_ax_cx, adc_cx_cx, adc_dx_cx, adc_bx_cx, adc_sp_cx, adc_bp_cx, adc_si_cx, adc_di_cx
	.word adc_ax_dx, adc_cx_dx, adc_dx_dx, adc_bx_dx, adc_sp_dx, adc_bp_dx, adc_si_dx, adc_di_dx
	.word adc_ax_bx, adc_cx_bx, adc_dx_bx, adc_bx_bx, adc_sp_bx, adc_bp_bx, adc_si_bx, adc_di_bx
	.word adc_ax_sp, adc_cx_sp, adc_dx_sp, adc_bx_sp, adc_sp_sp, adc_bp_sp, adc_si_sp, adc_di_sp
	.word adc_ax_bp, adc_cx_bp, adc_dx_bp, adc_bx_bp, adc_sp_bp, adc_bp_bp, adc_si_bp, adc_di_bp
	.word adc_ax_si, adc_cx_si, adc_dx_si, adc_bx_si, adc_sp_si, adc_bp_si, adc_si_si, adc_di_si
	.word adc_ax_di, adc_cx_di, adc_dx_di, adc_bx_di, adc_sp_di, adc_bp_di, adc_si_di, adc_di_di

// These are called from "cpu_67.s":

	.global adc_siidx_ax, adc_diidx_ax, adc_bxidx_ax
	.global adc_siidx_cx, adc_diidx_cx, adc_bxidx_cx
	.global adc_siidx_dx, adc_diidx_dx, adc_bxidx_dx
	.global adc_siidx_bx, adc_diidx_bx, adc_bxidx_bx
	.global adc_siidx_sp, adc_diidx_sp, adc_bxidx_sp
	.global adc_siidx_bp, adc_diidx_bp, adc_bxidx_bp
	.global adc_siidx_si, adc_diidx_si, adc_bxidx_si
	.global adc_siidx_di, adc_diidx_di, adc_bxidx_di
	.global adc_sidisp8_ax, adc_didisp8_ax, adc_bpdisp8_ax, adc_bxdisp8_ax
	.global adc_sidisp8_cx, adc_didisp8_cx, adc_bpdisp8_cx, adc_bxdisp8_cx
	.global adc_sidisp8_dx, adc_didisp8_dx, adc_bpdisp8_dx, adc_bxdisp8_dx
	.global adc_sidisp8_bx, adc_didisp8_bx, adc_bpdisp8_bx, adc_bxdisp8_bx
	.global adc_sidisp8_sp, adc_didisp8_sp, adc_bpdisp8_sp, adc_bxdisp8_sp
	.global adc_sidisp8_bp, adc_didisp8_bp, adc_bpdisp8_bp, adc_bxdisp8_bp
	.global adc_sidisp8_si, adc_didisp8_si, adc_bpdisp8_si, adc_bxdisp8_si
	.global adc_sidisp8_di, adc_didisp8_di, adc_bpdisp8_di, adc_bxdisp8_di
	.global adc_ax_ax, adc_cx_ax, adc_dx_ax, adc_bx_ax, adc_sp_ax, adc_bp_ax, adc_si_ax, adc_di_ax
	.global adc_ax_cx, adc_cx_cx, adc_dx_cx, adc_bx_cx, adc_sp_cx, adc_bp_cx, adc_si_cx, adc_di_cx
	.global adc_ax_dx, adc_cx_dx, adc_dx_dx, adc_bx_dx, adc_sp_dx, adc_bp_dx, adc_si_dx, adc_di_dx
	.global adc_ax_bx, adc_cx_bx, adc_dx_bx, adc_bx_bx, adc_sp_bx, adc_bp_bx, adc_si_bx, adc_di_bx
	.global adc_ax_sp, adc_cx_sp, adc_dx_sp, adc_bx_sp, adc_sp_sp, adc_bp_sp, adc_si_sp, adc_di_sp
	.global adc_ax_bp, adc_cx_bp, adc_dx_bp, adc_bx_bp, adc_sp_bp, adc_bp_bp, adc_si_bp, adc_di_bp
	.global adc_ax_si, adc_cx_si, adc_dx_si, adc_bx_si, adc_sp_si, adc_bp_si, adc_si_si, adc_di_si
	.global adc_ax_di, adc_cx_di, adc_dx_di, adc_bx_di, adc_sp_di, adc_bp_di, adc_si_di, adc_di_di
	.global	adc_r0_r16_bp_r4, adc_r0_r16_bp_r5, adc_r0_r16_bp_r6, adc_r0_r16_bp_r7, adc_r0_r16_bp_r8, adc_r0_r16_bp_r9, adc_r0_r16_bp_r10, adc_r0_r16_bp_r11, adc_r0_r16_bp_r4
	.global	adc_r0_r16_r4, adc_r0_r16_r5, adc_r0_r16_r6, adc_r0_r16_r7, adc_r0_r16_r8, adc_r0_r16_r9, adc_r0_r16_r10, adc_r0_r16_r11, adc_r0_r16_r4

.macro adc_r0_r16_reg reg
adc_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
adc_r0_r16_\reg:
	mem_handler_jump_r0r3 .op_11_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory adcress
	//-------
.op_11_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	lsl		r0, #16
	orr		r0, r1, lsl #24			// r0 = low byte | (high byte << 8)
	addcs	r0, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, \reg, lsl #16		// Perform the actual addition, setting the resulting flags.
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		loop
.endm

	adc_r0_r16_reg r4
	adc_r0_r16_reg r5
	adc_r0_r16_reg r6
	adc_r0_r16_reg r7
	adc_r0_r16_reg r8
	adc_r0_r16_reg r9
	adc_r0_r16_reg r10
	adc_r0_r16_reg r11

	.ltorg

// --- [idx] ----

.macro adc_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		adc_r0_r16_\reg
.endm

adc_bxsi_ax:
	adc_bxidx_reg16 r10 r4
adc_bxsi_cx:
	adc_bxidx_reg16 r10 r5
adc_bxsi_dx:
	adc_bxidx_reg16 r10 r6
adc_bxsi_bx:
	adc_bxidx_reg16 r10 r7
adc_bxsi_sp:
	adc_bxidx_reg16 r10 r8
adc_bxsi_bp:
	adc_bxidx_reg16 r10 r9
adc_bxsi_si:
	adc_bxidx_reg16 r10 r10
adc_bxsi_di:
	adc_bxidx_reg16 r10 r11

adc_bxdi_ax:
	adc_bxidx_reg16 r11 r4
adc_bxdi_cx:
	adc_bxidx_reg16 r11 r5
adc_bxdi_dx:
	adc_bxidx_reg16 r11 r6
adc_bxdi_bx:
	adc_bxidx_reg16 r11 r7
adc_bxdi_sp:
	adc_bxidx_reg16 r11 r8
adc_bxdi_bp:
	adc_bxidx_reg16 r11 r9
adc_bxdi_si:
	adc_bxidx_reg16 r11 r10
adc_bxdi_di:
	adc_bxidx_reg16 r11 r11

.macro adc_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		adc_r0_r16_bp_\reg
.endm

adc_bpsi_ax:
	adc_bpidx_reg16 r10 r4
adc_bpsi_cx:
	adc_bpidx_reg16 r10 r5
adc_bpsi_dx:
	adc_bpidx_reg16 r10 r6
adc_bpsi_bx:
	adc_bpidx_reg16 r10 r7
adc_bpsi_sp:
	adc_bpidx_reg16 r10 r8
adc_bpsi_bp:
	adc_bpidx_reg16 r10 r9
adc_bpsi_si:
	adc_bpidx_reg16 r10 r10
adc_bpsi_di:
	adc_bpidx_reg16 r10 r11

adc_bpdi_ax:
	adc_bpidx_reg16 r11 r4
adc_bpdi_cx:
	adc_bpidx_reg16 r11 r5
adc_bpdi_dx:
	adc_bpidx_reg16 r11 r6
adc_bpdi_bx:
	adc_bpidx_reg16 r11 r7
adc_bpdi_sp:
	adc_bpidx_reg16 r11 r8
adc_bpdi_bp:
	adc_bpidx_reg16 r11 r9
adc_bpdi_si:
	adc_bpidx_reg16 r11 r10
adc_bpdi_di:
	adc_bpidx_reg16 r11 r11

.macro adc_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		adc_r0_r16_\reg
.endm

adc_siidx_ax:
	adc_idx_reg16 r10 r4
adc_siidx_cx:
	adc_idx_reg16 r10 r5
adc_siidx_dx:
	adc_idx_reg16 r10 r6
adc_siidx_bx:
	adc_idx_reg16 r10 r7
adc_siidx_sp:
	adc_idx_reg16 r10 r8
adc_siidx_bp:
	adc_idx_reg16 r10 r9
adc_siidx_si:
	adc_idx_reg16 r10 r10
adc_siidx_di:
	adc_idx_reg16 r10 r11

adc_diidx_ax:
	adc_idx_reg16 r11 r4
adc_diidx_cx:
	adc_idx_reg16 r11 r5
adc_diidx_dx:
	adc_idx_reg16 r11 r6
adc_diidx_bx:
	adc_idx_reg16 r11 r7
adc_diidx_sp:
	adc_idx_reg16 r11 r8
adc_diidx_bp:
	adc_idx_reg16 r11 r9
adc_diidx_si:
	adc_idx_reg16 r11 r10
adc_diidx_di:
	adc_idx_reg16 r11 r11

adc_bxidx_ax:
	adc_idx_reg16 r7 r4
adc_bxidx_cx:
	adc_idx_reg16 r7 r5
adc_bxidx_dx:
	adc_idx_reg16 r7 r6
adc_bxidx_bx:
	adc_idx_reg16 r7 r7
adc_bxidx_sp:
	adc_idx_reg16 r7 r8
adc_bxidx_bp:
	adc_idx_reg16 r7 r9
adc_bxidx_si:
	adc_idx_reg16 r7 r10
adc_bxidx_di:
	adc_idx_reg16 r7 r11
	
.macro adc_disp16_reg16 reg
	r0_from_disp16
	b		adc_r0_r16_\reg
.endm

adc_disp16_ax:
	adc_disp16_reg16 r4
adc_disp16_cx:
	adc_disp16_reg16 r5
adc_disp16_dx:
	adc_disp16_reg16 r6
adc_disp16_bx:
	adc_disp16_reg16 r7
adc_disp16_sp:
	adc_disp16_reg16 r8
adc_disp16_bp:
	adc_disp16_reg16 r9
adc_disp16_si:
	adc_disp16_reg16 r10
adc_disp16_di:
	adc_disp16_reg16 r11

// --- [idx+disp8] ----

.macro adc_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		adc_r0_r16_\reg
.endm

adc_bxsid8_ax:
	adc_bxidxd8_reg16 r10 r4
adc_bxsid8_cx:
	adc_bxidxd8_reg16 r10 r5
adc_bxsid8_dx:
	adc_bxidxd8_reg16 r10 r6
adc_bxsid8_bx:
	adc_bxidxd8_reg16 r10 r7
adc_bxsid8_sp:
	adc_bxidxd8_reg16 r10 r8
adc_bxsid8_bp:
	adc_bxidxd8_reg16 r10 r9
adc_bxsid8_si:
	adc_bxidxd8_reg16 r10 r10
adc_bxsid8_di:
	adc_bxidxd8_reg16 r10 r11

adc_bxdid8_ax:
	adc_bxidxd8_reg16 r11 r4
adc_bxdid8_cx:
	adc_bxidxd8_reg16 r11 r5
adc_bxdid8_dx:
	adc_bxidxd8_reg16 r11 r6
adc_bxdid8_bx:
	adc_bxidxd8_reg16 r11 r7
adc_bxdid8_sp:
	adc_bxidxd8_reg16 r11 r8
adc_bxdid8_bp:
	adc_bxidxd8_reg16 r11 r9
adc_bxdid8_si:
	adc_bxidxd8_reg16 r11 r10
adc_bxdid8_di:
	adc_bxidxd8_reg16 r11 r11

.macro adc_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		adc_r0_r16_bp_\reg
.endm

adc_bpsid8_ax:
	adc_bpidxd8_reg16 r10 r4
adc_bpsid8_cx:
	adc_bpidxd8_reg16 r10 r5
adc_bpsid8_dx:
	adc_bpidxd8_reg16 r10 r6
adc_bpsid8_bx:
	adc_bpidxd8_reg16 r10 r7
adc_bpsid8_sp:
	adc_bpidxd8_reg16 r10 r8
adc_bpsid8_bp:
	adc_bpidxd8_reg16 r10 r9
adc_bpsid8_si:
	adc_bpidxd8_reg16 r10 r10
adc_bpsid8_di:
	adc_bpidxd8_reg16 r10 r11

adc_bpdid8_ax:
	adc_bpidxd8_reg16 r11 r4
adc_bpdid8_cx:
	adc_bpidxd8_reg16 r11 r5
adc_bpdid8_dx:
	adc_bpidxd8_reg16 r11 r6
adc_bpdid8_bx:
	adc_bpidxd8_reg16 r11 r7
adc_bpdid8_sp:
	adc_bpidxd8_reg16 r11 r8
adc_bpdid8_bp:
	adc_bpidxd8_reg16 r11 r9
adc_bpdid8_si:
	adc_bpidxd8_reg16 r11 r10
adc_bpdid8_di:
	adc_bpidxd8_reg16 r11 r11

.macro adc_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		adc_r0_r16_\reg
.endm

adc_sidisp8_ax:
	adc_idxdisp8_reg16 r10 r4
adc_sidisp8_cx:
	adc_idxdisp8_reg16 r10 r5
adc_sidisp8_dx:
	adc_idxdisp8_reg16 r10 r6
adc_sidisp8_bx:
	adc_idxdisp8_reg16 r10 r7
adc_sidisp8_sp:
	adc_idxdisp8_reg16 r10 r8
adc_sidisp8_bp:
	adc_idxdisp8_reg16 r10 r9
adc_sidisp8_si:
	adc_idxdisp8_reg16 r10 r10
adc_sidisp8_di:
	adc_idxdisp8_reg16 r10 r11

adc_didisp8_ax:
	adc_idxdisp8_reg16 r11 r4
adc_didisp8_cx:
	adc_idxdisp8_reg16 r11 r5
adc_didisp8_dx:
	adc_idxdisp8_reg16 r11 r6
adc_didisp8_bx:
	adc_idxdisp8_reg16 r11 r7
adc_didisp8_sp:
	adc_idxdisp8_reg16 r11 r8
adc_didisp8_bp:
	adc_idxdisp8_reg16 r11 r9
adc_didisp8_si:
	adc_idxdisp8_reg16 r11 r10
adc_didisp8_di:
	adc_idxdisp8_reg16 r11 r11

adc_bxdisp8_ax:
	adc_idxdisp8_reg16 r7 r4
adc_bxdisp8_cx:
	adc_idxdisp8_reg16 r7 r5
adc_bxdisp8_dx:
	adc_idxdisp8_reg16 r7 r6
adc_bxdisp8_bx:
	adc_idxdisp8_reg16 r7 r7
adc_bxdisp8_sp:
	adc_idxdisp8_reg16 r7 r8
adc_bxdisp8_bp:
	adc_idxdisp8_reg16 r7 r9
adc_bxdisp8_si:
	adc_idxdisp8_reg16 r7 r10
adc_bxdisp8_di:
	adc_idxdisp8_reg16 r7 r11
	
.macro adc_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		adc_r0_r16_bp_\reg
.endm
	
adc_bpdisp8_ax:
	adc_bpdisp8_reg16 r4
adc_bpdisp8_cx:
	adc_bpdisp8_reg16 r5
adc_bpdisp8_dx:
	adc_bpdisp8_reg16 r6
adc_bpdisp8_bx:
	adc_bpdisp8_reg16 r7
adc_bpdisp8_sp:
	adc_bpdisp8_reg16 r8
adc_bpdisp8_bp:
	adc_bpdisp8_reg16 r9
adc_bpdisp8_si:
	adc_bpdisp8_reg16 r10
adc_bpdisp8_di:
	adc_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro adc_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		adc_r0_r16_\reg
.endm

adc_bxsid16_ax:
	adc_bxidxd16_reg16 r10 r4
adc_bxsid16_cx:
	adc_bxidxd16_reg16 r10 r5
adc_bxsid16_dx:
	adc_bxidxd16_reg16 r10 r6
adc_bxsid16_bx:
	adc_bxidxd16_reg16 r10 r7
adc_bxsid16_sp:
	adc_bxidxd16_reg16 r10 r8
adc_bxsid16_bp:
	adc_bxidxd16_reg16 r10 r9
adc_bxsid16_si:
	adc_bxidxd16_reg16 r10 r10
adc_bxsid16_di:
	adc_bxidxd16_reg16 r10 r11

adc_bxdid16_ax:
	adc_bxidxd16_reg16 r11 r4
adc_bxdid16_cx:
	adc_bxidxd16_reg16 r11 r5
adc_bxdid16_dx:
	adc_bxidxd16_reg16 r11 r6
adc_bxdid16_bx:
	adc_bxidxd16_reg16 r11 r7
adc_bxdid16_sp:
	adc_bxidxd16_reg16 r11 r8
adc_bxdid16_bp:
	adc_bxidxd16_reg16 r11 r9
adc_bxdid16_si:
	adc_bxidxd16_reg16 r11 r10
adc_bxdid16_di:
	adc_bxidxd16_reg16 r11 r11

.macro adc_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		adc_r0_r16_bp_\reg
.endm

adc_bpsid16_ax:
	adc_bpidxd16_reg16 r10 r4
adc_bpsid16_cx:
	adc_bpidxd16_reg16 r10 r5
adc_bpsid16_dx:
	adc_bpidxd16_reg16 r10 r6
adc_bpsid16_bx:
	adc_bpidxd16_reg16 r10 r7
adc_bpsid16_sp:
	adc_bpidxd16_reg16 r10 r8
adc_bpsid16_bp:
	adc_bpidxd16_reg16 r10 r9
adc_bpsid16_si:
	adc_bpidxd16_reg16 r10 r10
adc_bpsid16_di:
	adc_bpidxd16_reg16 r10 r11

adc_bpdid16_ax:
	adc_bpidxd16_reg16 r11 r4
adc_bpdid16_cx:
	adc_bpidxd16_reg16 r11 r5
adc_bpdid16_dx:
	adc_bpidxd16_reg16 r11 r6
adc_bpdid16_bx:
	adc_bpidxd16_reg16 r11 r7
adc_bpdid16_sp:
	adc_bpidxd16_reg16 r11 r8
adc_bpdid16_bp:
	adc_bpidxd16_reg16 r11 r9
adc_bpdid16_si:
	adc_bpidxd16_reg16 r11 r10
adc_bpdid16_di:
	adc_bpidxd16_reg16 r11 r11

.macro adc_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		adc_r0_r16_\reg
.endm

adc_sidisp16_ax:
	adc_idxdisp16_reg16 r10 r4
adc_sidisp16_cx:
	adc_idxdisp16_reg16 r10 r5
adc_sidisp16_dx:
	adc_idxdisp16_reg16 r10 r6
adc_sidisp16_bx:
	adc_idxdisp16_reg16 r10 r7
adc_sidisp16_sp:
	adc_idxdisp16_reg16 r10 r8
adc_sidisp16_bp:
	adc_idxdisp16_reg16 r10 r9
adc_sidisp16_si:
	adc_idxdisp16_reg16 r10 r10
adc_sidisp16_di:
	adc_idxdisp16_reg16 r10 r11

adc_didisp16_ax:
	adc_idxdisp16_reg16 r11 r4
adc_didisp16_cx:
	adc_idxdisp16_reg16 r11 r5
adc_didisp16_dx:
	adc_idxdisp16_reg16 r11 r6
adc_didisp16_bx:
	adc_idxdisp16_reg16 r11 r7
adc_didisp16_sp:
	adc_idxdisp16_reg16 r11 r8
adc_didisp16_bp:
	adc_idxdisp16_reg16 r11 r9
adc_didisp16_si:
	adc_idxdisp16_reg16 r11 r10
adc_didisp16_di:
	adc_idxdisp16_reg16 r11 r11

adc_bxdisp16_ax:
	adc_idxdisp16_reg16 r7 r4
adc_bxdisp16_cx:
	adc_idxdisp16_reg16 r7 r5
adc_bxdisp16_dx:
	adc_idxdisp16_reg16 r7 r6
adc_bxdisp16_bx:
	adc_idxdisp16_reg16 r7 r7
adc_bxdisp16_sp:
	adc_idxdisp16_reg16 r7 r8
adc_bxdisp16_bp:
	adc_idxdisp16_reg16 r7 r9
adc_bxdisp16_si:
	adc_idxdisp16_reg16 r7 r10
adc_bxdisp16_di:
	adc_idxdisp16_reg16 r7 r11

.macro adc_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		adc_r0_r16_bp_\reg
.endm

adc_bpdisp16_ax:
	adc_bpdisp16_reg16 r4
adc_bpdisp16_cx:
	adc_bpdisp16_reg16 r5
adc_bpdisp16_dx:
	adc_bpdisp16_reg16 r6
adc_bpdisp16_bx:
	adc_bpdisp16_reg16 r7
adc_bpdisp16_sp:
	adc_bpdisp16_reg16 r8
adc_bpdisp16_bp:
	adc_bpdisp16_reg16 r9
adc_bpdisp16_si:
	adc_bpdisp16_reg16 r10
adc_bpdisp16_di:
	adc_bpdisp16_reg16 r11


// ------------------- 12 = ADC r8, r/m8 -------------------------------
//
// All modrm variations supported!
//
//
op_12:
	modrm_jump_16
// 0
	.word adc_al_bxsi, adc_al_bxdi, adc_al_bpsi, adc_al_bpdi, adc_al_siidx, adc_al_diidx, adc_al_disp16, adc_al_bxidx
	.word adc_cl_bxsi, adc_cl_bxdi, adc_cl_bpsi, adc_cl_bpdi, adc_cl_siidx, adc_cl_diidx, adc_cl_disp16, adc_cl_bxidx
	.word adc_dl_bxsi, adc_dl_bxdi, adc_dl_bpsi, adc_dl_bpdi, adc_dl_siidx, adc_dl_diidx, adc_dl_disp16, adc_dl_bxidx
	.word adc_bl_bxsi, adc_bl_bxdi, adc_bl_bpsi, adc_bl_bpdi, adc_bl_siidx, adc_bl_diidx, adc_bl_disp16, adc_bl_bxidx
	.word adc_ah_bxsi, adc_ah_bxdi, adc_ah_bpsi, adc_ah_bpdi, adc_ah_siidx, adc_ah_diidx, adc_ah_disp16, adc_ah_bxidx
	.word adc_ch_bxsi, adc_ch_bxdi, adc_ch_bpsi, adc_ch_bpdi, adc_ch_siidx, adc_ch_diidx, adc_ch_disp16, adc_ch_bxidx
	.word adc_dh_bxsi, adc_dh_bxdi, adc_dh_bpsi, adc_dh_bpdi, adc_dh_siidx, adc_dh_diidx, adc_dh_disp16, adc_dh_bxidx
	.word adc_bh_bxsi, adc_bh_bxdi, adc_bh_bpsi, adc_bh_bpdi, adc_bh_siidx, adc_bh_diidx, adc_bh_disp16, adc_bh_bxidx
//0x40
	.word adc_al_bxsid8, adc_al_bxdid8, adc_al_bpsid8, adc_al_bpdid8, adc_al_sidisp8, adc_al_didisp8, adc_al_bpdisp8, adc_al_bxdisp8
	.word adc_cl_bxsid8, adc_cl_bxdid8, adc_cl_bpsid8, adc_cl_bpdid8, adc_cl_sidisp8, adc_cl_didisp8, adc_cl_bpdisp8, adc_cl_bxdisp8
	.word adc_dl_bxsid8, adc_dl_bxdid8, adc_dl_bpsid8, adc_dl_bpdid8, adc_dl_sidisp8, adc_dl_didisp8, adc_dl_bpdisp8, adc_dl_bxdisp8
	.word adc_bl_bxsid8, adc_bl_bxdid8, adc_bl_bpsid8, adc_bl_bpdid8, adc_bl_sidisp8, adc_bl_didisp8, adc_bl_bpdisp8, adc_bl_bxdisp8
	.word adc_ah_bxsid8, adc_ah_bxdid8, adc_ah_bpsid8, adc_ah_bpdid8, adc_ah_sidisp8, adc_ah_didisp8, adc_ah_bpdisp8, adc_ah_bxdisp8
	.word adc_ch_bxsid8, adc_ch_bxdid8, adc_ch_bpsid8, adc_ch_bpdid8, adc_ch_sidisp8, adc_ch_didisp8, adc_ch_bpdisp8, adc_ch_bxdisp8
	.word adc_dh_bxsid8, adc_dh_bxdid8, adc_dh_bpsid8, adc_dh_bpdid8, adc_dh_sidisp8, adc_dh_didisp8, adc_dh_bpdisp8, adc_dh_bxdisp8
	.word adc_bh_bxsid8, adc_bh_bxdid8, adc_bh_bpsid8, adc_bh_bpdid8, adc_bh_sidisp8, adc_bh_didisp8, adc_bh_bpdisp8, adc_bh_bxdisp8
//0x80
	.word adc_al_bxsid16, adc_al_bxdid16, adc_al_bpsid16, adc_al_bpdid16, adc_al_sidisp16, adc_al_didisp16, adc_al_bpdisp16, adc_al_bxdisp16
	.word adc_cl_bxsid16, adc_cl_bxdid16, adc_cl_bpsid16, adc_cl_bpdid16, adc_cl_sidisp16, adc_cl_didisp16, adc_cl_bpdisp16, adc_cl_bxdisp16
	.word adc_dl_bxsid16, adc_dl_bxdid16, adc_dl_bpsid16, adc_dl_bpdid16, adc_dl_sidisp16, adc_dl_didisp16, adc_dl_bpdisp16, adc_dl_bxdisp16
	.word adc_bl_bxsid16, adc_bl_bxdid16, adc_bl_bpsid16, adc_bl_bpdid16, adc_bl_sidisp16, adc_bl_didisp16, adc_bl_bpdisp16, adc_bl_bxdisp16
	.word adc_ah_bxsid16, adc_ah_bxdid16, adc_ah_bpsid16, adc_ah_bpdid16, adc_ah_sidisp16, adc_ah_didisp16, adc_ah_bpdisp16, adc_ah_bxdisp16
	.word adc_ch_bxsid16, adc_ch_bxdid16, adc_ch_bpsid16, adc_ch_bpdid16, adc_ch_sidisp16, adc_ch_didisp16, adc_ch_bpdisp16, adc_ch_bxdisp16
	.word adc_dh_bxsid16, adc_dh_bxdid16, adc_dh_bpsid16, adc_dh_bpdid16, adc_dh_sidisp16, adc_dh_didisp16, adc_dh_bpdisp16, adc_dh_bxdisp16
	.word adc_bh_bxsid16, adc_bh_bxdid16, adc_bh_bpsid16, adc_bh_bpdid16, adc_bh_sidisp16, adc_bh_didisp16, adc_bh_bpdisp16, adc_bh_bxdisp16
// 0xC0 = two register operands
	.word adc_al_al, adc_al_cl, adc_al_dl, adc_al_bl, adc_al_ah, adc_al_ch, adc_al_dh, adc_al_bh
	.word adc_cl_al, adc_cl_cl, adc_cl_dl, adc_cl_bl, adc_cl_ah, adc_cl_ch, adc_cl_dh, adc_cl_bh
	.word adc_dl_al, adc_dl_cl, adc_dl_dl, adc_dl_bl, adc_dl_ah, adc_dl_ch, adc_dl_dh, adc_dl_bh
	.word adc_bl_al, adc_bl_cl, adc_bl_dl, adc_bl_bl, adc_bl_ah, adc_bl_ch, adc_bl_dh, adc_bl_bh
	.word adc_ah_al, adc_ah_cl, adc_ah_dl, adc_ah_bl, adc_ah_ah, adc_ah_ch, adc_ah_dh, adc_ah_bh
	.word adc_ch_al, adc_ch_cl, adc_ch_dl, adc_ch_bl, adc_ch_ah, adc_ch_ch, adc_ch_dh, adc_ch_bh
	.word adc_dh_al, adc_dh_cl, adc_dh_dl, adc_dh_bl, adc_dh_ah, adc_dh_ch, adc_dh_dh, adc_dh_bh
	.word adc_bh_al, adc_bh_cl, adc_bh_dl, adc_bh_bl, adc_bh_ah, adc_bh_ch, adc_bh_dh, adc_bh_bh

// These are called from "cpu_386.s":

	.global adc_al_siidx, adc_cl_siidx, adc_dl_siidx, adc_bl_siidx, adc_ah_siidx, adc_ch_siidx, adc_dh_siidx, adc_bh_siidx
	.global adc_al_diidx, adc_cl_diidx, adc_dl_diidx, adc_bl_diidx, adc_ah_diidx, adc_ch_diidx, adc_dh_diidx, adc_bh_diidx
	.global adc_al_bxidx, adc_cl_bxidx, adc_dl_bxidx, adc_bl_bxidx, adc_ah_bxidx, adc_ch_bxidx, adc_dh_bxidx, adc_bh_bxidx
	.global adc_al_sidisp8, adc_al_didisp8, adc_al_bpdisp8, adc_al_bxdisp8
	.global adc_cl_sidisp8, adc_cl_didisp8, adc_cl_bpdisp8, adc_cl_bxdisp8
	.global adc_dl_sidisp8, adc_dl_didisp8, adc_dl_bpdisp8, adc_dl_bxdisp8
	.global adc_bl_sidisp8, adc_bl_didisp8, adc_bl_bpdisp8, adc_bl_bxdisp8
	.global adc_ah_sidisp8, adc_ah_didisp8, adc_ah_bpdisp8, adc_ah_bxdisp8
	.global adc_ch_sidisp8, adc_ch_didisp8, adc_ch_bpdisp8, adc_ch_bxdisp8
	.global adc_dh_sidisp8, adc_dh_didisp8, adc_dh_bpdisp8, adc_dh_bxdisp8
	.global adc_bh_sidisp8, adc_bh_didisp8, adc_bh_bpdisp8, adc_bh_bxdisp8
	.global adc_al_al, adc_cl_al, adc_dl_al, adc_bl_al, adc_ah_al, adc_ch_al, adc_dh_al, adc_bh_al
	.global adc_al_cl, adc_cl_cl, adc_dl_cl, adc_bl_cl, adc_ah_cl, adc_ch_cl, adc_dh_cl, adc_bh_cl
	.global adc_al_dl, adc_cl_dl, adc_dl_dl, adc_bl_dl, adc_ah_dl, adc_ch_dl, adc_dh_dl, adc_bh_dl
	.global adc_al_bl, adc_cl_bl, adc_dl_bl, adc_bl_bl, adc_ah_bl, adc_ch_bl, adc_dh_bl, adc_bh_bl
	.global adc_al_ah, adc_cl_ah, adc_dl_ah, adc_bl_ah, adc_ah_ah, adc_ch_ah, adc_dh_ah, adc_bh_ah
	.global adc_al_ch, adc_cl_ch, adc_dl_ch, adc_bl_ch, adc_ah_ch, adc_ch_ch, adc_dh_ch, adc_bh_ch
	.global adc_al_dh, adc_cl_dh, adc_dl_dh, adc_bl_dh, adc_ah_dh, adc_ch_dh, adc_dh_dh, adc_bh_dh
	.global adc_al_bh, adc_cl_bh, adc_dl_bh, adc_bl_bh, adc_ah_bh, adc_ch_bh, adc_dh_bh, adc_bh_bh

.macro adc_reg8l_r0high reg
	.global	adc_r8l_r0_bp_\reg
adc_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	adc_r8l_r0_\reg
adc_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_12_RAM_l_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory adcress
	//-------
.op_12_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	lsl		r0, #24
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, \reg, lsl #24		// Perform the actual addition, setting the resulting flags.
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r0, lsr #24		// Put the result to the lowest byte of the left register
	b		loop
.endm
.macro adc_reg8h_r0high reg
	.global	adc_r8h_r0_bp_\reg
adc_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	adc_r8h_r0_\reg
adc_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_12_RAM_h_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory adcress
	//-------
.op_12_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00		// Left operand already uses just the rightmost byte
	lsl		r0, #24
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, lsl #16			// Perform the actual addition, setting the resulting flags.
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r0, lsr #16
	b		loop
.endm

	adc_reg8l_r0high r4
	adc_reg8l_r0high r5
	adc_reg8l_r0high r6
	adc_reg8l_r0high r7
	adc_reg8h_r0high r4
	adc_reg8h_r0high r5
	adc_reg8h_r0high r6
	adc_reg8h_r0high r7

	.ltorg

// --- [idx] ---

.macro adc_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		adc_r8l_r0_\reg
.endm
.macro adc_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		adc_r8h_r0_\reg
.endm

adc_al_bxsi:
	adc_reg8l_bxidx r4 r10
adc_cl_bxsi:
	adc_reg8l_bxidx r5 r10
adc_dl_bxsi:
	adc_reg8l_bxidx r6 r10
adc_bl_bxsi:
	adc_reg8l_bxidx r7 r10
adc_ah_bxsi:
	adc_reg8h_bxidx r4 r10
adc_ch_bxsi:
	adc_reg8h_bxidx r5 r10
adc_dh_bxsi:
	adc_reg8h_bxidx r6 r10
adc_bh_bxsi:
	adc_reg8h_bxidx r7 r10

adc_al_bxdi:
	adc_reg8l_bxidx r4 r11
adc_cl_bxdi:
	adc_reg8l_bxidx r5 r11
adc_dl_bxdi:
	adc_reg8l_bxidx r6 r11
adc_bl_bxdi:
	adc_reg8l_bxidx r7 r11
adc_ah_bxdi:
	adc_reg8h_bxidx r4 r11
adc_ch_bxdi:
	adc_reg8h_bxidx r5 r11
adc_dh_bxdi:
	adc_reg8h_bxidx r6 r11
adc_bh_bxdi:
	adc_reg8h_bxidx r7 r11

.macro adc_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		adc_r8l_r0_bp_\reg
.endm
.macro adc_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		adc_r8h_r0_bp_\reg
.endm

adc_al_bpsi:
	adc_reg8l_bpidx r4 r10
adc_cl_bpsi:
	adc_reg8l_bpidx r5 r10
adc_dl_bpsi:
	adc_reg8l_bpidx r6 r10
adc_bl_bpsi:
	adc_reg8l_bpidx r7 r10
adc_ah_bpsi:
	adc_reg8h_bpidx r4 r10
adc_ch_bpsi:
	adc_reg8h_bpidx r5 r10
adc_dh_bpsi:
	adc_reg8h_bpidx r6 r10
adc_bh_bpsi:
	adc_reg8h_bpidx r7 r10

adc_al_bpdi:
	adc_reg8l_bpidx r4 r11
adc_cl_bpdi:
	adc_reg8l_bpidx r5 r11
adc_dl_bpdi:
	adc_reg8l_bpidx r6 r11
adc_bl_bpdi:
	adc_reg8l_bpidx r7 r11
adc_ah_bpdi:
	adc_reg8h_bpidx r4 r11
adc_ch_bpdi:
	adc_reg8h_bpidx r5 r11
adc_dh_bpdi:
	adc_reg8h_bpidx r6 r11
adc_bh_bpdi:
	adc_reg8h_bpidx r7 r11

.macro adc_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		adc_r8l_r0_\reg
.endm
.macro adc_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		adc_r8h_r0_\reg
.endm

adc_al_siidx:
	adc_reg8l_idx r4 r10
adc_cl_siidx:
	adc_reg8l_idx r5 r10
adc_dl_siidx:
	adc_reg8l_idx r6 r10
adc_bl_siidx:
	adc_reg8l_idx r7 r10
adc_ah_siidx:
	adc_reg8h_idx r4 r10
adc_ch_siidx:
	adc_reg8h_idx r5 r10
adc_dh_siidx:
	adc_reg8h_idx r6 r10
adc_bh_siidx:
	adc_reg8h_idx r7 r10

adc_al_diidx:
	adc_reg8l_idx r4 r11
adc_cl_diidx:
	adc_reg8l_idx r5 r11
adc_dl_diidx:
	adc_reg8l_idx r6 r11
adc_bl_diidx:
	adc_reg8l_idx r7 r11
adc_ah_diidx:
	adc_reg8h_idx r4 r11
adc_ch_diidx:
	adc_reg8h_idx r5 r11
adc_dh_diidx:
	adc_reg8h_idx r6 r11
adc_bh_diidx:
	adc_reg8h_idx r7 r11

adc_al_bxidx:
	adc_reg8l_idx r4 r7
adc_cl_bxidx:
	adc_reg8l_idx r5 r7
adc_dl_bxidx:
	adc_reg8l_idx r6 r7
adc_bl_bxidx:
	adc_reg8l_idx r7 r7
adc_ah_bxidx:
	adc_reg8h_idx r4 r7
adc_ch_bxidx:
	adc_reg8h_idx r5 r7
adc_dh_bxidx:
	adc_reg8h_idx r6 r7
adc_bh_bxidx:
	adc_reg8h_idx r7 r7

.macro adc_reg8l_disp16 reg
	r0_from_disp16
	b		adc_r8l_r0_\reg
.endm
.macro adc_reg8h_disp16 reg
	r0_from_disp16
	b		adc_r8h_r0_\reg
.endm

adc_al_disp16:
	adc_reg8l_disp16 r4
adc_cl_disp16:
	adc_reg8l_disp16 r5
adc_dl_disp16:
	adc_reg8l_disp16 r6
adc_bl_disp16:
	adc_reg8l_disp16 r7
adc_ah_disp16:
	adc_reg8h_disp16 r4
adc_ch_disp16:
	adc_reg8h_disp16 r5
adc_dh_disp16:
	adc_reg8h_disp16 r6
adc_bh_disp16:
	adc_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro adc_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		adc_r8l_r0_\reg
.endm
.macro adc_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		adc_r8h_r0_\reg
.endm

adc_al_bxsid8:
	adc_reg8l_bxidxd8 r4 r10
adc_cl_bxsid8:
	adc_reg8l_bxidxd8 r5 r10
adc_dl_bxsid8:
	adc_reg8l_bxidxd8 r6 r10
adc_bl_bxsid8:
	adc_reg8l_bxidxd8 r7 r10
adc_ah_bxsid8:
	adc_reg8h_bxidxd8 r4 r10
adc_ch_bxsid8:
	adc_reg8h_bxidxd8 r5 r10
adc_dh_bxsid8:
	adc_reg8h_bxidxd8 r6 r10
adc_bh_bxsid8:
	adc_reg8h_bxidxd8 r7 r10

adc_al_bxdid8:
	adc_reg8l_bxidxd8 r4 r11
adc_cl_bxdid8:
	adc_reg8l_bxidxd8 r5 r11
adc_dl_bxdid8:
	adc_reg8l_bxidxd8 r6 r11
adc_bl_bxdid8:
	adc_reg8l_bxidxd8 r7 r11
adc_ah_bxdid8:
	adc_reg8h_bxidxd8 r4 r11
adc_ch_bxdid8:
	adc_reg8h_bxidxd8 r5 r11
adc_dh_bxdid8:
	adc_reg8h_bxidxd8 r6 r11
adc_bh_bxdid8:
	adc_reg8h_bxidxd8 r7 r11

.macro adc_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		adc_r8l_r0_bp_\reg
.endm
.macro adc_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		adc_r8h_r0_bp_\reg
.endm

adc_al_bpsid8:
	adc_reg8l_bpidxd8 r4 r10
adc_cl_bpsid8:
	adc_reg8l_bpidxd8 r5 r10
adc_dl_bpsid8:
	adc_reg8l_bpidxd8 r6 r10
adc_bl_bpsid8:
	adc_reg8l_bpidxd8 r7 r10
adc_ah_bpsid8:
	adc_reg8h_bpidxd8 r4 r10
adc_ch_bpsid8:
	adc_reg8h_bpidxd8 r5 r10
adc_dh_bpsid8:
	adc_reg8h_bpidxd8 r6 r10
adc_bh_bpsid8:
	adc_reg8h_bpidxd8 r7 r10

adc_al_bpdid8:
	adc_reg8l_bpidxd8 r4 r11
adc_cl_bpdid8:
	adc_reg8l_bpidxd8 r5 r11
adc_dl_bpdid8:
	adc_reg8l_bpidxd8 r6 r11
adc_bl_bpdid8:
	adc_reg8l_bpidxd8 r7 r11
adc_ah_bpdid8:
	adc_reg8h_bpidxd8 r4 r11
adc_ch_bpdid8:
	adc_reg8h_bpidxd8 r5 r11
adc_dh_bpdid8:
	adc_reg8h_bpidxd8 r6 r11
adc_bh_bpdid8:
	adc_reg8h_bpidxd8 r7 r11

.macro adc_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		adc_r8l_r0_\reg
.endm
.macro adc_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		adc_r8h_r0_\reg
.endm

adc_al_sidisp8:
	adc_reg8l_idxdisp8 r4 r10
adc_cl_sidisp8:
	adc_reg8l_idxdisp8 r5 r10
adc_dl_sidisp8:
	adc_reg8l_idxdisp8 r6 r10
adc_bl_sidisp8:
	adc_reg8l_idxdisp8 r7 r10
adc_ah_sidisp8:
	adc_reg8h_idxdisp8 r4 r10
adc_ch_sidisp8:
	adc_reg8h_idxdisp8 r5 r10
adc_dh_sidisp8:
	adc_reg8h_idxdisp8 r6 r10
adc_bh_sidisp8:
	adc_reg8h_idxdisp8 r7 r10
	
adc_al_didisp8:
	adc_reg8l_idxdisp8 r4 r11
adc_cl_didisp8:
	adc_reg8l_idxdisp8 r5 r11
adc_dl_didisp8:
	adc_reg8l_idxdisp8 r6 r11
adc_bl_didisp8:
	adc_reg8l_idxdisp8 r7 r11
adc_ah_didisp8:
	adc_reg8h_idxdisp8 r4 r11
adc_ch_didisp8:
	adc_reg8h_idxdisp8 r5 r11
adc_dh_didisp8:
	adc_reg8h_idxdisp8 r6 r11
adc_bh_didisp8:
	adc_reg8h_idxdisp8 r7 r11

adc_al_bxdisp8:
	adc_reg8l_idxdisp8 r4 r7
adc_cl_bxdisp8:
	adc_reg8l_idxdisp8 r5 r7
adc_dl_bxdisp8:
	adc_reg8l_idxdisp8 r6 r7
adc_bl_bxdisp8:
	adc_reg8l_idxdisp8 r7 r7
adc_ah_bxdisp8:
	adc_reg8h_idxdisp8 r4 r7
adc_ch_bxdisp8:
	adc_reg8h_idxdisp8 r5 r7
adc_dh_bxdisp8:
	adc_reg8h_idxdisp8 r6 r7
adc_bh_bxdisp8:
	adc_reg8h_idxdisp8 r7 r7

.macro adc_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		adc_r8l_r0_bp_\reg
.endm
.macro adc_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		adc_r8h_r0_bp_\reg
.endm

adc_al_bpdisp8:
	adc_reg8l_bpdisp8 r4
adc_cl_bpdisp8:
	adc_reg8l_bpdisp8 r5
adc_dl_bpdisp8:
	adc_reg8l_bpdisp8 r6
adc_bl_bpdisp8:
	adc_reg8l_bpdisp8 r7
adc_ah_bpdisp8:
	adc_reg8h_bpdisp8 r4
adc_ch_bpdisp8:
	adc_reg8h_bpdisp8 r5
adc_dh_bpdisp8:
	adc_reg8h_bpdisp8 r6
adc_bh_bpdisp8:
	adc_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro adc_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		adc_r8l_r0_\reg
.endm
.macro adc_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		adc_r8h_r0_\reg
.endm

adc_al_bxsid16:
	adc_reg8l_bxidxd16 r4 r10
adc_cl_bxsid16:
	adc_reg8l_bxidxd16 r5 r10
adc_dl_bxsid16:
	adc_reg8l_bxidxd16 r6 r10
adc_bl_bxsid16:
	adc_reg8l_bxidxd16 r7 r10
adc_ah_bxsid16:
	adc_reg8h_bxidxd16 r4 r10
adc_ch_bxsid16:
	adc_reg8h_bxidxd16 r5 r10
adc_dh_bxsid16:
	adc_reg8h_bxidxd16 r6 r10
adc_bh_bxsid16:
	adc_reg8h_bxidxd16 r7 r10

adc_al_bxdid16:
	adc_reg8l_bxidxd16 r4 r11
adc_cl_bxdid16:
	adc_reg8l_bxidxd16 r5 r11
adc_dl_bxdid16:
	adc_reg8l_bxidxd16 r6 r11
adc_bl_bxdid16:
	adc_reg8l_bxidxd16 r7 r11
adc_ah_bxdid16:
	adc_reg8h_bxidxd16 r4 r11
adc_ch_bxdid16:
	adc_reg8h_bxidxd16 r5 r11
adc_dh_bxdid16:
	adc_reg8h_bxidxd16 r6 r11
adc_bh_bxdid16:
	adc_reg8h_bxidxd16 r7 r11

.macro adc_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		adc_r8l_r0_bp_\reg
.endm
.macro adc_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		adc_r8h_r0_bp_\reg
.endm

adc_al_bpsid16:
	adc_reg8l_bpidxd16 r4 r10
adc_cl_bpsid16:
	adc_reg8l_bpidxd16 r5 r10
adc_dl_bpsid16:
	adc_reg8l_bpidxd16 r6 r10
adc_bl_bpsid16:
	adc_reg8l_bpidxd16 r7 r10
adc_ah_bpsid16:
	adc_reg8h_bpidxd16 r4 r10
adc_ch_bpsid16:
	adc_reg8h_bpidxd16 r5 r10
adc_dh_bpsid16:
	adc_reg8h_bpidxd16 r6 r10
adc_bh_bpsid16:
	adc_reg8h_bpidxd16 r7 r10

adc_al_bpdid16:
	adc_reg8l_bpidxd16 r4 r11
adc_cl_bpdid16:
	adc_reg8l_bpidxd16 r5 r11
adc_dl_bpdid16:
	adc_reg8l_bpidxd16 r6 r11
adc_bl_bpdid16:
	adc_reg8l_bpidxd16 r7 r11
adc_ah_bpdid16:
	adc_reg8h_bpidxd16 r4 r11
adc_ch_bpdid16:
	adc_reg8h_bpidxd16 r5 r11
adc_dh_bpdid16:
	adc_reg8h_bpidxd16 r6 r11
adc_bh_bpdid16:
	adc_reg8h_bpidxd16 r7 r11

.macro adc_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		adc_r8l_r0_\reg
.endm
.macro adc_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		adc_r8h_r0_\reg
.endm

adc_al_sidisp16:
	adc_reg8l_idxdisp16 r4 r10
adc_cl_sidisp16:
	adc_reg8l_idxdisp16 r5 r10
adc_dl_sidisp16:
	adc_reg8l_idxdisp16 r6 r10
adc_bl_sidisp16:
	adc_reg8l_idxdisp16 r7 r10
adc_ah_sidisp16:
	adc_reg8h_idxdisp16 r4 r10
adc_ch_sidisp16:
	adc_reg8h_idxdisp16 r5 r10
adc_dh_sidisp16:
	adc_reg8h_idxdisp16 r6 r10
adc_bh_sidisp16:
	adc_reg8h_idxdisp16 r7 r10

adc_al_didisp16:
	adc_reg8l_idxdisp16 r4 r11
adc_cl_didisp16:
	adc_reg8l_idxdisp16 r5 r11
adc_dl_didisp16:
	adc_reg8l_idxdisp16 r6 r11
adc_bl_didisp16:
	adc_reg8l_idxdisp16 r7 r11
adc_ah_didisp16:
	adc_reg8h_idxdisp16 r4 r11
adc_ch_didisp16:
	adc_reg8h_idxdisp16 r5 r11
adc_dh_didisp16:
	adc_reg8h_idxdisp16 r6 r11
adc_bh_didisp16:
	adc_reg8h_idxdisp16 r7 r11

adc_al_bxdisp16:
	adc_reg8l_idxdisp16 r4 r7
adc_cl_bxdisp16:
	adc_reg8l_idxdisp16 r5 r7
adc_dl_bxdisp16:
	adc_reg8l_idxdisp16 r6 r7
adc_bl_bxdisp16:
	adc_reg8l_idxdisp16 r7 r7
adc_ah_bxdisp16:
	adc_reg8h_idxdisp16 r4 r7
adc_ch_bxdisp16:
	adc_reg8h_idxdisp16 r5 r7
adc_dh_bxdisp16:
	adc_reg8h_idxdisp16 r6 r7
adc_bh_bxdisp16:
	adc_reg8h_idxdisp16 r7 r7
	
.macro adc_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		adc_r8l_r0_bp_\reg
.endm
.macro adc_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		adc_r8h_r0_bp_\reg
.endm

adc_al_bpdisp16:
	adc_reg8l_bpdisp16 r4 
adc_cl_bpdisp16:
	adc_reg8l_bpdisp16 r5 
adc_dl_bpdisp16:
	adc_reg8l_bpdisp16 r6 
adc_bl_bpdisp16:
	adc_reg8l_bpdisp16 r7 
adc_ah_bpdisp16:
	adc_reg8h_bpdisp16 r4 
adc_ch_bpdisp16:
	adc_reg8h_bpdisp16 r5 
adc_dh_bpdisp16:
	adc_reg8h_bpdisp16 r6 
adc_bh_bpdisp16:
	adc_reg8h_bpdisp16 r7 


// --- Register operands ---

.macro adc_reg8l_reg8l rl rr
	mov		r0, \rl, lsl #24		// r0 high byte = the left operand
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, \rr, lsl #24		// Perform the actual addition, setting the resulting flags.
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	b		loop
.endm
.macro adc_reg8l_reg8h rl rr
	and		r1, \rr, #0xFF00		// r1 high byte = the right operand
	mov		r0, \rl, lsl #24		// r0 high byte = the left operand
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, lsl #16			// Perform the actual addition, setting the resulting flags.
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	b		loop
.endm
.macro adc_reg8h_reg8l rl rr
	mov		r0, \rr, lsl #24		// r1 high byte = the right operand
	and		r1, \rl, #0xFF00		// r0 high byte = the left operand
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, lsl #16			// Perform the actual addition, setting the resulting flags.
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16		// Put the result to the high byte of the high halfword of the left register
	b		loop
.endm
.macro adc_reg8h_reg8h rl rr
	and		r1, \rr, #0xFF00		// r1 high byte = the right operand
	and		r0, \rl, #0xFF00		// r0 high byte = the left operand
	lsl		r0, #16
	addcs	r0, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, lsl #16			// Perform the actual addition, setting the resulting flags.
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16		// Put the result to the high byte of the high halfword of the left register
	b		loop
.endm

adc_al_al:
	adc_reg8l_reg8l r4 r4
adc_al_cl:
	adc_reg8l_reg8l r4 r5
adc_al_dl:
	adc_reg8l_reg8l r4 r6
adc_al_bl:
	adc_reg8l_reg8l r4 r7
adc_al_ah:
	adc_reg8l_reg8h r4 r4
adc_al_ch:
	adc_reg8l_reg8h r4 r5
adc_al_dh:
	adc_reg8l_reg8h r4 r6
adc_al_bh:
	adc_reg8l_reg8h r4 r7

adc_cl_al:
	adc_reg8l_reg8l r5 r4
adc_cl_cl:
	adc_reg8l_reg8l r5 r5
adc_cl_dl:
	adc_reg8l_reg8l r5 r6
adc_cl_bl:
	adc_reg8l_reg8l r5 r7
adc_cl_ah:
	adc_reg8l_reg8h r5 r4
adc_cl_ch:
	adc_reg8l_reg8h r5 r5
adc_cl_dh:
	adc_reg8l_reg8h r5 r6
adc_cl_bh:
	adc_reg8l_reg8h r5 r7

adc_dl_al:
	adc_reg8l_reg8l r6 r4
adc_dl_cl:
	adc_reg8l_reg8l r6 r5
adc_dl_dl:
	adc_reg8l_reg8l r6 r6
adc_dl_bl:
	adc_reg8l_reg8l r6 r7
adc_dl_ah:
	adc_reg8l_reg8h r6 r4
adc_dl_ch:
	adc_reg8l_reg8h r6 r5
adc_dl_dh:
	adc_reg8l_reg8h r6 r6
adc_dl_bh:
	adc_reg8l_reg8h r6 r7

adc_bl_al:
	adc_reg8l_reg8l r7 r4
adc_bl_cl:
	adc_reg8l_reg8l r7 r5
adc_bl_dl:
	adc_reg8l_reg8l r7 r6
adc_bl_bl:
	adc_reg8l_reg8l r7 r7
adc_bl_ah:
	adc_reg8l_reg8h r7 r4
adc_bl_ch:
	adc_reg8l_reg8h r7 r5
adc_bl_dh:
	adc_reg8l_reg8h r7 r6
adc_bl_bh:
	adc_reg8l_reg8h r7 r7

adc_ah_al:
	adc_reg8h_reg8l r4 r4
adc_ah_cl:
	adc_reg8h_reg8l r4 r5
adc_ah_dl:
	adc_reg8h_reg8l r4 r6
adc_ah_bl:
	adc_reg8h_reg8l r4 r7
adc_ah_ah:
	adc_reg8h_reg8h r4 r4
adc_ah_ch:
	adc_reg8h_reg8h r4 r5
adc_ah_dh:
	adc_reg8h_reg8h r4 r6
adc_ah_bh:
	adc_reg8h_reg8h r4 r7

adc_ch_al:
	adc_reg8h_reg8l r5 r4
adc_ch_cl:
	adc_reg8h_reg8l r5 r5
adc_ch_dl:
	adc_reg8h_reg8l r5 r6
adc_ch_bl:
	adc_reg8h_reg8l r5 r7
adc_ch_ah:
	adc_reg8h_reg8h r5 r4
adc_ch_ch:
	adc_reg8h_reg8h r5 r5
adc_ch_dh:
	adc_reg8h_reg8h r5 r6
adc_ch_bh:
	adc_reg8h_reg8h r5 r7

adc_dh_al:
	adc_reg8h_reg8l r6 r4
adc_dh_cl:
	adc_reg8h_reg8l r6 r5
adc_dh_dl:
	adc_reg8h_reg8l r6 r6
adc_dh_bl:
	adc_reg8h_reg8l r6 r7
adc_dh_ah:
	adc_reg8h_reg8h r6 r4
adc_dh_ch:
	adc_reg8h_reg8h r6 r5
adc_dh_dh:
	adc_reg8h_reg8h r6 r6
adc_dh_bh:
	adc_reg8h_reg8h r6 r7

adc_bh_al:
	adc_reg8h_reg8l r7 r4
adc_bh_cl:
	adc_reg8h_reg8l r7 r5
adc_bh_dl:
	adc_reg8h_reg8l r7 r6
adc_bh_bl:
	adc_reg8h_reg8l r7 r7
adc_bh_ah:
	adc_reg8h_reg8h r7 r4
adc_bh_ch:
	adc_reg8h_reg8h r7 r5
adc_bh_dh:
	adc_reg8h_reg8h r7 r6
adc_bh_bh:
	adc_reg8h_reg8h r7 r7

// ------------------- 13 = adc r16, r/m16 ------------------------------
//
// All modrm variations supported!
//
//
op_13:
	modrm_jump_16
// 0
	.word adc_ax_bxsi, adc_ax_bxdi, adc_ax_bpsi, adc_ax_bpdi, adc_ax_siidx, adc_ax_diidx, adc_ax_disp16, adc_ax_bxidx
	.word adc_cx_bxsi, adc_cx_bxdi, adc_cx_bpsi, adc_cx_bpdi, adc_cx_siidx, adc_cx_diidx, adc_cx_disp16, adc_cx_bxidx
	.word adc_dx_bxsi, adc_dx_bxdi, adc_dx_bpsi, adc_dx_bpdi, adc_dx_siidx, adc_dx_diidx, adc_dx_disp16, adc_dx_bxidx
	.word adc_bx_bxsi, adc_bx_bxdi, adc_bx_bpsi, adc_bx_bpdi, adc_bx_siidx, adc_bx_diidx, adc_bx_disp16, adc_bx_bxidx
	.word adc_sp_bxsi, adc_sp_bxdi, adc_sp_bpsi, adc_sp_bpdi, adc_sp_siidx, adc_sp_diidx, adc_sp_disp16, adc_sp_bxidx
	.word adc_bp_bxsi, adc_bp_bxdi, adc_bp_bpsi, adc_bp_bpdi, adc_bp_siidx, adc_bp_diidx, adc_bp_disp16, adc_bp_bxidx
	.word adc_si_bxsi, adc_si_bxdi, adc_si_bpsi, adc_si_bpdi, adc_si_siidx, adc_si_diidx, adc_si_disp16, adc_si_bxidx
	.word adc_di_bxsi, adc_di_bxdi, adc_di_bpsi, adc_di_bpdi, adc_di_siidx, adc_di_diidx, adc_di_disp16, adc_di_bxidx
//0x40
	.word adc_ax_bxsid8, adc_ax_bxdid8, adc_ax_bpsid8, adc_ax_bpdid8, adc_ax_sidisp8, adc_ax_didisp8, adc_ax_bpdisp8, adc_ax_bxdisp8
	.word adc_cx_bxsid8, adc_cx_bxdid8, adc_cx_bpsid8, adc_cx_bpdid8, adc_cx_sidisp8, adc_cx_didisp8, adc_cx_bpdisp8, adc_cx_bxdisp8
	.word adc_dx_bxsid8, adc_dx_bxdid8, adc_dx_bpsid8, adc_dx_bpdid8, adc_dx_sidisp8, adc_dx_didisp8, adc_dx_bpdisp8, adc_dx_bxdisp8
	.word adc_bx_bxsid8, adc_bx_bxdid8, adc_bx_bpsid8, adc_bx_bpdid8, adc_bx_sidisp8, adc_bx_didisp8, adc_bx_bpdisp8, adc_bx_bxdisp8
	.word adc_sp_bxsid8, adc_sp_bxdid8, adc_sp_bpsid8, adc_sp_bpdid8, adc_sp_sidisp8, adc_sp_didisp8, adc_sp_bpdisp8, adc_sp_bxdisp8
	.word adc_bp_bxsid8, adc_bp_bxdid8, adc_bp_bpsid8, adc_bp_bpdid8, adc_bp_sidisp8, adc_bp_didisp8, adc_bp_bpdisp8, adc_bp_bxdisp8
	.word adc_si_bxsid8, adc_si_bxdid8, adc_si_bpsid8, adc_si_bpdid8, adc_si_sidisp8, adc_si_didisp8, adc_si_bpdisp8, adc_si_bxdisp8
	.word adc_di_bxsid8, adc_di_bxdid8, adc_di_bpsid8, adc_di_bpdid8, adc_di_sidisp8, adc_di_didisp8, adc_di_bpdisp8, adc_di_bxdisp8
//0x80
	.word adc_ax_bxsid16, adc_ax_bxdid16, adc_ax_bpsid16, adc_ax_bpdid16, adc_ax_sidisp16, adc_ax_didisp16, adc_ax_bpdisp16, adc_ax_bxdisp16
	.word adc_cx_bxsid16, adc_cx_bxdid16, adc_cx_bpsid16, adc_cx_bpdid16, adc_cx_sidisp16, adc_cx_didisp16, adc_cx_bpdisp16, adc_cx_bxdisp16
	.word adc_dx_bxsid16, adc_dx_bxdid16, adc_dx_bpsid16, adc_dx_bpdid16, adc_dx_sidisp16, adc_dx_didisp16, adc_dx_bpdisp16, adc_dx_bxdisp16
	.word adc_bx_bxsid16, adc_bx_bxdid16, adc_bx_bpsid16, adc_bx_bpdid16, adc_bx_sidisp16, adc_bx_didisp16, adc_bx_bpdisp16, adc_bx_bxdisp16
	.word adc_sp_bxsid16, adc_sp_bxdid16, adc_sp_bpsid16, adc_sp_bpdid16, adc_sp_sidisp16, adc_sp_didisp16, adc_sp_bpdisp16, adc_sp_bxdisp16
	.word adc_bp_bxsid16, adc_bp_bxdid16, adc_bp_bpsid16, adc_bp_bpdid16, adc_bp_sidisp16, adc_bp_didisp16, adc_bp_bpdisp16, adc_bp_bxdisp16
	.word adc_si_bxsid16, adc_si_bxdid16, adc_si_bpsid16, adc_si_bpdid16, adc_si_sidisp16, adc_si_didisp16, adc_si_bpdisp16, adc_si_bxdisp16
	.word adc_di_bxsid16, adc_di_bxdid16, adc_di_bpsid16, adc_di_bpdid16, adc_di_sidisp16, adc_di_didisp16, adc_di_bpdisp16, adc_di_bxdisp16
// 0xC0 = two register operands
	.word adc_ax_ax, adc_ax_cx, adc_ax_dx, adc_ax_bx, adc_ax_sp, adc_ax_bp, adc_ax_si, adc_ax_di
	.word adc_cx_ax, adc_cx_cx, adc_cx_dx, adc_cx_bx, adc_cx_sp, adc_cx_bp, adc_cx_si, adc_cx_di
	.word adc_dx_ax, adc_dx_cx, adc_dx_dx, adc_dx_bx, adc_dx_sp, adc_dx_bp, adc_dx_si, adc_dx_di
	.word adc_bx_ax, adc_bx_cx, adc_bx_dx, adc_bx_bx, adc_bx_sp, adc_bx_bp, adc_bx_si, adc_bx_di
	.word adc_sp_ax, adc_sp_cx, adc_sp_dx, adc_sp_bx, adc_sp_sp, adc_sp_bp, adc_sp_si, adc_sp_di
	.word adc_bp_ax, adc_bp_cx, adc_bp_dx, adc_bp_bx, adc_bp_sp, adc_bp_bp, adc_bp_si, adc_bp_di
	.word adc_si_ax, adc_si_cx, adc_si_dx, adc_si_bx, adc_si_sp, adc_si_bp, adc_si_si, adc_si_di
	.word adc_di_ax, adc_di_cx, adc_di_dx, adc_di_bx, adc_di_sp, adc_di_bp, adc_di_si, adc_di_di

// These are called from "cpu_67.s":

	.global adc_ax_siidx, adc_ax_diidx, adc_ax_bxidx
	.global adc_cx_siidx, adc_cx_diidx, adc_cx_bxidx
	.global adc_dx_siidx, adc_dx_diidx, adc_dx_bxidx
	.global adc_bx_siidx, adc_bx_diidx, adc_bx_bxidx
	.global adc_sp_siidx, adc_sp_diidx, adc_sp_bxidx
	.global adc_bp_siidx, adc_bp_diidx, adc_bp_bxidx
	.global adc_si_siidx, adc_si_diidx, adc_si_bxidx
	.global adc_di_siidx, adc_di_diidx, adc_di_bxidx
	.global adc_ax_sidisp8, adc_ax_didisp8, adc_ax_bpdisp8, adc_ax_bxdisp8
	.global adc_cx_sidisp8, adc_cx_didisp8, adc_cx_bpdisp8, adc_cx_bxdisp8
	.global adc_dx_sidisp8, adc_dx_didisp8, adc_dx_bpdisp8, adc_dx_bxdisp8
	.global adc_bx_sidisp8, adc_bx_didisp8, adc_bx_bpdisp8, adc_bx_bxdisp8
	.global adc_sp_sidisp8, adc_sp_didisp8, adc_sp_bpdisp8, adc_sp_bxdisp8
	.global adc_bp_sidisp8, adc_bp_didisp8, adc_bp_bpdisp8, adc_bp_bxdisp8
	.global adc_si_sidisp8, adc_si_didisp8, adc_si_bpdisp8, adc_si_bxdisp8
	.global adc_di_sidisp8, adc_di_didisp8, adc_di_bpdisp8, adc_di_bxdisp8
	.global	adc_r16_r0_bp_r4, adc_r16_r0_bp_r5, adc_r16_r0_bp_r6, adc_r16_r0_bp_r7, adc_r16_r0_bp_r8, adc_r16_r0_bp_r9, adc_r16_r0_bp_r10, adc_r16_r0_bp_r11
	.global	adc_r16_r0_r4, adc_r16_r0_r5, adc_r16_r0_r6, adc_r16_r0_r7, adc_r16_r0_r8, adc_r16_r0_r9, adc_r16_r0_r10, adc_r16_r0_r11

.macro adc_reg16_r0high reg
adc_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
adc_r16_r0_\reg:
	mem_handler_jump_r0r3 .op_13_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory adcress
	//-------
.op_13_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r2, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	eor		\reg, r2, lsr #16
	addcs	r2, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r2, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r2, r0, lsl #16		// Perform the actual addition, setting the resulting flags.
	orr		\reg, r0, lsr #16
	b		loop
.endm

	adc_reg16_r0high r4
	adc_reg16_r0high r5
	adc_reg16_r0high r6
	adc_reg16_r0high r7
	adc_reg16_r0high r8
	adc_reg16_r0high r9
	adc_reg16_r0high r10
	adc_reg16_r0high r11

	.ltorg

// --- [idx] ---

.macro adc_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		adc_r16_r0_\reg
.endm

adc_ax_bxsi:
	adc_reg16_bxidx r4 r10
adc_cx_bxsi:
	adc_reg16_bxidx r5 r10
adc_dx_bxsi:
	adc_reg16_bxidx r6 r10
adc_bx_bxsi:
	adc_reg16_bxidx r7 r10
adc_bp_bxsi:
	adc_reg16_bxidx r9 r10
adc_sp_bxsi:
	adc_reg16_bxidx r8 r10
adc_si_bxsi:
	adc_reg16_bxidx r10 r10
adc_di_bxsi:
	adc_reg16_bxidx r11 r10

adc_ax_bxdi:
	adc_reg16_bxidx r4 r11
adc_cx_bxdi:
	adc_reg16_bxidx r5 r11
adc_dx_bxdi:
	adc_reg16_bxidx r6 r11
adc_bx_bxdi:
	adc_reg16_bxidx r7 r11
adc_sp_bxdi:
	adc_reg16_bxidx r8 r11
adc_bp_bxdi:
	adc_reg16_bxidx r9 r11
adc_si_bxdi:
	adc_reg16_bxidx r10 r11
adc_di_bxdi:
	adc_reg16_bxidx r11 r11

.macro adc_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		adc_r16_r0_bp_\reg
.endm

adc_ax_bpsi:
	adc_reg16_bpidx r4 r10
adc_cx_bpsi:
	adc_reg16_bpidx r5 r10
adc_dx_bpsi:
	adc_reg16_bpidx r6 r10
adc_bx_bpsi:
	adc_reg16_bpidx r7 r10
adc_sp_bpsi:
	adc_reg16_bpidx r8 r10
adc_bp_bpsi:
	adc_reg16_bpidx r9 r10
adc_si_bpsi:
	adc_reg16_bpidx r10 r10
adc_di_bpsi:
	adc_reg16_bpidx r11 r10

adc_ax_bpdi:
	adc_reg16_bpidx r4 r11
adc_cx_bpdi:
	adc_reg16_bpidx r5 r11
adc_dx_bpdi:
	adc_reg16_bpidx r6 r11
adc_bx_bpdi:
	adc_reg16_bpidx r7 r11
adc_sp_bpdi:
	adc_reg16_bpidx r8 r11
adc_bp_bpdi:
	adc_reg16_bpidx r9 r11
adc_si_bpdi:
	adc_reg16_bpidx r10 r11
adc_di_bpdi:
	adc_reg16_bpidx r11 r11

.macro adc_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		adc_r16_r0_\reg
.endm

adc_ax_siidx:
	adc_reg16_idx r4 r10
adc_cx_siidx:
	adc_reg16_idx r5 r10
adc_dx_siidx:
	adc_reg16_idx r6 r10
adc_bx_siidx:
	adc_reg16_idx r7 r10
adc_sp_siidx:
	adc_reg16_idx r8 r10
adc_bp_siidx:
	adc_reg16_idx r9 r10
adc_si_siidx:
	adc_reg16_idx r10 r10
adc_di_siidx:
	adc_reg16_idx r11 r10

adc_ax_diidx:
	adc_reg16_idx r4 r11
adc_cx_diidx:
	adc_reg16_idx r5 r11
adc_dx_diidx:
	adc_reg16_idx r6 r11
adc_bx_diidx:
	adc_reg16_idx r7 r11
adc_sp_diidx:
	adc_reg16_idx r8 r11
adc_bp_diidx:
	adc_reg16_idx r9 r11
adc_si_diidx:
	adc_reg16_idx r10 r11
adc_di_diidx:
	adc_reg16_idx r11 r11

adc_ax_bxidx:
	adc_reg16_idx r4 r7
adc_cx_bxidx:
	adc_reg16_idx r5 r7
adc_dx_bxidx:
	adc_reg16_idx r6 r7
adc_bx_bxidx:
	adc_reg16_idx r7 r7
adc_sp_bxidx:
	adc_reg16_idx r8 r7
adc_bp_bxidx:
	adc_reg16_idx r9 r7
adc_si_bxidx:
	adc_reg16_idx r10 r7
adc_di_bxidx:
	adc_reg16_idx r11 r7

.macro adc_reg16_disp16 reg
	r0_from_disp16
	b		adc_r16_r0_\reg
.endm

adc_ax_disp16:
	adc_reg16_disp16 r4
adc_cx_disp16:
	adc_reg16_disp16 r5
adc_dx_disp16:
	adc_reg16_disp16 r6
adc_bx_disp16:
	adc_reg16_disp16 r7
adc_sp_disp16:
	adc_reg16_disp16 r8
adc_bp_disp16:
	adc_reg16_disp16 r9
adc_si_disp16:
	adc_reg16_disp16 r10
adc_di_disp16:
	adc_reg16_disp16 r11

// --- [idx+disp8] ---

.macro adc_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		adc_r16_r0_\reg
.endm

adc_ax_bxsid8:
	adc_reg16_bxidxdisp8 r4 r10
adc_cx_bxsid8:
	adc_reg16_bxidxdisp8 r5 r10
adc_dx_bxsid8:
	adc_reg16_bxidxdisp8 r6 r10
adc_bx_bxsid8:
	adc_reg16_bxidxdisp8 r7 r10
adc_sp_bxsid8:
	adc_reg16_bxidxdisp8 r8 r10
adc_bp_bxsid8:
	adc_reg16_bxidxdisp8 r9 r10
adc_si_bxsid8:
	adc_reg16_bxidxdisp8 r10 r10
adc_di_bxsid8:
	adc_reg16_bxidxdisp8 r11 r10

adc_ax_bxdid8:
	adc_reg16_bxidxdisp8 r4 r11
adc_cx_bxdid8:
	adc_reg16_bxidxdisp8 r5 r11
adc_dx_bxdid8:
	adc_reg16_bxidxdisp8 r6 r11
adc_bx_bxdid8:
	adc_reg16_bxidxdisp8 r7 r11
adc_sp_bxdid8:
	adc_reg16_bxidxdisp8 r8 r11
adc_bp_bxdid8:
	adc_reg16_bxidxdisp8 r9 r11
adc_si_bxdid8:
	adc_reg16_bxidxdisp8 r10 r11
adc_di_bxdid8:
	adc_reg16_bxidxdisp8 r11 r11

.macro adc_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		adc_r16_r0_bp_\reg
.endm

adc_ax_bpsid8:
	adc_reg16_bpidxdisp8 r4 r10
adc_cx_bpsid8:
	adc_reg16_bpidxdisp8 r5 r10
adc_dx_bpsid8:
	adc_reg16_bpidxdisp8 r6 r10
adc_bx_bpsid8:
	adc_reg16_bpidxdisp8 r7 r10
adc_sp_bpsid8:
	adc_reg16_bpidxdisp8 r8 r10
adc_bp_bpsid8:
	adc_reg16_bpidxdisp8 r9 r10
adc_si_bpsid8:
	adc_reg16_bpidxdisp8 r10 r10
adc_di_bpsid8:
	adc_reg16_bpidxdisp8 r11 r10

adc_ax_bpdid8:
	adc_reg16_bpidxdisp8 r4 r11
adc_cx_bpdid8:
	adc_reg16_bpidxdisp8 r5 r11
adc_dx_bpdid8:
	adc_reg16_bpidxdisp8 r6 r11
adc_bx_bpdid8:
	adc_reg16_bpidxdisp8 r7 r11
adc_sp_bpdid8:
	adc_reg16_bpidxdisp8 r8 r11
adc_bp_bpdid8:
	adc_reg16_bpidxdisp8 r9 r11
adc_si_bpdid8:
	adc_reg16_bpidxdisp8 r10 r11
adc_di_bpdid8:
	adc_reg16_bpidxdisp8 r11 r11

.macro adc_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		adc_r16_r0_\reg
.endm

adc_ax_sidisp8:
	adc_reg16_idxdisp8 r4 r10
adc_cx_sidisp8:
	adc_reg16_idxdisp8 r5 r10
adc_dx_sidisp8:
	adc_reg16_idxdisp8 r6 r10
adc_bx_sidisp8:
	adc_reg16_idxdisp8 r7 r10
adc_sp_sidisp8:
	adc_reg16_idxdisp8 r8 r10
adc_bp_sidisp8:
	adc_reg16_idxdisp8 r9 r10
adc_si_sidisp8:
	adc_reg16_idxdisp8 r10 r10
adc_di_sidisp8:
	adc_reg16_idxdisp8 r11 r10

adc_ax_didisp8:
	adc_reg16_idxdisp8 r4 r11
adc_cx_didisp8:
	adc_reg16_idxdisp8 r5 r11
adc_dx_didisp8:
	adc_reg16_idxdisp8 r6 r11
adc_bx_didisp8:
	adc_reg16_idxdisp8 r7 r11
adc_sp_didisp8:
	adc_reg16_idxdisp8 r8 r11
adc_bp_didisp8:
	adc_reg16_idxdisp8 r9 r11
adc_si_didisp8:
	adc_reg16_idxdisp8 r10 r11
adc_di_didisp8:
	adc_reg16_idxdisp8 r11 r11

adc_ax_bxdisp8:
	adc_reg16_idxdisp8 r4 r7
adc_cx_bxdisp8:
	adc_reg16_idxdisp8 r5 r7
adc_dx_bxdisp8:
	adc_reg16_idxdisp8 r6 r7
adc_bx_bxdisp8:
	adc_reg16_idxdisp8 r7 r7
adc_sp_bxdisp8:
	adc_reg16_idxdisp8 r8 r7
adc_bp_bxdisp8:
	adc_reg16_idxdisp8 r9 r7
adc_si_bxdisp8:
	adc_reg16_idxdisp8 r10 r7
adc_di_bxdisp8:
	adc_reg16_idxdisp8 r11 r7

.macro adc_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		adc_r16_r0_bp_\reg
.endm

adc_ax_bpdisp8:
	adc_reg16_bpdisp8 r4
adc_cx_bpdisp8:
	adc_reg16_bpdisp8 r5
adc_dx_bpdisp8:
	adc_reg16_bpdisp8 r6
adc_bx_bpdisp8:
	adc_reg16_bpdisp8 r7
adc_sp_bpdisp8:
	adc_reg16_bpdisp8 r8
adc_bp_bpdisp8:
	adc_reg16_bpdisp8 r9
adc_si_bpdisp8:
	adc_reg16_bpdisp8 r10
adc_di_bpdisp8:
	adc_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro adc_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		adc_r16_r0_\reg
.endm

adc_ax_bxsid16:
	adc_reg16_bxidxdisp16 r4 r10
adc_cx_bxsid16:
	adc_reg16_bxidxdisp16 r5 r10
adc_dx_bxsid16:
	adc_reg16_bxidxdisp16 r6 r10
adc_bx_bxsid16:
	adc_reg16_bxidxdisp16 r7 r10
adc_sp_bxsid16:
	adc_reg16_bxidxdisp16 r8 r10
adc_bp_bxsid16:
	adc_reg16_bxidxdisp16 r9 r10
adc_si_bxsid16:
	adc_reg16_bxidxdisp16 r10 r10
adc_di_bxsid16:
	adc_reg16_bxidxdisp16 r11 r10

adc_ax_bxdid16:
	adc_reg16_bxidxdisp16 r4 r11
adc_cx_bxdid16:
	adc_reg16_bxidxdisp16 r5 r11
adc_dx_bxdid16:
	adc_reg16_bxidxdisp16 r6 r11
adc_bx_bxdid16:
	adc_reg16_bxidxdisp16 r7 r11
adc_sp_bxdid16:
	adc_reg16_bxidxdisp16 r8 r11
adc_bp_bxdid16:
	adc_reg16_bxidxdisp16 r9 r11
adc_si_bxdid16:
	adc_reg16_bxidxdisp16 r10 r11
adc_di_bxdid16:
	adc_reg16_bxidxdisp16 r11 r11

.macro adc_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		adc_r16_r0_bp_\reg
.endm

adc_ax_bpsid16:
	adc_reg16_bpidxdisp16 r4 r10
adc_cx_bpsid16:
	adc_reg16_bpidxdisp16 r5 r10
adc_dx_bpsid16:
	adc_reg16_bpidxdisp16 r6 r10
adc_bx_bpsid16:
	adc_reg16_bpidxdisp16 r7 r10
adc_sp_bpsid16:
	adc_reg16_bpidxdisp16 r8 r10
adc_bp_bpsid16:
	adc_reg16_bpidxdisp16 r9 r10
adc_si_bpsid16:
	adc_reg16_bpidxdisp16 r10 r10
adc_di_bpsid16:
	adc_reg16_bpidxdisp16 r11 r10

adc_ax_bpdid16:
	adc_reg16_bpidxdisp16 r4 r11
adc_cx_bpdid16:
	adc_reg16_bpidxdisp16 r5 r11
adc_dx_bpdid16:
	adc_reg16_bpidxdisp16 r6 r11
adc_bx_bpdid16:
	adc_reg16_bpidxdisp16 r7 r11
adc_sp_bpdid16:
	adc_reg16_bpidxdisp16 r8 r11
adc_bp_bpdid16:
	adc_reg16_bpidxdisp16 r9 r11
adc_si_bpdid16:
	adc_reg16_bpidxdisp16 r10 r11
adc_di_bpdid16:
	adc_reg16_bpidxdisp16 r11 r11

.macro adc_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		adc_r16_r0_\reg
.endm

adc_ax_sidisp16:
	adc_reg16_idxdisp16 r4 r10
adc_cx_sidisp16:
	adc_reg16_idxdisp16 r5 r10
adc_dx_sidisp16:
	adc_reg16_idxdisp16 r6 r10
adc_bx_sidisp16:
	adc_reg16_idxdisp16 r7 r10
adc_sp_sidisp16:
	adc_reg16_idxdisp16 r8 r10
adc_bp_sidisp16:
	adc_reg16_idxdisp16 r9 r10
adc_si_sidisp16:
	adc_reg16_idxdisp16 r10 r10
adc_di_sidisp16:
	adc_reg16_idxdisp16 r11 r10

adc_ax_didisp16:
	adc_reg16_idxdisp16 r4 r11
adc_cx_didisp16:
	adc_reg16_idxdisp16 r5 r11
adc_dx_didisp16:
	adc_reg16_idxdisp16 r6 r11
adc_bx_didisp16:
	adc_reg16_idxdisp16 r7 r11
adc_sp_didisp16:
	adc_reg16_idxdisp16 r8 r11
adc_bp_didisp16:
	adc_reg16_idxdisp16 r9 r11
adc_si_didisp16:
	adc_reg16_idxdisp16 r10 r11
adc_di_didisp16:
	adc_reg16_idxdisp16 r11 r11

adc_ax_bxdisp16:
	adc_reg16_idxdisp16 r4 r7
adc_cx_bxdisp16:
	adc_reg16_idxdisp16 r5 r7
adc_dx_bxdisp16:
	adc_reg16_idxdisp16 r6 r7
adc_bx_bxdisp16:
	adc_reg16_idxdisp16 r7 r7
adc_sp_bxdisp16:
	adc_reg16_idxdisp16 r8 r7
adc_bp_bxdisp16:
	adc_reg16_idxdisp16 r9 r7
adc_si_bxdisp16:
	adc_reg16_idxdisp16 r10 r7
adc_di_bxdisp16:
	adc_reg16_idxdisp16 r11 r7

.macro adc_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		adc_r16_r0_bp_\reg
.endm

adc_ax_bpdisp16:
	adc_reg16_bpdisp16 r4
adc_cx_bpdisp16:
	adc_reg16_bpdisp16 r5
adc_dx_bpdisp16:
	adc_reg16_bpdisp16 r6
adc_bx_bpdisp16:
	adc_reg16_bpdisp16 r7
adc_sp_bpdisp16:
	adc_reg16_bpdisp16 r8
adc_bp_bpdisp16:
	adc_reg16_bpdisp16 r9
adc_si_bpdisp16:
	adc_reg16_bpdisp16 r10
adc_di_bpdisp16:
	adc_reg16_bpdisp16 r11


// --- registers ---

.macro adc_reg16_reg16 rl rr
	mov		r0, \rl, lsl #16		// r0 = left operand in high halfword
	mov		r1, \rr, lsl #16		// r1 = right operand in high halfword
	eor		\rl, r0, lsr #16
	addcs	r0, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1					// Perform the actual addition, setting the resulting flags.
	orr		\rl, r0, lsr #16
	b		loop
.endm

adc_ax_ax:
	adc_reg16_reg16		r4 r4
adc_ax_cx:
	adc_reg16_reg16		r4 r5
adc_ax_dx:
	adc_reg16_reg16		r4 r6
adc_ax_bx:
	adc_reg16_reg16		r4 r7
adc_ax_sp:
	adc_reg16_reg16		r4 r8
adc_ax_bp:
	adc_reg16_reg16		r4 r9
adc_ax_si:
	adc_reg16_reg16		r4 r10
adc_ax_di:
	adc_reg16_reg16		r4 r11
adc_cx_ax:
	adc_reg16_reg16		r5 r4
adc_cx_cx:
	adc_reg16_reg16		r5 r5
adc_cx_dx:
	adc_reg16_reg16		r5 r6
adc_cx_bx:
	adc_reg16_reg16		r5 r7
adc_cx_sp:
	adc_reg16_reg16		r5 r8
adc_cx_bp:
	adc_reg16_reg16		r5 r9
adc_cx_si:
	adc_reg16_reg16		r5 r10
adc_cx_di:
	adc_reg16_reg16		r5 r11
adc_dx_ax:
	adc_reg16_reg16		r6 r4
adc_dx_cx:
	adc_reg16_reg16		r6 r5
adc_dx_dx:
	adc_reg16_reg16		r6 r6
adc_dx_bx:
	adc_reg16_reg16		r6 r7
adc_dx_sp:
	adc_reg16_reg16		r6 r8
adc_dx_bp:
	adc_reg16_reg16		r6 r9
adc_dx_si:
	adc_reg16_reg16		r6 r10
adc_dx_di:
	adc_reg16_reg16		r6 r11
adc_bx_ax:
	adc_reg16_reg16		r7 r4
adc_bx_cx:
	adc_reg16_reg16		r7 r5
adc_bx_dx:
	adc_reg16_reg16		r7 r6
adc_bx_bx:
	adc_reg16_reg16		r7 r7
adc_bx_sp:
	adc_reg16_reg16		r7 r8
adc_bx_bp:
	adc_reg16_reg16		r7 r9
adc_bx_si:
	adc_reg16_reg16		r7 r10
adc_bx_di:
	adc_reg16_reg16		r7 r11
adc_sp_ax:
	adc_reg16_reg16		r8 r4
adc_sp_cx:
	adc_reg16_reg16		r8 r5
adc_sp_dx:
	adc_reg16_reg16		r8 r6
adc_sp_bx:
	adc_reg16_reg16		r8 r7
adc_sp_sp:
	adc_reg16_reg16		r8 r8
adc_sp_bp:
	adc_reg16_reg16		r8 r9
adc_sp_si:
	adc_reg16_reg16		r8 r10
adc_sp_di:
	adc_reg16_reg16		r8 r11
adc_bp_ax:
	adc_reg16_reg16		r9 r4
adc_bp_cx:
	adc_reg16_reg16		r9 r5
adc_bp_dx:
	adc_reg16_reg16		r9 r6
adc_bp_bx:
	adc_reg16_reg16		r9 r7
adc_bp_sp:
	adc_reg16_reg16		r9 r8
adc_bp_bp:
	adc_reg16_reg16		r9 r9
adc_bp_si:
	adc_reg16_reg16		r9 r10
adc_bp_di:
	adc_reg16_reg16		r9 r11
adc_si_ax:
	adc_reg16_reg16		r10 r4
adc_si_cx:
	adc_reg16_reg16		r10 r5
adc_si_dx:
	adc_reg16_reg16		r10 r6
adc_si_bx:
	adc_reg16_reg16		r10 r7
adc_si_sp:
	adc_reg16_reg16		r10 r8
adc_si_bp:
	adc_reg16_reg16		r10 r9
adc_si_si:
	adc_reg16_reg16		r10 r10
adc_si_di:
	adc_reg16_reg16		r10 r11
adc_di_ax:
	adc_reg16_reg16		r11 r4
adc_di_cx:
	adc_reg16_reg16		r11 r5
adc_di_dx:
	adc_reg16_reg16		r11 r6
adc_di_bx:
	adc_reg16_reg16		r11 r7
adc_di_sp:
	adc_reg16_reg16		r11 r8
adc_di_bp:
	adc_reg16_reg16		r11 r9
adc_di_si:
	adc_reg16_reg16		r11 r10
adc_di_di:
	adc_reg16_reg16		r11 r11


#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	


// ------------------- 14 = ADC AL,imm8 --------------------------------
op_14:
	ldrb	r1,[r12],#1				// Load low byte to r1, increment r12 by 1
	lsl		r1, #24
	addcs	r1, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r1, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, eax, lsl #24	// Perform the actual addition, setting the resulting flags.
	bic		eax, #0xFF				// Clear the current AL value
	orr		eax, r0, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	b		loop

// ------------------- 15 = ADC AX,imm16 -------------------------------
//
op_15:
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load high byte to r0, increment r12 by 1
	lsl		r0, #16
	orr		r0, r1, lsl #24			// r0 = low byte | (high byte << 8)
	mov		r1, eax, lsl #16
	eor		eax, r1, lsr #16
	addcs	r0, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1					// Perform the actual addition, setting the resulting flags.
	orr		eax, r0, lsr #16
	b		loop

// ------------------- 16 = PUSH SS ------------------------------------
op_16:
	ldr		r0, [sp, #SP_SS_VALUE]
	push_hword r0 r1 r2
	b		loop

// ------------------- 17 = POP SS -------------------------------------
op_17:
	pop_reg_low_tmp	r2 r1
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]				// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr							// Save current flags to r0
	tst		r3, #1								// Are we in protected mode (or in VM mode)?
	bne		mov_ss_r0r2_prot					// Yes we are, go handle protected mode version!
	msr		cpsr_f, r0							// Restore flags
	//-------
	// We are in real mode, so use the simple handling.
	//-------
	str		r2, [sp, #SP_SS_VALUE]
	lsl		r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_SS_BASE]
	mov		lr, r2
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_SS]
	//-------
	// NOTE! x86 disables interrupts until the next instruction has been executed.
	// Thus we must handle the next opcode immediately!
	//-------
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	ldr		r2, [sp, #SP_DS_BASE]				// r2 high halfword = logical DS segment, clear segment override flags
	ldr		pc,[sp, r0, lsl #2]					// Jump to the opcode handler


	.ltorg
	
	.text
	.align 2

// ------------------- 18 = SBB r/m8, r8 -----------------------------
//
// All modrm variations supported!
//
//
op_18:
	modrm_jump_16
// 0
	.word sbb_bxsi_al, sbb_bxdi_al, sbb_bpsi_al, sbb_bpdi_al, sbb_siidx_al, sbb_diidx_al, sbb_disp16_al, sbb_bxidx_al
	.word sbb_bxsi_cl, sbb_bxdi_cl, sbb_bpsi_cl, sbb_bpdi_cl, sbb_siidx_cl, sbb_diidx_cl, sbb_disp16_cl, sbb_bxidx_cl
	.word sbb_bxsi_dl, sbb_bxdi_dl, sbb_bpsi_dl, sbb_bpdi_dl, sbb_siidx_dl, sbb_diidx_dl, sbb_disp16_dl, sbb_bxidx_dl
	.word sbb_bxsi_bl, sbb_bxdi_bl, sbb_bpsi_bl, sbb_bpdi_bl, sbb_siidx_bl, sbb_diidx_bl, sbb_disp16_bl, sbb_bxidx_bl
	.word sbb_bxsi_ah, sbb_bxdi_ah, sbb_bpsi_ah, sbb_bpdi_ah, sbb_siidx_ah, sbb_diidx_ah, sbb_disp16_ah, sbb_bxidx_ah
	.word sbb_bxsi_ch, sbb_bxdi_ch, sbb_bpsi_ch, sbb_bpdi_ch, sbb_siidx_ch, sbb_diidx_ch, sbb_disp16_ch, sbb_bxidx_ch
	.word sbb_bxsi_dh, sbb_bxdi_dh, sbb_bpsi_dh, sbb_bpdi_dh, sbb_siidx_dh, sbb_diidx_dh, sbb_disp16_dh, sbb_bxidx_dh
	.word sbb_bxsi_bh, sbb_bxdi_bh, sbb_bpsi_bh, sbb_bpdi_bh, sbb_siidx_bh, sbb_diidx_bh, sbb_disp16_bh, sbb_bxidx_bh
//0x40
	.word sbb_bxsid8_al, sbb_bxdid8_al, sbb_bpsid8_al, sbb_bpdid8_al, sbb_sidisp8_al, sbb_didisp8_al, sbb_bpdisp8_al, sbb_bxdisp8_al
	.word sbb_bxsid8_cl, sbb_bxdid8_cl, sbb_bpsid8_cl, sbb_bpdid8_cl, sbb_sidisp8_cl, sbb_didisp8_cl, sbb_bpdisp8_cl, sbb_bxdisp8_cl
	.word sbb_bxsid8_dl, sbb_bxdid8_dl, sbb_bpsid8_dl, sbb_bpdid8_dl, sbb_sidisp8_dl, sbb_didisp8_dl, sbb_bpdisp8_dl, sbb_bxdisp8_dl
	.word sbb_bxsid8_bl, sbb_bxdid8_bl, sbb_bpsid8_bl, sbb_bpdid8_bl, sbb_sidisp8_bl, sbb_didisp8_bl, sbb_bpdisp8_bl, sbb_bxdisp8_bl
	.word sbb_bxsid8_ah, sbb_bxdid8_ah, sbb_bpsid8_ah, sbb_bpdid8_ah, sbb_sidisp8_ah, sbb_didisp8_ah, sbb_bpdisp8_ah, sbb_bxdisp8_ah
	.word sbb_bxsid8_ch, sbb_bxdid8_ch, sbb_bpsid8_ch, sbb_bpdid8_ch, sbb_sidisp8_ch, sbb_didisp8_ch, sbb_bpdisp8_ch, sbb_bxdisp8_ch
	.word sbb_bxsid8_dh, sbb_bxdid8_dh, sbb_bpsid8_dh, sbb_bpdid8_dh, sbb_sidisp8_dh, sbb_didisp8_dh, sbb_bpdisp8_dh, sbb_bxdisp8_dh
	.word sbb_bxsid8_bh, sbb_bxdid8_bh, sbb_bpsid8_bh, sbb_bpdid8_bh, sbb_sidisp8_bh, sbb_didisp8_bh, sbb_bpdisp8_bh, sbb_bxdisp8_bh
//0x80
	.word sbb_bxsid16_al, sbb_bxdid16_al, sbb_bpsid16_al, sbb_bpdid16_al, sbb_sidisp16_al, sbb_didisp16_al, sbb_bpdisp16_al, sbb_bxdisp16_al
	.word sbb_bxsid16_cl, sbb_bxdid16_cl, sbb_bpsid16_cl, sbb_bpdid16_cl, sbb_sidisp16_cl, sbb_didisp16_cl, sbb_bpdisp16_cl, sbb_bxdisp16_cl
	.word sbb_bxsid16_dl, sbb_bxdid16_dl, sbb_bpsid16_dl, sbb_bpdid16_dl, sbb_sidisp16_dl, sbb_didisp16_dl, sbb_bpdisp16_dl, sbb_bxdisp16_dl
	.word sbb_bxsid16_bl, sbb_bxdid16_bl, sbb_bpsid16_bl, sbb_bpdid16_bl, sbb_sidisp16_bl, sbb_didisp16_bl, sbb_bpdisp16_bl, sbb_bxdisp16_bl
	.word sbb_bxsid16_ah, sbb_bxdid16_ah, sbb_bpsid16_ah, sbb_bpdid16_ah, sbb_sidisp16_ah, sbb_didisp16_ah, sbb_bpdisp16_ah, sbb_bxdisp16_ah
	.word sbb_bxsid16_ch, sbb_bxdid16_ch, sbb_bpsid16_ch, sbb_bpdid16_ch, sbb_sidisp16_ch, sbb_didisp16_ch, sbb_bpdisp16_ch, sbb_bxdisp16_ch
	.word sbb_bxsid16_dh, sbb_bxdid16_dh, sbb_bpsid16_dh, sbb_bpdid16_dh, sbb_sidisp16_dh, sbb_didisp16_dh, sbb_bpdisp16_dh, sbb_bxdisp16_dh
	.word sbb_bxsid16_bh, sbb_bxdid16_bh, sbb_bpsid16_bh, sbb_bpdid16_bh, sbb_sidisp16_bh, sbb_didisp16_bh, sbb_bpdisp16_bh, sbb_bxdisp16_bh
// 0xC0 = two register operands
	.word sbb_al_al, sbb_cl_al, sbb_dl_al, sbb_bl_al, sbb_ah_al, sbb_ch_al, sbb_dh_al, sbb_bh_al
	.word sbb_al_cl, sbb_cl_cl, sbb_dl_cl, sbb_bl_cl, sbb_ah_cl, sbb_ch_cl, sbb_dh_cl, sbb_bh_cl
	.word sbb_al_dl, sbb_cl_dl, sbb_dl_dl, sbb_bl_dl, sbb_ah_dl, sbb_ch_dl, sbb_dh_dl, sbb_bh_dl
	.word sbb_al_bl, sbb_cl_bl, sbb_dl_bl, sbb_bl_bl, sbb_ah_bl, sbb_ch_bl, sbb_dh_bl, sbb_bh_bl
	.word sbb_al_ah, sbb_cl_ah, sbb_dl_ah, sbb_bl_ah, sbb_ah_ah, sbb_ch_ah, sbb_dh_ah, sbb_bh_ah
	.word sbb_al_ch, sbb_cl_ch, sbb_dl_ch, sbb_bl_ch, sbb_ah_ch, sbb_ch_ch, sbb_dh_ch, sbb_bh_ch
	.word sbb_al_dh, sbb_cl_dh, sbb_dl_dh, sbb_bl_dh, sbb_ah_dh, sbb_ch_dh, sbb_dh_dh, sbb_bh_dh
	.word sbb_al_bh, sbb_cl_bh, sbb_dl_bh, sbb_bl_bh, sbb_ah_bh, sbb_ch_bh, sbb_dh_bh, sbb_bh_bh

// These are called from "cpu_386.s":

	.global	sbb_siidx_al, sbb_siidx_cl, sbb_siidx_dl, sbb_siidx_bl, sbb_siidx_ah, sbb_siidx_ch, sbb_siidx_dh, sbb_siidx_bh
	.global	sbb_diidx_al, sbb_diidx_cl, sbb_diidx_dl, sbb_diidx_bl, sbb_diidx_ah, sbb_diidx_ch, sbb_diidx_dh, sbb_diidx_bh
	.global	sbb_bxidx_al, sbb_bxidx_cl, sbb_bxidx_dl, sbb_bxidx_bl, sbb_bxidx_ah, sbb_bxidx_ch, sbb_bxidx_dh, sbb_bxidx_bh
	.global	sbb_sidisp8_al, sbb_sidisp8_cl, sbb_sidisp8_dl, sbb_sidisp8_bl, sbb_sidisp8_ah, sbb_sidisp8_ch, sbb_sidisp8_dh, sbb_sidisp8_bh
	.global	sbb_didisp8_al, sbb_didisp8_cl, sbb_didisp8_dl, sbb_didisp8_bl, sbb_didisp8_ah, sbb_didisp8_ch, sbb_didisp8_dh, sbb_didisp8_bh
	.global	sbb_bpdisp8_al, sbb_bpdisp8_cl, sbb_bpdisp8_dl, sbb_bpdisp8_bl, sbb_bpdisp8_ah, sbb_bpdisp8_ch, sbb_bpdisp8_dh, sbb_bpdisp8_bh
	.global	sbb_bxdisp8_al, sbb_bxdisp8_cl, sbb_bxdisp8_dl, sbb_bxdisp8_bl, sbb_bxdisp8_ah, sbb_bxdisp8_ch, sbb_bxdisp8_dh, sbb_bxdisp8_bh

	//-------
	// SBB with input carry set, we need to calculate the proper flags manually.
	// On input:
	//	r0 = byte from RAM
	//	r1 = register value
	//	r2 = RAM address
	//	r3 = free
	//-------
.op_18_sbb_carry_r1:	
	sub		r3, r0, r1				// r2 = lf_var1d - lf_var2d
	sub		r3, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r3, r3, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	lsr		r3, #24
	strb	r3,[r2]					// Store byte to RAM
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0
	eor		r3, r0
	and		r1, r3
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0

.macro sbb_r0_reg8l reg
	.global	sbb_r0_r8l_bp_\reg
sbb_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	sbb_r0_r8l_\reg
sbb_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_18_RAM_l_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_18_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	bcs		1f
	lsl		r0, #24
	subs	r0, \reg, lsl #24		// Perform the actual subtraction, setting the resulting flags.
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to [physical segment + disp16]
	b		complement_carry
1:	and		r1, \reg, #0xFF
	b		.op_18_sbb_carry_r1
.endm
.macro sbb_r0_reg8h reg
	.global	sbb_r0_r8h_bp_\reg
sbb_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	sbb_r0_r8h_\reg
sbb_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_18_RAM_h_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_18_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	bcs		1f
	lsl		r0, #24
	subs	r0, r1, lsl #16			// Perform the actual subtraction, setting the resulting flags.
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to RAM
	b		complement_carry
1:	lsr		r1, #8
	b		.op_18_sbb_carry_r1
.endm

	sbb_r0_reg8l r4
	sbb_r0_reg8l r5
	sbb_r0_reg8l r6
	sbb_r0_reg8l r7
	sbb_r0_reg8h r4
	sbb_r0_reg8h r5
	sbb_r0_reg8h r6
	sbb_r0_reg8h r7

	.ltorg

// --- [idx] ---

.macro sbb_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		sbb_r0_r8l_\reg
.endm
.macro sbb_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		sbb_r0_r8h_\reg
.endm

sbb_bxsi_al:
	sbb_bxidx_reg8l r10 r4
sbb_bxsi_cl:
	sbb_bxidx_reg8l r10 r5
sbb_bxsi_dl:
	sbb_bxidx_reg8l r10 r6
sbb_bxsi_bl:
	sbb_bxidx_reg8l r10 r7
sbb_bxsi_ah:
	sbb_bxidx_reg8h r10 r4
sbb_bxsi_ch:
	sbb_bxidx_reg8h r10 r5
sbb_bxsi_dh:
	sbb_bxidx_reg8h r10 r6
sbb_bxsi_bh:
	sbb_bxidx_reg8h r10 r7

sbb_bxdi_al:
	sbb_bxidx_reg8l r11 r4
sbb_bxdi_cl:
	sbb_bxidx_reg8l r11 r5
sbb_bxdi_dl:
	sbb_bxidx_reg8l r11 r6
sbb_bxdi_bl:
	sbb_bxidx_reg8l r11 r7
sbb_bxdi_ah:
	sbb_bxidx_reg8h r11 r4
sbb_bxdi_ch:
	sbb_bxidx_reg8h r11 r5
sbb_bxdi_dh:
	sbb_bxidx_reg8h r11 r6
sbb_bxdi_bh:
	sbb_bxidx_reg8h r11 r7

.macro sbb_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		sbb_r0_r8l_bp_\reg
.endm
.macro sbb_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		sbb_r0_r8h_bp_\reg
.endm

sbb_bpsi_al:
	sbb_bpidx_reg8l r10 r4
sbb_bpsi_cl:
	sbb_bpidx_reg8l r10 r5
sbb_bpsi_dl:
	sbb_bpidx_reg8l r10 r6
sbb_bpsi_bl:
	sbb_bpidx_reg8l r10 r7
sbb_bpsi_ah:
	sbb_bpidx_reg8h r10 r4
sbb_bpsi_ch:
	sbb_bpidx_reg8h r10 r5
sbb_bpsi_dh:
	sbb_bpidx_reg8h r10 r6
sbb_bpsi_bh:
	sbb_bpidx_reg8h r10 r7

sbb_bpdi_al:
	sbb_bpidx_reg8l r11 r4
sbb_bpdi_cl:
	sbb_bpidx_reg8l r11 r5
sbb_bpdi_dl:
	sbb_bpidx_reg8l r11 r6
sbb_bpdi_bl:
	sbb_bpidx_reg8l r11 r7
sbb_bpdi_ah:
	sbb_bpidx_reg8h r11 r4
sbb_bpdi_ch:
	sbb_bpidx_reg8h r11 r5
sbb_bpdi_dh:
	sbb_bpidx_reg8h r11 r6
sbb_bpdi_bh:
	sbb_bpidx_reg8h r11 r7

.macro sbb_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		sbb_r0_r8l_\reg
.endm
.macro sbb_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		sbb_r0_r8h_\reg
.endm

sbb_siidx_al:
	sbb_idx_reg8l r10 r4
sbb_siidx_cl:
	sbb_idx_reg8l r10 r5
sbb_siidx_dl:
	sbb_idx_reg8l r10 r6
sbb_siidx_bl:
	sbb_idx_reg8l r10 r7
sbb_siidx_ah:
	sbb_idx_reg8h r10 r4
sbb_siidx_ch:
	sbb_idx_reg8h r10 r5
sbb_siidx_dh:
	sbb_idx_reg8h r10 r6
sbb_siidx_bh:
	sbb_idx_reg8h r10 r7

sbb_diidx_al:
	sbb_idx_reg8l r11 r4
sbb_diidx_cl:
	sbb_idx_reg8l r11 r5
sbb_diidx_dl:
	sbb_idx_reg8l r11 r6
sbb_diidx_bl:
	sbb_idx_reg8l r11 r7
sbb_diidx_ah:
	sbb_idx_reg8h r11 r4
sbb_diidx_ch:
	sbb_idx_reg8h r11 r5
sbb_diidx_dh:
	sbb_idx_reg8h r11 r6
sbb_diidx_bh:
	sbb_idx_reg8h r11 r7

sbb_bxidx_al:
	sbb_idx_reg8l r7 r4
sbb_bxidx_cl:
	sbb_idx_reg8l r7 r5
sbb_bxidx_dl:
	sbb_idx_reg8l r7 r6
sbb_bxidx_bl:
	sbb_idx_reg8l r7 r7
sbb_bxidx_ah:
	sbb_idx_reg8h r7 r4
sbb_bxidx_ch:
	sbb_idx_reg8h r7 r5
sbb_bxidx_dh:
	sbb_idx_reg8h r7 r6
sbb_bxidx_bh:
	sbb_idx_reg8h r7 r7
	
.macro sbb_disp16_reg8l reg
	r0_from_disp16
	b		sbb_r0_r8l_\reg
.endm

.macro sbb_disp16_reg8h reg
	r0_from_disp16
	b		sbb_r0_r8h_\reg
.endm

sbb_disp16_al:
	sbb_disp16_reg8l r4
sbb_disp16_cl:
	sbb_disp16_reg8l r5
sbb_disp16_dl:
	sbb_disp16_reg8l r6
sbb_disp16_bl:
	sbb_disp16_reg8l r7
sbb_disp16_ah:
	sbb_disp16_reg8h r4
sbb_disp16_ch:
	sbb_disp16_reg8h r5
sbb_disp16_dh:
	sbb_disp16_reg8h r6
sbb_disp16_bh:
	sbb_disp16_reg8h r7

// --- [idx+disp8] ---

.macro sbb_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		sbb_r0_r8l_\reg
.endm
.macro sbb_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		sbb_r0_r8h_\reg
.endm

sbb_bxsid8_al:
	sbb_bxidxd8_reg8l r10 r4
sbb_bxsid8_cl:
	sbb_bxidxd8_reg8l r10 r5
sbb_bxsid8_dl:
	sbb_bxidxd8_reg8l r10 r6
sbb_bxsid8_bl:
	sbb_bxidxd8_reg8l r10 r7
sbb_bxsid8_ah:
	sbb_bxidxd8_reg8h r10 r4
sbb_bxsid8_ch:
	sbb_bxidxd8_reg8h r10 r5
sbb_bxsid8_dh:
	sbb_bxidxd8_reg8h r10 r6
sbb_bxsid8_bh:
	sbb_bxidxd8_reg8h r10 r7

sbb_bxdid8_al:
	sbb_bxidxd8_reg8l r11 r4
sbb_bxdid8_cl:
	sbb_bxidxd8_reg8l r11 r5
sbb_bxdid8_dl:
	sbb_bxidxd8_reg8l r11 r6
sbb_bxdid8_bl:
	sbb_bxidxd8_reg8l r11 r7
sbb_bxdid8_ah:
	sbb_bxidxd8_reg8h r11 r4
sbb_bxdid8_ch:
	sbb_bxidxd8_reg8h r11 r5
sbb_bxdid8_dh:
	sbb_bxidxd8_reg8h r11 r6
sbb_bxdid8_bh:
	sbb_bxidxd8_reg8h r11 r7

.macro sbb_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		sbb_r0_r8l_bp_\reg
.endm
.macro sbb_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		sbb_r0_r8h_bp_\reg
.endm

sbb_bpsid8_al:
	sbb_bpidxd8_reg8l r10 r4
sbb_bpsid8_cl:
	sbb_bpidxd8_reg8l r10 r5
sbb_bpsid8_dl:
	sbb_bpidxd8_reg8l r10 r6
sbb_bpsid8_bl:
	sbb_bpidxd8_reg8l r10 r7
sbb_bpsid8_ah:
	sbb_bpidxd8_reg8h r10 r4
sbb_bpsid8_ch:
	sbb_bpidxd8_reg8h r10 r5
sbb_bpsid8_dh:
	sbb_bpidxd8_reg8h r10 r6
sbb_bpsid8_bh:
	sbb_bpidxd8_reg8h r10 r7

sbb_bpdid8_al:
	sbb_bpidxd8_reg8l r11 r4
sbb_bpdid8_cl:
	sbb_bpidxd8_reg8l r11 r5
sbb_bpdid8_dl:
	sbb_bpidxd8_reg8l r11 r6
sbb_bpdid8_bl:
	sbb_bpidxd8_reg8l r11 r7
sbb_bpdid8_ah:
	sbb_bpidxd8_reg8h r11 r4
sbb_bpdid8_ch:
	sbb_bpidxd8_reg8h r11 r5
sbb_bpdid8_dh:
	sbb_bpidxd8_reg8h r11 r6
sbb_bpdid8_bh:
	sbb_bpidxd8_reg8h r11 r7

.macro sbb_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		sbb_r0_r8l_\reg
.endm
.macro sbb_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		sbb_r0_r8h_\reg
.endm

sbb_sidisp8_al:
	sbb_idxdisp8_reg8l r10 r4
sbb_sidisp8_cl:
	sbb_idxdisp8_reg8l r10 r5
sbb_sidisp8_dl:
	sbb_idxdisp8_reg8l r10 r6
sbb_sidisp8_bl:
	sbb_idxdisp8_reg8l r10 r7
sbb_sidisp8_ah:
	sbb_idxdisp8_reg8h r10 r4
sbb_sidisp8_ch:
	sbb_idxdisp8_reg8h r10 r5
sbb_sidisp8_dh:
	sbb_idxdisp8_reg8h r10 r6
sbb_sidisp8_bh:
	sbb_idxdisp8_reg8h r10 r7

sbb_didisp8_al:
	sbb_idxdisp8_reg8l r11 r4
sbb_didisp8_cl:
	sbb_idxdisp8_reg8l r11 r5
sbb_didisp8_dl:
	sbb_idxdisp8_reg8l r11 r6
sbb_didisp8_bl:
	sbb_idxdisp8_reg8l r11 r7
sbb_didisp8_ah:
	sbb_idxdisp8_reg8h r11 r4
sbb_didisp8_ch:
	sbb_idxdisp8_reg8h r11 r5
sbb_didisp8_dh:
	sbb_idxdisp8_reg8h r11 r6
sbb_didisp8_bh:
	sbb_idxdisp8_reg8h r11 r7

sbb_bxdisp8_al:
	sbb_idxdisp8_reg8l r7 r4
sbb_bxdisp8_cl:
	sbb_idxdisp8_reg8l r7 r5
sbb_bxdisp8_dl:
	sbb_idxdisp8_reg8l r7 r6
sbb_bxdisp8_bl:
	sbb_idxdisp8_reg8l r7 r7
sbb_bxdisp8_ah:
	sbb_idxdisp8_reg8h r7 r4
sbb_bxdisp8_ch:
	sbb_idxdisp8_reg8h r7 r5
sbb_bxdisp8_dh:
	sbb_idxdisp8_reg8h r7 r6
sbb_bxdisp8_bh:
	sbb_idxdisp8_reg8h r7 r7

.macro sbb_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		sbb_r0_r8l_bp_\reg
.endm
.macro sbb_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		sbb_r0_r8h_bp_\reg
.endm

sbb_bpdisp8_al:
	sbb_bpdisp8_reg8l r4
sbb_bpdisp8_cl:
	sbb_bpdisp8_reg8l r5
sbb_bpdisp8_dl:
	sbb_bpdisp8_reg8l r6
sbb_bpdisp8_bl:
	sbb_bpdisp8_reg8l r7
sbb_bpdisp8_ah:
	sbb_bpdisp8_reg8h r4
sbb_bpdisp8_ch:
	sbb_bpdisp8_reg8h r5
sbb_bpdisp8_dh:
	sbb_bpdisp8_reg8h r6
sbb_bpdisp8_bh:
	sbb_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro sbb_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		sbb_r0_r8l_\reg
.endm
.macro sbb_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		sbb_r0_r8h_\reg
.endm

sbb_bxsid16_al:
	sbb_bxidxdisp16_reg8l r10 r4
sbb_bxsid16_cl:
	sbb_bxidxdisp16_reg8l r10 r5
sbb_bxsid16_dl:
	sbb_bxidxdisp16_reg8l r10 r6
sbb_bxsid16_bl:
	sbb_bxidxdisp16_reg8l r10 r7
sbb_bxsid16_ah:
	sbb_bxidxdisp16_reg8h r10 r4
sbb_bxsid16_ch:
	sbb_bxidxdisp16_reg8h r10 r5
sbb_bxsid16_dh:
	sbb_bxidxdisp16_reg8h r10 r6
sbb_bxsid16_bh:
	sbb_bxidxdisp16_reg8h r10 r7

sbb_bxdid16_al:
	sbb_bxidxdisp16_reg8l r11 r4
sbb_bxdid16_cl:
	sbb_bxidxdisp16_reg8l r11 r5
sbb_bxdid16_dl:
	sbb_bxidxdisp16_reg8l r11 r6
sbb_bxdid16_bl:
	sbb_bxidxdisp16_reg8l r11 r7
sbb_bxdid16_ah:
	sbb_bxidxdisp16_reg8h r11 r4
sbb_bxdid16_ch:
	sbb_bxidxdisp16_reg8h r11 r5
sbb_bxdid16_dh:
	sbb_bxidxdisp16_reg8h r11 r6
sbb_bxdid16_bh:
	sbb_bxidxdisp16_reg8h r11 r7

.macro sbb_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		sbb_r0_r8l_bp_\reg
.endm
.macro sbb_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		sbb_r0_r8h_bp_\reg
.endm

sbb_bpsid16_al:
	sbb_bpidxd16_reg8l r10 r4
sbb_bpsid16_cl:
	sbb_bpidxd16_reg8l r10 r5
sbb_bpsid16_dl:
	sbb_bpidxd16_reg8l r10 r6
sbb_bpsid16_bl:
	sbb_bpidxd16_reg8l r10 r7
sbb_bpsid16_ah:
	sbb_bpidxd16_reg8h r10 r4
sbb_bpsid16_ch:
	sbb_bpidxd16_reg8h r10 r5
sbb_bpsid16_dh:
	sbb_bpidxd16_reg8h r10 r6
sbb_bpsid16_bh:
	sbb_bpidxd16_reg8h r10 r7

sbb_bpdid16_al:
	sbb_bpidxd16_reg8l r11 r4
sbb_bpdid16_cl:
	sbb_bpidxd16_reg8l r11 r5
sbb_bpdid16_dl:
	sbb_bpidxd16_reg8l r11 r6
sbb_bpdid16_bl:
	sbb_bpidxd16_reg8l r11 r7
sbb_bpdid16_ah:
	sbb_bpidxd16_reg8h r11 r4
sbb_bpdid16_ch:
	sbb_bpidxd16_reg8h r11 r5
sbb_bpdid16_dh:
	sbb_bpidxd16_reg8h r11 r6
sbb_bpdid16_bh:
	sbb_bpidxd16_reg8h r11 r7

.macro sbb_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		sbb_r0_r8l_\reg
.endm
.macro sbb_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		sbb_r0_r8h_\reg
.endm

sbb_sidisp16_al:
	sbb_idxdisp16_reg8l r10 r4
sbb_sidisp16_cl:
	sbb_idxdisp16_reg8l r10 r5
sbb_sidisp16_dl:
	sbb_idxdisp16_reg8l r10 r6
sbb_sidisp16_bl:
	sbb_idxdisp16_reg8l r10 r7
sbb_sidisp16_ah:
	sbb_idxdisp16_reg8h r10 r4
sbb_sidisp16_ch:
	sbb_idxdisp16_reg8h r10 r5
sbb_sidisp16_dh:
	sbb_idxdisp16_reg8h r10 r6
sbb_sidisp16_bh:
	sbb_idxdisp16_reg8h r10 r7

sbb_didisp16_al:
	sbb_idxdisp16_reg8l r11 r4
sbb_didisp16_cl:
	sbb_idxdisp16_reg8l r11 r5
sbb_didisp16_dl:
	sbb_idxdisp16_reg8l r11 r6
sbb_didisp16_bl:
	sbb_idxdisp16_reg8l r11 r7
sbb_didisp16_ah:
	sbb_idxdisp16_reg8h r11 r4
sbb_didisp16_ch:
	sbb_idxdisp16_reg8h r11 r5
sbb_didisp16_dh:
	sbb_idxdisp16_reg8h r11 r6
sbb_didisp16_bh:
	sbb_idxdisp16_reg8h r11 r7

sbb_bxdisp16_al:
	sbb_idxdisp16_reg8l r7 r4
sbb_bxdisp16_cl:
	sbb_idxdisp16_reg8l r7 r5
sbb_bxdisp16_dl:
	sbb_idxdisp16_reg8l r7 r6
sbb_bxdisp16_bl:
	sbb_idxdisp16_reg8l r7 r7
sbb_bxdisp16_ah:
	sbb_idxdisp16_reg8h r7 r4
sbb_bxdisp16_ch:
	sbb_idxdisp16_reg8h r7 r5
sbb_bxdisp16_dh:
	sbb_idxdisp16_reg8h r7 r6
sbb_bxdisp16_bh:
	sbb_idxdisp16_reg8h r7 r7

.macro sbb_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		sbb_r0_r8l_bp_\reg
.endm
.macro sbb_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		sbb_r0_r8h_bp_\reg
.endm

sbb_bpdisp16_al:
	sbb_bpdisp16_reg8l r4
sbb_bpdisp16_cl:
	sbb_bpdisp16_reg8l r5
sbb_bpdisp16_dl:
	sbb_bpdisp16_reg8l r6
sbb_bpdisp16_bl:
	sbb_bpdisp16_reg8l r7
sbb_bpdisp16_ah:
	sbb_bpdisp16_reg8h r4
sbb_bpdisp16_ch:
	sbb_bpdisp16_reg8h r5
sbb_bpdisp16_dh:
	sbb_bpdisp16_reg8h r6
sbb_bpdisp16_bh:
	sbb_bpdisp16_reg8h r7


// ------------------- 19 = SBB r/m16, r16 -----------------------------
//
// All modrm variations supported!
//
//
op_19:
	modrm_jump_16
// 0
	.word sbb_bxsi_ax, sbb_bxdi_ax, sbb_bpsi_ax, sbb_bpdi_ax, sbb_siidx_ax, sbb_diidx_ax, sbb_disp16_ax, sbb_bxidx_ax
	.word sbb_bxsi_cx, sbb_bxdi_cx, sbb_bpsi_cx, sbb_bpdi_cx, sbb_siidx_cx, sbb_diidx_cx, sbb_disp16_cx, sbb_bxidx_cx
	.word sbb_bxsi_dx, sbb_bxdi_dx, sbb_bpsi_dx, sbb_bpdi_dx, sbb_siidx_dx, sbb_diidx_dx, sbb_disp16_dx, sbb_bxidx_dx
	.word sbb_bxsi_bx, sbb_bxdi_bx, sbb_bpsi_bx, sbb_bpdi_bx, sbb_siidx_bx, sbb_diidx_bx, sbb_disp16_bx, sbb_bxidx_bx
	.word sbb_bxsi_sp, sbb_bxdi_sp, sbb_bpsi_sp, sbb_bpdi_sp, sbb_siidx_sp, sbb_diidx_sp, sbb_disp16_sp, sbb_bxidx_sp
	.word sbb_bxsi_bp, sbb_bxdi_bp, sbb_bpsi_bp, sbb_bpdi_bp, sbb_siidx_bp, sbb_diidx_bp, sbb_disp16_bp, sbb_bxidx_bp
	.word sbb_bxsi_si, sbb_bxdi_si, sbb_bpsi_si, sbb_bpdi_si, sbb_siidx_si, sbb_diidx_si, sbb_disp16_si, sbb_bxidx_si
	.word sbb_bxsi_di, sbb_bxdi_di, sbb_bpsi_di, sbb_bpdi_di, sbb_siidx_di, sbb_diidx_di, sbb_disp16_di, sbb_bxidx_di
//0x40
	.word sbb_bxsid8_ax, sbb_bxdid8_ax, sbb_bpsid8_ax, sbb_bpdid8_ax, sbb_sidisp8_ax, sbb_didisp8_ax, sbb_bpdisp8_ax, sbb_bxdisp8_ax
	.word sbb_bxsid8_cx, sbb_bxdid8_cx, sbb_bpsid8_cx, sbb_bpdid8_cx, sbb_sidisp8_cx, sbb_didisp8_cx, sbb_bpdisp8_cx, sbb_bxdisp8_cx
	.word sbb_bxsid8_dx, sbb_bxdid8_dx, sbb_bpsid8_dx, sbb_bpdid8_dx, sbb_sidisp8_dx, sbb_didisp8_dx, sbb_bpdisp8_dx, sbb_bxdisp8_dx
	.word sbb_bxsid8_bx, sbb_bxdid8_bx, sbb_bpsid8_bx, sbb_bpdid8_bx, sbb_sidisp8_bx, sbb_didisp8_bx, sbb_bpdisp8_bx, sbb_bxdisp8_bx
	.word sbb_bxsid8_sp, sbb_bxdid8_sp, sbb_bpsid8_sp, sbb_bpdid8_sp, sbb_sidisp8_sp, sbb_didisp8_sp, sbb_bpdisp8_sp, sbb_bxdisp8_sp
	.word sbb_bxsid8_bp, sbb_bxdid8_bp, sbb_bpsid8_bp, sbb_bpdid8_bp, sbb_sidisp8_bp, sbb_didisp8_bp, sbb_bpdisp8_bp, sbb_bxdisp8_bp
	.word sbb_bxsid8_si, sbb_bxdid8_si, sbb_bpsid8_si, sbb_bpdid8_si, sbb_sidisp8_si, sbb_didisp8_si, sbb_bpdisp8_si, sbb_bxdisp8_si
	.word sbb_bxsid8_di, sbb_bxdid8_di, sbb_bpsid8_di, sbb_bpdid8_di, sbb_sidisp8_di, sbb_didisp8_di, sbb_bpdisp8_di, sbb_bxdisp8_di
//0x80
	.word sbb_bxsid16_ax, sbb_bxdid16_ax, sbb_bpsid16_ax, sbb_bpdid16_ax, sbb_sidisp16_ax, sbb_didisp16_ax, sbb_bpdisp16_ax, sbb_bxdisp16_ax
	.word sbb_bxsid16_cx, sbb_bxdid16_cx, sbb_bpsid16_cx, sbb_bpdid16_cx, sbb_sidisp16_cx, sbb_didisp16_cx, sbb_bpdisp16_cx, sbb_bxdisp16_cx
	.word sbb_bxsid16_dx, sbb_bxdid16_dx, sbb_bpsid16_dx, sbb_bpdid16_dx, sbb_sidisp16_dx, sbb_didisp16_dx, sbb_bpdisp16_dx, sbb_bxdisp16_dx
	.word sbb_bxsid16_bx, sbb_bxdid16_bx, sbb_bpsid16_bx, sbb_bpdid16_bx, sbb_sidisp16_bx, sbb_didisp16_bx, sbb_bpdisp16_bx, sbb_bxdisp16_bx
	.word sbb_bxsid16_sp, sbb_bxdid16_sp, sbb_bpsid16_sp, sbb_bpdid16_sp, sbb_sidisp16_sp, sbb_didisp16_sp, sbb_bpdisp16_sp, sbb_bxdisp16_sp
	.word sbb_bxsid16_bp, sbb_bxdid16_bp, sbb_bpsid16_bp, sbb_bpdid16_bp, sbb_sidisp16_bp, sbb_didisp16_bp, sbb_bpdisp16_bp, sbb_bxdisp16_bp
	.word sbb_bxsid16_si, sbb_bxdid16_si, sbb_bpsid16_si, sbb_bpdid16_si, sbb_sidisp16_si, sbb_didisp16_si, sbb_bpdisp16_si, sbb_bxdisp16_si
	.word sbb_bxsid16_di, sbb_bxdid16_di, sbb_bpsid16_di, sbb_bpdid16_di, sbb_sidisp16_di, sbb_didisp16_di, sbb_bpdisp16_di, sbb_bxdisp16_di
// 0xC0 = two register operands
	.word sbb_ax_ax, sbb_cx_ax, sbb_dx_ax, sbb_bx_ax, sbb_sp_ax, sbb_bp_ax, sbb_si_ax, sbb_di_ax
	.word sbb_ax_cx, sbb_cx_cx, sbb_dx_cx, sbb_bx_cx, sbb_sp_cx, sbb_bp_cx, sbb_si_cx, sbb_di_cx
	.word sbb_ax_dx, sbb_cx_dx, sbb_dx_dx, sbb_bx_dx, sbb_sp_dx, sbb_bp_dx, sbb_si_dx, sbb_di_dx
	.word sbb_ax_bx, sbb_cx_bx, sbb_dx_bx, sbb_bx_bx, sbb_sp_bx, sbb_bp_bx, sbb_si_bx, sbb_di_bx
	.word sbb_ax_sp, sbb_cx_sp, sbb_dx_sp, sbb_bx_sp, sbb_sp_sp, sbb_bp_sp, sbb_si_sp, sbb_di_sp
	.word sbb_ax_bp, sbb_cx_bp, sbb_dx_bp, sbb_bx_bp, sbb_sp_bp, sbb_bp_bp, sbb_si_bp, sbb_di_bp
	.word sbb_ax_si, sbb_cx_si, sbb_dx_si, sbb_bx_si, sbb_sp_si, sbb_bp_si, sbb_si_si, sbb_di_si
	.word sbb_ax_di, sbb_cx_di, sbb_dx_di, sbb_bx_di, sbb_sp_di, sbb_bp_di, sbb_si_di, sbb_di_di

// These are called from "cpu_67.s":

	.global sbb_siidx_ax, sbb_diidx_ax, sbb_bxidx_ax
	.global sbb_siidx_cx, sbb_diidx_cx, sbb_bxidx_cx
	.global sbb_siidx_dx, sbb_diidx_dx, sbb_bxidx_dx
	.global sbb_siidx_bx, sbb_diidx_bx, sbb_bxidx_bx
	.global sbb_siidx_sp, sbb_diidx_sp, sbb_bxidx_sp
	.global sbb_siidx_bp, sbb_diidx_bp, sbb_bxidx_bp
	.global sbb_siidx_si, sbb_diidx_si, sbb_bxidx_si
	.global sbb_siidx_di, sbb_diidx_di, sbb_bxidx_di
	.global sbb_sidisp8_ax, sbb_didisp8_ax, sbb_bpdisp8_ax, sbb_bxdisp8_ax
	.global sbb_sidisp8_cx, sbb_didisp8_cx, sbb_bpdisp8_cx, sbb_bxdisp8_cx
	.global sbb_sidisp8_dx, sbb_didisp8_dx, sbb_bpdisp8_dx, sbb_bxdisp8_dx
	.global sbb_sidisp8_bx, sbb_didisp8_bx, sbb_bpdisp8_bx, sbb_bxdisp8_bx
	.global sbb_sidisp8_sp, sbb_didisp8_sp, sbb_bpdisp8_sp, sbb_bxdisp8_sp
	.global sbb_sidisp8_bp, sbb_didisp8_bp, sbb_bpdisp8_bp, sbb_bxdisp8_bp
	.global sbb_sidisp8_si, sbb_didisp8_si, sbb_bpdisp8_si, sbb_bxdisp8_si
	.global sbb_sidisp8_di, sbb_didisp8_di, sbb_bpdisp8_di, sbb_bxdisp8_di
	.global sbb_ax_ax, sbb_cx_ax, sbb_dx_ax, sbb_bx_ax, sbb_sp_ax, sbb_bp_ax, sbb_si_ax, sbb_di_ax
	.global sbb_ax_cx, sbb_cx_cx, sbb_dx_cx, sbb_bx_cx, sbb_sp_cx, sbb_bp_cx, sbb_si_cx, sbb_di_cx
	.global sbb_ax_dx, sbb_cx_dx, sbb_dx_dx, sbb_bx_dx, sbb_sp_dx, sbb_bp_dx, sbb_si_dx, sbb_di_dx
	.global sbb_ax_bx, sbb_cx_bx, sbb_dx_bx, sbb_bx_bx, sbb_sp_bx, sbb_bp_bx, sbb_si_bx, sbb_di_bx
	.global sbb_ax_sp, sbb_cx_sp, sbb_dx_sp, sbb_bx_sp, sbb_sp_sp, sbb_bp_sp, sbb_si_sp, sbb_di_sp
	.global sbb_ax_bp, sbb_cx_bp, sbb_dx_bp, sbb_bx_bp, sbb_sp_bp, sbb_bp_bp, sbb_si_bp, sbb_di_bp
	.global sbb_ax_si, sbb_cx_si, sbb_dx_si, sbb_bx_si, sbb_sp_si, sbb_bp_si, sbb_si_si, sbb_di_si
	.global sbb_ax_di, sbb_cx_di, sbb_dx_di, sbb_bx_di, sbb_sp_di, sbb_bp_di, sbb_si_di, sbb_di_di
	.global	sbb_r0_r16_bp_r4, sbb_r0_r16_bp_r5, sbb_r0_r16_bp_r6, sbb_r0_r16_bp_r7, sbb_r0_r16_bp_r8, sbb_r0_r16_bp_r9, sbb_r0_r16_bp_r10, sbb_r0_r16_bp_r11, sbb_r0_r16_bp_r4
	.global	sbb_r0_r16_r4, sbb_r0_r16_r5, sbb_r0_r16_r6, sbb_r0_r16_r7, sbb_r0_r16_r8, sbb_r0_r16_r9, sbb_r0_r16_r10, sbb_r0_r16_r11, sbb_r0_r16_r4


	//-------
	// SBB with input carry set, we need to calculate the proper flags manually.
	// On input:
	//	r0 = halfword from RAM
	//	r1 = register value in high 16 bits
	//	r2 = RAM address
	//	r3 = free
	//-------
.op_19_sbb_carry_r1:	
	sub		r3, r0, r1, lsr #16		// r2 = lf_var1d - lf_var2d
	sub		r3, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r3, r3, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	lsr		r3, #16
	strb	r3,[r2]					// Store byte to RAM
	ror		r3, #8
	strb	r3,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0, r1, lsr #16
	eor		r3, r0, r3, ror #24
	and		r1, r3
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0

.macro sbb_r0_r16_reg reg
sbb_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
sbb_r0_r16_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_19_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_19_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	bcs		1f						// If input carry is set, we need to calculate the flags manually.
	lsl		r0, #16
	orr		r0, r1, lsl #24			// r0 = low byte | (high byte << 8)
	subs	r0, \reg, lsl #16		// Perform the actual subtraction, setting the resulting flags.
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		complement_carry
1:	orr		r0, r1, lsl #8
	mov		r1, \reg, lsl #16
	b		.op_19_sbb_carry_r1
.endm

	sbb_r0_r16_reg r4
	sbb_r0_r16_reg r5
	sbb_r0_r16_reg r6
	sbb_r0_r16_reg r7
	sbb_r0_r16_reg r8
	sbb_r0_r16_reg r9
	sbb_r0_r16_reg r10
	sbb_r0_r16_reg r11

	.ltorg

// --- [idx] ----

.macro sbb_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		sbb_r0_r16_\reg
.endm

sbb_bxsi_ax:
	sbb_bxidx_reg16 r10 r4
sbb_bxsi_cx:
	sbb_bxidx_reg16 r10 r5
sbb_bxsi_dx:
	sbb_bxidx_reg16 r10 r6
sbb_bxsi_bx:
	sbb_bxidx_reg16 r10 r7
sbb_bxsi_sp:
	sbb_bxidx_reg16 r10 r8
sbb_bxsi_bp:
	sbb_bxidx_reg16 r10 r9
sbb_bxsi_si:
	sbb_bxidx_reg16 r10 r10
sbb_bxsi_di:
	sbb_bxidx_reg16 r10 r11

sbb_bxdi_ax:
	sbb_bxidx_reg16 r11 r4
sbb_bxdi_cx:
	sbb_bxidx_reg16 r11 r5
sbb_bxdi_dx:
	sbb_bxidx_reg16 r11 r6
sbb_bxdi_bx:
	sbb_bxidx_reg16 r11 r7
sbb_bxdi_sp:
	sbb_bxidx_reg16 r11 r8
sbb_bxdi_bp:
	sbb_bxidx_reg16 r11 r9
sbb_bxdi_si:
	sbb_bxidx_reg16 r11 r10
sbb_bxdi_di:
	sbb_bxidx_reg16 r11 r11

.macro sbb_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		sbb_r0_r16_bp_\reg
.endm

sbb_bpsi_ax:
	sbb_bpidx_reg16 r10 r4
sbb_bpsi_cx:
	sbb_bpidx_reg16 r10 r5
sbb_bpsi_dx:
	sbb_bpidx_reg16 r10 r6
sbb_bpsi_bx:
	sbb_bpidx_reg16 r10 r7
sbb_bpsi_sp:
	sbb_bpidx_reg16 r10 r8
sbb_bpsi_bp:
	sbb_bpidx_reg16 r10 r9
sbb_bpsi_si:
	sbb_bpidx_reg16 r10 r10
sbb_bpsi_di:
	sbb_bpidx_reg16 r10 r11

sbb_bpdi_ax:
	sbb_bpidx_reg16 r11 r4
sbb_bpdi_cx:
	sbb_bpidx_reg16 r11 r5
sbb_bpdi_dx:
	sbb_bpidx_reg16 r11 r6
sbb_bpdi_bx:
	sbb_bpidx_reg16 r11 r7
sbb_bpdi_sp:
	sbb_bpidx_reg16 r11 r8
sbb_bpdi_bp:
	sbb_bpidx_reg16 r11 r9
sbb_bpdi_si:
	sbb_bpidx_reg16 r11 r10
sbb_bpdi_di:
	sbb_bpidx_reg16 r11 r11

.macro sbb_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		sbb_r0_r16_\reg
.endm

sbb_siidx_ax:
	sbb_idx_reg16 r10 r4
sbb_siidx_cx:
	sbb_idx_reg16 r10 r5
sbb_siidx_dx:
	sbb_idx_reg16 r10 r6
sbb_siidx_bx:
	sbb_idx_reg16 r10 r7
sbb_siidx_sp:
	sbb_idx_reg16 r10 r8
sbb_siidx_bp:
	sbb_idx_reg16 r10 r9
sbb_siidx_si:
	sbb_idx_reg16 r10 r10
sbb_siidx_di:
	sbb_idx_reg16 r10 r11

sbb_diidx_ax:
	sbb_idx_reg16 r11 r4
sbb_diidx_cx:
	sbb_idx_reg16 r11 r5
sbb_diidx_dx:
	sbb_idx_reg16 r11 r6
sbb_diidx_bx:
	sbb_idx_reg16 r11 r7
sbb_diidx_sp:
	sbb_idx_reg16 r11 r8
sbb_diidx_bp:
	sbb_idx_reg16 r11 r9
sbb_diidx_si:
	sbb_idx_reg16 r11 r10
sbb_diidx_di:
	sbb_idx_reg16 r11 r11

sbb_bxidx_ax:
	sbb_idx_reg16 r7 r4
sbb_bxidx_cx:
	sbb_idx_reg16 r7 r5
sbb_bxidx_dx:
	sbb_idx_reg16 r7 r6
sbb_bxidx_bx:
	sbb_idx_reg16 r7 r7
sbb_bxidx_sp:
	sbb_idx_reg16 r7 r8
sbb_bxidx_bp:
	sbb_idx_reg16 r7 r9
sbb_bxidx_si:
	sbb_idx_reg16 r7 r10
sbb_bxidx_di:
	sbb_idx_reg16 r7 r11
	
.macro sbb_disp16_reg16 reg
	r0_from_disp16
	b		sbb_r0_r16_\reg
.endm

sbb_disp16_ax:
	sbb_disp16_reg16 r4
sbb_disp16_cx:
	sbb_disp16_reg16 r5
sbb_disp16_dx:
	sbb_disp16_reg16 r6
sbb_disp16_bx:
	sbb_disp16_reg16 r7
sbb_disp16_sp:
	sbb_disp16_reg16 r8
sbb_disp16_bp:
	sbb_disp16_reg16 r9
sbb_disp16_si:
	sbb_disp16_reg16 r10
sbb_disp16_di:
	sbb_disp16_reg16 r11

// --- [idx+disp8] ----

.macro sbb_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		sbb_r0_r16_\reg
.endm

sbb_bxsid8_ax:
	sbb_bxidxd8_reg16 r10 r4
sbb_bxsid8_cx:
	sbb_bxidxd8_reg16 r10 r5
sbb_bxsid8_dx:
	sbb_bxidxd8_reg16 r10 r6
sbb_bxsid8_bx:
	sbb_bxidxd8_reg16 r10 r7
sbb_bxsid8_sp:
	sbb_bxidxd8_reg16 r10 r8
sbb_bxsid8_bp:
	sbb_bxidxd8_reg16 r10 r9
sbb_bxsid8_si:
	sbb_bxidxd8_reg16 r10 r10
sbb_bxsid8_di:
	sbb_bxidxd8_reg16 r10 r11

sbb_bxdid8_ax:
	sbb_bxidxd8_reg16 r11 r4
sbb_bxdid8_cx:
	sbb_bxidxd8_reg16 r11 r5
sbb_bxdid8_dx:
	sbb_bxidxd8_reg16 r11 r6
sbb_bxdid8_bx:
	sbb_bxidxd8_reg16 r11 r7
sbb_bxdid8_sp:
	sbb_bxidxd8_reg16 r11 r8
sbb_bxdid8_bp:
	sbb_bxidxd8_reg16 r11 r9
sbb_bxdid8_si:
	sbb_bxidxd8_reg16 r11 r10
sbb_bxdid8_di:
	sbb_bxidxd8_reg16 r11 r11

.macro sbb_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		sbb_r0_r16_bp_\reg
.endm

sbb_bpsid8_ax:
	sbb_bpidxd8_reg16 r10 r4
sbb_bpsid8_cx:
	sbb_bpidxd8_reg16 r10 r5
sbb_bpsid8_dx:
	sbb_bpidxd8_reg16 r10 r6
sbb_bpsid8_bx:
	sbb_bpidxd8_reg16 r10 r7
sbb_bpsid8_sp:
	sbb_bpidxd8_reg16 r10 r8
sbb_bpsid8_bp:
	sbb_bpidxd8_reg16 r10 r9
sbb_bpsid8_si:
	sbb_bpidxd8_reg16 r10 r10
sbb_bpsid8_di:
	sbb_bpidxd8_reg16 r10 r11

sbb_bpdid8_ax:
	sbb_bpidxd8_reg16 r11 r4
sbb_bpdid8_cx:
	sbb_bpidxd8_reg16 r11 r5
sbb_bpdid8_dx:
	sbb_bpidxd8_reg16 r11 r6
sbb_bpdid8_bx:
	sbb_bpidxd8_reg16 r11 r7
sbb_bpdid8_sp:
	sbb_bpidxd8_reg16 r11 r8
sbb_bpdid8_bp:
	sbb_bpidxd8_reg16 r11 r9
sbb_bpdid8_si:
	sbb_bpidxd8_reg16 r11 r10
sbb_bpdid8_di:
	sbb_bpidxd8_reg16 r11 r11

.macro sbb_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		sbb_r0_r16_\reg
.endm

sbb_sidisp8_ax:
	sbb_idxdisp8_reg16 r10 r4
sbb_sidisp8_cx:
	sbb_idxdisp8_reg16 r10 r5
sbb_sidisp8_dx:
	sbb_idxdisp8_reg16 r10 r6
sbb_sidisp8_bx:
	sbb_idxdisp8_reg16 r10 r7
sbb_sidisp8_sp:
	sbb_idxdisp8_reg16 r10 r8
sbb_sidisp8_bp:
	sbb_idxdisp8_reg16 r10 r9
sbb_sidisp8_si:
	sbb_idxdisp8_reg16 r10 r10
sbb_sidisp8_di:
	sbb_idxdisp8_reg16 r10 r11

sbb_didisp8_ax:
	sbb_idxdisp8_reg16 r11 r4
sbb_didisp8_cx:
	sbb_idxdisp8_reg16 r11 r5
sbb_didisp8_dx:
	sbb_idxdisp8_reg16 r11 r6
sbb_didisp8_bx:
	sbb_idxdisp8_reg16 r11 r7
sbb_didisp8_sp:
	sbb_idxdisp8_reg16 r11 r8
sbb_didisp8_bp:
	sbb_idxdisp8_reg16 r11 r9
sbb_didisp8_si:
	sbb_idxdisp8_reg16 r11 r10
sbb_didisp8_di:
	sbb_idxdisp8_reg16 r11 r11

sbb_bxdisp8_ax:
	sbb_idxdisp8_reg16 r7 r4
sbb_bxdisp8_cx:
	sbb_idxdisp8_reg16 r7 r5
sbb_bxdisp8_dx:
	sbb_idxdisp8_reg16 r7 r6
sbb_bxdisp8_bx:
	sbb_idxdisp8_reg16 r7 r7
sbb_bxdisp8_sp:
	sbb_idxdisp8_reg16 r7 r8
sbb_bxdisp8_bp:
	sbb_idxdisp8_reg16 r7 r9
sbb_bxdisp8_si:
	sbb_idxdisp8_reg16 r7 r10
sbb_bxdisp8_di:
	sbb_idxdisp8_reg16 r7 r11
	
.macro sbb_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		sbb_r0_r16_bp_\reg
.endm
	
sbb_bpdisp8_ax:
	sbb_bpdisp8_reg16 r4
sbb_bpdisp8_cx:
	sbb_bpdisp8_reg16 r5
sbb_bpdisp8_dx:
	sbb_bpdisp8_reg16 r6
sbb_bpdisp8_bx:
	sbb_bpdisp8_reg16 r7
sbb_bpdisp8_sp:
	sbb_bpdisp8_reg16 r8
sbb_bpdisp8_bp:
	sbb_bpdisp8_reg16 r9
sbb_bpdisp8_si:
	sbb_bpdisp8_reg16 r10
sbb_bpdisp8_di:
	sbb_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro sbb_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		sbb_r0_r16_\reg
.endm

sbb_bxsid16_ax:
	sbb_bxidxd16_reg16 r10 r4
sbb_bxsid16_cx:
	sbb_bxidxd16_reg16 r10 r5
sbb_bxsid16_dx:
	sbb_bxidxd16_reg16 r10 r6
sbb_bxsid16_bx:
	sbb_bxidxd16_reg16 r10 r7
sbb_bxsid16_sp:
	sbb_bxidxd16_reg16 r10 r8
sbb_bxsid16_bp:
	sbb_bxidxd16_reg16 r10 r9
sbb_bxsid16_si:
	sbb_bxidxd16_reg16 r10 r10
sbb_bxsid16_di:
	sbb_bxidxd16_reg16 r10 r11

sbb_bxdid16_ax:
	sbb_bxidxd16_reg16 r11 r4
sbb_bxdid16_cx:
	sbb_bxidxd16_reg16 r11 r5
sbb_bxdid16_dx:
	sbb_bxidxd16_reg16 r11 r6
sbb_bxdid16_bx:
	sbb_bxidxd16_reg16 r11 r7
sbb_bxdid16_sp:
	sbb_bxidxd16_reg16 r11 r8
sbb_bxdid16_bp:
	sbb_bxidxd16_reg16 r11 r9
sbb_bxdid16_si:
	sbb_bxidxd16_reg16 r11 r10
sbb_bxdid16_di:
	sbb_bxidxd16_reg16 r11 r11

.macro sbb_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		sbb_r0_r16_bp_\reg
.endm

sbb_bpsid16_ax:
	sbb_bpidxd16_reg16 r10 r4
sbb_bpsid16_cx:
	sbb_bpidxd16_reg16 r10 r5
sbb_bpsid16_dx:
	sbb_bpidxd16_reg16 r10 r6
sbb_bpsid16_bx:
	sbb_bpidxd16_reg16 r10 r7
sbb_bpsid16_sp:
	sbb_bpidxd16_reg16 r10 r8
sbb_bpsid16_bp:
	sbb_bpidxd16_reg16 r10 r9
sbb_bpsid16_si:
	sbb_bpidxd16_reg16 r10 r10
sbb_bpsid16_di:
	sbb_bpidxd16_reg16 r10 r11

sbb_bpdid16_ax:
	sbb_bpidxd16_reg16 r11 r4
sbb_bpdid16_cx:
	sbb_bpidxd16_reg16 r11 r5
sbb_bpdid16_dx:
	sbb_bpidxd16_reg16 r11 r6
sbb_bpdid16_bx:
	sbb_bpidxd16_reg16 r11 r7
sbb_bpdid16_sp:
	sbb_bpidxd16_reg16 r11 r8
sbb_bpdid16_bp:
	sbb_bpidxd16_reg16 r11 r9
sbb_bpdid16_si:
	sbb_bpidxd16_reg16 r11 r10
sbb_bpdid16_di:
	sbb_bpidxd16_reg16 r11 r11

.macro sbb_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		sbb_r0_r16_\reg
.endm

sbb_sidisp16_ax:
	sbb_idxdisp16_reg16 r10 r4
sbb_sidisp16_cx:
	sbb_idxdisp16_reg16 r10 r5
sbb_sidisp16_dx:
	sbb_idxdisp16_reg16 r10 r6
sbb_sidisp16_bx:
	sbb_idxdisp16_reg16 r10 r7
sbb_sidisp16_sp:
	sbb_idxdisp16_reg16 r10 r8
sbb_sidisp16_bp:
	sbb_idxdisp16_reg16 r10 r9
sbb_sidisp16_si:
	sbb_idxdisp16_reg16 r10 r10
sbb_sidisp16_di:
	sbb_idxdisp16_reg16 r10 r11

sbb_didisp16_ax:
	sbb_idxdisp16_reg16 r11 r4
sbb_didisp16_cx:
	sbb_idxdisp16_reg16 r11 r5
sbb_didisp16_dx:
	sbb_idxdisp16_reg16 r11 r6
sbb_didisp16_bx:
	sbb_idxdisp16_reg16 r11 r7
sbb_didisp16_sp:
	sbb_idxdisp16_reg16 r11 r8
sbb_didisp16_bp:
	sbb_idxdisp16_reg16 r11 r9
sbb_didisp16_si:
	sbb_idxdisp16_reg16 r11 r10
sbb_didisp16_di:
	sbb_idxdisp16_reg16 r11 r11

sbb_bxdisp16_ax:
	sbb_idxdisp16_reg16 r7 r4
sbb_bxdisp16_cx:
	sbb_idxdisp16_reg16 r7 r5
sbb_bxdisp16_dx:
	sbb_idxdisp16_reg16 r7 r6
sbb_bxdisp16_bx:
	sbb_idxdisp16_reg16 r7 r7
sbb_bxdisp16_sp:
	sbb_idxdisp16_reg16 r7 r8
sbb_bxdisp16_bp:
	sbb_idxdisp16_reg16 r7 r9
sbb_bxdisp16_si:
	sbb_idxdisp16_reg16 r7 r10
sbb_bxdisp16_di:
	sbb_idxdisp16_reg16 r7 r11

.macro sbb_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		sbb_r0_r16_bp_\reg
.endm

sbb_bpdisp16_ax:
	sbb_bpdisp16_reg16 r4
sbb_bpdisp16_cx:
	sbb_bpdisp16_reg16 r5
sbb_bpdisp16_dx:
	sbb_bpdisp16_reg16 r6
sbb_bpdisp16_bx:
	sbb_bpdisp16_reg16 r7
sbb_bpdisp16_sp:
	sbb_bpdisp16_reg16 r8
sbb_bpdisp16_bp:
	sbb_bpdisp16_reg16 r9
sbb_bpdisp16_si:
	sbb_bpdisp16_reg16 r10
sbb_bpdisp16_di:
	sbb_bpdisp16_reg16 r11


// ------------------- 1A = SBB r8, r/m8 -------------------------------
//
// All modrm variations supported!
//
//
op_1a:
	modrm_jump_16
// 0
	.word sbb_al_bxsi, sbb_al_bxdi, sbb_al_bpsi, sbb_al_bpdi, sbb_al_siidx, sbb_al_diidx, sbb_al_disp16, sbb_al_bxidx
	.word sbb_cl_bxsi, sbb_cl_bxdi, sbb_cl_bpsi, sbb_cl_bpdi, sbb_cl_siidx, sbb_cl_diidx, sbb_cl_disp16, sbb_cl_bxidx
	.word sbb_dl_bxsi, sbb_dl_bxdi, sbb_dl_bpsi, sbb_dl_bpdi, sbb_dl_siidx, sbb_dl_diidx, sbb_dl_disp16, sbb_dl_bxidx
	.word sbb_bl_bxsi, sbb_bl_bxdi, sbb_bl_bpsi, sbb_bl_bpdi, sbb_bl_siidx, sbb_bl_diidx, sbb_bl_disp16, sbb_bl_bxidx
	.word sbb_ah_bxsi, sbb_ah_bxdi, sbb_ah_bpsi, sbb_ah_bpdi, sbb_ah_siidx, sbb_ah_diidx, sbb_ah_disp16, sbb_ah_bxidx
	.word sbb_ch_bxsi, sbb_ch_bxdi, sbb_ch_bpsi, sbb_ch_bpdi, sbb_ch_siidx, sbb_ch_diidx, sbb_ch_disp16, sbb_ch_bxidx
	.word sbb_dh_bxsi, sbb_dh_bxdi, sbb_dh_bpsi, sbb_dh_bpdi, sbb_dh_siidx, sbb_dh_diidx, sbb_dh_disp16, sbb_dh_bxidx
	.word sbb_bh_bxsi, sbb_bh_bxdi, sbb_bh_bpsi, sbb_bh_bpdi, sbb_bh_siidx, sbb_bh_diidx, sbb_bh_disp16, sbb_bh_bxidx
//0x40
	.word sbb_al_bxsid8, sbb_al_bxdid8, sbb_al_bpsid8, sbb_al_bpdid8, sbb_al_sidisp8, sbb_al_didisp8, sbb_al_bpdisp8, sbb_al_bxdisp8
	.word sbb_cl_bxsid8, sbb_cl_bxdid8, sbb_cl_bpsid8, sbb_cl_bpdid8, sbb_cl_sidisp8, sbb_cl_didisp8, sbb_cl_bpdisp8, sbb_cl_bxdisp8
	.word sbb_dl_bxsid8, sbb_dl_bxdid8, sbb_dl_bpsid8, sbb_dl_bpdid8, sbb_dl_sidisp8, sbb_dl_didisp8, sbb_dl_bpdisp8, sbb_dl_bxdisp8
	.word sbb_bl_bxsid8, sbb_bl_bxdid8, sbb_bl_bpsid8, sbb_bl_bpdid8, sbb_bl_sidisp8, sbb_bl_didisp8, sbb_bl_bpdisp8, sbb_bl_bxdisp8
	.word sbb_ah_bxsid8, sbb_ah_bxdid8, sbb_ah_bpsid8, sbb_ah_bpdid8, sbb_ah_sidisp8, sbb_ah_didisp8, sbb_ah_bpdisp8, sbb_ah_bxdisp8
	.word sbb_ch_bxsid8, sbb_ch_bxdid8, sbb_ch_bpsid8, sbb_ch_bpdid8, sbb_ch_sidisp8, sbb_ch_didisp8, sbb_ch_bpdisp8, sbb_ch_bxdisp8
	.word sbb_dh_bxsid8, sbb_dh_bxdid8, sbb_dh_bpsid8, sbb_dh_bpdid8, sbb_dh_sidisp8, sbb_dh_didisp8, sbb_dh_bpdisp8, sbb_dh_bxdisp8
	.word sbb_bh_bxsid8, sbb_bh_bxdid8, sbb_bh_bpsid8, sbb_bh_bpdid8, sbb_bh_sidisp8, sbb_bh_didisp8, sbb_bh_bpdisp8, sbb_bh_bxdisp8
//0x80
	.word sbb_al_bxsid16, sbb_al_bxdid16, sbb_al_bpsid16, sbb_al_bpdid16, sbb_al_sidisp16, sbb_al_didisp16, sbb_al_bpdisp16, sbb_al_bxdisp16
	.word sbb_cl_bxsid16, sbb_cl_bxdid16, sbb_cl_bpsid16, sbb_cl_bpdid16, sbb_cl_sidisp16, sbb_cl_didisp16, sbb_cl_bpdisp16, sbb_cl_bxdisp16
	.word sbb_dl_bxsid16, sbb_dl_bxdid16, sbb_dl_bpsid16, sbb_dl_bpdid16, sbb_dl_sidisp16, sbb_dl_didisp16, sbb_dl_bpdisp16, sbb_dl_bxdisp16
	.word sbb_bl_bxsid16, sbb_bl_bxdid16, sbb_bl_bpsid16, sbb_bl_bpdid16, sbb_bl_sidisp16, sbb_bl_didisp16, sbb_bl_bpdisp16, sbb_bl_bxdisp16
	.word sbb_ah_bxsid16, sbb_ah_bxdid16, sbb_ah_bpsid16, sbb_ah_bpdid16, sbb_ah_sidisp16, sbb_ah_didisp16, sbb_ah_bpdisp16, sbb_ah_bxdisp16
	.word sbb_ch_bxsid16, sbb_ch_bxdid16, sbb_ch_bpsid16, sbb_ch_bpdid16, sbb_ch_sidisp16, sbb_ch_didisp16, sbb_ch_bpdisp16, sbb_ch_bxdisp16
	.word sbb_dh_bxsid16, sbb_dh_bxdid16, sbb_dh_bpsid16, sbb_dh_bpdid16, sbb_dh_sidisp16, sbb_dh_didisp16, sbb_dh_bpdisp16, sbb_dh_bxdisp16
	.word sbb_bh_bxsid16, sbb_bh_bxdid16, sbb_bh_bpsid16, sbb_bh_bpdid16, sbb_bh_sidisp16, sbb_bh_didisp16, sbb_bh_bpdisp16, sbb_bh_bxdisp16
// 0xC0 = two register operands
	.word sbb_al_al, sbb_al_cl, sbb_al_dl, sbb_al_bl, sbb_al_ah, sbb_al_ch, sbb_al_dh, sbb_al_bh
	.word sbb_cl_al, sbb_cl_cl, sbb_cl_dl, sbb_cl_bl, sbb_cl_ah, sbb_cl_ch, sbb_cl_dh, sbb_cl_bh
	.word sbb_dl_al, sbb_dl_cl, sbb_dl_dl, sbb_dl_bl, sbb_dl_ah, sbb_dl_ch, sbb_dl_dh, sbb_dl_bh
	.word sbb_bl_al, sbb_bl_cl, sbb_bl_dl, sbb_bl_bl, sbb_bl_ah, sbb_bl_ch, sbb_bl_dh, sbb_bl_bh
	.word sbb_ah_al, sbb_ah_cl, sbb_ah_dl, sbb_ah_bl, sbb_ah_ah, sbb_ah_ch, sbb_ah_dh, sbb_ah_bh
	.word sbb_ch_al, sbb_ch_cl, sbb_ch_dl, sbb_ch_bl, sbb_ch_ah, sbb_ch_ch, sbb_ch_dh, sbb_ch_bh
	.word sbb_dh_al, sbb_dh_cl, sbb_dh_dl, sbb_dh_bl, sbb_dh_ah, sbb_dh_ch, sbb_dh_dh, sbb_dh_bh
	.word sbb_bh_al, sbb_bh_cl, sbb_bh_dl, sbb_bh_bl, sbb_bh_ah, sbb_bh_ch, sbb_bh_dh, sbb_bh_bh

// These are called from "cpu_386.s":

	.global sbb_al_siidx, sbb_cl_siidx, sbb_dl_siidx, sbb_bl_siidx, sbb_ah_siidx, sbb_ch_siidx, sbb_dh_siidx, sbb_bh_siidx
	.global sbb_al_diidx, sbb_cl_diidx, sbb_dl_diidx, sbb_bl_diidx, sbb_ah_diidx, sbb_ch_diidx, sbb_dh_diidx, sbb_bh_diidx
	.global sbb_al_bxidx, sbb_cl_bxidx, sbb_dl_bxidx, sbb_bl_bxidx, sbb_ah_bxidx, sbb_ch_bxidx, sbb_dh_bxidx, sbb_bh_bxidx
	.global sbb_al_sidisp8, sbb_al_didisp8, sbb_al_bpdisp8, sbb_al_bxdisp8
	.global sbb_cl_sidisp8, sbb_cl_didisp8, sbb_cl_bpdisp8, sbb_cl_bxdisp8
	.global sbb_dl_sidisp8, sbb_dl_didisp8, sbb_dl_bpdisp8, sbb_dl_bxdisp8
	.global sbb_bl_sidisp8, sbb_bl_didisp8, sbb_bl_bpdisp8, sbb_bl_bxdisp8
	.global sbb_ah_sidisp8, sbb_ah_didisp8, sbb_ah_bpdisp8, sbb_ah_bxdisp8
	.global sbb_ch_sidisp8, sbb_ch_didisp8, sbb_ch_bpdisp8, sbb_ch_bxdisp8
	.global sbb_dh_sidisp8, sbb_dh_didisp8, sbb_dh_bpdisp8, sbb_dh_bxdisp8
	.global sbb_bh_sidisp8, sbb_bh_didisp8, sbb_bh_bpdisp8, sbb_bh_bxdisp8
	.global sbb_al_al, sbb_cl_al, sbb_dl_al, sbb_bl_al, sbb_ah_al, sbb_ch_al, sbb_dh_al, sbb_bh_al
	.global sbb_al_cl, sbb_cl_cl, sbb_dl_cl, sbb_bl_cl, sbb_ah_cl, sbb_ch_cl, sbb_dh_cl, sbb_bh_cl
	.global sbb_al_dl, sbb_cl_dl, sbb_dl_dl, sbb_bl_dl, sbb_ah_dl, sbb_ch_dl, sbb_dh_dl, sbb_bh_dl
	.global sbb_al_bl, sbb_cl_bl, sbb_dl_bl, sbb_bl_bl, sbb_ah_bl, sbb_ch_bl, sbb_dh_bl, sbb_bh_bl
	.global sbb_al_ah, sbb_cl_ah, sbb_dl_ah, sbb_bl_ah, sbb_ah_ah, sbb_ch_ah, sbb_dh_ah, sbb_bh_ah
	.global sbb_al_ch, sbb_cl_ch, sbb_dl_ch, sbb_bl_ch, sbb_ah_ch, sbb_ch_ch, sbb_dh_ch, sbb_bh_ch
	.global sbb_al_dh, sbb_cl_dh, sbb_dl_dh, sbb_bl_dh, sbb_ah_dh, sbb_ch_dh, sbb_dh_dh, sbb_bh_dh
	.global sbb_al_bh, sbb_cl_bh, sbb_dl_bh, sbb_bl_bh, sbb_ah_bh, sbb_ch_bh, sbb_dh_bh, sbb_bh_bh

.macro sbb_reg8l_r0high reg
	.global	sbb_r8l_r0_bp_\reg
sbb_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	sbb_r8l_r0_\reg
sbb_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_1a_RAM_l_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_1a_RAM_l_\reg:
	ldrb	r1, [r2] 				// Load byte to r0
	bcs		1f						// If input carry is set, we need to determine the flags ourselves.
	mov		r0, \reg, lsl #24
	subs	r0, r1, lsl #24			// Perform the actual subtraction, setting the resulting flags.
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r0, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	and		r0, \reg, #0xFF
	sub		r2, r0, r1				// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r2, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0
	eor		r2, r0, r2, lsr #24
	and		r1, r2
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm
.macro sbb_reg8h_r0high reg
	.global	sbb_r8h_r0_bp_\reg
sbb_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	sbb_r8h_r0_\reg
sbb_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_1a_RAM_h_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_1a_RAM_h_\reg:
	ldrb	r1, [r2] 				// Load byte to r0
	and		r0, \reg, #0xFF00		// Left operand already uses just the rightmost byte
	bcs		1f						// If input carry is set, we need to determine the flags ourselves.
	lsl		r0, #16
	subs	r0, r1, lsl #24			// Perform the actual subtraction, setting the resulting flags.
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r0, lsr #16
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	rsb		r2, r1, r0, lsr #8		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r2, lsr #16		// Put the result to the correct byte of the register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0, lsr #8
	eor		r2, r0, lsl #16
	and		r1, r2, lsr #24
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

	sbb_reg8l_r0high r4
	sbb_reg8l_r0high r5
	sbb_reg8l_r0high r6
	sbb_reg8l_r0high r7
	sbb_reg8h_r0high r4
	sbb_reg8h_r0high r5
	sbb_reg8h_r0high r6
	sbb_reg8h_r0high r7

	.ltorg

// --- [idx] ---

.macro sbb_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		sbb_r8l_r0_\reg
.endm
.macro sbb_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		sbb_r8h_r0_\reg
.endm

sbb_al_bxsi:
	sbb_reg8l_bxidx r4 r10
sbb_cl_bxsi:
	sbb_reg8l_bxidx r5 r10
sbb_dl_bxsi:
	sbb_reg8l_bxidx r6 r10
sbb_bl_bxsi:
	sbb_reg8l_bxidx r7 r10
sbb_ah_bxsi:
	sbb_reg8h_bxidx r4 r10
sbb_ch_bxsi:
	sbb_reg8h_bxidx r5 r10
sbb_dh_bxsi:
	sbb_reg8h_bxidx r6 r10
sbb_bh_bxsi:
	sbb_reg8h_bxidx r7 r10

sbb_al_bxdi:
	sbb_reg8l_bxidx r4 r11
sbb_cl_bxdi:
	sbb_reg8l_bxidx r5 r11
sbb_dl_bxdi:
	sbb_reg8l_bxidx r6 r11
sbb_bl_bxdi:
	sbb_reg8l_bxidx r7 r11
sbb_ah_bxdi:
	sbb_reg8h_bxidx r4 r11
sbb_ch_bxdi:
	sbb_reg8h_bxidx r5 r11
sbb_dh_bxdi:
	sbb_reg8h_bxidx r6 r11
sbb_bh_bxdi:
	sbb_reg8h_bxidx r7 r11

.macro sbb_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		sbb_r8l_r0_bp_\reg
.endm
.macro sbb_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		sbb_r8h_r0_bp_\reg
.endm

sbb_al_bpsi:
	sbb_reg8l_bpidx r4 r10
sbb_cl_bpsi:
	sbb_reg8l_bpidx r5 r10
sbb_dl_bpsi:
	sbb_reg8l_bpidx r6 r10
sbb_bl_bpsi:
	sbb_reg8l_bpidx r7 r10
sbb_ah_bpsi:
	sbb_reg8h_bpidx r4 r10
sbb_ch_bpsi:
	sbb_reg8h_bpidx r5 r10
sbb_dh_bpsi:
	sbb_reg8h_bpidx r6 r10
sbb_bh_bpsi:
	sbb_reg8h_bpidx r7 r10

sbb_al_bpdi:
	sbb_reg8l_bpidx r4 r11
sbb_cl_bpdi:
	sbb_reg8l_bpidx r5 r11
sbb_dl_bpdi:
	sbb_reg8l_bpidx r6 r11
sbb_bl_bpdi:
	sbb_reg8l_bpidx r7 r11
sbb_ah_bpdi:
	sbb_reg8h_bpidx r4 r11
sbb_ch_bpdi:
	sbb_reg8h_bpidx r5 r11
sbb_dh_bpdi:
	sbb_reg8h_bpidx r6 r11
sbb_bh_bpdi:
	sbb_reg8h_bpidx r7 r11

.macro sbb_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		sbb_r8l_r0_\reg
.endm
.macro sbb_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		sbb_r8h_r0_\reg
.endm

sbb_al_siidx:
	sbb_reg8l_idx r4 r10
sbb_cl_siidx:
	sbb_reg8l_idx r5 r10
sbb_dl_siidx:
	sbb_reg8l_idx r6 r10
sbb_bl_siidx:
	sbb_reg8l_idx r7 r10
sbb_ah_siidx:
	sbb_reg8h_idx r4 r10
sbb_ch_siidx:
	sbb_reg8h_idx r5 r10
sbb_dh_siidx:
	sbb_reg8h_idx r6 r10
sbb_bh_siidx:
	sbb_reg8h_idx r7 r10

sbb_al_diidx:
	sbb_reg8l_idx r4 r11
sbb_cl_diidx:
	sbb_reg8l_idx r5 r11
sbb_dl_diidx:
	sbb_reg8l_idx r6 r11
sbb_bl_diidx:
	sbb_reg8l_idx r7 r11
sbb_ah_diidx:
	sbb_reg8h_idx r4 r11
sbb_ch_diidx:
	sbb_reg8h_idx r5 r11
sbb_dh_diidx:
	sbb_reg8h_idx r6 r11
sbb_bh_diidx:
	sbb_reg8h_idx r7 r11

sbb_al_bxidx:
	sbb_reg8l_idx r4 r7
sbb_cl_bxidx:
	sbb_reg8l_idx r5 r7
sbb_dl_bxidx:
	sbb_reg8l_idx r6 r7
sbb_bl_bxidx:
	sbb_reg8l_idx r7 r7
sbb_ah_bxidx:
	sbb_reg8h_idx r4 r7
sbb_ch_bxidx:
	sbb_reg8h_idx r5 r7
sbb_dh_bxidx:
	sbb_reg8h_idx r6 r7
sbb_bh_bxidx:
	sbb_reg8h_idx r7 r7

.macro sbb_reg8l_disp16 reg
	r0_from_disp16
	b		sbb_r8l_r0_\reg
.endm
.macro sbb_reg8h_disp16 reg
	r0_from_disp16
	b		sbb_r8h_r0_\reg
.endm

sbb_al_disp16:
	sbb_reg8l_disp16 r4
sbb_cl_disp16:
	sbb_reg8l_disp16 r5
sbb_dl_disp16:
	sbb_reg8l_disp16 r6
sbb_bl_disp16:
	sbb_reg8l_disp16 r7
sbb_ah_disp16:
	sbb_reg8h_disp16 r4
sbb_ch_disp16:
	sbb_reg8h_disp16 r5
sbb_dh_disp16:
	sbb_reg8h_disp16 r6
sbb_bh_disp16:
	sbb_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro sbb_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		sbb_r8l_r0_\reg
.endm
.macro sbb_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		sbb_r8h_r0_\reg
.endm

sbb_al_bxsid8:
	sbb_reg8l_bxidxd8 r4 r10
sbb_cl_bxsid8:
	sbb_reg8l_bxidxd8 r5 r10
sbb_dl_bxsid8:
	sbb_reg8l_bxidxd8 r6 r10
sbb_bl_bxsid8:
	sbb_reg8l_bxidxd8 r7 r10
sbb_ah_bxsid8:
	sbb_reg8h_bxidxd8 r4 r10
sbb_ch_bxsid8:
	sbb_reg8h_bxidxd8 r5 r10
sbb_dh_bxsid8:
	sbb_reg8h_bxidxd8 r6 r10
sbb_bh_bxsid8:
	sbb_reg8h_bxidxd8 r7 r10

sbb_al_bxdid8:
	sbb_reg8l_bxidxd8 r4 r11
sbb_cl_bxdid8:
	sbb_reg8l_bxidxd8 r5 r11
sbb_dl_bxdid8:
	sbb_reg8l_bxidxd8 r6 r11
sbb_bl_bxdid8:
	sbb_reg8l_bxidxd8 r7 r11
sbb_ah_bxdid8:
	sbb_reg8h_bxidxd8 r4 r11
sbb_ch_bxdid8:
	sbb_reg8h_bxidxd8 r5 r11
sbb_dh_bxdid8:
	sbb_reg8h_bxidxd8 r6 r11
sbb_bh_bxdid8:
	sbb_reg8h_bxidxd8 r7 r11

.macro sbb_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		sbb_r8l_r0_bp_\reg
.endm
.macro sbb_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		sbb_r8h_r0_bp_\reg
.endm

sbb_al_bpsid8:
	sbb_reg8l_bpidxd8 r4 r10
sbb_cl_bpsid8:
	sbb_reg8l_bpidxd8 r5 r10
sbb_dl_bpsid8:
	sbb_reg8l_bpidxd8 r6 r10
sbb_bl_bpsid8:
	sbb_reg8l_bpidxd8 r7 r10
sbb_ah_bpsid8:
	sbb_reg8h_bpidxd8 r4 r10
sbb_ch_bpsid8:
	sbb_reg8h_bpidxd8 r5 r10
sbb_dh_bpsid8:
	sbb_reg8h_bpidxd8 r6 r10
sbb_bh_bpsid8:
	sbb_reg8h_bpidxd8 r7 r10

sbb_al_bpdid8:
	sbb_reg8l_bpidxd8 r4 r11
sbb_cl_bpdid8:
	sbb_reg8l_bpidxd8 r5 r11
sbb_dl_bpdid8:
	sbb_reg8l_bpidxd8 r6 r11
sbb_bl_bpdid8:
	sbb_reg8l_bpidxd8 r7 r11
sbb_ah_bpdid8:
	sbb_reg8h_bpidxd8 r4 r11
sbb_ch_bpdid8:
	sbb_reg8h_bpidxd8 r5 r11
sbb_dh_bpdid8:
	sbb_reg8h_bpidxd8 r6 r11
sbb_bh_bpdid8:
	sbb_reg8h_bpidxd8 r7 r11

.macro sbb_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		sbb_r8l_r0_\reg
.endm
.macro sbb_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		sbb_r8h_r0_\reg
.endm

sbb_al_sidisp8:
	sbb_reg8l_idxdisp8 r4 r10
sbb_cl_sidisp8:
	sbb_reg8l_idxdisp8 r5 r10
sbb_dl_sidisp8:
	sbb_reg8l_idxdisp8 r6 r10
sbb_bl_sidisp8:
	sbb_reg8l_idxdisp8 r7 r10
sbb_ah_sidisp8:
	sbb_reg8h_idxdisp8 r4 r10
sbb_ch_sidisp8:
	sbb_reg8h_idxdisp8 r5 r10
sbb_dh_sidisp8:
	sbb_reg8h_idxdisp8 r6 r10
sbb_bh_sidisp8:
	sbb_reg8h_idxdisp8 r7 r10
	
sbb_al_didisp8:
	sbb_reg8l_idxdisp8 r4 r11
sbb_cl_didisp8:
	sbb_reg8l_idxdisp8 r5 r11
sbb_dl_didisp8:
	sbb_reg8l_idxdisp8 r6 r11
sbb_bl_didisp8:
	sbb_reg8l_idxdisp8 r7 r11
sbb_ah_didisp8:
	sbb_reg8h_idxdisp8 r4 r11
sbb_ch_didisp8:
	sbb_reg8h_idxdisp8 r5 r11
sbb_dh_didisp8:
	sbb_reg8h_idxdisp8 r6 r11
sbb_bh_didisp8:
	sbb_reg8h_idxdisp8 r7 r11

sbb_al_bxdisp8:
	sbb_reg8l_idxdisp8 r4 r7
sbb_cl_bxdisp8:
	sbb_reg8l_idxdisp8 r5 r7
sbb_dl_bxdisp8:
	sbb_reg8l_idxdisp8 r6 r7
sbb_bl_bxdisp8:
	sbb_reg8l_idxdisp8 r7 r7
sbb_ah_bxdisp8:
	sbb_reg8h_idxdisp8 r4 r7
sbb_ch_bxdisp8:
	sbb_reg8h_idxdisp8 r5 r7
sbb_dh_bxdisp8:
	sbb_reg8h_idxdisp8 r6 r7
sbb_bh_bxdisp8:
	sbb_reg8h_idxdisp8 r7 r7

.macro sbb_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		sbb_r8l_r0_bp_\reg
.endm
.macro sbb_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		sbb_r8h_r0_bp_\reg
.endm

sbb_al_bpdisp8:
	sbb_reg8l_bpdisp8 r4
sbb_cl_bpdisp8:
	sbb_reg8l_bpdisp8 r5
sbb_dl_bpdisp8:
	sbb_reg8l_bpdisp8 r6
sbb_bl_bpdisp8:
	sbb_reg8l_bpdisp8 r7
sbb_ah_bpdisp8:
	sbb_reg8h_bpdisp8 r4
sbb_ch_bpdisp8:
	sbb_reg8h_bpdisp8 r5
sbb_dh_bpdisp8:
	sbb_reg8h_bpdisp8 r6
sbb_bh_bpdisp8:
	sbb_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro sbb_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		sbb_r8l_r0_\reg
.endm
.macro sbb_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		sbb_r8h_r0_\reg
.endm

sbb_al_bxsid16:
	sbb_reg8l_bxidxd16 r4 r10
sbb_cl_bxsid16:
	sbb_reg8l_bxidxd16 r5 r10
sbb_dl_bxsid16:
	sbb_reg8l_bxidxd16 r6 r10
sbb_bl_bxsid16:
	sbb_reg8l_bxidxd16 r7 r10
sbb_ah_bxsid16:
	sbb_reg8h_bxidxd16 r4 r10
sbb_ch_bxsid16:
	sbb_reg8h_bxidxd16 r5 r10
sbb_dh_bxsid16:
	sbb_reg8h_bxidxd16 r6 r10
sbb_bh_bxsid16:
	sbb_reg8h_bxidxd16 r7 r10

sbb_al_bxdid16:
	sbb_reg8l_bxidxd16 r4 r11
sbb_cl_bxdid16:
	sbb_reg8l_bxidxd16 r5 r11
sbb_dl_bxdid16:
	sbb_reg8l_bxidxd16 r6 r11
sbb_bl_bxdid16:
	sbb_reg8l_bxidxd16 r7 r11
sbb_ah_bxdid16:
	sbb_reg8h_bxidxd16 r4 r11
sbb_ch_bxdid16:
	sbb_reg8h_bxidxd16 r5 r11
sbb_dh_bxdid16:
	sbb_reg8h_bxidxd16 r6 r11
sbb_bh_bxdid16:
	sbb_reg8h_bxidxd16 r7 r11

.macro sbb_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		sbb_r8l_r0_bp_\reg
.endm
.macro sbb_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		sbb_r8h_r0_bp_\reg
.endm

sbb_al_bpsid16:
	sbb_reg8l_bpidxd16 r4 r10
sbb_cl_bpsid16:
	sbb_reg8l_bpidxd16 r5 r10
sbb_dl_bpsid16:
	sbb_reg8l_bpidxd16 r6 r10
sbb_bl_bpsid16:
	sbb_reg8l_bpidxd16 r7 r10
sbb_ah_bpsid16:
	sbb_reg8h_bpidxd16 r4 r10
sbb_ch_bpsid16:
	sbb_reg8h_bpidxd16 r5 r10
sbb_dh_bpsid16:
	sbb_reg8h_bpidxd16 r6 r10
sbb_bh_bpsid16:
	sbb_reg8h_bpidxd16 r7 r10

sbb_al_bpdid16:
	sbb_reg8l_bpidxd16 r4 r11
sbb_cl_bpdid16:
	sbb_reg8l_bpidxd16 r5 r11
sbb_dl_bpdid16:
	sbb_reg8l_bpidxd16 r6 r11
sbb_bl_bpdid16:
	sbb_reg8l_bpidxd16 r7 r11
sbb_ah_bpdid16:
	sbb_reg8h_bpidxd16 r4 r11
sbb_ch_bpdid16:
	sbb_reg8h_bpidxd16 r5 r11
sbb_dh_bpdid16:
	sbb_reg8h_bpidxd16 r6 r11
sbb_bh_bpdid16:
	sbb_reg8h_bpidxd16 r7 r11

.macro sbb_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		sbb_r8l_r0_\reg
.endm
.macro sbb_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		sbb_r8h_r0_\reg
.endm

sbb_al_sidisp16:
	sbb_reg8l_idxdisp16 r4 r10
sbb_cl_sidisp16:
	sbb_reg8l_idxdisp16 r5 r10
sbb_dl_sidisp16:
	sbb_reg8l_idxdisp16 r6 r10
sbb_bl_sidisp16:
	sbb_reg8l_idxdisp16 r7 r10
sbb_ah_sidisp16:
	sbb_reg8h_idxdisp16 r4 r10
sbb_ch_sidisp16:
	sbb_reg8h_idxdisp16 r5 r10
sbb_dh_sidisp16:
	sbb_reg8h_idxdisp16 r6 r10
sbb_bh_sidisp16:
	sbb_reg8h_idxdisp16 r7 r10

sbb_al_didisp16:
	sbb_reg8l_idxdisp16 r4 r11
sbb_cl_didisp16:
	sbb_reg8l_idxdisp16 r5 r11
sbb_dl_didisp16:
	sbb_reg8l_idxdisp16 r6 r11
sbb_bl_didisp16:
	sbb_reg8l_idxdisp16 r7 r11
sbb_ah_didisp16:
	sbb_reg8h_idxdisp16 r4 r11
sbb_ch_didisp16:
	sbb_reg8h_idxdisp16 r5 r11
sbb_dh_didisp16:
	sbb_reg8h_idxdisp16 r6 r11
sbb_bh_didisp16:
	sbb_reg8h_idxdisp16 r7 r11

sbb_al_bxdisp16:
	sbb_reg8l_idxdisp16 r4 r7
sbb_cl_bxdisp16:
	sbb_reg8l_idxdisp16 r5 r7
sbb_dl_bxdisp16:
	sbb_reg8l_idxdisp16 r6 r7
sbb_bl_bxdisp16:
	sbb_reg8l_idxdisp16 r7 r7
sbb_ah_bxdisp16:
	sbb_reg8h_idxdisp16 r4 r7
sbb_ch_bxdisp16:
	sbb_reg8h_idxdisp16 r5 r7
sbb_dh_bxdisp16:
	sbb_reg8h_idxdisp16 r6 r7
sbb_bh_bxdisp16:
	sbb_reg8h_idxdisp16 r7 r7
	
.macro sbb_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		sbb_r8l_r0_bp_\reg
.endm
.macro sbb_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		sbb_r8h_r0_bp_\reg
.endm

sbb_al_bpdisp16:
	sbb_reg8l_bpdisp16 r4 
sbb_cl_bpdisp16:
	sbb_reg8l_bpdisp16 r5 
sbb_dl_bpdisp16:
	sbb_reg8l_bpdisp16 r6 
sbb_bl_bpdisp16:
	sbb_reg8l_bpdisp16 r7 
sbb_ah_bpdisp16:
	sbb_reg8h_bpdisp16 r4 
sbb_ch_bpdisp16:
	sbb_reg8h_bpdisp16 r5 
sbb_dh_bpdisp16:
	sbb_reg8h_bpdisp16 r6 
sbb_bh_bpdisp16:
	sbb_reg8h_bpdisp16 r7 


// --- registers ---

.macro sbb_reg8l_reg8l rl rr
	bcs		1f						// If input carry is set, we need to determine the flags ourselves.
	mov		r0, \rl, lsl #24		// Put left operand to r0 high byte
	subs	r0, \rr, lsl #24		// Perform the actual subtraction, setting the resulting flags.
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// and put the result there
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	and		r0, \rl, #0xFF	
	and		r1, \rr, #0xFF
	sub		r2, r0, r1				// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r2, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0
	eor		r2, r0, r2, lsr #24
	and		r1, r2
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm
.macro sbb_reg8l_reg8h rl rr
	and		r1, \rr, #0xFF00		// Put the right operand into r1 high byte
	bcs		1f						// If input carry is set, we need to determine the flags ourselves.
	mov		r0, \rl, lsl #24		// Put left operand to r0 high byte
	subs	r0, r1, lsl #16			// Perform the actual subtraction, setting the resulting flags.
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r0, lsr #24		// and put the result there
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	and		r0, \rl, #0xFF	
	sub		r2, r0, r1, lsr #8		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\rl, #0xFF				// Clear the current reg8l value
	orr		\rl, r2, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0, r1, lsr #8
	eor		r2, r0, r2, lsr #24
	and		r1, r2
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm
.macro sbb_reg8h_reg8l rl rr
	and		r0, \rl, #0xFF00		// Put left operand to r0 high byte
	bcs		1f						// If input carry is set, we need to determine the flags ourselves.
	lsl		r0, #16					// Put left operand to r0 high byte
	subs	r0, \rr, lsl #24		// Perform the actual subtraction, setting the resulting flags.
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16		// and put the result there
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	and		r1, \rr, #0xFF	
	rsb		r2, r1, r0, lsr #8		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\rl, #0xFF00			// Clear the current reg8l value
	orr		\rl, r2, lsr #16		// Put the result to the lower byte of the high halfword of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0, lsr #8
	eor		r2, r0, lsl #16
	and		r1, r2, lsr #24
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm
.macro sbb_reg8h_reg8h rl rr
	and		r0, \rl, #0xFF00		// Put left operand to r0 high byte
	and		r1, \rr, #0xFF00		// Put the right operand into r1 high byte
	bcs		1f						// If input carry is set, we need to determine the flags ourselves.
	lsl		r0, #16
	subs	r0, r1, lsl #16			// Perform the actual subtraction, setting the resulting flags.
	bic		\rl, #0xFF00			// Clear the current reg8h value
	orr		\rl, r0, lsr #16		// and put the result there
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	sub		r2, r0, r1				// r2 = lf_var1d - lf_var2d
	sub		r2, #0x100				// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\rl, #0xFF00			// Clear the current reg8l value
	orr		\rl, r2, lsr #16		// Put the result to the lower byte of the high halfword of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0
	eor		r2, r0, lsl #16
	and		r1, r2, lsr #16
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

sbb_al_al:
	sbb_reg8l_reg8l r4 r4
sbb_al_cl:	
	sbb_reg8l_reg8l r4 r5
sbb_al_dl:
	sbb_reg8l_reg8l r4 r6
sbb_al_bl:	
	sbb_reg8l_reg8l r4 r7

sbb_cl_al:
	sbb_reg8l_reg8l r5 r4
sbb_cl_cl:	
	sbb_reg8l_reg8l r5 r5
sbb_cl_dl:
	sbb_reg8l_reg8l r5 r6
sbb_cl_bl:	
	sbb_reg8l_reg8l r5 r7
	
sbb_dl_al:
	sbb_reg8l_reg8l r6 r4
sbb_dl_cl:	
	sbb_reg8l_reg8l r6 r5
sbb_dl_dl:
	sbb_reg8l_reg8l r6 r6
sbb_dl_bl:	
	sbb_reg8l_reg8l r6 r7
	
sbb_bl_al:
	sbb_reg8l_reg8l r7 r4
sbb_bl_cl:	
	sbb_reg8l_reg8l r7 r5
sbb_bl_dl:
	sbb_reg8l_reg8l r7 r6
sbb_bl_bl:	
	sbb_reg8l_reg8l r7 r7

sbb_al_ah:
	sbb_reg8l_reg8h r4 r4
sbb_al_ch:	
	sbb_reg8l_reg8h r4 r5
sbb_al_dh:
	sbb_reg8l_reg8h r4 r6
sbb_al_bh:	
	sbb_reg8l_reg8h r4 r7

sbb_cl_ah:
	sbb_reg8l_reg8h r5 r4
sbb_cl_ch:	
	sbb_reg8l_reg8h r5 r5
sbb_cl_dh:
	sbb_reg8l_reg8h r5 r6
sbb_cl_bh:	
	sbb_reg8l_reg8h r5 r7
	
sbb_dl_ah:
	sbb_reg8l_reg8h r6 r4
sbb_dl_ch:	
	sbb_reg8l_reg8h r6 r5
sbb_dl_dh:
	sbb_reg8l_reg8h r6 r6
sbb_dl_bh:	
	sbb_reg8l_reg8h r6 r7
	
sbb_bl_ah:
	sbb_reg8l_reg8h r7 r4
sbb_bl_ch:	
	sbb_reg8l_reg8h r7 r5
sbb_bl_dh:
	sbb_reg8l_reg8h r7 r6
sbb_bl_bh:	
	sbb_reg8l_reg8h r7 r7

sbb_ah_al:
	sbb_reg8h_reg8l r4 r4
sbb_ah_cl:	
	sbb_reg8h_reg8l r4 r5
sbb_ah_dl:
	sbb_reg8h_reg8l r4 r6
sbb_ah_bl:	
	sbb_reg8h_reg8l r4 r7

sbb_ch_al:
	sbb_reg8h_reg8l r5 r4
sbb_ch_cl:	
	sbb_reg8h_reg8l r5 r5
sbb_ch_dl:
	sbb_reg8h_reg8l r5 r6
sbb_ch_bl:	
	sbb_reg8h_reg8l r5 r7
	
sbb_dh_al:
	sbb_reg8h_reg8l r6 r4
sbb_dh_cl:	
	sbb_reg8h_reg8l r6 r5
sbb_dh_dl:
	sbb_reg8h_reg8l r6 r6
sbb_dh_bl:	
	sbb_reg8h_reg8l r6 r7
	
sbb_bh_al:
	sbb_reg8h_reg8l r7 r4
sbb_bh_cl:	
	sbb_reg8h_reg8l r7 r5
sbb_bh_dl:
	sbb_reg8h_reg8l r7 r6
sbb_bh_bl:	
	sbb_reg8h_reg8l r7 r7

sbb_ah_ah:
	sbb_reg8h_reg8h r4 r4
sbb_ah_ch:	
	sbb_reg8h_reg8h r4 r5
sbb_ah_dh:
	sbb_reg8h_reg8h r4 r6
sbb_ah_bh:	
	sbb_reg8h_reg8h r4 r7

sbb_ch_ah:
	sbb_reg8h_reg8h r5 r4
sbb_ch_ch:	
	sbb_reg8h_reg8h r5 r5
sbb_ch_dh:
	sbb_reg8h_reg8h r5 r6
sbb_ch_bh:	
	sbb_reg8h_reg8h r5 r7
	
sbb_dh_ah:
	sbb_reg8h_reg8h r6 r4
sbb_dh_ch:	
	sbb_reg8h_reg8h r6 r5
sbb_dh_dh:
	sbb_reg8h_reg8h r6 r6
sbb_dh_bh:	
	sbb_reg8h_reg8h r6 r7
	
sbb_bh_ah:
	sbb_reg8h_reg8h r7 r4
sbb_bh_ch:	
	sbb_reg8h_reg8h r7 r5
sbb_bh_dh:
	sbb_reg8h_reg8h r7 r6
sbb_bh_bh:	
	sbb_reg8h_reg8h r7 r7
	
// ------------------- 1B = SBB r16, r/m16 -----------------------------
//
// All modrm variations supported!
//
//
op_1b:
	modrm_jump_16
// 0
	.word sbb_ax_bxsi, sbb_ax_bxdi, sbb_ax_bpsi, sbb_ax_bpdi, sbb_ax_siidx, sbb_ax_diidx, sbb_ax_disp16, sbb_ax_bxidx
	.word sbb_cx_bxsi, sbb_cx_bxdi, sbb_cx_bpsi, sbb_cx_bpdi, sbb_cx_siidx, sbb_cx_diidx, sbb_cx_disp16, sbb_cx_bxidx
	.word sbb_dx_bxsi, sbb_dx_bxdi, sbb_dx_bpsi, sbb_dx_bpdi, sbb_dx_siidx, sbb_dx_diidx, sbb_dx_disp16, sbb_dx_bxidx
	.word sbb_bx_bxsi, sbb_bx_bxdi, sbb_bx_bpsi, sbb_bx_bpdi, sbb_bx_siidx, sbb_bx_diidx, sbb_bx_disp16, sbb_bx_bxidx
	.word sbb_sp_bxsi, sbb_sp_bxdi, sbb_sp_bpsi, sbb_sp_bpdi, sbb_sp_siidx, sbb_sp_diidx, sbb_sp_disp16, sbb_sp_bxidx
	.word sbb_bp_bxsi, sbb_bp_bxdi, sbb_bp_bpsi, sbb_bp_bpdi, sbb_bp_siidx, sbb_bp_diidx, sbb_bp_disp16, sbb_bp_bxidx
	.word sbb_si_bxsi, sbb_si_bxdi, sbb_si_bpsi, sbb_si_bpdi, sbb_si_siidx, sbb_si_diidx, sbb_si_disp16, sbb_si_bxidx
	.word sbb_di_bxsi, sbb_di_bxdi, sbb_di_bpsi, sbb_di_bpdi, sbb_di_siidx, sbb_di_diidx, sbb_di_disp16, sbb_di_bxidx
//0x40
	.word sbb_ax_bxsid8, sbb_ax_bxdid8, sbb_ax_bpsid8, sbb_ax_bpdid8, sbb_ax_sidisp8, sbb_ax_didisp8, sbb_ax_bpdisp8, sbb_ax_bxdisp8
	.word sbb_cx_bxsid8, sbb_cx_bxdid8, sbb_cx_bpsid8, sbb_cx_bpdid8, sbb_cx_sidisp8, sbb_cx_didisp8, sbb_cx_bpdisp8, sbb_cx_bxdisp8
	.word sbb_dx_bxsid8, sbb_dx_bxdid8, sbb_dx_bpsid8, sbb_dx_bpdid8, sbb_dx_sidisp8, sbb_dx_didisp8, sbb_dx_bpdisp8, sbb_dx_bxdisp8
	.word sbb_bx_bxsid8, sbb_bx_bxdid8, sbb_bx_bpsid8, sbb_bx_bpdid8, sbb_bx_sidisp8, sbb_bx_didisp8, sbb_bx_bpdisp8, sbb_bx_bxdisp8
	.word sbb_sp_bxsid8, sbb_sp_bxdid8, sbb_sp_bpsid8, sbb_sp_bpdid8, sbb_sp_sidisp8, sbb_sp_didisp8, sbb_sp_bpdisp8, sbb_sp_bxdisp8
	.word sbb_bp_bxsid8, sbb_bp_bxdid8, sbb_bp_bpsid8, sbb_bp_bpdid8, sbb_bp_sidisp8, sbb_bp_didisp8, sbb_bp_bpdisp8, sbb_bp_bxdisp8
	.word sbb_si_bxsid8, sbb_si_bxdid8, sbb_si_bpsid8, sbb_si_bpdid8, sbb_si_sidisp8, sbb_si_didisp8, sbb_si_bpdisp8, sbb_si_bxdisp8
	.word sbb_di_bxsid8, sbb_di_bxdid8, sbb_di_bpsid8, sbb_di_bpdid8, sbb_di_sidisp8, sbb_di_didisp8, sbb_di_bpdisp8, sbb_di_bxdisp8
//0x80
	.word sbb_ax_bxsid16, sbb_ax_bxdid16, sbb_ax_bpsid16, sbb_ax_bpdid16, sbb_ax_sidisp16, sbb_ax_didisp16, sbb_ax_bpdisp16, sbb_ax_bxdisp16
	.word sbb_cx_bxsid16, sbb_cx_bxdid16, sbb_cx_bpsid16, sbb_cx_bpdid16, sbb_cx_sidisp16, sbb_cx_didisp16, sbb_cx_bpdisp16, sbb_cx_bxdisp16
	.word sbb_dx_bxsid16, sbb_dx_bxdid16, sbb_dx_bpsid16, sbb_dx_bpdid16, sbb_dx_sidisp16, sbb_dx_didisp16, sbb_dx_bpdisp16, sbb_dx_bxdisp16
	.word sbb_bx_bxsid16, sbb_bx_bxdid16, sbb_bx_bpsid16, sbb_bx_bpdid16, sbb_bx_sidisp16, sbb_bx_didisp16, sbb_bx_bpdisp16, sbb_bx_bxdisp16
	.word sbb_sp_bxsid16, sbb_sp_bxdid16, sbb_sp_bpsid16, sbb_sp_bpdid16, sbb_sp_sidisp16, sbb_sp_didisp16, sbb_sp_bpdisp16, sbb_sp_bxdisp16
	.word sbb_bp_bxsid16, sbb_bp_bxdid16, sbb_bp_bpsid16, sbb_bp_bpdid16, sbb_bp_sidisp16, sbb_bp_didisp16, sbb_bp_bpdisp16, sbb_bp_bxdisp16
	.word sbb_si_bxsid16, sbb_si_bxdid16, sbb_si_bpsid16, sbb_si_bpdid16, sbb_si_sidisp16, sbb_si_didisp16, sbb_si_bpdisp16, sbb_si_bxdisp16
	.word sbb_di_bxsid16, sbb_di_bxdid16, sbb_di_bpsid16, sbb_di_bpdid16, sbb_di_sidisp16, sbb_di_didisp16, sbb_di_bpdisp16, sbb_di_bxdisp16
// 0xC0 = two register operands
	.word sbb_ax_ax, sbb_ax_cx, sbb_ax_dx, sbb_ax_bx, sbb_ax_sp, sbb_ax_bp, sbb_ax_si, sbb_ax_di
	.word sbb_cx_ax, sbb_cx_cx, sbb_cx_dx, sbb_cx_bx, sbb_cx_sp, sbb_cx_bp, sbb_cx_si, sbb_cx_di
	.word sbb_dx_ax, sbb_dx_cx, sbb_dx_dx, sbb_dx_bx, sbb_dx_sp, sbb_dx_bp, sbb_dx_si, sbb_dx_di
	.word sbb_bx_ax, sbb_bx_cx, sbb_bx_dx, sbb_bx_bx, sbb_bx_sp, sbb_bx_bp, sbb_bx_si, sbb_bx_di
	.word sbb_sp_ax, sbb_sp_cx, sbb_sp_dx, sbb_sp_bx, sbb_sp_sp, sbb_sp_bp, sbb_sp_si, sbb_sp_di
	.word sbb_bp_ax, sbb_bp_cx, sbb_bp_dx, sbb_bp_bx, sbb_bp_sp, sbb_bp_bp, sbb_bp_si, sbb_bp_di
	.word sbb_si_ax, sbb_si_cx, sbb_si_dx, sbb_si_bx, sbb_si_sp, sbb_si_bp, sbb_si_si, sbb_si_di
	.word sbb_di_ax, sbb_di_cx, sbb_di_dx, sbb_di_bx, sbb_di_sp, sbb_di_bp, sbb_di_si, sbb_di_di

// These are called from "cpu_67.s":

	.global sbb_ax_siidx, sbb_ax_diidx, sbb_ax_bxidx
	.global sbb_cx_siidx, sbb_cx_diidx, sbb_cx_bxidx
	.global sbb_dx_siidx, sbb_dx_diidx, sbb_dx_bxidx
	.global sbb_bx_siidx, sbb_bx_diidx, sbb_bx_bxidx
	.global sbb_sp_siidx, sbb_sp_diidx, sbb_sp_bxidx
	.global sbb_bp_siidx, sbb_bp_diidx, sbb_bp_bxidx
	.global sbb_si_siidx, sbb_si_diidx, sbb_si_bxidx
	.global sbb_di_siidx, sbb_di_diidx, sbb_di_bxidx
	.global sbb_ax_sidisp8, sbb_ax_didisp8, sbb_ax_bpdisp8, sbb_ax_bxdisp8
	.global sbb_cx_sidisp8, sbb_cx_didisp8, sbb_cx_bpdisp8, sbb_cx_bxdisp8
	.global sbb_dx_sidisp8, sbb_dx_didisp8, sbb_dx_bpdisp8, sbb_dx_bxdisp8
	.global sbb_bx_sidisp8, sbb_bx_didisp8, sbb_bx_bpdisp8, sbb_bx_bxdisp8
	.global sbb_sp_sidisp8, sbb_sp_didisp8, sbb_sp_bpdisp8, sbb_sp_bxdisp8
	.global sbb_bp_sidisp8, sbb_bp_didisp8, sbb_bp_bpdisp8, sbb_bp_bxdisp8
	.global sbb_si_sidisp8, sbb_si_didisp8, sbb_si_bpdisp8, sbb_si_bxdisp8
	.global sbb_di_sidisp8, sbb_di_didisp8, sbb_di_bpdisp8, sbb_di_bxdisp8
	.global	sbb_r16_r0_bp_r4, sbb_r16_r0_bp_r5, sbb_r16_r0_bp_r6, sbb_r16_r0_bp_r7, sbb_r16_r0_bp_r8, sbb_r16_r0_bp_r9, sbb_r16_r0_bp_r10, sbb_r16_r0_bp_r11
	.global	sbb_r16_r0_r4, sbb_r16_r0_r5, sbb_r16_r0_r6, sbb_r16_r0_r7, sbb_r16_r0_r8, sbb_r16_r0_r9, sbb_r16_r0_r10, sbb_r16_r0_r11


.macro sbb_reg16_r0high reg
sbb_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
sbb_r16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_1b_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_1b_RAM_\reg:
	ldrb	r1, [r2] 				// Load low byte
	ldrb	r2, [r2, #1]			// Load high byte
	mov		r0, \reg, lsl #16
	orr		r1, r2, lsl #8			// r1 = low byte | (high byte << 8)
	eor		\reg, r0, lsr #16
	bcs		1f						// Calculate the flags separately if input carry is set.
	subs	r0, r1, lsl #16			// Perform the actual subtraction, setting the resulting flags.
	orr		\reg, r0, lsr #16
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	rsb		r2, r1, r0, lsr #16		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	orr		\reg, r2, lsr #16
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0, lsr #16
	eor		r2, r0
	and		r1, r2, lsr #16
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

	sbb_reg16_r0high r4
	sbb_reg16_r0high r5
	sbb_reg16_r0high r6
	sbb_reg16_r0high r7
	sbb_reg16_r0high r8
	sbb_reg16_r0high r9
	sbb_reg16_r0high r10
	sbb_reg16_r0high r11

	.ltorg

// --- [idx] ---

.macro sbb_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		sbb_r16_r0_\reg
.endm

sbb_ax_bxsi:
	sbb_reg16_bxidx r4 r10
sbb_cx_bxsi:
	sbb_reg16_bxidx r5 r10
sbb_dx_bxsi:
	sbb_reg16_bxidx r6 r10
sbb_bx_bxsi:
	sbb_reg16_bxidx r7 r10
sbb_bp_bxsi:
	sbb_reg16_bxidx r9 r10
sbb_sp_bxsi:
	sbb_reg16_bxidx r8 r10
sbb_si_bxsi:
	sbb_reg16_bxidx r10 r10
sbb_di_bxsi:
	sbb_reg16_bxidx r11 r10

sbb_ax_bxdi:
	sbb_reg16_bxidx r4 r11
sbb_cx_bxdi:
	sbb_reg16_bxidx r5 r11
sbb_dx_bxdi:
	sbb_reg16_bxidx r6 r11
sbb_bx_bxdi:
	sbb_reg16_bxidx r7 r11
sbb_sp_bxdi:
	sbb_reg16_bxidx r8 r11
sbb_bp_bxdi:
	sbb_reg16_bxidx r9 r11
sbb_si_bxdi:
	sbb_reg16_bxidx r10 r11
sbb_di_bxdi:
	sbb_reg16_bxidx r11 r11

.macro sbb_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		sbb_r16_r0_bp_\reg
.endm

sbb_ax_bpsi:
	sbb_reg16_bpidx r4 r10
sbb_cx_bpsi:
	sbb_reg16_bpidx r5 r10
sbb_dx_bpsi:
	sbb_reg16_bpidx r6 r10
sbb_bx_bpsi:
	sbb_reg16_bpidx r7 r10
sbb_sp_bpsi:
	sbb_reg16_bpidx r8 r10
sbb_bp_bpsi:
	sbb_reg16_bpidx r9 r10
sbb_si_bpsi:
	sbb_reg16_bpidx r10 r10
sbb_di_bpsi:
	sbb_reg16_bpidx r11 r10

sbb_ax_bpdi:
	sbb_reg16_bpidx r4 r11
sbb_cx_bpdi:
	sbb_reg16_bpidx r5 r11
sbb_dx_bpdi:
	sbb_reg16_bpidx r6 r11
sbb_bx_bpdi:
	sbb_reg16_bpidx r7 r11
sbb_sp_bpdi:
	sbb_reg16_bpidx r8 r11
sbb_bp_bpdi:
	sbb_reg16_bpidx r9 r11
sbb_si_bpdi:
	sbb_reg16_bpidx r10 r11
sbb_di_bpdi:
	sbb_reg16_bpidx r11 r11

.macro sbb_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		sbb_r16_r0_\reg
.endm

sbb_ax_siidx:
	sbb_reg16_idx r4 r10
sbb_cx_siidx:
	sbb_reg16_idx r5 r10
sbb_dx_siidx:
	sbb_reg16_idx r6 r10
sbb_bx_siidx:
	sbb_reg16_idx r7 r10
sbb_sp_siidx:
	sbb_reg16_idx r8 r10
sbb_bp_siidx:
	sbb_reg16_idx r9 r10
sbb_si_siidx:
	sbb_reg16_idx r10 r10
sbb_di_siidx:
	sbb_reg16_idx r11 r10

sbb_ax_diidx:
	sbb_reg16_idx r4 r11
sbb_cx_diidx:
	sbb_reg16_idx r5 r11
sbb_dx_diidx:
	sbb_reg16_idx r6 r11
sbb_bx_diidx:
	sbb_reg16_idx r7 r11
sbb_sp_diidx:
	sbb_reg16_idx r8 r11
sbb_bp_diidx:
	sbb_reg16_idx r9 r11
sbb_si_diidx:
	sbb_reg16_idx r10 r11
sbb_di_diidx:
	sbb_reg16_idx r11 r11

sbb_ax_bxidx:
	sbb_reg16_idx r4 r7
sbb_cx_bxidx:
	sbb_reg16_idx r5 r7
sbb_dx_bxidx:
	sbb_reg16_idx r6 r7
sbb_bx_bxidx:
	sbb_reg16_idx r7 r7
sbb_sp_bxidx:
	sbb_reg16_idx r8 r7
sbb_bp_bxidx:
	sbb_reg16_idx r9 r7
sbb_si_bxidx:
	sbb_reg16_idx r10 r7
sbb_di_bxidx:
	sbb_reg16_idx r11 r7

.macro sbb_reg16_disp16 reg
	r0_from_disp16
	b		sbb_r16_r0_\reg
.endm

sbb_ax_disp16:
	sbb_reg16_disp16 r4
sbb_cx_disp16:
	sbb_reg16_disp16 r5
sbb_dx_disp16:
	sbb_reg16_disp16 r6
sbb_bx_disp16:
	sbb_reg16_disp16 r7
sbb_sp_disp16:
	sbb_reg16_disp16 r8
sbb_bp_disp16:
	sbb_reg16_disp16 r9
sbb_si_disp16:
	sbb_reg16_disp16 r10
sbb_di_disp16:
	sbb_reg16_disp16 r11

// --- [idx+disp8] ---

.macro sbb_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		sbb_r16_r0_\reg
.endm

sbb_ax_bxsid8:
	sbb_reg16_bxidxdisp8 r4 r10
sbb_cx_bxsid8:
	sbb_reg16_bxidxdisp8 r5 r10
sbb_dx_bxsid8:
	sbb_reg16_bxidxdisp8 r6 r10
sbb_bx_bxsid8:
	sbb_reg16_bxidxdisp8 r7 r10
sbb_sp_bxsid8:
	sbb_reg16_bxidxdisp8 r8 r10
sbb_bp_bxsid8:
	sbb_reg16_bxidxdisp8 r9 r10
sbb_si_bxsid8:
	sbb_reg16_bxidxdisp8 r10 r10
sbb_di_bxsid8:
	sbb_reg16_bxidxdisp8 r11 r10

sbb_ax_bxdid8:
	sbb_reg16_bxidxdisp8 r4 r11
sbb_cx_bxdid8:
	sbb_reg16_bxidxdisp8 r5 r11
sbb_dx_bxdid8:
	sbb_reg16_bxidxdisp8 r6 r11
sbb_bx_bxdid8:
	sbb_reg16_bxidxdisp8 r7 r11
sbb_sp_bxdid8:
	sbb_reg16_bxidxdisp8 r8 r11
sbb_bp_bxdid8:
	sbb_reg16_bxidxdisp8 r9 r11
sbb_si_bxdid8:
	sbb_reg16_bxidxdisp8 r10 r11
sbb_di_bxdid8:
	sbb_reg16_bxidxdisp8 r11 r11

.macro sbb_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		sbb_r16_r0_bp_\reg
.endm

sbb_ax_bpsid8:
	sbb_reg16_bpidxdisp8 r4 r10
sbb_cx_bpsid8:
	sbb_reg16_bpidxdisp8 r5 r10
sbb_dx_bpsid8:
	sbb_reg16_bpidxdisp8 r6 r10
sbb_bx_bpsid8:
	sbb_reg16_bpidxdisp8 r7 r10
sbb_sp_bpsid8:
	sbb_reg16_bpidxdisp8 r8 r10
sbb_bp_bpsid8:
	sbb_reg16_bpidxdisp8 r9 r10
sbb_si_bpsid8:
	sbb_reg16_bpidxdisp8 r10 r10
sbb_di_bpsid8:
	sbb_reg16_bpidxdisp8 r11 r10

sbb_ax_bpdid8:
	sbb_reg16_bpidxdisp8 r4 r11
sbb_cx_bpdid8:
	sbb_reg16_bpidxdisp8 r5 r11
sbb_dx_bpdid8:
	sbb_reg16_bpidxdisp8 r6 r11
sbb_bx_bpdid8:
	sbb_reg16_bpidxdisp8 r7 r11
sbb_sp_bpdid8:
	sbb_reg16_bpidxdisp8 r8 r11
sbb_bp_bpdid8:
	sbb_reg16_bpidxdisp8 r9 r11
sbb_si_bpdid8:
	sbb_reg16_bpidxdisp8 r10 r11
sbb_di_bpdid8:
	sbb_reg16_bpidxdisp8 r11 r11

.macro sbb_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		sbb_r16_r0_\reg
.endm

sbb_ax_sidisp8:
	sbb_reg16_idxdisp8 r4 r10
sbb_cx_sidisp8:
	sbb_reg16_idxdisp8 r5 r10
sbb_dx_sidisp8:
	sbb_reg16_idxdisp8 r6 r10
sbb_bx_sidisp8:
	sbb_reg16_idxdisp8 r7 r10
sbb_sp_sidisp8:
	sbb_reg16_idxdisp8 r8 r10
sbb_bp_sidisp8:
	sbb_reg16_idxdisp8 r9 r10
sbb_si_sidisp8:
	sbb_reg16_idxdisp8 r10 r10
sbb_di_sidisp8:
	sbb_reg16_idxdisp8 r11 r10

sbb_ax_didisp8:
	sbb_reg16_idxdisp8 r4 r11
sbb_cx_didisp8:
	sbb_reg16_idxdisp8 r5 r11
sbb_dx_didisp8:
	sbb_reg16_idxdisp8 r6 r11
sbb_bx_didisp8:
	sbb_reg16_idxdisp8 r7 r11
sbb_sp_didisp8:
	sbb_reg16_idxdisp8 r8 r11
sbb_bp_didisp8:
	sbb_reg16_idxdisp8 r9 r11
sbb_si_didisp8:
	sbb_reg16_idxdisp8 r10 r11
sbb_di_didisp8:
	sbb_reg16_idxdisp8 r11 r11

sbb_ax_bxdisp8:
	sbb_reg16_idxdisp8 r4 r7
sbb_cx_bxdisp8:
	sbb_reg16_idxdisp8 r5 r7
sbb_dx_bxdisp8:
	sbb_reg16_idxdisp8 r6 r7
sbb_bx_bxdisp8:
	sbb_reg16_idxdisp8 r7 r7
sbb_sp_bxdisp8:
	sbb_reg16_idxdisp8 r8 r7
sbb_bp_bxdisp8:
	sbb_reg16_idxdisp8 r9 r7
sbb_si_bxdisp8:
	sbb_reg16_idxdisp8 r10 r7
sbb_di_bxdisp8:
	sbb_reg16_idxdisp8 r11 r7

.macro sbb_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		sbb_r16_r0_bp_\reg
.endm

sbb_ax_bpdisp8:
	sbb_reg16_bpdisp8 r4
sbb_cx_bpdisp8:
	sbb_reg16_bpdisp8 r5
sbb_dx_bpdisp8:
	sbb_reg16_bpdisp8 r6
sbb_bx_bpdisp8:
	sbb_reg16_bpdisp8 r7
sbb_sp_bpdisp8:
	sbb_reg16_bpdisp8 r8
sbb_bp_bpdisp8:
	sbb_reg16_bpdisp8 r9
sbb_si_bpdisp8:
	sbb_reg16_bpdisp8 r10
sbb_di_bpdisp8:
	sbb_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro sbb_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		sbb_r16_r0_\reg
.endm

sbb_ax_bxsid16:
	sbb_reg16_bxidxdisp16 r4 r10
sbb_cx_bxsid16:
	sbb_reg16_bxidxdisp16 r5 r10
sbb_dx_bxsid16:
	sbb_reg16_bxidxdisp16 r6 r10
sbb_bx_bxsid16:
	sbb_reg16_bxidxdisp16 r7 r10
sbb_sp_bxsid16:
	sbb_reg16_bxidxdisp16 r8 r10
sbb_bp_bxsid16:
	sbb_reg16_bxidxdisp16 r9 r10
sbb_si_bxsid16:
	sbb_reg16_bxidxdisp16 r10 r10
sbb_di_bxsid16:
	sbb_reg16_bxidxdisp16 r11 r10

sbb_ax_bxdid16:
	sbb_reg16_bxidxdisp16 r4 r11
sbb_cx_bxdid16:
	sbb_reg16_bxidxdisp16 r5 r11
sbb_dx_bxdid16:
	sbb_reg16_bxidxdisp16 r6 r11
sbb_bx_bxdid16:
	sbb_reg16_bxidxdisp16 r7 r11
sbb_sp_bxdid16:
	sbb_reg16_bxidxdisp16 r8 r11
sbb_bp_bxdid16:
	sbb_reg16_bxidxdisp16 r9 r11
sbb_si_bxdid16:
	sbb_reg16_bxidxdisp16 r10 r11
sbb_di_bxdid16:
	sbb_reg16_bxidxdisp16 r11 r11

.macro sbb_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		sbb_r16_r0_bp_\reg
.endm

sbb_ax_bpsid16:
	sbb_reg16_bpidxdisp16 r4 r10
sbb_cx_bpsid16:
	sbb_reg16_bpidxdisp16 r5 r10
sbb_dx_bpsid16:
	sbb_reg16_bpidxdisp16 r6 r10
sbb_bx_bpsid16:
	sbb_reg16_bpidxdisp16 r7 r10
sbb_sp_bpsid16:
	sbb_reg16_bpidxdisp16 r8 r10
sbb_bp_bpsid16:
	sbb_reg16_bpidxdisp16 r9 r10
sbb_si_bpsid16:
	sbb_reg16_bpidxdisp16 r10 r10
sbb_di_bpsid16:
	sbb_reg16_bpidxdisp16 r11 r10

sbb_ax_bpdid16:
	sbb_reg16_bpidxdisp16 r4 r11
sbb_cx_bpdid16:
	sbb_reg16_bpidxdisp16 r5 r11
sbb_dx_bpdid16:
	sbb_reg16_bpidxdisp16 r6 r11
sbb_bx_bpdid16:
	sbb_reg16_bpidxdisp16 r7 r11
sbb_sp_bpdid16:
	sbb_reg16_bpidxdisp16 r8 r11
sbb_bp_bpdid16:
	sbb_reg16_bpidxdisp16 r9 r11
sbb_si_bpdid16:
	sbb_reg16_bpidxdisp16 r10 r11
sbb_di_bpdid16:
	sbb_reg16_bpidxdisp16 r11 r11

.macro sbb_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		sbb_r16_r0_\reg
.endm

sbb_ax_sidisp16:
	sbb_reg16_idxdisp16 r4 r10
sbb_cx_sidisp16:
	sbb_reg16_idxdisp16 r5 r10
sbb_dx_sidisp16:
	sbb_reg16_idxdisp16 r6 r10
sbb_bx_sidisp16:
	sbb_reg16_idxdisp16 r7 r10
sbb_sp_sidisp16:
	sbb_reg16_idxdisp16 r8 r10
sbb_bp_sidisp16:
	sbb_reg16_idxdisp16 r9 r10
sbb_si_sidisp16:
	sbb_reg16_idxdisp16 r10 r10
sbb_di_sidisp16:
	sbb_reg16_idxdisp16 r11 r10

sbb_ax_didisp16:
	sbb_reg16_idxdisp16 r4 r11
sbb_cx_didisp16:
	sbb_reg16_idxdisp16 r5 r11
sbb_dx_didisp16:
	sbb_reg16_idxdisp16 r6 r11
sbb_bx_didisp16:
	sbb_reg16_idxdisp16 r7 r11
sbb_sp_didisp16:
	sbb_reg16_idxdisp16 r8 r11
sbb_bp_didisp16:
	sbb_reg16_idxdisp16 r9 r11
sbb_si_didisp16:
	sbb_reg16_idxdisp16 r10 r11
sbb_di_didisp16:
	sbb_reg16_idxdisp16 r11 r11

sbb_ax_bxdisp16:
	sbb_reg16_idxdisp16 r4 r7
sbb_cx_bxdisp16:
	sbb_reg16_idxdisp16 r5 r7
sbb_dx_bxdisp16:
	sbb_reg16_idxdisp16 r6 r7
sbb_bx_bxdisp16:
	sbb_reg16_idxdisp16 r7 r7
sbb_sp_bxdisp16:
	sbb_reg16_idxdisp16 r8 r7
sbb_bp_bxdisp16:
	sbb_reg16_idxdisp16 r9 r7
sbb_si_bxdisp16:
	sbb_reg16_idxdisp16 r10 r7
sbb_di_bxdisp16:
	sbb_reg16_idxdisp16 r11 r7

.macro sbb_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		sbb_r16_r0_bp_\reg
.endm

sbb_ax_bpdisp16:
	sbb_reg16_bpdisp16 r4
sbb_cx_bpdisp16:
	sbb_reg16_bpdisp16 r5
sbb_dx_bpdisp16:
	sbb_reg16_bpdisp16 r6
sbb_bx_bpdisp16:
	sbb_reg16_bpdisp16 r7
sbb_sp_bpdisp16:
	sbb_reg16_bpdisp16 r8
sbb_bp_bpdisp16:
	sbb_reg16_bpdisp16 r9
sbb_si_bpdisp16:
	sbb_reg16_bpdisp16 r10
sbb_di_bpdisp16:
	sbb_reg16_bpdisp16 r11


// --- registers ---

.macro sbb_reg16_reg16 rl rr
	mov		r0, \rl, lsl #16
	mov		r1, \rr, lsl #16		// r1 = right operand at high halfword
	eor		\rl, r0, lsr #16
	bcs		1f
	subs	r0, r1					// Perform the actual subtraction, setting the resulting flags.
	orr		\rl, r0, lsr #16
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	lsr		r0, #16
	sub		r2, r0, r1, lsr #16		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	orr		\rl, r2, lsr #16
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0, r1, lsr #16
	eor		r2, r0, r2, lsr #16
	and		r1, r2
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm
	
sbb_ax_ax:
	sbb_reg16_reg16		r4 r4
sbb_ax_cx:
	sbb_reg16_reg16		r4 r5
sbb_ax_dx:
	sbb_reg16_reg16		r4 r6
sbb_ax_bx:
	sbb_reg16_reg16		r4 r7
sbb_ax_sp:
	sbb_reg16_reg16		r4 r8
sbb_ax_bp:
	sbb_reg16_reg16		r4 r9
sbb_ax_si:
	sbb_reg16_reg16		r4 r10
sbb_ax_di:
	sbb_reg16_reg16		r4 r11
sbb_cx_ax:
	sbb_reg16_reg16		r5 r4
sbb_cx_cx:
	sbb_reg16_reg16		r5 r5
sbb_cx_dx:
	sbb_reg16_reg16		r5 r6
sbb_cx_bx:
	sbb_reg16_reg16		r5 r7
sbb_cx_sp:
	sbb_reg16_reg16		r5 r8
sbb_cx_bp:
	sbb_reg16_reg16		r5 r9
sbb_cx_si:
	sbb_reg16_reg16		r5 r10
sbb_cx_di:
	sbb_reg16_reg16		r5 r11
sbb_dx_ax:
	sbb_reg16_reg16		r6 r4
sbb_dx_cx:
	sbb_reg16_reg16		r6 r5
sbb_dx_dx:
	sbb_reg16_reg16		r6 r6
sbb_dx_bx:
	sbb_reg16_reg16		r6 r7
sbb_dx_sp:
	sbb_reg16_reg16		r6 r8
sbb_dx_bp:
	sbb_reg16_reg16		r6 r9
sbb_dx_si:
	sbb_reg16_reg16		r6 r10
sbb_dx_di:
	sbb_reg16_reg16		r6 r11
sbb_bx_ax:
	sbb_reg16_reg16		r7 r4
sbb_bx_cx:
	sbb_reg16_reg16		r7 r5
sbb_bx_dx:
	sbb_reg16_reg16		r7 r6
sbb_bx_bx:
	sbb_reg16_reg16		r7 r7
sbb_bx_sp:
	sbb_reg16_reg16		r7 r8
sbb_bx_bp:
	sbb_reg16_reg16		r7 r9
sbb_bx_si:
	sbb_reg16_reg16		r7 r10
sbb_bx_di:
	sbb_reg16_reg16		r7 r11
sbb_sp_ax:
	sbb_reg16_reg16		r8 r4
sbb_sp_cx:
	sbb_reg16_reg16		r8 r5
sbb_sp_dx:
	sbb_reg16_reg16		r8 r6
sbb_sp_bx:
	sbb_reg16_reg16		r8 r7
sbb_sp_sp:
	sbb_reg16_reg16		r8 r8
sbb_sp_bp:
	sbb_reg16_reg16		r8 r9
sbb_sp_si:
	sbb_reg16_reg16		r8 r10
sbb_sp_di:
	sbb_reg16_reg16		r8 r11
sbb_bp_ax:
	sbb_reg16_reg16		r9 r4
sbb_bp_cx:
	sbb_reg16_reg16		r9 r5
sbb_bp_dx:
	sbb_reg16_reg16		r9 r6
sbb_bp_bx:
	sbb_reg16_reg16		r9 r7
sbb_bp_sp:
	sbb_reg16_reg16		r9 r8
sbb_bp_bp:
	sbb_reg16_reg16		r9 r9
sbb_bp_si:
	sbb_reg16_reg16		r9 r10
sbb_bp_di:
	sbb_reg16_reg16		r9 r11
sbb_si_ax:
	sbb_reg16_reg16		r10 r4
sbb_si_cx:
	sbb_reg16_reg16		r10 r5
sbb_si_dx:
	sbb_reg16_reg16		r10 r6
sbb_si_bx:
	sbb_reg16_reg16		r10 r7
sbb_si_sp:
	sbb_reg16_reg16		r10 r8
sbb_si_bp:
	sbb_reg16_reg16		r10 r9
sbb_si_si:
	sbb_reg16_reg16		r10 r10
sbb_si_di:
	sbb_reg16_reg16		r10 r11
sbb_di_ax:
	sbb_reg16_reg16		r11 r4
sbb_di_cx:
	sbb_reg16_reg16		r11 r5
sbb_di_dx:
	sbb_reg16_reg16		r11 r6
sbb_di_bx:
	sbb_reg16_reg16		r11 r7
sbb_di_sp:
	sbb_reg16_reg16		r11 r8
sbb_di_bp:
	sbb_reg16_reg16		r11 r9
sbb_di_si:
	sbb_reg16_reg16		r11 r10
sbb_di_di:
	sbb_reg16_reg16		r11 r11

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	


// ------------------- 1C = SBB AL,imm8 --------------------------------
//
op_1c:
	ldrb	r1,[r12],#1				// Load low byte to r1, increment r12 by 1
	bcs		1f						// If input Carry is set, we need to perform a more complex operation to get correct flags.
	mov		r0, eax, lsl #24		// r0 high byte = the left operand
	subs	r0, r1, lsl #24			// Perform the actual subtraction, setting the resulting flags.
	bic		eax, #0xFF				// Clear the current AL value
	orr		eax, r0, lsr #24		// Put the result to the lower byte of the left register
	b		complement_carry
	//-------
	// SBB with input carry set, we need to calculate the proper flags manually.
	//-------
1:	and		r0, eax, #0xFF
	sub		r2, r0, r1				// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		eax, #0xFF				// Clear the current AL value
	orr		eax, r2, lsr #24		// Put the result to the lower byte of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0
	eor		r2, r0, r2, lsr #24
	and		r1, r2
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
	

// ------------------- 1D = SBB AX,imm16 -------------------------------
//
	.global op_1d
op_1d:
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load high byte to r0, increment r12 by 1
	bcs		1f
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	mov		r1, eax, lsl #16
	eor		eax, r1, lsr #16
	subs	r1, r0, lsl #16			// Perform the actual subtraction, setting the resulting flags.
	orr		eax, r1, lsr #16
	b		complement_carry
	//-------
	// SBB with input carry set, we need to calculate the proper flags manually.
	//-------
1:	orr		r1, r0, r1, lsl #8		// r1 = low byte | (high byte << 8)
	mov		r0, eax, lsl #16
	eor		eax, r0, lsr #16		// Clear the current AX value
	rsb		r2, r1, r0, lsr #16		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	orr		eax, r2, lsr #16		// Put the result to the lower 16 bits of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0, lsr #16			// r1 in low 16bit, r0 in high 16bit, result to low 16bit
	eor		r0, r2					// Both in high 16bit, result to high 16bit
	and		r1, r0, lsr #16			// r1 in low 16bit, r0 in high 16bit, result to low 16bit
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
	
// ------------------- 1E = PUSH DS ------------------------------------
op_1e:
	ldr		r1, [sp, #SP_DS_VALUE]	
	push_hword r1 r0 r2
	b		loop

// ------------------- 1F = POP DS -------------------------------------
// Profiler: 14467, 18, 26.62, 385083, 0.2%
//
op_1f:
	pop_reg_low_tmp	r2 r1			// NOTE! When using paging, we can not pop the value before checking for exception!
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr				// Save current flags to r0
	tst		r3, #1					// Are we in protected mode (or in VM mode)?
	bne		mov_ds_r0r2_prot		// Yes we are, go handle protected mode version!
	//-------
	// We are in real mode, so use the simple handling.
	//-------
	lsl		r1, r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_DS_VALUE]
	str		r1, [sp, #SP_DS_BASE]	
	b		restore_flags_from_r0				// Go back to the opcode loop, restoring flags

.ltorg								// Dump the current literal pool here


	.text
	.align	2
	

// ------------------- 20 = AND r/m8,r8 --------------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual ands operation, so C and O work like in x86.
//
// All modrm variations supported!
//
//
	.global	op_20
op_20:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word and_bxsi_al, and_bxdi_al, and_bpsi_al, and_bpdi_al, and_siidx_al, and_diidx_al, and_disp16_al, and_bxidx_al
	.word and_bxsi_cl, and_bxdi_cl, and_bpsi_cl, and_bpdi_cl, and_siidx_cl, and_diidx_cl, and_disp16_cl, and_bxidx_cl
	.word and_bxsi_dl, and_bxdi_dl, and_bpsi_dl, and_bpdi_dl, and_siidx_dl, and_diidx_dl, and_disp16_dl, and_bxidx_dl
	.word and_bxsi_bl, and_bxdi_bl, and_bpsi_bl, and_bpdi_bl, and_siidx_bl, and_diidx_bl, and_disp16_bl, and_bxidx_bl
	.word and_bxsi_ah, and_bxdi_ah, and_bpsi_ah, and_bpdi_ah, and_siidx_ah, and_diidx_ah, and_disp16_ah, and_bxidx_ah
	.word and_bxsi_ch, and_bxdi_ch, and_bpsi_ch, and_bpdi_ch, and_siidx_ch, and_diidx_ch, and_disp16_ch, and_bxidx_ch
	.word and_bxsi_dh, and_bxdi_dh, and_bpsi_dh, and_bpdi_dh, and_siidx_dh, and_diidx_dh, and_disp16_dh, and_bxidx_dh
	.word and_bxsi_bh, and_bxdi_bh, and_bpsi_bh, and_bpdi_bh, and_siidx_bh, and_diidx_bh, and_disp16_bh, and_bxidx_bh
//0x40
	.word and_bxsid8_al, and_bxdid8_al, and_bpsid8_al, and_bpdid8_al, and_sidisp8_al, and_didisp8_al, and_bpdisp8_al, and_bxdisp8_al
	.word and_bxsid8_cl, and_bxdid8_cl, and_bpsid8_cl, and_bpdid8_cl, and_sidisp8_cl, and_didisp8_cl, and_bpdisp8_cl, and_bxdisp8_cl
	.word and_bxsid8_dl, and_bxdid8_dl, and_bpsid8_dl, and_bpdid8_dl, and_sidisp8_dl, and_didisp8_dl, and_bpdisp8_dl, and_bxdisp8_dl
	.word and_bxsid8_bl, and_bxdid8_bl, and_bpsid8_bl, and_bpdid8_bl, and_sidisp8_bl, and_didisp8_bl, and_bpdisp8_bl, and_bxdisp8_bl
	.word and_bxsid8_ah, and_bxdid8_ah, and_bpsid8_ah, and_bpdid8_ah, and_sidisp8_ah, and_didisp8_ah, and_bpdisp8_ah, and_bxdisp8_ah
	.word and_bxsid8_ch, and_bxdid8_ch, and_bpsid8_ch, and_bpdid8_ch, and_sidisp8_ch, and_didisp8_ch, and_bpdisp8_ch, and_bxdisp8_ch
	.word and_bxsid8_dh, and_bxdid8_dh, and_bpsid8_dh, and_bpdid8_dh, and_sidisp8_dh, and_didisp8_dh, and_bpdisp8_dh, and_bxdisp8_dh
	.word and_bxsid8_bh, and_bxdid8_bh, and_bpsid8_bh, and_bpdid8_bh, and_sidisp8_bh, and_didisp8_bh, and_bpdisp8_bh, and_bxdisp8_bh
//0x80
	.word and_bxsid16_al, and_bxdid16_al, and_bpsid16_al, and_bpdid16_al, and_sidisp16_al, and_didisp16_al, and_bpdisp16_al, and_bxdisp16_al
	.word and_bxsid16_cl, and_bxdid16_cl, and_bpsid16_cl, and_bpdid16_cl, and_sidisp16_cl, and_didisp16_cl, and_bpdisp16_cl, and_bxdisp16_cl
	.word and_bxsid16_dl, and_bxdid16_dl, and_bpsid16_dl, and_bpdid16_dl, and_sidisp16_dl, and_didisp16_dl, and_bpdisp16_dl, and_bxdisp16_dl
	.word and_bxsid16_bl, and_bxdid16_bl, and_bpsid16_bl, and_bpdid16_bl, and_sidisp16_bl, and_didisp16_bl, and_bpdisp16_bl, and_bxdisp16_bl
	.word and_bxsid16_ah, and_bxdid16_ah, and_bpsid16_ah, and_bpdid16_ah, and_sidisp16_ah, and_didisp16_ah, and_bpdisp16_ah, and_bxdisp16_ah
	.word and_bxsid16_ch, and_bxdid16_ch, and_bpsid16_ch, and_bpdid16_ch, and_sidisp16_ch, and_didisp16_ch, and_bpdisp16_ch, and_bxdisp16_ch
	.word and_bxsid16_dh, and_bxdid16_dh, and_bpsid16_dh, and_bpdid16_dh, and_sidisp16_dh, and_didisp16_dh, and_bpdisp16_dh, and_bxdisp16_dh
	.word and_bxsid16_bh, and_bxdid16_bh, and_bpsid16_bh, and_bpdid16_bh, and_sidisp16_bh, and_didisp16_bh, and_bpdisp16_bh, and_bxdisp16_bh
// 0xC0 = two register operands
	.word and_al_al, and_cl_al, and_dl_al, and_bl_al, and_ah_al, and_ch_al, and_dh_al, and_bh_al
	.word and_al_cl, and_cl_cl, and_dl_cl, and_bl_cl, and_ah_cl, and_ch_cl, and_dh_cl, and_bh_cl
	.word and_al_dl, and_cl_dl, and_dl_dl, and_bl_dl, and_ah_dl, and_ch_dl, and_dh_dl, and_bh_dl
	.word and_al_bl, and_cl_bl, and_dl_bl, and_bl_bl, and_ah_bl, and_ch_bl, and_dh_bl, and_bh_bl
	.word and_al_ah, and_cl_ah, and_dl_ah, and_bl_ah, and_ah_ah, and_ch_ah, and_dh_ah, and_bh_ah
	.word and_al_ch, and_cl_ch, and_dl_ch, and_bl_ch, and_ah_ch, and_ch_ch, and_dh_ch, and_bh_ch
	.word and_al_dh, and_cl_dh, and_dl_dh, and_bl_dh, and_ah_dh, and_ch_dh, and_dh_dh, and_bh_dh
	.word and_al_bh, and_cl_bh, and_dl_bh, and_bl_bh, and_ah_bh, and_ch_bh, and_dh_bh, and_bh_bh

// These are called from "cpu_386.s":

	.global	and_siidx_al, and_siidx_cl, and_siidx_dl, and_siidx_bl, and_siidx_ah, and_siidx_ch, and_siidx_dh, and_siidx_bh
	.global	and_diidx_al, and_diidx_cl, and_diidx_dl, and_diidx_bl, and_diidx_ah, and_diidx_ch, and_diidx_dh, and_diidx_bh
	.global	and_bxidx_al, and_bxidx_cl, and_bxidx_dl, and_bxidx_bl, and_bxidx_ah, and_bxidx_ch, and_bxidx_dh, and_bxidx_bh
	.global	and_sidisp8_al, and_sidisp8_cl, and_sidisp8_dl, and_sidisp8_bl, and_sidisp8_ah, and_sidisp8_ch, and_sidisp8_dh, and_sidisp8_bh
	.global	and_didisp8_al, and_didisp8_cl, and_didisp8_dl, and_didisp8_bl, and_didisp8_ah, and_didisp8_ch, and_didisp8_dh, and_didisp8_bh
	.global	and_bpdisp8_al, and_bpdisp8_cl, and_bpdisp8_dl, and_bpdisp8_bl, and_bpdisp8_ah, and_bpdisp8_ch, and_bpdisp8_dh, and_bpdisp8_bh
	.global	and_bxdisp8_al, and_bxdisp8_cl, and_bxdisp8_dl, and_bxdisp8_bl, and_bxdisp8_ah, and_bxdisp8_ch, and_bxdisp8_dh, and_bxdisp8_bh

.macro and_r0_reg8l reg
	.global	and_r0_r8l_bp_\reg
and_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	and_r0_r8l_\reg
and_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_20_RAM_l_\reg op_20_EGA_l_\reg op_20_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_20_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	ands	r0, r1, r0, lsl #24		// Perform the operation using the highest bytes to get the correct flags
	lsr		r0, #24
	strb	r0,[r2]					// Store the byte back
	b		loop
.endm
.macro and_r0_reg8h reg
	.global	and_r0_r8h_bp_\reg
and_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	and_r0_r8h_\reg
and_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_20_RAM_h_\reg op_20_EGA_h_\reg op_20_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_20_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #16		// No need to clear the reg8l value, as the AND will do that for us.
	ands	r0, r1, r0, lsl #24		// Perform the operation using the highest bytes to get the correct flags
	lsr		r0, #24
	strb	r0,[r2]					// Store the byte back
	b		loop
.endm

	and_r0_reg8l r4
	and_r0_reg8l r5
	and_r0_reg8l r6
	and_r0_reg8l r7
	and_r0_reg8h r4
	and_r0_reg8h r5
	and_r0_reg8h r6
	and_r0_reg8h r7

	.ltorg

// --- [idx] ---

.macro and_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		and_r0_r8l_\reg
.endm
.macro and_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		and_r0_r8h_\reg
.endm

and_bxsi_al:
	and_bxidx_reg8l r10 r4
and_bxsi_cl:
	and_bxidx_reg8l r10 r5
and_bxsi_dl:
	and_bxidx_reg8l r10 r6
and_bxsi_bl:
	and_bxidx_reg8l r10 r7
and_bxsi_ah:
	and_bxidx_reg8h r10 r4
and_bxsi_ch:
	and_bxidx_reg8h r10 r5
and_bxsi_dh:
	and_bxidx_reg8h r10 r6
and_bxsi_bh:
	and_bxidx_reg8h r10 r7

and_bxdi_al:
	and_bxidx_reg8l r11 r4
and_bxdi_cl:
	and_bxidx_reg8l r11 r5
and_bxdi_dl:
	and_bxidx_reg8l r11 r6
and_bxdi_bl:
	and_bxidx_reg8l r11 r7
and_bxdi_ah:
	and_bxidx_reg8h r11 r4
and_bxdi_ch:
	and_bxidx_reg8h r11 r5
and_bxdi_dh:
	and_bxidx_reg8h r11 r6
and_bxdi_bh:
	and_bxidx_reg8h r11 r7

.macro and_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		and_r0_r8l_bp_\reg
.endm
.macro and_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		and_r0_r8h_bp_\reg
.endm

and_bpsi_al:
	and_bpidx_reg8l r10 r4
and_bpsi_cl:
	and_bpidx_reg8l r10 r5
and_bpsi_dl:
	and_bpidx_reg8l r10 r6
and_bpsi_bl:
	and_bpidx_reg8l r10 r7
and_bpsi_ah:
	and_bpidx_reg8h r10 r4
and_bpsi_ch:
	and_bpidx_reg8h r10 r5
and_bpsi_dh:
	and_bpidx_reg8h r10 r6
and_bpsi_bh:
	and_bpidx_reg8h r10 r7

and_bpdi_al:
	and_bpidx_reg8l r11 r4
and_bpdi_cl:
	and_bpidx_reg8l r11 r5
and_bpdi_dl:
	and_bpidx_reg8l r11 r6
and_bpdi_bl:
	and_bpidx_reg8l r11 r7
and_bpdi_ah:
	and_bpidx_reg8h r11 r4
and_bpdi_ch:
	and_bpidx_reg8h r11 r5
and_bpdi_dh:
	and_bpidx_reg8h r11 r6
and_bpdi_bh:
	and_bpidx_reg8h r11 r7

.macro and_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		and_r0_r8l_\reg
.endm
.macro and_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		and_r0_r8h_\reg
.endm

and_siidx_al:
	and_idx_reg8l r10 r4
and_siidx_cl:
	and_idx_reg8l r10 r5
and_siidx_dl:
	and_idx_reg8l r10 r6
and_siidx_bl:
	and_idx_reg8l r10 r7
and_siidx_ah:
	and_idx_reg8h r10 r4
and_siidx_ch:
	and_idx_reg8h r10 r5
and_siidx_dh:
	and_idx_reg8h r10 r6
and_siidx_bh:
	and_idx_reg8h r10 r7

and_diidx_al:
	and_idx_reg8l r11 r4
and_diidx_cl:
	and_idx_reg8l r11 r5
and_diidx_dl:
	and_idx_reg8l r11 r6
and_diidx_bl:
	and_idx_reg8l r11 r7
and_diidx_ah:
	and_idx_reg8h r11 r4
and_diidx_ch:
	and_idx_reg8h r11 r5
and_diidx_dh:
	and_idx_reg8h r11 r6
and_diidx_bh:
	and_idx_reg8h r11 r7

and_bxidx_al:
	and_idx_reg8l r7 r4
and_bxidx_cl:
	and_idx_reg8l r7 r5
and_bxidx_dl:
	and_idx_reg8l r7 r6
and_bxidx_bl:
	and_idx_reg8l r7 r7
and_bxidx_ah:
	and_idx_reg8h r7 r4
and_bxidx_ch:
	and_idx_reg8h r7 r5
and_bxidx_dh:
	and_idx_reg8h r7 r6
and_bxidx_bh:
	and_idx_reg8h r7 r7
	
.macro and_disp16_reg8l reg
	r0_from_disp16
	b		and_r0_r8l_\reg
.endm

.macro and_disp16_reg8h reg
	r0_from_disp16
	b		and_r0_r8h_\reg
.endm

and_disp16_al:
	and_disp16_reg8l r4
and_disp16_cl:
	and_disp16_reg8l r5
and_disp16_dl:
	and_disp16_reg8l r6
and_disp16_bl:
	and_disp16_reg8l r7
and_disp16_ah:
	and_disp16_reg8h r4
and_disp16_ch:
	and_disp16_reg8h r5
and_disp16_dh:
	and_disp16_reg8h r6
and_disp16_bh:
	and_disp16_reg8h r7

// --- [idx+disp8] ---

.macro and_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		and_r0_r8l_\reg
.endm
.macro and_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		and_r0_r8h_\reg
.endm

and_bxsid8_al:
	and_bxidxd8_reg8l r10 r4
and_bxsid8_cl:
	and_bxidxd8_reg8l r10 r5
and_bxsid8_dl:
	and_bxidxd8_reg8l r10 r6
and_bxsid8_bl:
	and_bxidxd8_reg8l r10 r7
and_bxsid8_ah:
	and_bxidxd8_reg8h r10 r4
and_bxsid8_ch:
	and_bxidxd8_reg8h r10 r5
and_bxsid8_dh:
	and_bxidxd8_reg8h r10 r6
and_bxsid8_bh:
	and_bxidxd8_reg8h r10 r7

and_bxdid8_al:
	and_bxidxd8_reg8l r11 r4
and_bxdid8_cl:
	and_bxidxd8_reg8l r11 r5
and_bxdid8_dl:
	and_bxidxd8_reg8l r11 r6
and_bxdid8_bl:
	and_bxidxd8_reg8l r11 r7
and_bxdid8_ah:
	and_bxidxd8_reg8h r11 r4
and_bxdid8_ch:
	and_bxidxd8_reg8h r11 r5
and_bxdid8_dh:
	and_bxidxd8_reg8h r11 r6
and_bxdid8_bh:
	and_bxidxd8_reg8h r11 r7

.macro and_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		and_r0_r8l_bp_\reg
.endm
.macro and_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		and_r0_r8h_bp_\reg
.endm

and_bpsid8_al:
	and_bpidxd8_reg8l r10 r4
and_bpsid8_cl:
	and_bpidxd8_reg8l r10 r5
and_bpsid8_dl:
	and_bpidxd8_reg8l r10 r6
and_bpsid8_bl:
	and_bpidxd8_reg8l r10 r7
and_bpsid8_ah:
	and_bpidxd8_reg8h r10 r4
and_bpsid8_ch:
	and_bpidxd8_reg8h r10 r5
and_bpsid8_dh:
	and_bpidxd8_reg8h r10 r6
and_bpsid8_bh:
	and_bpidxd8_reg8h r10 r7

and_bpdid8_al:
	and_bpidxd8_reg8l r11 r4
and_bpdid8_cl:
	and_bpidxd8_reg8l r11 r5
and_bpdid8_dl:
	and_bpidxd8_reg8l r11 r6
and_bpdid8_bl:
	and_bpidxd8_reg8l r11 r7
and_bpdid8_ah:
	and_bpidxd8_reg8h r11 r4
and_bpdid8_ch:
	and_bpidxd8_reg8h r11 r5
and_bpdid8_dh:
	and_bpidxd8_reg8h r11 r6
and_bpdid8_bh:
	and_bpidxd8_reg8h r11 r7

.macro and_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		and_r0_r8l_\reg
.endm
.macro and_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		and_r0_r8h_\reg
.endm

and_sidisp8_al:
	and_idxdisp8_reg8l r10 r4
and_sidisp8_cl:
	and_idxdisp8_reg8l r10 r5
and_sidisp8_dl:
	and_idxdisp8_reg8l r10 r6
and_sidisp8_bl:
	and_idxdisp8_reg8l r10 r7
and_sidisp8_ah:
	and_idxdisp8_reg8h r10 r4
and_sidisp8_ch:
	and_idxdisp8_reg8h r10 r5
and_sidisp8_dh:
	and_idxdisp8_reg8h r10 r6
and_sidisp8_bh:
	and_idxdisp8_reg8h r10 r7

and_didisp8_al:
	and_idxdisp8_reg8l r11 r4
and_didisp8_cl:
	and_idxdisp8_reg8l r11 r5
and_didisp8_dl:
	and_idxdisp8_reg8l r11 r6
and_didisp8_bl:
	and_idxdisp8_reg8l r11 r7
and_didisp8_ah:
	and_idxdisp8_reg8h r11 r4
and_didisp8_ch:
	and_idxdisp8_reg8h r11 r5
and_didisp8_dh:
	and_idxdisp8_reg8h r11 r6
and_didisp8_bh:
	and_idxdisp8_reg8h r11 r7

and_bxdisp8_al:
	and_idxdisp8_reg8l r7 r4
and_bxdisp8_cl:
	and_idxdisp8_reg8l r7 r5
and_bxdisp8_dl:
	and_idxdisp8_reg8l r7 r6
and_bxdisp8_bl:
	and_idxdisp8_reg8l r7 r7
and_bxdisp8_ah:
	and_idxdisp8_reg8h r7 r4
and_bxdisp8_ch:
	and_idxdisp8_reg8h r7 r5
and_bxdisp8_dh:
	and_idxdisp8_reg8h r7 r6
and_bxdisp8_bh:
	and_idxdisp8_reg8h r7 r7

.macro and_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		and_r0_r8l_bp_\reg
.endm
.macro and_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		and_r0_r8h_bp_\reg
.endm

and_bpdisp8_al:
	and_bpdisp8_reg8l r4
and_bpdisp8_cl:
	and_bpdisp8_reg8l r5
and_bpdisp8_dl:
	and_bpdisp8_reg8l r6
and_bpdisp8_bl:
	and_bpdisp8_reg8l r7
and_bpdisp8_ah:
	and_bpdisp8_reg8h r4
and_bpdisp8_ch:
	and_bpdisp8_reg8h r5
and_bpdisp8_dh:
	and_bpdisp8_reg8h r6
and_bpdisp8_bh:
	and_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro and_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		and_r0_r8l_\reg
.endm
.macro and_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		and_r0_r8h_\reg
.endm

and_bxsid16_al:
	and_bxidxdisp16_reg8l r10 r4
and_bxsid16_cl:
	and_bxidxdisp16_reg8l r10 r5
and_bxsid16_dl:
	and_bxidxdisp16_reg8l r10 r6
and_bxsid16_bl:
	and_bxidxdisp16_reg8l r10 r7
and_bxsid16_ah:
	and_bxidxdisp16_reg8h r10 r4
and_bxsid16_ch:
	and_bxidxdisp16_reg8h r10 r5
and_bxsid16_dh:
	and_bxidxdisp16_reg8h r10 r6
and_bxsid16_bh:
	and_bxidxdisp16_reg8h r10 r7

and_bxdid16_al:
	and_bxidxdisp16_reg8l r11 r4
and_bxdid16_cl:
	and_bxidxdisp16_reg8l r11 r5
and_bxdid16_dl:
	and_bxidxdisp16_reg8l r11 r6
and_bxdid16_bl:
	and_bxidxdisp16_reg8l r11 r7
and_bxdid16_ah:
	and_bxidxdisp16_reg8h r11 r4
and_bxdid16_ch:
	and_bxidxdisp16_reg8h r11 r5
and_bxdid16_dh:
	and_bxidxdisp16_reg8h r11 r6
and_bxdid16_bh:
	and_bxidxdisp16_reg8h r11 r7

.macro and_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		and_r0_r8l_bp_\reg
.endm
.macro and_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		and_r0_r8h_bp_\reg
.endm

and_bpsid16_al:
	and_bpidxd16_reg8l r10 r4
and_bpsid16_cl:
	and_bpidxd16_reg8l r10 r5
and_bpsid16_dl:
	and_bpidxd16_reg8l r10 r6
and_bpsid16_bl:
	and_bpidxd16_reg8l r10 r7
and_bpsid16_ah:
	and_bpidxd16_reg8h r10 r4
and_bpsid16_ch:
	and_bpidxd16_reg8h r10 r5
and_bpsid16_dh:
	and_bpidxd16_reg8h r10 r6
and_bpsid16_bh:
	and_bpidxd16_reg8h r10 r7

and_bpdid16_al:
	and_bpidxd16_reg8l r11 r4
and_bpdid16_cl:
	and_bpidxd16_reg8l r11 r5
and_bpdid16_dl:
	and_bpidxd16_reg8l r11 r6
and_bpdid16_bl:
	and_bpidxd16_reg8l r11 r7
and_bpdid16_ah:
	and_bpidxd16_reg8h r11 r4
and_bpdid16_ch:
	and_bpidxd16_reg8h r11 r5
and_bpdid16_dh:
	and_bpidxd16_reg8h r11 r6
and_bpdid16_bh:
	and_bpidxd16_reg8h r11 r7

.macro and_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		and_r0_r8l_\reg
.endm
.macro and_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		and_r0_r8h_\reg
.endm

and_sidisp16_al:
	and_idxdisp16_reg8l r10 r4
and_sidisp16_cl:
	and_idxdisp16_reg8l r10 r5
and_sidisp16_dl:
	and_idxdisp16_reg8l r10 r6
and_sidisp16_bl:
	and_idxdisp16_reg8l r10 r7
and_sidisp16_ah:
	and_idxdisp16_reg8h r10 r4
and_sidisp16_ch:
	and_idxdisp16_reg8h r10 r5
and_sidisp16_dh:
	and_idxdisp16_reg8h r10 r6
and_sidisp16_bh:
	and_idxdisp16_reg8h r10 r7

and_didisp16_al:
	and_idxdisp16_reg8l r11 r4
and_didisp16_cl:
	and_idxdisp16_reg8l r11 r5
and_didisp16_dl:
	and_idxdisp16_reg8l r11 r6
and_didisp16_bl:
	and_idxdisp16_reg8l r11 r7
and_didisp16_ah:
	and_idxdisp16_reg8h r11 r4
and_didisp16_ch:
	and_idxdisp16_reg8h r11 r5
and_didisp16_dh:
	and_idxdisp16_reg8h r11 r6
and_didisp16_bh:
	and_idxdisp16_reg8h r11 r7

and_bxdisp16_al:
	and_idxdisp16_reg8l r7 r4
and_bxdisp16_cl:
	and_idxdisp16_reg8l r7 r5
and_bxdisp16_dl:
	and_idxdisp16_reg8l r7 r6
and_bxdisp16_bl:
	and_idxdisp16_reg8l r7 r7
and_bxdisp16_ah:
	and_idxdisp16_reg8h r7 r4
and_bxdisp16_ch:
	and_idxdisp16_reg8h r7 r5
and_bxdisp16_dh:
	and_idxdisp16_reg8h r7 r6
and_bxdisp16_bh:
	and_idxdisp16_reg8h r7 r7

.macro and_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		and_r0_r8l_bp_\reg
.endm
.macro and_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		and_r0_r8h_bp_\reg
.endm

and_bpdisp16_al:
	and_bpdisp16_reg8l r4
and_bpdisp16_cl:
	and_bpdisp16_reg8l r5
and_bpdisp16_dl:
	and_bpdisp16_reg8l r6
and_bpdisp16_bl:
	and_bpdisp16_reg8l r7
and_bpdisp16_ah:
	and_bpdisp16_reg8h r4
and_bpdisp16_ch:
	and_bpdisp16_reg8h r5
and_bpdisp16_dh:
	and_bpdisp16_reg8h r6
and_bpdisp16_bh:
	and_bpdisp16_reg8h r7


// ------------------- 21 = AND r/m16,r16 ------------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual ands operation, so C and O work like in x86.
//
// All modrm variations supported!
//
//
	.global op_21
op_21:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word and_bxsi_ax, and_bxdi_ax, and_bpsi_ax, and_bpdi_ax, and_siidx_ax, and_diidx_ax, and_disp16_ax, and_bxidx_ax
	.word and_bxsi_cx, and_bxdi_cx, and_bpsi_cx, and_bpdi_cx, and_siidx_cx, and_diidx_cx, and_disp16_cx, and_bxidx_cx
	.word and_bxsi_dx, and_bxdi_dx, and_bpsi_dx, and_bpdi_dx, and_siidx_dx, and_diidx_dx, and_disp16_dx, and_bxidx_dx
	.word and_bxsi_bx, and_bxdi_bx, and_bpsi_bx, and_bpdi_bx, and_siidx_bx, and_diidx_bx, and_disp16_bx, and_bxidx_bx
	.word and_bxsi_sp, and_bxdi_sp, and_bpsi_sp, and_bpdi_sp, and_siidx_sp, and_diidx_sp, and_disp16_sp, and_bxidx_sp
	.word and_bxsi_bp, and_bxdi_bp, and_bpsi_bp, and_bpdi_bp, and_siidx_bp, and_diidx_bp, and_disp16_bp, and_bxidx_bp
	.word and_bxsi_si, and_bxdi_si, and_bpsi_si, and_bpdi_si, and_siidx_si, and_diidx_si, and_disp16_si, and_bxidx_si
	.word and_bxsi_di, and_bxdi_di, and_bpsi_di, and_bpdi_di, and_siidx_di, and_diidx_di, and_disp16_di, and_bxidx_di
//0x40
	.word and_bxsid8_ax, and_bxdid8_ax, and_bpsid8_ax, and_bpdid8_ax, and_sidisp8_ax, and_didisp8_ax, and_bpdisp8_ax, and_bxdisp8_ax
	.word and_bxsid8_cx, and_bxdid8_cx, and_bpsid8_cx, and_bpdid8_cx, and_sidisp8_cx, and_didisp8_cx, and_bpdisp8_cx, and_bxdisp8_cx
	.word and_bxsid8_dx, and_bxdid8_dx, and_bpsid8_dx, and_bpdid8_dx, and_sidisp8_dx, and_didisp8_dx, and_bpdisp8_dx, and_bxdisp8_dx
	.word and_bxsid8_bx, and_bxdid8_bx, and_bpsid8_bx, and_bpdid8_bx, and_sidisp8_bx, and_didisp8_bx, and_bpdisp8_bx, and_bxdisp8_bx
	.word and_bxsid8_sp, and_bxdid8_sp, and_bpsid8_sp, and_bpdid8_sp, and_sidisp8_sp, and_didisp8_sp, and_bpdisp8_sp, and_bxdisp8_sp
	.word and_bxsid8_bp, and_bxdid8_bp, and_bpsid8_bp, and_bpdid8_bp, and_sidisp8_bp, and_didisp8_bp, and_bpdisp8_bp, and_bxdisp8_bp
	.word and_bxsid8_si, and_bxdid8_si, and_bpsid8_si, and_bpdid8_si, and_sidisp8_si, and_didisp8_si, and_bpdisp8_si, and_bxdisp8_si
	.word and_bxsid8_di, and_bxdid8_di, and_bpsid8_di, and_bpdid8_di, and_sidisp8_di, and_didisp8_di, and_bpdisp8_di, and_bxdisp8_di
//0x80
	.word and_bxsid16_ax, and_bxdid16_ax, and_bpsid16_ax, and_bpdid16_ax, and_sidisp16_ax, and_didisp16_ax, and_bpdisp16_ax, and_bxdisp16_ax
	.word and_bxsid16_cx, and_bxdid16_cx, and_bpsid16_cx, and_bpdid16_cx, and_sidisp16_cx, and_didisp16_cx, and_bpdisp16_cx, and_bxdisp16_cx
	.word and_bxsid16_dx, and_bxdid16_dx, and_bpsid16_dx, and_bpdid16_dx, and_sidisp16_dx, and_didisp16_dx, and_bpdisp16_dx, and_bxdisp16_dx
	.word and_bxsid16_bx, and_bxdid16_bx, and_bpsid16_bx, and_bpdid16_bx, and_sidisp16_bx, and_didisp16_bx, and_bpdisp16_bx, and_bxdisp16_bx
	.word and_bxsid16_sp, and_bxdid16_sp, and_bpsid16_sp, and_bpdid16_sp, and_sidisp16_sp, and_didisp16_sp, and_bpdisp16_sp, and_bxdisp16_sp
	.word and_bxsid16_bp, and_bxdid16_bp, and_bpsid16_bp, and_bpdid16_bp, and_sidisp16_bp, and_didisp16_bp, and_bpdisp16_bp, and_bxdisp16_bp
	.word and_bxsid16_si, and_bxdid16_si, and_bpsid16_si, and_bpdid16_si, and_sidisp16_si, and_didisp16_si, and_bpdisp16_si, and_bxdisp16_si
	.word and_bxsid16_di, and_bxdid16_di, and_bpsid16_di, and_bpdid16_di, and_sidisp16_di, and_didisp16_di, and_bpdisp16_di, and_bxdisp16_di
// 0xC0 = two register operands
	.word and_ax_ax, and_cx_ax, and_dx_ax, and_bx_ax, and_sp_ax, and_bp_ax, and_si_ax, and_di_ax
	.word and_ax_cx, and_cx_cx, and_dx_cx, and_bx_cx, and_sp_cx, and_bp_cx, and_si_cx, and_di_cx
	.word and_ax_dx, and_cx_dx, and_dx_dx, and_bx_dx, and_sp_dx, and_bp_dx, and_si_dx, and_di_dx
	.word and_ax_bx, and_cx_bx, and_dx_bx, and_bx_bx, and_sp_bx, and_bp_bx, and_si_bx, and_di_bx
	.word and_ax_sp, and_cx_sp, and_dx_sp, and_bx_sp, and_sp_sp, and_bp_sp, and_si_sp, and_di_sp
	.word and_ax_bp, and_cx_bp, and_dx_bp, and_bx_bp, and_sp_bp, and_bp_bp, and_si_bp, and_di_bp
	.word and_ax_si, and_cx_si, and_dx_si, and_bx_si, and_sp_si, and_bp_si, and_si_si, and_di_si
	.word and_ax_di, and_cx_di, and_dx_di, and_bx_di, and_sp_di, and_bp_di, and_si_di, and_di_di

// These are called from "cpu_67.s":

	.global and_siidx_ax, and_diidx_ax, and_bxidx_ax
	.global and_siidx_cx, and_diidx_cx, and_bxidx_cx
	.global and_siidx_dx, and_diidx_dx, and_bxidx_dx
	.global and_siidx_bx, and_diidx_bx, and_bxidx_bx
	.global and_siidx_sp, and_diidx_sp, and_bxidx_sp
	.global and_siidx_bp, and_diidx_bp, and_bxidx_bp
	.global and_siidx_si, and_diidx_si, and_bxidx_si
	.global and_siidx_di, and_diidx_di, and_bxidx_di
	.global and_sidisp8_ax, and_didisp8_ax, and_bpdisp8_ax, and_bxdisp8_ax
	.global and_sidisp8_cx, and_didisp8_cx, and_bpdisp8_cx, and_bxdisp8_cx
	.global and_sidisp8_dx, and_didisp8_dx, and_bpdisp8_dx, and_bxdisp8_dx
	.global and_sidisp8_bx, and_didisp8_bx, and_bpdisp8_bx, and_bxdisp8_bx
	.global and_sidisp8_sp, and_didisp8_sp, and_bpdisp8_sp, and_bxdisp8_sp
	.global and_sidisp8_bp, and_didisp8_bp, and_bpdisp8_bp, and_bxdisp8_bp
	.global and_sidisp8_si, and_didisp8_si, and_bpdisp8_si, and_bxdisp8_si
	.global and_sidisp8_di, and_didisp8_di, and_bpdisp8_di, and_bxdisp8_di
	.global and_ax_ax, and_cx_ax, and_dx_ax, and_bx_ax, and_sp_ax, and_bp_ax, and_si_ax, and_di_ax
	.global and_ax_cx, and_cx_cx, and_dx_cx, and_bx_cx, and_sp_cx, and_bp_cx, and_si_cx, and_di_cx
	.global and_ax_dx, and_cx_dx, and_dx_dx, and_bx_dx, and_sp_dx, and_bp_dx, and_si_dx, and_di_dx
	.global and_ax_bx, and_cx_bx, and_dx_bx, and_bx_bx, and_sp_bx, and_bp_bx, and_si_bx, and_di_bx
	.global and_ax_sp, and_cx_sp, and_dx_sp, and_bx_sp, and_sp_sp, and_bp_sp, and_si_sp, and_di_sp
	.global and_ax_bp, and_cx_bp, and_dx_bp, and_bx_bp, and_sp_bp, and_bp_bp, and_si_bp, and_di_bp
	.global and_ax_si, and_cx_si, and_dx_si, and_bx_si, and_sp_si, and_bp_si, and_si_si, and_di_si
	.global and_ax_di, and_cx_di, and_dx_di, and_bx_di, and_sp_di, and_bp_di, and_si_di, and_di_di
	.global	and_r0_r16_bp_r4, and_r0_r16_bp_r5, and_r0_r16_bp_r6, and_r0_r16_bp_r7, and_r0_r16_bp_r8, and_r0_r16_bp_r9, and_r0_r16_bp_r10, and_r0_r16_bp_r11, and_r0_r16_bp_r4
	.global	and_r0_r16_r4, and_r0_r16_r5, and_r0_r16_r6, and_r0_r16_r7, and_r0_r16_r8, and_r0_r16_r9, and_r0_r16_r10, and_r0_r16_r11, and_r0_r16_r4


.macro and_r0_r16_reg reg
and_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
and_r0_r16_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_21_RAM_\reg op_21_EGA_r2_\reg bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_21_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r3, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	ands	r0, r3, r0, lsl #16
	lsr		r0, #16
	strb	r0, [r2]				// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0, [r2, #1]			// Store high byte to [physical segment + disp16 + 1]
	b		loop
.endm

	and_r0_r16_reg r4
	and_r0_r16_reg r5
	and_r0_r16_reg r6
	and_r0_r16_reg r7
	and_r0_r16_reg r8
	and_r0_r16_reg r9
	and_r0_r16_reg r10
	and_r0_r16_reg r11

	.ltorg
	
// --- [idx] ----

.macro and_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		and_r0_r16_\reg
.endm

and_bxsi_ax:
	and_bxidx_reg16 r10 r4
and_bxsi_cx:
	and_bxidx_reg16 r10 r5
and_bxsi_dx:
	and_bxidx_reg16 r10 r6
and_bxsi_bx:
	and_bxidx_reg16 r10 r7
and_bxsi_sp:
	and_bxidx_reg16 r10 r8
and_bxsi_bp:
	and_bxidx_reg16 r10 r9
and_bxsi_si:
	and_bxidx_reg16 r10 r10
and_bxsi_di:
	and_bxidx_reg16 r10 r11

and_bxdi_ax:
	and_bxidx_reg16 r11 r4
and_bxdi_cx:
	and_bxidx_reg16 r11 r5
and_bxdi_dx:
	and_bxidx_reg16 r11 r6
and_bxdi_bx:
	and_bxidx_reg16 r11 r7
and_bxdi_sp:
	and_bxidx_reg16 r11 r8
and_bxdi_bp:
	and_bxidx_reg16 r11 r9
and_bxdi_si:
	and_bxidx_reg16 r11 r10
and_bxdi_di:
	and_bxidx_reg16 r11 r11

.macro and_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		and_r0_r16_bp_\reg
.endm

and_bpsi_ax:
	and_bpidx_reg16 r10 r4
and_bpsi_cx:
	and_bpidx_reg16 r10 r5
and_bpsi_dx:
	and_bpidx_reg16 r10 r6
and_bpsi_bx:
	and_bpidx_reg16 r10 r7
and_bpsi_sp:
	and_bpidx_reg16 r10 r8
and_bpsi_bp:
	and_bpidx_reg16 r10 r9
and_bpsi_si:
	and_bpidx_reg16 r10 r10
and_bpsi_di:
	and_bpidx_reg16 r10 r11

and_bpdi_ax:
	and_bpidx_reg16 r11 r4
and_bpdi_cx:
	and_bpidx_reg16 r11 r5
and_bpdi_dx:
	and_bpidx_reg16 r11 r6
and_bpdi_bx:
	and_bpidx_reg16 r11 r7
and_bpdi_sp:
	and_bpidx_reg16 r11 r8
and_bpdi_bp:
	and_bpidx_reg16 r11 r9
and_bpdi_si:
	and_bpidx_reg16 r11 r10
and_bpdi_di:
	and_bpidx_reg16 r11 r11

.macro and_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		and_r0_r16_\reg
.endm

and_siidx_ax:
	and_idx_reg16 r10 r4
and_siidx_cx:
	and_idx_reg16 r10 r5
and_siidx_dx:
	and_idx_reg16 r10 r6
and_siidx_bx:
	and_idx_reg16 r10 r7
and_siidx_sp:
	and_idx_reg16 r10 r8
and_siidx_bp:
	and_idx_reg16 r10 r9
and_siidx_si:
	and_idx_reg16 r10 r10
and_siidx_di:
	and_idx_reg16 r10 r11

and_diidx_ax:
	and_idx_reg16 r11 r4
and_diidx_cx:
	and_idx_reg16 r11 r5
and_diidx_dx:
	and_idx_reg16 r11 r6
and_diidx_bx:
	and_idx_reg16 r11 r7
and_diidx_sp:
	and_idx_reg16 r11 r8
and_diidx_bp:
	and_idx_reg16 r11 r9
and_diidx_si:
	and_idx_reg16 r11 r10
and_diidx_di:
	and_idx_reg16 r11 r11

and_bxidx_ax:
	and_idx_reg16 r7 r4
and_bxidx_cx:
	and_idx_reg16 r7 r5
and_bxidx_dx:
	and_idx_reg16 r7 r6
and_bxidx_bx:
	and_idx_reg16 r7 r7
and_bxidx_sp:
	and_idx_reg16 r7 r8
and_bxidx_bp:
	and_idx_reg16 r7 r9
and_bxidx_si:
	and_idx_reg16 r7 r10
and_bxidx_di:
	and_idx_reg16 r7 r11
	
.macro and_disp16_reg16 reg
	r0_from_disp16
	b		and_r0_r16_\reg
.endm

and_disp16_ax:
	and_disp16_reg16 r4
and_disp16_cx:
	and_disp16_reg16 r5
and_disp16_dx:
	and_disp16_reg16 r6
and_disp16_bx:
	and_disp16_reg16 r7
and_disp16_sp:
	and_disp16_reg16 r8
and_disp16_bp:
	and_disp16_reg16 r9
and_disp16_si:
	and_disp16_reg16 r10
and_disp16_di:
	and_disp16_reg16 r11

// --- [idx+disp8] ----

.macro and_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		and_r0_r16_\reg
.endm

and_bxsid8_ax:
	and_bxidxd8_reg16 r10 r4
and_bxsid8_cx:
	and_bxidxd8_reg16 r10 r5
and_bxsid8_dx:
	and_bxidxd8_reg16 r10 r6
and_bxsid8_bx:
	and_bxidxd8_reg16 r10 r7
and_bxsid8_sp:
	and_bxidxd8_reg16 r10 r8
and_bxsid8_bp:
	and_bxidxd8_reg16 r10 r9
and_bxsid8_si:
	and_bxidxd8_reg16 r10 r10
and_bxsid8_di:
	and_bxidxd8_reg16 r10 r11

and_bxdid8_ax:
	and_bxidxd8_reg16 r11 r4
and_bxdid8_cx:
	and_bxidxd8_reg16 r11 r5
and_bxdid8_dx:
	and_bxidxd8_reg16 r11 r6
and_bxdid8_bx:
	and_bxidxd8_reg16 r11 r7
and_bxdid8_sp:
	and_bxidxd8_reg16 r11 r8
and_bxdid8_bp:
	and_bxidxd8_reg16 r11 r9
and_bxdid8_si:
	and_bxidxd8_reg16 r11 r10
and_bxdid8_di:
	and_bxidxd8_reg16 r11 r11

.macro and_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		and_r0_r16_bp_\reg
.endm

and_bpsid8_ax:
	and_bpidxd8_reg16 r10 r4
and_bpsid8_cx:
	and_bpidxd8_reg16 r10 r5
and_bpsid8_dx:
	and_bpidxd8_reg16 r10 r6
and_bpsid8_bx:
	and_bpidxd8_reg16 r10 r7
and_bpsid8_sp:
	and_bpidxd8_reg16 r10 r8
and_bpsid8_bp:
	and_bpidxd8_reg16 r10 r9
and_bpsid8_si:
	and_bpidxd8_reg16 r10 r10
and_bpsid8_di:
	and_bpidxd8_reg16 r10 r11

and_bpdid8_ax:
	and_bpidxd8_reg16 r11 r4
and_bpdid8_cx:
	and_bpidxd8_reg16 r11 r5
and_bpdid8_dx:
	and_bpidxd8_reg16 r11 r6
and_bpdid8_bx:
	and_bpidxd8_reg16 r11 r7
and_bpdid8_sp:
	and_bpidxd8_reg16 r11 r8
and_bpdid8_bp:
	and_bpidxd8_reg16 r11 r9
and_bpdid8_si:
	and_bpidxd8_reg16 r11 r10
and_bpdid8_di:
	and_bpidxd8_reg16 r11 r11

.macro and_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		and_r0_r16_\reg
.endm

and_sidisp8_ax:
	and_idxdisp8_reg16 r10 r4
and_sidisp8_cx:
	and_idxdisp8_reg16 r10 r5
and_sidisp8_dx:
	and_idxdisp8_reg16 r10 r6
and_sidisp8_bx:
	and_idxdisp8_reg16 r10 r7
and_sidisp8_sp:
	and_idxdisp8_reg16 r10 r8
and_sidisp8_bp:
	and_idxdisp8_reg16 r10 r9
and_sidisp8_si:
	and_idxdisp8_reg16 r10 r10
and_sidisp8_di:
	and_idxdisp8_reg16 r10 r11

and_didisp8_ax:
	and_idxdisp8_reg16 r11 r4
and_didisp8_cx:
	and_idxdisp8_reg16 r11 r5
and_didisp8_dx:
	and_idxdisp8_reg16 r11 r6
and_didisp8_bx:
	and_idxdisp8_reg16 r11 r7
and_didisp8_sp:
	and_idxdisp8_reg16 r11 r8
and_didisp8_bp:
	and_idxdisp8_reg16 r11 r9
and_didisp8_si:
	and_idxdisp8_reg16 r11 r10
and_didisp8_di:
	and_idxdisp8_reg16 r11 r11

and_bxdisp8_ax:
	and_idxdisp8_reg16 r7 r4
and_bxdisp8_cx:
	and_idxdisp8_reg16 r7 r5
and_bxdisp8_dx:
	and_idxdisp8_reg16 r7 r6
and_bxdisp8_bx:
	and_idxdisp8_reg16 r7 r7
and_bxdisp8_sp:
	and_idxdisp8_reg16 r7 r8
and_bxdisp8_bp:
	and_idxdisp8_reg16 r7 r9
and_bxdisp8_si:
	and_idxdisp8_reg16 r7 r10
and_bxdisp8_di:
	and_idxdisp8_reg16 r7 r11
	
.macro and_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		and_r0_r16_bp_\reg
.endm
	
and_bpdisp8_ax:
	and_bpdisp8_reg16 r4
and_bpdisp8_cx:
	and_bpdisp8_reg16 r5
and_bpdisp8_dx:
	and_bpdisp8_reg16 r6
and_bpdisp8_bx:
	and_bpdisp8_reg16 r7
and_bpdisp8_sp:
	and_bpdisp8_reg16 r8
and_bpdisp8_bp:
	and_bpdisp8_reg16 r9
and_bpdisp8_si:
	and_bpdisp8_reg16 r10
and_bpdisp8_di:
	and_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro and_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		and_r0_r16_\reg
.endm

and_bxsid16_ax:
	and_bxidxd16_reg16 r10 r4
and_bxsid16_cx:
	and_bxidxd16_reg16 r10 r5
and_bxsid16_dx:
	and_bxidxd16_reg16 r10 r6
and_bxsid16_bx:
	and_bxidxd16_reg16 r10 r7
and_bxsid16_sp:
	and_bxidxd16_reg16 r10 r8
and_bxsid16_bp:
	and_bxidxd16_reg16 r10 r9
and_bxsid16_si:
	and_bxidxd16_reg16 r10 r10
and_bxsid16_di:
	and_bxidxd16_reg16 r10 r11

and_bxdid16_ax:
	and_bxidxd16_reg16 r11 r4
and_bxdid16_cx:
	and_bxidxd16_reg16 r11 r5
and_bxdid16_dx:
	and_bxidxd16_reg16 r11 r6
and_bxdid16_bx:
	and_bxidxd16_reg16 r11 r7
and_bxdid16_sp:
	and_bxidxd16_reg16 r11 r8
and_bxdid16_bp:
	and_bxidxd16_reg16 r11 r9
and_bxdid16_si:
	and_bxidxd16_reg16 r11 r10
and_bxdid16_di:
	and_bxidxd16_reg16 r11 r11

.macro and_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		and_r0_r16_bp_\reg
.endm

and_bpsid16_ax:
	and_bpidxd16_reg16 r10 r4
and_bpsid16_cx:
	and_bpidxd16_reg16 r10 r5
and_bpsid16_dx:
	and_bpidxd16_reg16 r10 r6
and_bpsid16_bx:
	and_bpidxd16_reg16 r10 r7
and_bpsid16_sp:
	and_bpidxd16_reg16 r10 r8
and_bpsid16_bp:
	and_bpidxd16_reg16 r10 r9
and_bpsid16_si:
	and_bpidxd16_reg16 r10 r10
and_bpsid16_di:
	and_bpidxd16_reg16 r10 r11

and_bpdid16_ax:
	and_bpidxd16_reg16 r11 r4
and_bpdid16_cx:
	and_bpidxd16_reg16 r11 r5
and_bpdid16_dx:
	and_bpidxd16_reg16 r11 r6
and_bpdid16_bx:
	and_bpidxd16_reg16 r11 r7
and_bpdid16_sp:
	and_bpidxd16_reg16 r11 r8
and_bpdid16_bp:
	and_bpidxd16_reg16 r11 r9
and_bpdid16_si:
	and_bpidxd16_reg16 r11 r10
and_bpdid16_di:
	and_bpidxd16_reg16 r11 r11

.macro and_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		and_r0_r16_\reg
.endm

and_sidisp16_ax:
	and_idxdisp16_reg16 r10 r4
and_sidisp16_cx:
	and_idxdisp16_reg16 r10 r5
and_sidisp16_dx:
	and_idxdisp16_reg16 r10 r6
and_sidisp16_bx:
	and_idxdisp16_reg16 r10 r7
and_sidisp16_sp:
	and_idxdisp16_reg16 r10 r8
and_sidisp16_bp:
	and_idxdisp16_reg16 r10 r9
and_sidisp16_si:
	and_idxdisp16_reg16 r10 r10
and_sidisp16_di:
	and_idxdisp16_reg16 r10 r11

and_didisp16_ax:
	and_idxdisp16_reg16 r11 r4
and_didisp16_cx:
	and_idxdisp16_reg16 r11 r5
and_didisp16_dx:
	and_idxdisp16_reg16 r11 r6
and_didisp16_bx:
	and_idxdisp16_reg16 r11 r7
and_didisp16_sp:
	and_idxdisp16_reg16 r11 r8
and_didisp16_bp:
	and_idxdisp16_reg16 r11 r9
and_didisp16_si:
	and_idxdisp16_reg16 r11 r10
and_didisp16_di:
	and_idxdisp16_reg16 r11 r11

and_bxdisp16_ax:
	and_idxdisp16_reg16 r7 r4
and_bxdisp16_cx:
	and_idxdisp16_reg16 r7 r5
and_bxdisp16_dx:
	and_idxdisp16_reg16 r7 r6
and_bxdisp16_bx:
	and_idxdisp16_reg16 r7 r7
and_bxdisp16_sp:
	and_idxdisp16_reg16 r7 r8
and_bxdisp16_bp:
	and_idxdisp16_reg16 r7 r9
and_bxdisp16_si:
	and_idxdisp16_reg16 r7 r10
and_bxdisp16_di:
	and_idxdisp16_reg16 r7 r11

.macro and_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		and_r0_r16_bp_\reg
.endm

and_bpdisp16_ax:
	and_bpdisp16_reg16 r4
and_bpdisp16_cx:
	and_bpdisp16_reg16 r5
and_bpdisp16_dx:
	and_bpdisp16_reg16 r6
and_bpdisp16_bx:
	and_bpdisp16_reg16 r7
and_bpdisp16_sp:
	and_bpdisp16_reg16 r8
and_bpdisp16_bp:
	and_bpdisp16_reg16 r9
and_bpdisp16_si:
	and_bpdisp16_reg16 r10
and_bpdisp16_di:
	and_bpdisp16_reg16 r11


// ------------------- 22 = AND r8,r/m8 --------------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual ands operation, so C and O work like in x86.
//
// All modrm variations supported!
//
//
	.global	op_22
op_22:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word and_al_bxsi, and_al_bxdi, and_al_bpsi, and_al_bpdi, and_al_siidx, and_al_diidx, and_al_disp16, and_al_bxidx
	.word and_cl_bxsi, and_cl_bxdi, and_cl_bpsi, and_cl_bpdi, and_cl_siidx, and_cl_diidx, and_cl_disp16, and_cl_bxidx
	.word and_dl_bxsi, and_dl_bxdi, and_dl_bpsi, and_dl_bpdi, and_dl_siidx, and_dl_diidx, and_dl_disp16, and_dl_bxidx
	.word and_bl_bxsi, and_bl_bxdi, and_bl_bpsi, and_bl_bpdi, and_bl_siidx, and_bl_diidx, and_bl_disp16, and_bl_bxidx
	.word and_ah_bxsi, and_ah_bxdi, and_ah_bpsi, and_ah_bpdi, and_ah_siidx, and_ah_diidx, and_ah_disp16, and_ah_bxidx
	.word and_ch_bxsi, and_ch_bxdi, and_ch_bpsi, and_ch_bpdi, and_ch_siidx, and_ch_diidx, and_ch_disp16, and_ch_bxidx
	.word and_dh_bxsi, and_dh_bxdi, and_dh_bpsi, and_dh_bpdi, and_dh_siidx, and_dh_diidx, and_dh_disp16, and_dh_bxidx
	.word and_bh_bxsi, and_bh_bxdi, and_bh_bpsi, and_bh_bpdi, and_bh_siidx, and_bh_diidx, and_bh_disp16, and_bh_bxidx
//0x40
	.word and_al_bxsid8, and_al_bxdid8, and_al_bpsid8, and_al_bpdid8, and_al_sidisp8, and_al_didisp8, and_al_bpdisp8, and_al_bxdisp8
	.word and_cl_bxsid8, and_cl_bxdid8, and_cl_bpsid8, and_cl_bpdid8, and_cl_sidisp8, and_cl_didisp8, and_cl_bpdisp8, and_cl_bxdisp8
	.word and_dl_bxsid8, and_dl_bxdid8, and_dl_bpsid8, and_dl_bpdid8, and_dl_sidisp8, and_dl_didisp8, and_dl_bpdisp8, and_dl_bxdisp8
	.word and_bl_bxsid8, and_bl_bxdid8, and_bl_bpsid8, and_bl_bpdid8, and_bl_sidisp8, and_bl_didisp8, and_bl_bpdisp8, and_bl_bxdisp8
	.word and_ah_bxsid8, and_ah_bxdid8, and_ah_bpsid8, and_ah_bpdid8, and_ah_sidisp8, and_ah_didisp8, and_ah_bpdisp8, and_ah_bxdisp8
	.word and_ch_bxsid8, and_ch_bxdid8, and_ch_bpsid8, and_ch_bpdid8, and_ch_sidisp8, and_ch_didisp8, and_ch_bpdisp8, and_ch_bxdisp8
	.word and_dh_bxsid8, and_dh_bxdid8, and_dh_bpsid8, and_dh_bpdid8, and_dh_sidisp8, and_dh_didisp8, and_dh_bpdisp8, and_dh_bxdisp8
	.word and_bh_bxsid8, and_bh_bxdid8, and_bh_bpsid8, and_bh_bpdid8, and_bh_sidisp8, and_bh_didisp8, and_bh_bpdisp8, and_bh_bxdisp8
//0x80
	.word and_al_bxsid16, and_al_bxdid16, and_al_bpsid16, and_al_bpdid16, and_al_sidisp16, and_al_didisp16, and_al_bpdisp16, and_al_bxdisp16
	.word and_cl_bxsid16, and_cl_bxdid16, and_cl_bpsid16, and_cl_bpdid16, and_cl_sidisp16, and_cl_didisp16, and_cl_bpdisp16, and_cl_bxdisp16
	.word and_dl_bxsid16, and_dl_bxdid16, and_dl_bpsid16, and_dl_bpdid16, and_dl_sidisp16, and_dl_didisp16, and_dl_bpdisp16, and_dl_bxdisp16
	.word and_bl_bxsid16, and_bl_bxdid16, and_bl_bpsid16, and_bl_bpdid16, and_bl_sidisp16, and_bl_didisp16, and_bl_bpdisp16, and_bl_bxdisp16
	.word and_ah_bxsid16, and_ah_bxdid16, and_ah_bpsid16, and_ah_bpdid16, and_ah_sidisp16, and_ah_didisp16, and_ah_bpdisp16, and_ah_bxdisp16
	.word and_ch_bxsid16, and_ch_bxdid16, and_ch_bpsid16, and_ch_bpdid16, and_ch_sidisp16, and_ch_didisp16, and_ch_bpdisp16, and_ch_bxdisp16
	.word and_dh_bxsid16, and_dh_bxdid16, and_dh_bpsid16, and_dh_bpdid16, and_dh_sidisp16, and_dh_didisp16, and_dh_bpdisp16, and_dh_bxdisp16
	.word and_bh_bxsid16, and_bh_bxdid16, and_bh_bpsid16, and_bh_bpdid16, and_bh_sidisp16, and_bh_didisp16, and_bh_bpdisp16, and_bh_bxdisp16
// 0xC0 = two register operands
	.word and_al_al, and_al_cl, and_al_dl, and_al_bl, and_al_ah, and_al_ch, and_al_dh, and_al_bh
	.word and_cl_al, and_cl_cl, and_cl_dl, and_cl_bl, and_cl_ah, and_cl_ch, and_cl_dh, and_cl_bh
	.word and_dl_al, and_dl_cl, and_dl_dl, and_dl_bl, and_dl_ah, and_dl_ch, and_dl_dh, and_dl_bh
	.word and_bl_al, and_bl_cl, and_bl_dl, and_bl_bl, and_bl_ah, and_bl_ch, and_bl_dh, and_bl_bh
	.word and_ah_al, and_ah_cl, and_ah_dl, and_ah_bl, and_ah_ah, and_ah_ch, and_ah_dh, and_ah_bh
	.word and_ch_al, and_ch_cl, and_ch_dl, and_ch_bl, and_ch_ah, and_ch_ch, and_ch_dh, and_ch_bh
	.word and_dh_al, and_dh_cl, and_dh_dl, and_dh_bl, and_dh_ah, and_dh_ch, and_dh_dh, and_dh_bh
	.word and_bh_al, and_bh_cl, and_bh_dl, and_bh_bl, and_bh_ah, and_bh_ch, and_bh_dh, and_bh_bh

// These are called from "cpu_386.s":

	.global and_al_siidx, and_cl_siidx, and_dl_siidx, and_bl_siidx, and_ah_siidx, and_ch_siidx, and_dh_siidx, and_bh_siidx
	.global and_al_diidx, and_cl_diidx, and_dl_diidx, and_bl_diidx, and_ah_diidx, and_ch_diidx, and_dh_diidx, and_bh_diidx
	.global and_al_bxidx, and_cl_bxidx, and_dl_bxidx, and_bl_bxidx, and_ah_bxidx, and_ch_bxidx, and_dh_bxidx, and_bh_bxidx
	.global and_al_sidisp8, and_al_didisp8, and_al_bpdisp8, and_al_bxdisp8
	.global and_cl_sidisp8, and_cl_didisp8, and_cl_bpdisp8, and_cl_bxdisp8
	.global and_dl_sidisp8, and_dl_didisp8, and_dl_bpdisp8, and_dl_bxdisp8
	.global and_bl_sidisp8, and_bl_didisp8, and_bl_bpdisp8, and_bl_bxdisp8
	.global and_ah_sidisp8, and_ah_didisp8, and_ah_bpdisp8, and_ah_bxdisp8
	.global and_ch_sidisp8, and_ch_didisp8, and_ch_bpdisp8, and_ch_bxdisp8
	.global and_dh_sidisp8, and_dh_didisp8, and_dh_bpdisp8, and_dh_bxdisp8
	.global and_bh_sidisp8, and_bh_didisp8, and_bh_bpdisp8, and_bh_bxdisp8
	.global and_al_al, and_cl_al, and_dl_al, and_bl_al, and_ah_al, and_ch_al, and_dh_al, and_bh_al
	.global and_al_cl, and_cl_cl, and_dl_cl, and_bl_cl, and_ah_cl, and_ch_cl, and_dh_cl, and_bh_cl
	.global and_al_dl, and_cl_dl, and_dl_dl, and_bl_dl, and_ah_dl, and_ch_dl, and_dh_dl, and_bh_dl
	.global and_al_bl, and_cl_bl, and_dl_bl, and_bl_bl, and_ah_bl, and_ch_bl, and_dh_bl, and_bh_bl
	.global and_al_ah, and_cl_ah, and_dl_ah, and_bl_ah, and_ah_ah, and_ch_ah, and_dh_ah, and_bh_ah
	.global and_al_ch, and_cl_ch, and_dl_ch, and_bl_ch, and_ah_ch, and_ch_ch, and_dh_ch, and_bh_ch
	.global and_al_dh, and_cl_dh, and_dl_dh, and_bl_dh, and_ah_dh, and_ch_dh, and_dh_dh, and_bh_dh
	.global and_al_bh, and_cl_bh, and_dl_bh, and_bl_bh, and_ah_bh, and_ch_bh, and_dh_bh, and_bh_bh

.macro and_reg8l_r0high reg
	.global	and_r8l_r0_bp_\reg
and_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	and_r8l_r0_\reg
and_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_22_RAM_l_\reg op_22_EGA_l_\reg op_22_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_22_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	ands	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	b		loop
.endm
.macro and_reg8h_r0high reg
	.global	and_r8h_r0_bp_\reg
and_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	and_r8h_r0_\reg
and_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_22_RAM_h_\reg op_22_EGA_h_\reg op_22_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_22_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #16		// No need to clear the reg8l value from r1, as the AND will do that for us.
	ands	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsr #16
	b		loop
.endm

	and_reg8l_r0high r4
	and_reg8l_r0high r5
	and_reg8l_r0high r6
	and_reg8l_r0high r7
	and_reg8h_r0high r4
	and_reg8h_r0high r5
	and_reg8h_r0high r6
	and_reg8h_r0high r7

	.ltorg


// --- [idx] ---

.macro and_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		and_r8l_r0_\reg
.endm
.macro and_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		and_r8h_r0_\reg
.endm

and_al_bxsi:
	and_reg8l_bxidx r4 r10
and_cl_bxsi:
	and_reg8l_bxidx r5 r10
and_dl_bxsi:
	and_reg8l_bxidx r6 r10
and_bl_bxsi:
	and_reg8l_bxidx r7 r10
and_ah_bxsi:
	and_reg8h_bxidx r4 r10
and_ch_bxsi:
	and_reg8h_bxidx r5 r10
and_dh_bxsi:
	and_reg8h_bxidx r6 r10
and_bh_bxsi:
	and_reg8h_bxidx r7 r10

and_al_bxdi:
	and_reg8l_bxidx r4 r11
and_cl_bxdi:
	and_reg8l_bxidx r5 r11
and_dl_bxdi:
	and_reg8l_bxidx r6 r11
and_bl_bxdi:
	and_reg8l_bxidx r7 r11
and_ah_bxdi:
	and_reg8h_bxidx r4 r11
and_ch_bxdi:
	and_reg8h_bxidx r5 r11
and_dh_bxdi:
	and_reg8h_bxidx r6 r11
and_bh_bxdi:
	and_reg8h_bxidx r7 r11

.macro and_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		and_r8l_r0_bp_\reg
.endm
.macro and_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		and_r8h_r0_bp_\reg
.endm

and_al_bpsi:
	and_reg8l_bpidx r4 r10
and_cl_bpsi:
	and_reg8l_bpidx r5 r10
and_dl_bpsi:
	and_reg8l_bpidx r6 r10
and_bl_bpsi:
	and_reg8l_bpidx r7 r10
and_ah_bpsi:
	and_reg8h_bpidx r4 r10
and_ch_bpsi:
	and_reg8h_bpidx r5 r10
and_dh_bpsi:
	and_reg8h_bpidx r6 r10
and_bh_bpsi:
	and_reg8h_bpidx r7 r10

and_al_bpdi:
	and_reg8l_bpidx r4 r11
and_cl_bpdi:
	and_reg8l_bpidx r5 r11
and_dl_bpdi:
	and_reg8l_bpidx r6 r11
and_bl_bpdi:
	and_reg8l_bpidx r7 r11
and_ah_bpdi:
	and_reg8h_bpidx r4 r11
and_ch_bpdi:
	and_reg8h_bpidx r5 r11
and_dh_bpdi:
	and_reg8h_bpidx r6 r11
and_bh_bpdi:
	and_reg8h_bpidx r7 r11

.macro and_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		and_r8l_r0_\reg
.endm
.macro and_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		and_r8h_r0_\reg
.endm

and_al_siidx:
	and_reg8l_idx r4 r10
and_cl_siidx:
	and_reg8l_idx r5 r10
and_dl_siidx:
	and_reg8l_idx r6 r10
and_bl_siidx:
	and_reg8l_idx r7 r10
and_ah_siidx:
	and_reg8h_idx r4 r10
and_ch_siidx:
	and_reg8h_idx r5 r10
and_dh_siidx:
	and_reg8h_idx r6 r10
and_bh_siidx:
	and_reg8h_idx r7 r10

and_al_diidx:
	and_reg8l_idx r4 r11
and_cl_diidx:
	and_reg8l_idx r5 r11
and_dl_diidx:
	and_reg8l_idx r6 r11
and_bl_diidx:
	and_reg8l_idx r7 r11
and_ah_diidx:
	and_reg8h_idx r4 r11
and_ch_diidx:
	and_reg8h_idx r5 r11
and_dh_diidx:
	and_reg8h_idx r6 r11
and_bh_diidx:
	and_reg8h_idx r7 r11

and_al_bxidx:
	and_reg8l_idx r4 r7
and_cl_bxidx:
	and_reg8l_idx r5 r7
and_dl_bxidx:
	and_reg8l_idx r6 r7
and_bl_bxidx:
	and_reg8l_idx r7 r7
and_ah_bxidx:
	and_reg8h_idx r4 r7
and_ch_bxidx:
	and_reg8h_idx r5 r7
and_dh_bxidx:
	and_reg8h_idx r6 r7
and_bh_bxidx:
	and_reg8h_idx r7 r7

.macro and_reg8l_disp16 reg
	r0_from_disp16
	b		and_r8l_r0_\reg
.endm
.macro and_reg8h_disp16 reg
	r0_from_disp16
	b		and_r8h_r0_\reg
.endm

and_al_disp16:
	and_reg8l_disp16 r4
and_cl_disp16:
	and_reg8l_disp16 r5
and_dl_disp16:
	and_reg8l_disp16 r6
and_bl_disp16:
	and_reg8l_disp16 r7
and_ah_disp16:
	and_reg8h_disp16 r4
and_ch_disp16:
	and_reg8h_disp16 r5
and_dh_disp16:
	and_reg8h_disp16 r6
and_bh_disp16:
	and_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro and_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		and_r8l_r0_\reg
.endm
.macro and_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		and_r8h_r0_\reg
.endm

and_al_bxsid8:
	and_reg8l_bxidxd8 r4 r10
and_cl_bxsid8:
	and_reg8l_bxidxd8 r5 r10
and_dl_bxsid8:
	and_reg8l_bxidxd8 r6 r10
and_bl_bxsid8:
	and_reg8l_bxidxd8 r7 r10
and_ah_bxsid8:
	and_reg8h_bxidxd8 r4 r10
and_ch_bxsid8:
	and_reg8h_bxidxd8 r5 r10
and_dh_bxsid8:
	and_reg8h_bxidxd8 r6 r10
and_bh_bxsid8:
	and_reg8h_bxidxd8 r7 r10

and_al_bxdid8:
	and_reg8l_bxidxd8 r4 r11
and_cl_bxdid8:
	and_reg8l_bxidxd8 r5 r11
and_dl_bxdid8:
	and_reg8l_bxidxd8 r6 r11
and_bl_bxdid8:
	and_reg8l_bxidxd8 r7 r11
and_ah_bxdid8:
	and_reg8h_bxidxd8 r4 r11
and_ch_bxdid8:
	and_reg8h_bxidxd8 r5 r11
and_dh_bxdid8:
	and_reg8h_bxidxd8 r6 r11
and_bh_bxdid8:
	and_reg8h_bxidxd8 r7 r11

.macro and_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		and_r8l_r0_bp_\reg
.endm
.macro and_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		and_r8h_r0_bp_\reg
.endm

and_al_bpsid8:
	and_reg8l_bpidxd8 r4 r10
and_cl_bpsid8:
	and_reg8l_bpidxd8 r5 r10
and_dl_bpsid8:
	and_reg8l_bpidxd8 r6 r10
and_bl_bpsid8:
	and_reg8l_bpidxd8 r7 r10
and_ah_bpsid8:
	and_reg8h_bpidxd8 r4 r10
and_ch_bpsid8:
	and_reg8h_bpidxd8 r5 r10
and_dh_bpsid8:
	and_reg8h_bpidxd8 r6 r10
and_bh_bpsid8:
	and_reg8h_bpidxd8 r7 r10

and_al_bpdid8:
	and_reg8l_bpidxd8 r4 r11
and_cl_bpdid8:
	and_reg8l_bpidxd8 r5 r11
and_dl_bpdid8:
	and_reg8l_bpidxd8 r6 r11
and_bl_bpdid8:
	and_reg8l_bpidxd8 r7 r11
and_ah_bpdid8:
	and_reg8h_bpidxd8 r4 r11
and_ch_bpdid8:
	and_reg8h_bpidxd8 r5 r11
and_dh_bpdid8:
	and_reg8h_bpidxd8 r6 r11
and_bh_bpdid8:
	and_reg8h_bpidxd8 r7 r11

.macro and_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		and_r8l_r0_\reg
.endm
.macro and_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		and_r8h_r0_\reg
.endm

and_al_sidisp8:
	and_reg8l_idxdisp8 r4 r10
and_cl_sidisp8:
	and_reg8l_idxdisp8 r5 r10
and_dl_sidisp8:
	and_reg8l_idxdisp8 r6 r10
and_bl_sidisp8:
	and_reg8l_idxdisp8 r7 r10
and_ah_sidisp8:
	and_reg8h_idxdisp8 r4 r10
and_ch_sidisp8:
	and_reg8h_idxdisp8 r5 r10
and_dh_sidisp8:
	and_reg8h_idxdisp8 r6 r10
and_bh_sidisp8:
	and_reg8h_idxdisp8 r7 r10
	
and_al_didisp8:
	and_reg8l_idxdisp8 r4 r11
and_cl_didisp8:
	and_reg8l_idxdisp8 r5 r11
and_dl_didisp8:
	and_reg8l_idxdisp8 r6 r11
and_bl_didisp8:
	and_reg8l_idxdisp8 r7 r11
and_ah_didisp8:
	and_reg8h_idxdisp8 r4 r11
and_ch_didisp8:
	and_reg8h_idxdisp8 r5 r11
and_dh_didisp8:
	and_reg8h_idxdisp8 r6 r11
and_bh_didisp8:
	and_reg8h_idxdisp8 r7 r11

and_al_bxdisp8:
	and_reg8l_idxdisp8 r4 r7
and_cl_bxdisp8:
	and_reg8l_idxdisp8 r5 r7
and_dl_bxdisp8:
	and_reg8l_idxdisp8 r6 r7
and_bl_bxdisp8:
	and_reg8l_idxdisp8 r7 r7
and_ah_bxdisp8:
	and_reg8h_idxdisp8 r4 r7
and_ch_bxdisp8:
	and_reg8h_idxdisp8 r5 r7
and_dh_bxdisp8:
	and_reg8h_idxdisp8 r6 r7
and_bh_bxdisp8:
	and_reg8h_idxdisp8 r7 r7

.macro and_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		and_r8l_r0_bp_\reg
.endm
.macro and_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		and_r8h_r0_bp_\reg
.endm

and_al_bpdisp8:
	and_reg8l_bpdisp8 r4
and_cl_bpdisp8:
	and_reg8l_bpdisp8 r5
and_dl_bpdisp8:
	and_reg8l_bpdisp8 r6
and_bl_bpdisp8:
	and_reg8l_bpdisp8 r7
and_ah_bpdisp8:
	and_reg8h_bpdisp8 r4
and_ch_bpdisp8:
	and_reg8h_bpdisp8 r5
and_dh_bpdisp8:
	and_reg8h_bpdisp8 r6
and_bh_bpdisp8:
	and_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro and_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		and_r8l_r0_\reg
.endm
.macro and_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		and_r8h_r0_\reg
.endm

and_al_bxsid16:
	and_reg8l_bxidxd16 r4 r10
and_cl_bxsid16:
	and_reg8l_bxidxd16 r5 r10
and_dl_bxsid16:
	and_reg8l_bxidxd16 r6 r10
and_bl_bxsid16:
	and_reg8l_bxidxd16 r7 r10
and_ah_bxsid16:
	and_reg8h_bxidxd16 r4 r10
and_ch_bxsid16:
	and_reg8h_bxidxd16 r5 r10
and_dh_bxsid16:
	and_reg8h_bxidxd16 r6 r10
and_bh_bxsid16:
	and_reg8h_bxidxd16 r7 r10

and_al_bxdid16:
	and_reg8l_bxidxd16 r4 r11
and_cl_bxdid16:
	and_reg8l_bxidxd16 r5 r11
and_dl_bxdid16:
	and_reg8l_bxidxd16 r6 r11
and_bl_bxdid16:
	and_reg8l_bxidxd16 r7 r11
and_ah_bxdid16:
	and_reg8h_bxidxd16 r4 r11
and_ch_bxdid16:
	and_reg8h_bxidxd16 r5 r11
and_dh_bxdid16:
	and_reg8h_bxidxd16 r6 r11
and_bh_bxdid16:
	and_reg8h_bxidxd16 r7 r11

.macro and_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		and_r8l_r0_bp_\reg
.endm
.macro and_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		and_r8h_r0_bp_\reg
.endm

and_al_bpsid16:
	and_reg8l_bpidxd16 r4 r10
and_cl_bpsid16:
	and_reg8l_bpidxd16 r5 r10
and_dl_bpsid16:
	and_reg8l_bpidxd16 r6 r10
and_bl_bpsid16:
	and_reg8l_bpidxd16 r7 r10
and_ah_bpsid16:
	and_reg8h_bpidxd16 r4 r10
and_ch_bpsid16:
	and_reg8h_bpidxd16 r5 r10
and_dh_bpsid16:
	and_reg8h_bpidxd16 r6 r10
and_bh_bpsid16:
	and_reg8h_bpidxd16 r7 r10

and_al_bpdid16:
	and_reg8l_bpidxd16 r4 r11
and_cl_bpdid16:
	and_reg8l_bpidxd16 r5 r11
and_dl_bpdid16:
	and_reg8l_bpidxd16 r6 r11
and_bl_bpdid16:
	and_reg8l_bpidxd16 r7 r11
and_ah_bpdid16:
	and_reg8h_bpidxd16 r4 r11
and_ch_bpdid16:
	and_reg8h_bpidxd16 r5 r11
and_dh_bpdid16:
	and_reg8h_bpidxd16 r6 r11
and_bh_bpdid16:
	and_reg8h_bpidxd16 r7 r11

.macro and_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		and_r8l_r0_\reg
.endm
.macro and_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		and_r8h_r0_\reg
.endm

and_al_sidisp16:
	and_reg8l_idxdisp16 r4 r10
and_cl_sidisp16:
	and_reg8l_idxdisp16 r5 r10
and_dl_sidisp16:
	and_reg8l_idxdisp16 r6 r10
and_bl_sidisp16:
	and_reg8l_idxdisp16 r7 r10
and_ah_sidisp16:
	and_reg8h_idxdisp16 r4 r10
and_ch_sidisp16:
	and_reg8h_idxdisp16 r5 r10
and_dh_sidisp16:
	and_reg8h_idxdisp16 r6 r10
and_bh_sidisp16:
	and_reg8h_idxdisp16 r7 r10

and_al_didisp16:
	and_reg8l_idxdisp16 r4 r11
and_cl_didisp16:
	and_reg8l_idxdisp16 r5 r11
and_dl_didisp16:
	and_reg8l_idxdisp16 r6 r11
and_bl_didisp16:
	and_reg8l_idxdisp16 r7 r11
and_ah_didisp16:
	and_reg8h_idxdisp16 r4 r11
and_ch_didisp16:
	and_reg8h_idxdisp16 r5 r11
and_dh_didisp16:
	and_reg8h_idxdisp16 r6 r11
and_bh_didisp16:
	and_reg8h_idxdisp16 r7 r11

and_al_bxdisp16:
	and_reg8l_idxdisp16 r4 r7
and_cl_bxdisp16:
	and_reg8l_idxdisp16 r5 r7
and_dl_bxdisp16:
	and_reg8l_idxdisp16 r6 r7
and_bl_bxdisp16:
	and_reg8l_idxdisp16 r7 r7
and_ah_bxdisp16:
	and_reg8h_idxdisp16 r4 r7
and_ch_bxdisp16:
	and_reg8h_idxdisp16 r5 r7
and_dh_bxdisp16:
	and_reg8h_idxdisp16 r6 r7
and_bh_bxdisp16:
	and_reg8h_idxdisp16 r7 r7
	
.macro and_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		and_r8l_r0_bp_\reg
.endm
.macro and_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		and_r8h_r0_bp_\reg
.endm

and_al_bpdisp16:
	and_reg8l_bpdisp16 r4 
and_cl_bpdisp16:
	and_reg8l_bpdisp16 r5 
and_dl_bpdisp16:
	and_reg8l_bpdisp16 r6 
and_bl_bpdisp16:
	and_reg8l_bpdisp16 r7 
and_ah_bpdisp16:
	and_reg8h_bpdisp16 r4 
and_ch_bpdisp16:
	and_reg8h_bpdisp16 r5 
and_dh_bpdisp16:
	and_reg8h_bpdisp16 r6 
and_bh_bpdisp16:
	and_reg8h_bpdisp16 r7 

// ----- registers -----

.macro and_reg8l_reg8l reg1 reg2
	mov		r0, \reg1, lsl #24
	mov		r1, \reg2, lsl #24
	ands	r0, r1
	bic		\reg1, #0xFF			// Clear the current reg8l value
	orr		\reg1, r0, lsr #24		// and replace it with r0
	b		loop
.endm

.macro and_reg8l_reg8h reg1 reg2
	mov		r0, \reg1, lsl #24
	mov		r1, \reg2, lsl #16		// No need to clear the reg8l value from r1, as the AND will do that for us.
	ands	r0, r1
	bic		\reg1, #0xFF			// Clear the current reg8l value
	orr		\reg1, r0, lsr #24		// and replace it with r0
	b		loop
.endm

and_al_al:
	and_reg8l_reg8l r4 r4
and_al_cl:	
	and_reg8l_reg8l r4 r5
and_al_dl:
	and_reg8l_reg8l r4 r6
and_al_bl:	
	and_reg8l_reg8l r4 r7
and_al_ah:
	and_reg8l_reg8h r4 r4
and_al_ch:
	and_reg8l_reg8h r4 r5
and_al_dh:
	and_reg8l_reg8h r4 r6
and_al_bh:
	and_reg8l_reg8h r4 r7

and_cl_al:
	and_reg8l_reg8l r5 r4
and_cl_cl:	
	and_reg8l_reg8l r5 r5
and_cl_dl:
	and_reg8l_reg8l r5 r6
and_cl_bl:	
	and_reg8l_reg8l r5 r7
and_cl_ah:
	and_reg8l_reg8h r5 r4
and_cl_ch:
	and_reg8l_reg8h r5 r5
and_cl_dh:
	and_reg8l_reg8h r5 r6
and_cl_bh:
	and_reg8l_reg8h r5 r7
	
and_dl_al:
	and_reg8l_reg8l r6 r4
and_dl_cl:	
	and_reg8l_reg8l r6 r5
and_dl_dl:
	and_reg8l_reg8l r6 r6
and_dl_bl:	
	and_reg8l_reg8l r6 r7
and_dl_ah:
	and_reg8l_reg8h r6 r4
and_dl_ch:
	and_reg8l_reg8h r6 r5
and_dl_dh:
	and_reg8l_reg8h r6 r6
and_dl_bh:
	and_reg8l_reg8h r6 r7
	
and_bl_al:
	and_reg8l_reg8l r7 r4
and_bl_cl:	
	and_reg8l_reg8l r7 r5
and_bl_dl:
	and_reg8l_reg8l r7 r6
and_bl_bl:	
	and_reg8l_reg8l r7 r7
and_bl_ah:
	and_reg8l_reg8h r7 r4
and_bl_ch:
	and_reg8l_reg8h r7 r5
and_bl_dh:
	and_reg8l_reg8h r7 r6
and_bl_bh:
	and_reg8l_reg8h r7 r7

.macro and_reg8h_reg8l reg1 reg2
	mov		r0, \reg1, lsl #16		// No need to clear the reg8l value from r1, as the AND will do that for us.
	mov		r1, \reg2, lsl #24
	ands	r0, r1
	bic		\reg1, #0xFF00			// Clear the current reg8h value
	orr		\reg1, r0, lsr #16		// and replace it with r0
	b		loop
.endm
.macro and_reg8h_reg8h reg1 reg2
	and		r0, \reg1, #0xFF00
	lsl		r0, #16
	mov		r1, \reg2, lsl #16
	ands	r0, r1
	bic		\reg1, #0xFF00			// Clear the current reg8h value
	orr		\reg1, r0, lsr #16		// and replace it with r0
	b		loop
.endm

and_ah_al:
	and_reg8h_reg8l r4 r4
and_ah_cl:	
	and_reg8h_reg8l r4 r5
and_ah_dl:
	and_reg8h_reg8l r4 r6
and_ah_bl:	
	and_reg8h_reg8l r4 r7
and_ah_ah:
	and_reg8h_reg8h r4 r4
and_ah_ch:	
	and_reg8h_reg8h r4 r5
and_ah_dh:
	and_reg8h_reg8h r4 r6
and_ah_bh:	
	and_reg8h_reg8h r4 r7

and_ch_al:
	and_reg8h_reg8l r5 r4
and_ch_cl:	
	and_reg8h_reg8l r5 r5
and_ch_dl:
	and_reg8h_reg8l r5 r6
and_ch_bl:	
	and_reg8h_reg8l r5 r7
and_ch_ah:
	and_reg8h_reg8h r5 r4
and_ch_ch:	
	and_reg8h_reg8h r5 r5
and_ch_dh:
	and_reg8h_reg8h r5 r6
and_ch_bh:	
	and_reg8h_reg8h r5 r7
	
and_dh_al:
	and_reg8h_reg8l r6 r4
and_dh_cl:	
	and_reg8h_reg8l r6 r5
and_dh_dl:
	and_reg8h_reg8l r6 r6
and_dh_bl:	
	and_reg8h_reg8l r6 r7
and_dh_ah:
	and_reg8h_reg8h r6 r4
and_dh_ch:	
	and_reg8h_reg8h r6 r5
and_dh_dh:
	and_reg8h_reg8h r6 r6
and_dh_bh:	
	and_reg8h_reg8h r6 r7
	
and_bh_al:
	and_reg8h_reg8l r7 r4
and_bh_cl:	
	and_reg8h_reg8l r7 r5
and_bh_dl:
	and_reg8h_reg8l r7 r6
and_bh_bl:	
	and_reg8h_reg8l r7 r7
and_bh_ah:
	and_reg8h_reg8h r7 r4
and_bh_ch:	
	and_reg8h_reg8h r7 r5
and_bh_dh:
	and_reg8h_reg8h r7 r6
and_bh_bh:	
	and_reg8h_reg8h r7 r7

// ------------------- 23 = AND r16,r/m16 ------------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual ands operation, so C and O work like in x86.
//
//
	.global	op_23
op_23:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word and_ax_bxsi, and_ax_bxdi, and_ax_bpsi, and_ax_bpdi, and_ax_siidx, and_ax_diidx, and_ax_disp16, and_ax_bxidx
	.word and_cx_bxsi, and_cx_bxdi, and_cx_bpsi, and_cx_bpdi, and_cx_siidx, and_cx_diidx, and_cx_disp16, and_cx_bxidx
	.word and_dx_bxsi, and_dx_bxdi, and_dx_bpsi, and_dx_bpdi, and_dx_siidx, and_dx_diidx, and_dx_disp16, and_dx_bxidx
	.word and_bx_bxsi, and_bx_bxdi, and_bx_bpsi, and_bx_bpdi, and_bx_siidx, and_bx_diidx, and_bx_disp16, and_bx_bxidx
	.word and_sp_bxsi, and_sp_bxdi, and_sp_bpsi, and_sp_bpdi, and_sp_siidx, and_sp_diidx, and_sp_disp16, and_sp_bxidx
	.word and_bp_bxsi, and_bp_bxdi, and_bp_bpsi, and_bp_bpdi, and_bp_siidx, and_bp_diidx, and_bp_disp16, and_bp_bxidx
	.word and_si_bxsi, and_si_bxdi, and_si_bpsi, and_si_bpdi, and_si_siidx, and_si_diidx, and_si_disp16, and_si_bxidx
	.word and_di_bxsi, and_di_bxdi, and_di_bpsi, and_di_bpdi, and_di_siidx, and_di_diidx, and_di_disp16, and_di_bxidx
//0x40
	.word and_ax_bxsid8, and_ax_bxdid8, and_ax_bpsid8, and_ax_bpdid8, and_ax_sidisp8, and_ax_didisp8, and_ax_bpdisp8, and_ax_bxdisp8
	.word and_cx_bxsid8, and_cx_bxdid8, and_cx_bpsid8, and_cx_bpdid8, and_cx_sidisp8, and_cx_didisp8, and_cx_bpdisp8, and_cx_bxdisp8
	.word and_dx_bxsid8, and_dx_bxdid8, and_dx_bpsid8, and_dx_bpdid8, and_dx_sidisp8, and_dx_didisp8, and_dx_bpdisp8, and_dx_bxdisp8
	.word and_bx_bxsid8, and_bx_bxdid8, and_bx_bpsid8, and_bx_bpdid8, and_bx_sidisp8, and_bx_didisp8, and_bx_bpdisp8, and_bx_bxdisp8
	.word and_sp_bxsid8, and_sp_bxdid8, and_sp_bpsid8, and_sp_bpdid8, and_sp_sidisp8, and_sp_didisp8, and_sp_bpdisp8, and_sp_bxdisp8
	.word and_bp_bxsid8, and_bp_bxdid8, and_bp_bpsid8, and_bp_bpdid8, and_bp_sidisp8, and_bp_didisp8, and_bp_bpdisp8, and_bp_bxdisp8
	.word and_si_bxsid8, and_si_bxdid8, and_si_bpsid8, and_si_bpdid8, and_si_sidisp8, and_si_didisp8, and_si_bpdisp8, and_si_bxdisp8
	.word and_di_bxsid8, and_di_bxdid8, and_di_bpsid8, and_di_bpdid8, and_di_sidisp8, and_di_didisp8, and_di_bpdisp8, and_di_bxdisp8
//0x80
	.word and_ax_bxsid16, and_ax_bxdid16, and_ax_bpsid16, and_ax_bpdid16, and_ax_sidisp16, and_ax_didisp16, and_ax_bpdisp16, and_ax_bxdisp16
	.word and_cx_bxsid16, and_cx_bxdid16, and_cx_bpsid16, and_cx_bpdid16, and_cx_sidisp16, and_cx_didisp16, and_cx_bpdisp16, and_cx_bxdisp16
	.word and_dx_bxsid16, and_dx_bxdid16, and_dx_bpsid16, and_dx_bpdid16, and_dx_sidisp16, and_dx_didisp16, and_dx_bpdisp16, and_dx_bxdisp16
	.word and_bx_bxsid16, and_bx_bxdid16, and_bx_bpsid16, and_bx_bpdid16, and_bx_sidisp16, and_bx_didisp16, and_bx_bpdisp16, and_bx_bxdisp16
	.word and_sp_bxsid16, and_sp_bxdid16, and_sp_bpsid16, and_sp_bpdid16, and_sp_sidisp16, and_sp_didisp16, and_sp_bpdisp16, and_sp_bxdisp16
	.word and_bp_bxsid16, and_bp_bxdid16, and_bp_bpsid16, and_bp_bpdid16, and_bp_sidisp16, and_bp_didisp16, and_bp_bpdisp16, and_bp_bxdisp16
	.word and_si_bxsid16, and_si_bxdid16, and_si_bpsid16, and_si_bpdid16, and_si_sidisp16, and_si_didisp16, and_si_bpdisp16, and_si_bxdisp16
	.word and_di_bxsid16, and_di_bxdid16, and_di_bpsid16, and_di_bpdid16, and_di_sidisp16, and_di_didisp16, and_di_bpdisp16, and_di_bxdisp16
// 0xC0 = two register operands
	.word and_ax_ax, and_ax_cx, and_ax_dx, and_ax_bx, and_ax_sp, and_ax_bp, and_ax_si, and_ax_di
	.word and_cx_ax, and_cx_cx, and_cx_dx, and_cx_bx, and_cx_sp, and_cx_bp, and_cx_si, and_cx_di
	.word and_dx_ax, and_dx_cx, and_dx_dx, and_dx_bx, and_dx_sp, and_dx_bp, and_dx_si, and_dx_di
	.word and_bx_ax, and_bx_cx, and_bx_dx, and_bx_bx, and_bx_sp, and_bx_bp, and_bx_si, and_bx_di
	.word and_sp_ax, and_sp_cx, and_sp_dx, and_sp_bx, and_sp_sp, and_sp_bp, and_sp_si, and_sp_di
	.word and_bp_ax, and_bp_cx, and_bp_dx, and_bp_bx, and_bp_sp, and_bp_bp, and_bp_si, and_bp_di
	.word and_si_ax, and_si_cx, and_si_dx, and_si_bx, and_si_sp, and_si_bp, and_si_si, and_si_di
	.word and_di_ax, and_di_cx, and_di_dx, and_di_bx, and_di_sp, and_di_bp, and_di_si, and_di_di

// These are called from "cpu_67.s":

	.global and_ax_siidx, and_ax_diidx, and_ax_bxidx
	.global and_cx_siidx, and_cx_diidx, and_cx_bxidx
	.global and_dx_siidx, and_dx_diidx, and_dx_bxidx
	.global and_bx_siidx, and_bx_diidx, and_bx_bxidx
	.global and_sp_siidx, and_sp_diidx, and_sp_bxidx
	.global and_bp_siidx, and_bp_diidx, and_bp_bxidx
	.global and_si_siidx, and_si_diidx, and_si_bxidx
	.global and_di_siidx, and_di_diidx, and_di_bxidx
	.global and_ax_sidisp8, and_ax_didisp8, and_ax_bpdisp8, and_ax_bxdisp8
	.global and_cx_sidisp8, and_cx_didisp8, and_cx_bpdisp8, and_cx_bxdisp8
	.global and_dx_sidisp8, and_dx_didisp8, and_dx_bpdisp8, and_dx_bxdisp8
	.global and_bx_sidisp8, and_bx_didisp8, and_bx_bpdisp8, and_bx_bxdisp8
	.global and_sp_sidisp8, and_sp_didisp8, and_sp_bpdisp8, and_sp_bxdisp8
	.global and_bp_sidisp8, and_bp_didisp8, and_bp_bpdisp8, and_bp_bxdisp8
	.global and_si_sidisp8, and_si_didisp8, and_si_bpdisp8, and_si_bxdisp8
	.global and_di_sidisp8, and_di_didisp8, and_di_bpdisp8, and_di_bxdisp8
	.global	and_r16_r0_bp_r4, and_r16_r0_bp_r5, and_r16_r0_bp_r6, and_r16_r0_bp_r7, and_r16_r0_bp_r8, and_r16_r0_bp_r9, and_r16_r0_bp_r10, and_r16_r0_bp_r11
	.global	and_r16_r0_r4, and_r16_r0_r5, and_r16_r0_r6, and_r16_r0_r7, and_r16_r0_r8, and_r16_r0_r9, and_r16_r0_r10, and_r16_r0_r11

.macro and_reg16_r0high reg
and_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
and_r16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_23_RAM_\reg op_23_EGA_\reg op_23_MODEX_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_23_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r3, \reg, lsl #16
	eor		\reg, r3, lsr #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	ands	r0, r3, r0, lsl #16
	orr		\reg, r0, lsr #16
	b		loop
.endm

	and_reg16_r0high r4
	and_reg16_r0high r5
	and_reg16_r0high r6
	and_reg16_r0high r7
	and_reg16_r0high r8
	and_reg16_r0high r9
	and_reg16_r0high r10
	and_reg16_r0high r11

	.ltorg

.macro and_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		and_r16_r0_\reg
.endm

and_ax_bxsi:
	and_reg16_bxidx r4 r10
and_cx_bxsi:
	and_reg16_bxidx r5 r10
and_dx_bxsi:
	and_reg16_bxidx r6 r10
and_bx_bxsi:
	and_reg16_bxidx r7 r10
and_bp_bxsi:
	and_reg16_bxidx r9 r10
and_sp_bxsi:
	and_reg16_bxidx r8 r10
and_si_bxsi:
	and_reg16_bxidx r10 r10
and_di_bxsi:
	and_reg16_bxidx r11 r10

and_ax_bxdi:
	and_reg16_bxidx r4 r11
and_cx_bxdi:
	and_reg16_bxidx r5 r11
and_dx_bxdi:
	and_reg16_bxidx r6 r11
and_bx_bxdi:
	and_reg16_bxidx r7 r11
and_sp_bxdi:
	and_reg16_bxidx r8 r11
and_bp_bxdi:
	and_reg16_bxidx r9 r11
and_si_bxdi:
	and_reg16_bxidx r10 r11
and_di_bxdi:
	and_reg16_bxidx r11 r11

.macro and_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		and_r16_r0_bp_\reg
.endm

and_ax_bpsi:
	and_reg16_bpidx r4 r10
and_cx_bpsi:
	and_reg16_bpidx r5 r10
and_dx_bpsi:
	and_reg16_bpidx r6 r10
and_bx_bpsi:
	and_reg16_bpidx r7 r10
and_sp_bpsi:
	and_reg16_bpidx r8 r10
and_bp_bpsi:
	and_reg16_bpidx r9 r10
and_si_bpsi:
	and_reg16_bpidx r10 r10
and_di_bpsi:
	and_reg16_bpidx r11 r10

and_ax_bpdi:
	and_reg16_bpidx r4 r11
and_cx_bpdi:
	and_reg16_bpidx r5 r11
and_dx_bpdi:
	and_reg16_bpidx r6 r11
and_bx_bpdi:
	and_reg16_bpidx r7 r11
and_sp_bpdi:
	and_reg16_bpidx r8 r11
and_bp_bpdi:
	and_reg16_bpidx r9 r11
and_si_bpdi:
	and_reg16_bpidx r10 r11
and_di_bpdi:
	and_reg16_bpidx r11 r11

.macro and_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		and_r16_r0_\reg
.endm

and_ax_siidx:
	and_reg16_idx r4 r10
and_cx_siidx:
	and_reg16_idx r5 r10
and_dx_siidx:
	and_reg16_idx r6 r10
and_bx_siidx:
	and_reg16_idx r7 r10
and_sp_siidx:
	and_reg16_idx r8 r10
and_bp_siidx:
	and_reg16_idx r9 r10
and_si_siidx:
	and_reg16_idx r10 r10
and_di_siidx:
	and_reg16_idx r11 r10

and_ax_diidx:
	and_reg16_idx r4 r11
and_cx_diidx:
	and_reg16_idx r5 r11
and_dx_diidx:
	and_reg16_idx r6 r11
and_bx_diidx:
	and_reg16_idx r7 r11
and_sp_diidx:
	and_reg16_idx r8 r11
and_bp_diidx:
	and_reg16_idx r9 r11
and_si_diidx:
	and_reg16_idx r10 r11
and_di_diidx:
	and_reg16_idx r11 r11

and_ax_bxidx:
	and_reg16_idx r4 r7
and_cx_bxidx:
	and_reg16_idx r5 r7
and_dx_bxidx:
	and_reg16_idx r6 r7
and_bx_bxidx:
	and_reg16_idx r7 r7
and_sp_bxidx:
	and_reg16_idx r8 r7
and_bp_bxidx:
	and_reg16_idx r9 r7
and_si_bxidx:
	and_reg16_idx r10 r7
and_di_bxidx:
	and_reg16_idx r11 r7

.macro and_reg16_disp16 reg
	r0_from_disp16
	b		and_r16_r0_\reg
.endm

and_ax_disp16:
	and_reg16_disp16 r4
and_cx_disp16:
	and_reg16_disp16 r5
and_dx_disp16:
	and_reg16_disp16 r6
and_bx_disp16:
	and_reg16_disp16 r7
and_sp_disp16:
	and_reg16_disp16 r8
and_bp_disp16:
	and_reg16_disp16 r9
and_si_disp16:
	and_reg16_disp16 r10
and_di_disp16:
	and_reg16_disp16 r11

// --- [idx+disp8] ---

.macro and_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		and_r16_r0_\reg
.endm

and_ax_bxsid8:
	and_reg16_bxidxdisp8 r4 r10
and_cx_bxsid8:
	and_reg16_bxidxdisp8 r5 r10
and_dx_bxsid8:
	and_reg16_bxidxdisp8 r6 r10
and_bx_bxsid8:
	and_reg16_bxidxdisp8 r7 r10
and_sp_bxsid8:
	and_reg16_bxidxdisp8 r8 r10
and_bp_bxsid8:
	and_reg16_bxidxdisp8 r9 r10
and_si_bxsid8:
	and_reg16_bxidxdisp8 r10 r10
and_di_bxsid8:
	and_reg16_bxidxdisp8 r11 r10

and_ax_bxdid8:
	and_reg16_bxidxdisp8 r4 r11
and_cx_bxdid8:
	and_reg16_bxidxdisp8 r5 r11
and_dx_bxdid8:
	and_reg16_bxidxdisp8 r6 r11
and_bx_bxdid8:
	and_reg16_bxidxdisp8 r7 r11
and_sp_bxdid8:
	and_reg16_bxidxdisp8 r8 r11
and_bp_bxdid8:
	and_reg16_bxidxdisp8 r9 r11
and_si_bxdid8:
	and_reg16_bxidxdisp8 r10 r11
and_di_bxdid8:
	and_reg16_bxidxdisp8 r11 r11

.macro and_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		and_r16_r0_bp_\reg
.endm

and_ax_bpsid8:
	and_reg16_bpidxdisp8 r4 r10
and_cx_bpsid8:
	and_reg16_bpidxdisp8 r5 r10
and_dx_bpsid8:
	and_reg16_bpidxdisp8 r6 r10
and_bx_bpsid8:
	and_reg16_bpidxdisp8 r7 r10
and_sp_bpsid8:
	and_reg16_bpidxdisp8 r8 r10
and_bp_bpsid8:
	and_reg16_bpidxdisp8 r9 r10
and_si_bpsid8:
	and_reg16_bpidxdisp8 r10 r10
and_di_bpsid8:
	and_reg16_bpidxdisp8 r11 r10

and_ax_bpdid8:
	and_reg16_bpidxdisp8 r4 r11
and_cx_bpdid8:
	and_reg16_bpidxdisp8 r5 r11
and_dx_bpdid8:
	and_reg16_bpidxdisp8 r6 r11
and_bx_bpdid8:
	and_reg16_bpidxdisp8 r7 r11
and_sp_bpdid8:
	and_reg16_bpidxdisp8 r8 r11
and_bp_bpdid8:
	and_reg16_bpidxdisp8 r9 r11
and_si_bpdid8:
	and_reg16_bpidxdisp8 r10 r11
and_di_bpdid8:
	and_reg16_bpidxdisp8 r11 r11

.macro and_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		and_r16_r0_\reg
.endm

and_ax_sidisp8:
	and_reg16_idxdisp8 r4 r10
and_cx_sidisp8:
	and_reg16_idxdisp8 r5 r10
and_dx_sidisp8:
	and_reg16_idxdisp8 r6 r10
and_bx_sidisp8:
	and_reg16_idxdisp8 r7 r10
and_sp_sidisp8:
	and_reg16_idxdisp8 r8 r10
and_bp_sidisp8:
	and_reg16_idxdisp8 r9 r10
and_si_sidisp8:
	and_reg16_idxdisp8 r10 r10
and_di_sidisp8:
	and_reg16_idxdisp8 r11 r10

and_ax_didisp8:
	and_reg16_idxdisp8 r4 r11
and_cx_didisp8:
	and_reg16_idxdisp8 r5 r11
and_dx_didisp8:
	and_reg16_idxdisp8 r6 r11
and_bx_didisp8:
	and_reg16_idxdisp8 r7 r11
and_sp_didisp8:
	and_reg16_idxdisp8 r8 r11
and_bp_didisp8:
	and_reg16_idxdisp8 r9 r11
and_si_didisp8:
	and_reg16_idxdisp8 r10 r11
and_di_didisp8:
	and_reg16_idxdisp8 r11 r11

and_ax_bxdisp8:
	and_reg16_idxdisp8 r4 r7
and_cx_bxdisp8:
	and_reg16_idxdisp8 r5 r7
and_dx_bxdisp8:
	and_reg16_idxdisp8 r6 r7
and_bx_bxdisp8:
	and_reg16_idxdisp8 r7 r7
and_sp_bxdisp8:
	and_reg16_idxdisp8 r8 r7
and_bp_bxdisp8:
	and_reg16_idxdisp8 r9 r7
and_si_bxdisp8:
	and_reg16_idxdisp8 r10 r7
and_di_bxdisp8:
	and_reg16_idxdisp8 r11 r7

.macro and_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		and_r16_r0_bp_\reg
.endm

and_ax_bpdisp8:
	and_reg16_bpdisp8 r4
and_cx_bpdisp8:
	and_reg16_bpdisp8 r5
and_dx_bpdisp8:
	and_reg16_bpdisp8 r6
and_bx_bpdisp8:
	and_reg16_bpdisp8 r7
and_sp_bpdisp8:
	and_reg16_bpdisp8 r8
and_bp_bpdisp8:
	and_reg16_bpdisp8 r9
and_si_bpdisp8:
	and_reg16_bpdisp8 r10
and_di_bpdisp8:
	and_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro and_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		and_r16_r0_\reg
.endm

and_ax_bxsid16:
	and_reg16_bxidxdisp16 r4 r10
and_cx_bxsid16:
	and_reg16_bxidxdisp16 r5 r10
and_dx_bxsid16:
	and_reg16_bxidxdisp16 r6 r10
and_bx_bxsid16:
	and_reg16_bxidxdisp16 r7 r10
and_sp_bxsid16:
	and_reg16_bxidxdisp16 r8 r10
and_bp_bxsid16:
	and_reg16_bxidxdisp16 r9 r10
and_si_bxsid16:
	and_reg16_bxidxdisp16 r10 r10
and_di_bxsid16:
	and_reg16_bxidxdisp16 r11 r10

and_ax_bxdid16:
	and_reg16_bxidxdisp16 r4 r11
and_cx_bxdid16:
	and_reg16_bxidxdisp16 r5 r11
and_dx_bxdid16:
	and_reg16_bxidxdisp16 r6 r11
and_bx_bxdid16:
	and_reg16_bxidxdisp16 r7 r11
and_sp_bxdid16:
	and_reg16_bxidxdisp16 r8 r11
and_bp_bxdid16:
	and_reg16_bxidxdisp16 r9 r11
and_si_bxdid16:
	and_reg16_bxidxdisp16 r10 r11
and_di_bxdid16:
	and_reg16_bxidxdisp16 r11 r11

.macro and_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		and_r16_r0_bp_\reg
.endm

and_ax_bpsid16:
	and_reg16_bpidxdisp16 r4 r10
and_cx_bpsid16:
	and_reg16_bpidxdisp16 r5 r10
and_dx_bpsid16:
	and_reg16_bpidxdisp16 r6 r10
and_bx_bpsid16:
	and_reg16_bpidxdisp16 r7 r10
and_sp_bpsid16:
	and_reg16_bpidxdisp16 r8 r10
and_bp_bpsid16:
	and_reg16_bpidxdisp16 r9 r10
and_si_bpsid16:
	and_reg16_bpidxdisp16 r10 r10
and_di_bpsid16:
	and_reg16_bpidxdisp16 r11 r10

and_ax_bpdid16:
	and_reg16_bpidxdisp16 r4 r11
and_cx_bpdid16:
	and_reg16_bpidxdisp16 r5 r11
and_dx_bpdid16:
	and_reg16_bpidxdisp16 r6 r11
and_bx_bpdid16:
	and_reg16_bpidxdisp16 r7 r11
and_sp_bpdid16:
	and_reg16_bpidxdisp16 r8 r11
and_bp_bpdid16:
	and_reg16_bpidxdisp16 r9 r11
and_si_bpdid16:
	and_reg16_bpidxdisp16 r10 r11
and_di_bpdid16:
	and_reg16_bpidxdisp16 r11 r11

.macro and_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		and_r16_r0_\reg
.endm

and_ax_sidisp16:
	and_reg16_idxdisp16 r4 r10
and_cx_sidisp16:
	and_reg16_idxdisp16 r5 r10
and_dx_sidisp16:
	and_reg16_idxdisp16 r6 r10
and_bx_sidisp16:
	and_reg16_idxdisp16 r7 r10
and_sp_sidisp16:
	and_reg16_idxdisp16 r8 r10
and_bp_sidisp16:
	and_reg16_idxdisp16 r9 r10
and_si_sidisp16:
	and_reg16_idxdisp16 r10 r10
and_di_sidisp16:
	and_reg16_idxdisp16 r11 r10

and_ax_didisp16:
	and_reg16_idxdisp16 r4 r11
and_cx_didisp16:
	and_reg16_idxdisp16 r5 r11
and_dx_didisp16:
	and_reg16_idxdisp16 r6 r11
and_bx_didisp16:
	and_reg16_idxdisp16 r7 r11
and_sp_didisp16:
	and_reg16_idxdisp16 r8 r11
and_bp_didisp16:
	and_reg16_idxdisp16 r9 r11
and_si_didisp16:
	and_reg16_idxdisp16 r10 r11
and_di_didisp16:
	and_reg16_idxdisp16 r11 r11

and_ax_bxdisp16:
	and_reg16_idxdisp16 r4 r7
and_cx_bxdisp16:
	and_reg16_idxdisp16 r5 r7
and_dx_bxdisp16:
	and_reg16_idxdisp16 r6 r7
and_bx_bxdisp16:
	and_reg16_idxdisp16 r7 r7
and_sp_bxdisp16:
	and_reg16_idxdisp16 r8 r7
and_bp_bxdisp16:
	and_reg16_idxdisp16 r9 r7
and_si_bxdisp16:
	and_reg16_idxdisp16 r10 r7
and_di_bxdisp16:
	and_reg16_idxdisp16 r11 r7

.macro and_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		and_r16_r0_bp_\reg
.endm

and_ax_bpdisp16:
	and_reg16_bpdisp16 r4
and_cx_bpdisp16:
	and_reg16_bpdisp16 r5
and_dx_bpdisp16:
	and_reg16_bpdisp16 r6
and_bx_bpdisp16:
	and_reg16_bpdisp16 r7
and_sp_bpdisp16:
	and_reg16_bpdisp16 r8
and_bp_bpdisp16:
	and_reg16_bpdisp16 r9
and_si_bpdisp16:
	and_reg16_bpdisp16 r10
and_di_bpdisp16:
	and_reg16_bpdisp16 r11


// --- OR reg16, reg16 ---

.macro and_reg16_reg16 rl rr
	mov		r0, \rl, lsl #16
	mov		r1, \rr, lsl #16
	eor		\rl, r0, lsr #16
	ands	r0, r1
	orr		\rl, r0, lsr #16
	b		loop
.endm

and_ax_ax:
	and_reg16_reg16		r4 r4
and_ax_cx:
	and_reg16_reg16		r4 r5
and_ax_dx:
	and_reg16_reg16		r4 r6
and_ax_bx:
	and_reg16_reg16		r4 r7
and_ax_sp:
	and_reg16_reg16		r4 r8
and_ax_bp:
	and_reg16_reg16		r4 r9
and_ax_si:
	and_reg16_reg16		r4 r10
and_ax_di:
	and_reg16_reg16		r4 r11
and_cx_ax:
	and_reg16_reg16		r5 r4
and_cx_cx:
	and_reg16_reg16		r5 r5
and_cx_dx:
	and_reg16_reg16		r5 r6
and_cx_bx:
	and_reg16_reg16		r5 r7
and_cx_sp:
	and_reg16_reg16		r5 r8
and_cx_bp:
	and_reg16_reg16		r5 r9
and_cx_si:
	and_reg16_reg16		r5 r10
and_cx_di:
	and_reg16_reg16		r5 r11
and_dx_ax:
	and_reg16_reg16		r6 r4
and_dx_cx:
	and_reg16_reg16		r6 r5
and_dx_dx:
	and_reg16_reg16		r6 r6
and_dx_bx:
	and_reg16_reg16		r6 r7
and_dx_sp:
	and_reg16_reg16		r6 r8
and_dx_bp:
	and_reg16_reg16		r6 r9
and_dx_si:
	and_reg16_reg16		r6 r10
and_dx_di:
	and_reg16_reg16		r6 r11
and_bx_ax:
	and_reg16_reg16		r7 r4
and_bx_cx:
	and_reg16_reg16		r7 r5
and_bx_dx:
	and_reg16_reg16		r7 r6
and_bx_bx:
	and_reg16_reg16		r7 r7
and_bx_sp:
	and_reg16_reg16		r7 r8
and_bx_bp:
	and_reg16_reg16		r7 r9
and_bx_si:
	and_reg16_reg16		r7 r10
and_bx_di:
	and_reg16_reg16		r7 r11

and_sp_ax:
	and_reg16_reg16		r8 r4
and_sp_cx:
	and_reg16_reg16		r8 r5
and_sp_dx:
	and_reg16_reg16		r8 r6
and_sp_bx:
	and_reg16_reg16		r8 r7
and_sp_sp:
	and_reg16_reg16		r8 r8
and_sp_bp:
	and_reg16_reg16		r8 r9
and_sp_si:
	and_reg16_reg16		r8 r10
and_sp_di:
	and_reg16_reg16		r8 r11

and_bp_ax:
	and_reg16_reg16		r9 r4
and_bp_cx:
	and_reg16_reg16		r9 r5
and_bp_dx:
	and_reg16_reg16		r9 r6
and_bp_bx:
	and_reg16_reg16		r9 r7
and_bp_sp:
	and_reg16_reg16		r9 r8
and_bp_bp:
	and_reg16_reg16		r9 r9
and_bp_si:
	and_reg16_reg16		r9 r10
and_bp_di:
	and_reg16_reg16		r9 r11
and_si_ax:
	and_reg16_reg16		r10 r4
and_si_cx:
	and_reg16_reg16		r10 r5
and_si_dx:
	and_reg16_reg16		r10 r6
and_si_bx:
	and_reg16_reg16		r10 r7
and_si_sp:
	and_reg16_reg16		r10 r8
and_si_bp:
	and_reg16_reg16		r10 r9
and_si_si:
	and_reg16_reg16		r10 r10
and_si_di:
	and_reg16_reg16		r10 r11
and_di_ax:
	and_reg16_reg16		r11 r4
and_di_cx:
	and_reg16_reg16		r11 r5
and_di_dx:
	and_reg16_reg16		r11 r6
and_di_bx:
	and_reg16_reg16		r11 r7
and_di_sp:
	and_reg16_reg16		r11 r8
and_di_bp:
	and_reg16_reg16		r11 r9
and_di_si:
	and_reg16_reg16		r11 r10
and_di_di:
	and_reg16_reg16		r11 r11


#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

// ------------------- 24 = AND AL, imm8 ------------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual ands operation, so C and O work like in x86.
//
op_24:
	ldrb	r1,[r12],#1				// Load byte to r1, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r0, eax, lsl #24
	ands	r0, r1, lsl #24			// Perform the AND
	bic		eax, #0xFF
	orr		eax, r0, lsr #24		// Put the result to AL
	//-------
	// Save the resulting byte (for possible later parity check)
	//-------
	strb	eax, [sp, #SP_PARITY_BYTE]	// For "Chess Genius 3", save the parity byte to stack.
	b		loop

// ------------------- 25 = AND AX, imm16 ------------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual ands operation, so C and O work like in x86.
//
op_25:
	ldrb	r1,[r12],#1				// Load byte to r1, increment r12 by 1
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	orr		r0, r1, r0, lsl #8		// r0 = low byte | (high byte << 8)
	mov		r1, eax, lsl #16
	eor		eax, r1, lsr #16
	ands	r0, r1, r0, lsl #16
	orr		eax, r0, lsr #16
	b		loop

// ------------------- Segment Overrides using "opcodetable_16_16" -----------------------

op_26:
	ldr		r2, [sp, #SP_ES_BASE]				// r2 = current effective logical ES segment
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	mov		lr, r2
	add		r1, pc, #(3+5*5)*4					// (opcodetable_16_16 - 8 - .)
	ldr		pc,[r1, r0, lsl #2]					// Jump to the handler

op_2e:
	ldr		r2, [sp, #SP_CS_BASE]				// r2 = current effective logical CS segment
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	mov		lr, r2
	add		r1, pc, #(3+4*5)*4					// (opcodetable_16_16 - 8 - .)
	ldr		pc,[r1, r0, lsl #2]					// Jump to the handler

op_36:
	ldr		r2, [sp, #SP_SS_BASE]				// r2 = current effective logical SS segment
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	mov		lr, r2
	add		r1, pc, #(3+3*5)*4					// (opcodetable_16_16 - 8 - .)
	ldr		pc,[r1, r0, lsl #2]					// Jump to the handler

op_3e:
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	ldr		r2, [sp, #SP_DS_BASE]				// r2 = logical DS segment in high halfword
	mov		lr, r2
	add		r1, pc, #(3+2*5)*4					// (opcodetable_16_16 - 8 - .)
	ldr		pc,[r1, r0, lsl #2]					// Jump to the handler

op_64:
	ldr		r2, [sp, #SP_FS_BASE]				// r2 = current effective logical GS segment
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	mov		lr, r2
	add		r1, pc, #(3+1*5)*4					// (opcodetable_16_16 - 8 - .)
	ldr		pc,[r1, r0, lsl #2]					// Jump to the handler

op_65:
	ldr		r2, [sp, #SP_GS_BASE]				// r2 = current effective logical GS segment
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1
	mov		lr, r2
	add		r1, pc, #(3+0*5)*4					// (opcodetable_16_16 - 8 - .)
	ldr		pc,[r1, r0, lsl #2]					// Jump to the handler


// ------------------- 6667 = Operand- and Address-size Prefixes -------
	.global	op_66_67_USE32
op_66_67_USE32:
	ldrb	r0,[r12],#1							// Load the second opcode byte to r0, increment r12 by 1
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0
	//---------------------------------------------
	// Operand Size = 16bit, Address Size = 16bit
	//---------------------------------------------
	.global	opcodetable_16_16					// Also used from "cpu_prot.S" when returning to real mode
opcodetable_16_16:
// 0
	.word op_00, op_01, op_02, op_03, op_04, op_05, op_06, op_07
	.word op_08, op_09, op_0a, op_0b, op_0c, op_0d, op_0e, op_0f
	.word op_10, op_11, op_12, op_13, op_14, op_15, op_16, op_17
	.word op_18, op_19, op_1a, op_1b, op_1c, op_1d, op_1e, op_1f
	.word op_20, op_21, op_22, op_23, op_24, op_25, op_26, op_27
	.word op_28, op_29, op_2a, op_2b, op_2c, op_2d, op_2e, op_2f
	.word op_30, op_31, op_32, op_33, op_34, op_35, op_36, op_37
	.word op_38, op_39, op_3a, op_3b, op_3c, op_3d, op_3e, op_3f
// 0x40
	.word op_40, op_41, op_42, op_43, op_44, op_45, op_46, op_47
	.word op_48, op_49, op_4a, op_4b, op_4c, op_4d, op_4e, op_4f
	.word op_50, op_51, op_52, op_53, op_54, op_55, op_56, op_57
	.word op_58, op_59, op_5a, op_5b, op_5c, op_5d, op_5e, op_5f
	.word op_60, op_61, .unknown, .unknown, op_64, op_65, op_66_USE16, op_67_USE16
	.word op_68, op_69, op_6a, op_6b, op_6c_insb, .unknown, op_6e_outsb, op_6f_outsw
	.word op_70, op_71, op_72, op_73, op_74, op_75, op_76, op_77
	.word op_78, op_79, op_7a, op_7b, op_7c, op_7d, op_7e, op_7f
// 0x80
	.word op_80, op_81, op_82, op_83, op_84, op_85, op_86, op_87
	.word op_88, op_89, op_8a, op_8b, op_8c, op_8d, op_8e, op_8f
	.word loop, xchg_ax_cx, xchg_ax_dx, xchg_ax_bx, xchg_ax_sp, xchg_ax_bp, xchg_ax_si, xchg_ax_di
	.word op_98, op_99, op_9a, loop, op_9c, op_9d, op_9e, op_9f
	.word op_a0, op_a1, op_a2, op_a3, op_a4_movsb, op_a5_movsw, op_a6_cmpsb, op_a7_cmpsw
	.word op_a8, op_a9, op_aa_stosb, op_ab_stosw, op_ac_lodsb, op_ad_lodsw, op_ae_scasb, op_af_scasw
	.word op_b0, op_b1, op_b2, op_b3, op_b4, op_b5, op_b6, op_b7
	.word op_b8, op_b9, op_ba, op_bb, op_bc, op_bd, op_be, op_bf
// 0xC0
	.word op_c0, op_c1, op_c2, op_c3, op_c4, op_c5, op_c6, op_c7
	.word op_c8, op_c9, op_ca, op_cb, op_cc, op_cd, op_ce, op_cf
	.word op_d0, op_d1, op_d2, op_d3, op_d4, op_d5, op_d6, op_d7
	.word op_d8, op_d9, op_da, op_db, op_dc, op_dd, op_de, op_df
	.word op_e0, op_e1, op_e2, op_e3, op_e4_in_al_imm8, op_e5_in_ax_imm8, op_e6_out_imm8_al, op_e7_out_imm8_ax
	.word op_e8, op_e9, op_ea, op_eb, op_ec_in_al_dx, op_ed_in_ax_dx, op_ee_out_dx_al, op_ef_out_dx_ax
	.word loop, .unknown, op_f2, op_f3, op_f4, op_f5, op_f6, op_f7
	.word op_f8, op_f9, op_fa_CLI, op_fb_STI, op_fc, op_fd, op_fe, op_ff

	.text
	.align 2

// ------------------- 27 = DAA ----------------------------------------
// Weird BCD opcode.
//
// if(AL & 0xF > 9 || AF == 1) {
//	CF = OldCF | GetCarry(AL = AL + 6);
//	AF = 1;
// }
// else AF = 0;
//
// if(OldAL > 0x99 || OldCF == 1) {
//	AL = AL + 0x60;
//	CF = 1;
// }
// else CF = 0;
//
	.global	op_27
op_27:
	ldr		r2, [sp, #SP_FLAGS]					// r2 = current x86 flags (for FLAG_AF)
	mrs		r0, cpsr							// r0 = current ARM flags (for other flags)
	and		r1, eax, #0x0F						//	if (((reg_al & 0x0F)>0x09) || get_AF()) {
	cmp		r1, #0x09
	and		r1, eax, #0xFF						// r1 = AL value
	bgt		1f
	tst		r2, #FLAG_AF
	beq		2f
1:	
	cmp		r1, #0x99							//		if ((reg_al > 0x99) || get_CF()) {
	bgt		6f
	tst		r0, #ARM_CARRY
	beq		7f
6:	add		r1, #0x60							//			reg_al+=0x60;
	orr		r0, #ARM_CARRY						//			SETFLAGBIT(CF,true);
	b		8f									//		} else
7:	bic		r0, #ARM_CARRY						//			SETFLAGBIT(CF,false);
8:	add		r1, #0x06							//		reg_al+=0x06;
	orr		r2, #FLAG_AF						//		SETFLAGBIT(AF,true);
	b		9f									//	} else {
	
2:	cmp		r1, #0x99							//		if ((reg_al > 0x99) || get_CF()) {
	bgt		3f
	tst		r0, #ARM_CARRY
	beq		4f
3:	add		r1, #0x60							//			reg_al+=0x60;
	orr		r0, #ARM_CARRY						//			SETFLAGBIT(CF,true);
	b		5f									//		} else
4:	bic		r0, #ARM_CARRY						//			SETFLAGBIT(CF,false);
5:	bic		r2, #FLAG_AF						//		SETFLAGBIT(AF,false);
9:	bic		r0, #(ARM_ZERO|ARM_NEG)
	//------
	// SETFLAGBIT(ZF,(reg_al==0));
	//------
	ands	r1, #0xFF
	orreq	r0, #ARM_ZERO
	//------
	// SETFLAGBIT(SF,(reg_al&0x80));
	//------
	tst		r1, #0x80
	orrne	r0, #ARM_NEG
	//------
	// SETFLAGBIT(PF,parity_lookup[reg_al]);
	//------
	//------
	// Put the result into EAX low byte
	//------
	bic		eax, #0xFF
	orr		eax, r1
	str		r2, [sp, #SP_FLAGS]					// Save new x86 flags (for FLAG_AF)
	b		restore_flags_from_r0

// ------------------- 28 = SUB r/m8, r8 -----------------------------
//
// All modrm variations supported!
//
//
op_28:
	modrm_jump_16
// 0
	.word sub_bxsi_al, sub_bxdi_al, sub_bpsi_al, sub_bpdi_al, sub_siidx_al, sub_diidx_al, sub_disp16_al, sub_bxidx_al
	.word sub_bxsi_cl, sub_bxdi_cl, sub_bpsi_cl, sub_bpdi_cl, sub_siidx_cl, sub_diidx_cl, sub_disp16_cl, sub_bxidx_cl
	.word sub_bxsi_dl, sub_bxdi_dl, sub_bpsi_dl, sub_bpdi_dl, sub_siidx_dl, sub_diidx_dl, sub_disp16_dl, sub_bxidx_dl
	.word sub_bxsi_bl, sub_bxdi_bl, sub_bpsi_bl, sub_bpdi_bl, sub_siidx_bl, sub_diidx_bl, sub_disp16_bl, sub_bxidx_bl
	.word sub_bxsi_ah, sub_bxdi_ah, sub_bpsi_ah, sub_bpdi_ah, sub_siidx_ah, sub_diidx_ah, sub_disp16_ah, sub_bxidx_ah
	.word sub_bxsi_ch, sub_bxdi_ch, sub_bpsi_ch, sub_bpdi_ch, sub_siidx_ch, sub_diidx_ch, sub_disp16_ch, sub_bxidx_ch
	.word sub_bxsi_dh, sub_bxdi_dh, sub_bpsi_dh, sub_bpdi_dh, sub_siidx_dh, sub_diidx_dh, sub_disp16_dh, sub_bxidx_dh
	.word sub_bxsi_bh, sub_bxdi_bh, sub_bpsi_bh, sub_bpdi_bh, sub_siidx_bh, sub_diidx_bh, sub_disp16_bh, sub_bxidx_bh
//0x40
	.word sub_bxsid8_al, sub_bxdid8_al, sub_bpsid8_al, sub_bpdid8_al, sub_sidisp8_al, sub_didisp8_al, sub_bpdisp8_al, sub_bxdisp8_al
	.word sub_bxsid8_cl, sub_bxdid8_cl, sub_bpsid8_cl, sub_bpdid8_cl, sub_sidisp8_cl, sub_didisp8_cl, sub_bpdisp8_cl, sub_bxdisp8_cl
	.word sub_bxsid8_dl, sub_bxdid8_dl, sub_bpsid8_dl, sub_bpdid8_dl, sub_sidisp8_dl, sub_didisp8_dl, sub_bpdisp8_dl, sub_bxdisp8_dl
	.word sub_bxsid8_bl, sub_bxdid8_bl, sub_bpsid8_bl, sub_bpdid8_bl, sub_sidisp8_bl, sub_didisp8_bl, sub_bpdisp8_bl, sub_bxdisp8_bl
	.word sub_bxsid8_ah, sub_bxdid8_ah, sub_bpsid8_ah, sub_bpdid8_ah, sub_sidisp8_ah, sub_didisp8_ah, sub_bpdisp8_ah, sub_bxdisp8_ah
	.word sub_bxsid8_ch, sub_bxdid8_ch, sub_bpsid8_ch, sub_bpdid8_ch, sub_sidisp8_ch, sub_didisp8_ch, sub_bpdisp8_ch, sub_bxdisp8_ch
	.word sub_bxsid8_dh, sub_bxdid8_dh, sub_bpsid8_dh, sub_bpdid8_dh, sub_sidisp8_dh, sub_didisp8_dh, sub_bpdisp8_dh, sub_bxdisp8_dh
	.word sub_bxsid8_bh, sub_bxdid8_bh, sub_bpsid8_bh, sub_bpdid8_bh, sub_sidisp8_bh, sub_didisp8_bh, sub_bpdisp8_bh, sub_bxdisp8_bh
//0x80
	.word sub_bxsid16_al, sub_bxdid16_al, sub_bpsid16_al, sub_bpdid16_al, sub_sidisp16_al, sub_didisp16_al, sub_bpdisp16_al, sub_bxdisp16_al
	.word sub_bxsid16_cl, sub_bxdid16_cl, sub_bpsid16_cl, sub_bpdid16_cl, sub_sidisp16_cl, sub_didisp16_cl, sub_bpdisp16_cl, sub_bxdisp16_cl
	.word sub_bxsid16_dl, sub_bxdid16_dl, sub_bpsid16_dl, sub_bpdid16_dl, sub_sidisp16_dl, sub_didisp16_dl, sub_bpdisp16_dl, sub_bxdisp16_dl
	.word sub_bxsid16_bl, sub_bxdid16_bl, sub_bpsid16_bl, sub_bpdid16_bl, sub_sidisp16_bl, sub_didisp16_bl, sub_bpdisp16_bl, sub_bxdisp16_bl
	.word sub_bxsid16_ah, sub_bxdid16_ah, sub_bpsid16_ah, sub_bpdid16_ah, sub_sidisp16_ah, sub_didisp16_ah, sub_bpdisp16_ah, sub_bxdisp16_ah
	.word sub_bxsid16_ch, sub_bxdid16_ch, sub_bpsid16_ch, sub_bpdid16_ch, sub_sidisp16_ch, sub_didisp16_ch, sub_bpdisp16_ch, sub_bxdisp16_ch
	.word sub_bxsid16_dh, sub_bxdid16_dh, sub_bpsid16_dh, sub_bpdid16_dh, sub_sidisp16_dh, sub_didisp16_dh, sub_bpdisp16_dh, sub_bxdisp16_dh
	.word sub_bxsid16_bh, sub_bxdid16_bh, sub_bpsid16_bh, sub_bpdid16_bh, sub_sidisp16_bh, sub_didisp16_bh, sub_bpdisp16_bh, sub_bxdisp16_bh
// 0xC0 = two register operands
	.word sub_al_al, sub_cl_al, sub_dl_al, sub_bl_al, sub_ah_al, sub_ch_al, sub_dh_al, sub_bh_al
	.word sub_al_cl, sub_cl_cl, sub_dl_cl, sub_bl_cl, sub_ah_cl, sub_ch_cl, sub_dh_cl, sub_bh_cl
	.word sub_al_dl, sub_cl_dl, sub_dl_dl, sub_bl_dl, sub_ah_dl, sub_ch_dl, sub_dh_dl, sub_bh_dl
	.word sub_al_bl, sub_cl_bl, sub_dl_bl, sub_bl_bl, sub_ah_bl, sub_ch_bl, sub_dh_bl, sub_bh_bl
	.word sub_al_ah, sub_cl_ah, sub_dl_ah, sub_bl_ah, sub_ah_ah, sub_ch_ah, sub_dh_ah, sub_bh_ah
	.word sub_al_ch, sub_cl_ch, sub_dl_ch, sub_bl_ch, sub_ah_ch, sub_ch_ch, sub_dh_ch, sub_bh_ch
	.word sub_al_dh, sub_cl_dh, sub_dl_dh, sub_bl_dh, sub_ah_dh, sub_ch_dh, sub_dh_dh, sub_bh_dh
	.word sub_al_bh, sub_cl_bh, sub_dl_bh, sub_bl_bh, sub_ah_bh, sub_ch_bh, sub_dh_bh, sub_bh_bh

// These are called from "cpu_386.s":

	.global	sub_siidx_al, sub_siidx_cl, sub_siidx_dl, sub_siidx_bl, sub_siidx_ah, sub_siidx_ch, sub_siidx_dh, sub_siidx_bh
	.global	sub_diidx_al, sub_diidx_cl, sub_diidx_dl, sub_diidx_bl, sub_diidx_ah, sub_diidx_ch, sub_diidx_dh, sub_diidx_bh
	.global	sub_bxidx_al, sub_bxidx_cl, sub_bxidx_dl, sub_bxidx_bl, sub_bxidx_ah, sub_bxidx_ch, sub_bxidx_dh, sub_bxidx_bh
	.global	sub_sidisp8_al, sub_sidisp8_cl, sub_sidisp8_dl, sub_sidisp8_bl, sub_sidisp8_ah, sub_sidisp8_ch, sub_sidisp8_dh, sub_sidisp8_bh
	.global	sub_didisp8_al, sub_didisp8_cl, sub_didisp8_dl, sub_didisp8_bl, sub_didisp8_ah, sub_didisp8_ch, sub_didisp8_dh, sub_didisp8_bh
	.global	sub_bpdisp8_al, sub_bpdisp8_cl, sub_bpdisp8_dl, sub_bpdisp8_bl, sub_bpdisp8_ah, sub_bpdisp8_ch, sub_bpdisp8_dh, sub_bpdisp8_bh
	.global	sub_bxdisp8_al, sub_bxdisp8_cl, sub_bxdisp8_dl, sub_bxdisp8_bl, sub_bxdisp8_ah, sub_bxdisp8_ch, sub_bxdisp8_dh, sub_bxdisp8_bh

.macro sub_r0_reg8l reg
	.global	sub_r0_r8l_bp_\reg
sub_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	sub_r0_r8l_\reg
sub_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_28_RAM_l_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_28_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	rsbs	r0, r1, r0, lsl #24
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to [physical segment + disp16]
	b		complement_carry
.endm
.macro sub_r0_reg8h reg
	.global	sub_r0_r8h_bp_\reg
sub_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	sub_r0_r8h_\reg
sub_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_28_RAM_h_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_28_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r1, #16
	rsbs	r0, r1, r0, lsl #24
	lsr		r0, #24
	strb	r0,[r2]					// Store byte to RAM
	b		complement_carry
.endm

	sub_r0_reg8l r4
	sub_r0_reg8l r5
	sub_r0_reg8l r6
	sub_r0_reg8l r7
	sub_r0_reg8h r4
	sub_r0_reg8h r5
	sub_r0_reg8h r6
	sub_r0_reg8h r7

	.ltorg

// --- [idx] ---

.macro sub_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		sub_r0_r8l_\reg
.endm
.macro sub_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		sub_r0_r8h_\reg
.endm

sub_bxsi_al:
	sub_bxidx_reg8l r10 r4
sub_bxsi_cl:
	sub_bxidx_reg8l r10 r5
sub_bxsi_dl:
	sub_bxidx_reg8l r10 r6
sub_bxsi_bl:
	sub_bxidx_reg8l r10 r7
sub_bxsi_ah:
	sub_bxidx_reg8h r10 r4
sub_bxsi_ch:
	sub_bxidx_reg8h r10 r5
sub_bxsi_dh:
	sub_bxidx_reg8h r10 r6
sub_bxsi_bh:
	sub_bxidx_reg8h r10 r7

sub_bxdi_al:
	sub_bxidx_reg8l r11 r4
sub_bxdi_cl:
	sub_bxidx_reg8l r11 r5
sub_bxdi_dl:
	sub_bxidx_reg8l r11 r6
sub_bxdi_bl:
	sub_bxidx_reg8l r11 r7
sub_bxdi_ah:
	sub_bxidx_reg8h r11 r4
sub_bxdi_ch:
	sub_bxidx_reg8h r11 r5
sub_bxdi_dh:
	sub_bxidx_reg8h r11 r6
sub_bxdi_bh:
	sub_bxidx_reg8h r11 r7

.macro sub_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		sub_r0_r8l_bp_\reg
.endm
.macro sub_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		sub_r0_r8h_bp_\reg
.endm

sub_bpsi_al:
	sub_bpidx_reg8l r10 r4
sub_bpsi_cl:
	sub_bpidx_reg8l r10 r5
sub_bpsi_dl:
	sub_bpidx_reg8l r10 r6
sub_bpsi_bl:
	sub_bpidx_reg8l r10 r7
sub_bpsi_ah:
	sub_bpidx_reg8h r10 r4
sub_bpsi_ch:
	sub_bpidx_reg8h r10 r5
sub_bpsi_dh:
	sub_bpidx_reg8h r10 r6
sub_bpsi_bh:
	sub_bpidx_reg8h r10 r7

sub_bpdi_al:
	sub_bpidx_reg8l r11 r4
sub_bpdi_cl:
	sub_bpidx_reg8l r11 r5
sub_bpdi_dl:
	sub_bpidx_reg8l r11 r6
sub_bpdi_bl:
	sub_bpidx_reg8l r11 r7
sub_bpdi_ah:
	sub_bpidx_reg8h r11 r4
sub_bpdi_ch:
	sub_bpidx_reg8h r11 r5
sub_bpdi_dh:
	sub_bpidx_reg8h r11 r6
sub_bpdi_bh:
	sub_bpidx_reg8h r11 r7

.macro sub_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		sub_r0_r8l_\reg
.endm
.macro sub_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		sub_r0_r8h_\reg
.endm

sub_siidx_al:
	sub_idx_reg8l r10 r4
sub_siidx_cl:
	sub_idx_reg8l r10 r5
sub_siidx_dl:
	sub_idx_reg8l r10 r6
sub_siidx_bl:
	sub_idx_reg8l r10 r7
sub_siidx_ah:
	sub_idx_reg8h r10 r4
sub_siidx_ch:
	sub_idx_reg8h r10 r5
sub_siidx_dh:
	sub_idx_reg8h r10 r6
sub_siidx_bh:
	sub_idx_reg8h r10 r7

sub_diidx_al:
	sub_idx_reg8l r11 r4
sub_diidx_cl:
	sub_idx_reg8l r11 r5
sub_diidx_dl:
	sub_idx_reg8l r11 r6
sub_diidx_bl:
	sub_idx_reg8l r11 r7
sub_diidx_ah:
	sub_idx_reg8h r11 r4
sub_diidx_ch:
	sub_idx_reg8h r11 r5
sub_diidx_dh:
	sub_idx_reg8h r11 r6
sub_diidx_bh:
	sub_idx_reg8h r11 r7

sub_bxidx_al:
	sub_idx_reg8l r7 r4
sub_bxidx_cl:
	sub_idx_reg8l r7 r5
sub_bxidx_dl:
	sub_idx_reg8l r7 r6
sub_bxidx_bl:
	sub_idx_reg8l r7 r7
sub_bxidx_ah:
	sub_idx_reg8h r7 r4
sub_bxidx_ch:
	sub_idx_reg8h r7 r5
sub_bxidx_dh:
	sub_idx_reg8h r7 r6
sub_bxidx_bh:
	sub_idx_reg8h r7 r7
	
.macro sub_disp16_reg8l reg
	r0_from_disp16
	b		sub_r0_r8l_\reg
.endm

.macro sub_disp16_reg8h reg
	r0_from_disp16
	b		sub_r0_r8h_\reg
.endm

sub_disp16_al:
	sub_disp16_reg8l r4
sub_disp16_cl:
	sub_disp16_reg8l r5
sub_disp16_dl:
	sub_disp16_reg8l r6
sub_disp16_bl:
	sub_disp16_reg8l r7
sub_disp16_ah:
	sub_disp16_reg8h r4
sub_disp16_ch:
	sub_disp16_reg8h r5
sub_disp16_dh:
	sub_disp16_reg8h r6
sub_disp16_bh:
	sub_disp16_reg8h r7

// --- [idx+disp8] ---

.macro sub_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		sub_r0_r8l_\reg
.endm
.macro sub_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		sub_r0_r8h_\reg
.endm

sub_bxsid8_al:
	sub_bxidxd8_reg8l r10 r4
sub_bxsid8_cl:
	sub_bxidxd8_reg8l r10 r5
sub_bxsid8_dl:
	sub_bxidxd8_reg8l r10 r6
sub_bxsid8_bl:
	sub_bxidxd8_reg8l r10 r7
sub_bxsid8_ah:
	sub_bxidxd8_reg8h r10 r4
sub_bxsid8_ch:
	sub_bxidxd8_reg8h r10 r5
sub_bxsid8_dh:
	sub_bxidxd8_reg8h r10 r6
sub_bxsid8_bh:
	sub_bxidxd8_reg8h r10 r7

sub_bxdid8_al:
	sub_bxidxd8_reg8l r11 r4
sub_bxdid8_cl:
	sub_bxidxd8_reg8l r11 r5
sub_bxdid8_dl:
	sub_bxidxd8_reg8l r11 r6
sub_bxdid8_bl:
	sub_bxidxd8_reg8l r11 r7
sub_bxdid8_ah:
	sub_bxidxd8_reg8h r11 r4
sub_bxdid8_ch:
	sub_bxidxd8_reg8h r11 r5
sub_bxdid8_dh:
	sub_bxidxd8_reg8h r11 r6
sub_bxdid8_bh:
	sub_bxidxd8_reg8h r11 r7

.macro sub_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		sub_r0_r8l_bp_\reg
.endm
.macro sub_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		sub_r0_r8h_bp_\reg
.endm

sub_bpsid8_al:
	sub_bpidxd8_reg8l r10 r4
sub_bpsid8_cl:
	sub_bpidxd8_reg8l r10 r5
sub_bpsid8_dl:
	sub_bpidxd8_reg8l r10 r6
sub_bpsid8_bl:
	sub_bpidxd8_reg8l r10 r7
sub_bpsid8_ah:
	sub_bpidxd8_reg8h r10 r4
sub_bpsid8_ch:
	sub_bpidxd8_reg8h r10 r5
sub_bpsid8_dh:
	sub_bpidxd8_reg8h r10 r6
sub_bpsid8_bh:
	sub_bpidxd8_reg8h r10 r7

sub_bpdid8_al:
	sub_bpidxd8_reg8l r11 r4
sub_bpdid8_cl:
	sub_bpidxd8_reg8l r11 r5
sub_bpdid8_dl:
	sub_bpidxd8_reg8l r11 r6
sub_bpdid8_bl:
	sub_bpidxd8_reg8l r11 r7
sub_bpdid8_ah:
	sub_bpidxd8_reg8h r11 r4
sub_bpdid8_ch:
	sub_bpidxd8_reg8h r11 r5
sub_bpdid8_dh:
	sub_bpidxd8_reg8h r11 r6
sub_bpdid8_bh:
	sub_bpidxd8_reg8h r11 r7

.macro sub_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		sub_r0_r8l_\reg
.endm
.macro sub_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		sub_r0_r8h_\reg
.endm

sub_sidisp8_al:
	sub_idxdisp8_reg8l r10 r4
sub_sidisp8_cl:
	sub_idxdisp8_reg8l r10 r5
sub_sidisp8_dl:
	sub_idxdisp8_reg8l r10 r6
sub_sidisp8_bl:
	sub_idxdisp8_reg8l r10 r7
sub_sidisp8_ah:
	sub_idxdisp8_reg8h r10 r4
sub_sidisp8_ch:
	sub_idxdisp8_reg8h r10 r5
sub_sidisp8_dh:
	sub_idxdisp8_reg8h r10 r6
sub_sidisp8_bh:
	sub_idxdisp8_reg8h r10 r7

sub_didisp8_al:
	sub_idxdisp8_reg8l r11 r4
sub_didisp8_cl:
	sub_idxdisp8_reg8l r11 r5
sub_didisp8_dl:
	sub_idxdisp8_reg8l r11 r6
sub_didisp8_bl:
	sub_idxdisp8_reg8l r11 r7
sub_didisp8_ah:
	sub_idxdisp8_reg8h r11 r4
sub_didisp8_ch:
	sub_idxdisp8_reg8h r11 r5
sub_didisp8_dh:
	sub_idxdisp8_reg8h r11 r6
sub_didisp8_bh:
	sub_idxdisp8_reg8h r11 r7

sub_bxdisp8_al:
	sub_idxdisp8_reg8l r7 r4
sub_bxdisp8_cl:
	sub_idxdisp8_reg8l r7 r5
sub_bxdisp8_dl:
	sub_idxdisp8_reg8l r7 r6
sub_bxdisp8_bl:
	sub_idxdisp8_reg8l r7 r7
sub_bxdisp8_ah:
	sub_idxdisp8_reg8h r7 r4
sub_bxdisp8_ch:
	sub_idxdisp8_reg8h r7 r5
sub_bxdisp8_dh:
	sub_idxdisp8_reg8h r7 r6
sub_bxdisp8_bh:
	sub_idxdisp8_reg8h r7 r7

.macro sub_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		sub_r0_r8l_bp_\reg
.endm
.macro sub_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		sub_r0_r8h_bp_\reg
.endm

sub_bpdisp8_al:
	sub_bpdisp8_reg8l r4
sub_bpdisp8_cl:
	sub_bpdisp8_reg8l r5
sub_bpdisp8_dl:
	sub_bpdisp8_reg8l r6
sub_bpdisp8_bl:
	sub_bpdisp8_reg8l r7
sub_bpdisp8_ah:
	sub_bpdisp8_reg8h r4
sub_bpdisp8_ch:
	sub_bpdisp8_reg8h r5
sub_bpdisp8_dh:
	sub_bpdisp8_reg8h r6
sub_bpdisp8_bh:
	sub_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro sub_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		sub_r0_r8l_\reg
.endm
.macro sub_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		sub_r0_r8h_\reg
.endm

sub_bxsid16_al:
	sub_bxidxdisp16_reg8l r10 r4
sub_bxsid16_cl:
	sub_bxidxdisp16_reg8l r10 r5
sub_bxsid16_dl:
	sub_bxidxdisp16_reg8l r10 r6
sub_bxsid16_bl:
	sub_bxidxdisp16_reg8l r10 r7
sub_bxsid16_ah:
	sub_bxidxdisp16_reg8h r10 r4
sub_bxsid16_ch:
	sub_bxidxdisp16_reg8h r10 r5
sub_bxsid16_dh:
	sub_bxidxdisp16_reg8h r10 r6
sub_bxsid16_bh:
	sub_bxidxdisp16_reg8h r10 r7

sub_bxdid16_al:
	sub_bxidxdisp16_reg8l r11 r4
sub_bxdid16_cl:
	sub_bxidxdisp16_reg8l r11 r5
sub_bxdid16_dl:
	sub_bxidxdisp16_reg8l r11 r6
sub_bxdid16_bl:
	sub_bxidxdisp16_reg8l r11 r7
sub_bxdid16_ah:
	sub_bxidxdisp16_reg8h r11 r4
sub_bxdid16_ch:
	sub_bxidxdisp16_reg8h r11 r5
sub_bxdid16_dh:
	sub_bxidxdisp16_reg8h r11 r6
sub_bxdid16_bh:
	sub_bxidxdisp16_reg8h r11 r7

.macro sub_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		sub_r0_r8l_bp_\reg
.endm
.macro sub_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		sub_r0_r8h_bp_\reg
.endm

sub_bpsid16_al:
	sub_bpidxd16_reg8l r10 r4
sub_bpsid16_cl:
	sub_bpidxd16_reg8l r10 r5
sub_bpsid16_dl:
	sub_bpidxd16_reg8l r10 r6
sub_bpsid16_bl:
	sub_bpidxd16_reg8l r10 r7
sub_bpsid16_ah:
	sub_bpidxd16_reg8h r10 r4
sub_bpsid16_ch:
	sub_bpidxd16_reg8h r10 r5
sub_bpsid16_dh:
	sub_bpidxd16_reg8h r10 r6
sub_bpsid16_bh:
	sub_bpidxd16_reg8h r10 r7

sub_bpdid16_al:
	sub_bpidxd16_reg8l r11 r4
sub_bpdid16_cl:
	sub_bpidxd16_reg8l r11 r5
sub_bpdid16_dl:
	sub_bpidxd16_reg8l r11 r6
sub_bpdid16_bl:
	sub_bpidxd16_reg8l r11 r7
sub_bpdid16_ah:
	sub_bpidxd16_reg8h r11 r4
sub_bpdid16_ch:
	sub_bpidxd16_reg8h r11 r5
sub_bpdid16_dh:
	sub_bpidxd16_reg8h r11 r6
sub_bpdid16_bh:
	sub_bpidxd16_reg8h r11 r7

.macro sub_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		sub_r0_r8l_\reg
.endm
.macro sub_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		sub_r0_r8h_\reg
.endm

sub_sidisp16_al:
	sub_idxdisp16_reg8l r10 r4
sub_sidisp16_cl:
	sub_idxdisp16_reg8l r10 r5
sub_sidisp16_dl:
	sub_idxdisp16_reg8l r10 r6
sub_sidisp16_bl:
	sub_idxdisp16_reg8l r10 r7
sub_sidisp16_ah:
	sub_idxdisp16_reg8h r10 r4
sub_sidisp16_ch:
	sub_idxdisp16_reg8h r10 r5
sub_sidisp16_dh:
	sub_idxdisp16_reg8h r10 r6
sub_sidisp16_bh:
	sub_idxdisp16_reg8h r10 r7

sub_didisp16_al:
	sub_idxdisp16_reg8l r11 r4
sub_didisp16_cl:
	sub_idxdisp16_reg8l r11 r5
sub_didisp16_dl:
	sub_idxdisp16_reg8l r11 r6
sub_didisp16_bl:
	sub_idxdisp16_reg8l r11 r7
sub_didisp16_ah:
	sub_idxdisp16_reg8h r11 r4
sub_didisp16_ch:
	sub_idxdisp16_reg8h r11 r5
sub_didisp16_dh:
	sub_idxdisp16_reg8h r11 r6
sub_didisp16_bh:
	sub_idxdisp16_reg8h r11 r7

sub_bxdisp16_al:
	sub_idxdisp16_reg8l r7 r4
sub_bxdisp16_cl:
	sub_idxdisp16_reg8l r7 r5
sub_bxdisp16_dl:
	sub_idxdisp16_reg8l r7 r6
sub_bxdisp16_bl:
	sub_idxdisp16_reg8l r7 r7
sub_bxdisp16_ah:
	sub_idxdisp16_reg8h r7 r4
sub_bxdisp16_ch:
	sub_idxdisp16_reg8h r7 r5
sub_bxdisp16_dh:
	sub_idxdisp16_reg8h r7 r6
sub_bxdisp16_bh:
	sub_idxdisp16_reg8h r7 r7

.macro sub_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		sub_r0_r8l_bp_\reg
.endm
.macro sub_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		sub_r0_r8h_bp_\reg
.endm

sub_bpdisp16_al:
	sub_bpdisp16_reg8l r4
sub_bpdisp16_cl:
	sub_bpdisp16_reg8l r5
sub_bpdisp16_dl:
	sub_bpdisp16_reg8l r6
sub_bpdisp16_bl:
	sub_bpdisp16_reg8l r7
sub_bpdisp16_ah:
	sub_bpdisp16_reg8h r4
sub_bpdisp16_ch:
	sub_bpdisp16_reg8h r5
sub_bpdisp16_dh:
	sub_bpdisp16_reg8h r6
sub_bpdisp16_bh:
	sub_bpdisp16_reg8h r7


// ------------------- 29 = SUB r/m16, r16 -----------------------------
//
// All modrm variations supported!
//
//
op_29:
	modrm_jump_16
// 0
	.word sub_bxsi_ax, sub_bxdi_ax, sub_bpsi_ax, sub_bpdi_ax, sub_siidx_ax, sub_diidx_ax, sub_disp16_ax, sub_bxidx_ax
	.word sub_bxsi_cx, sub_bxdi_cx, sub_bpsi_cx, sub_bpdi_cx, sub_siidx_cx, sub_diidx_cx, sub_disp16_cx, sub_bxidx_cx
	.word sub_bxsi_dx, sub_bxdi_dx, sub_bpsi_dx, sub_bpdi_dx, sub_siidx_dx, sub_diidx_dx, sub_disp16_dx, sub_bxidx_dx
	.word sub_bxsi_bx, sub_bxdi_bx, sub_bpsi_bx, sub_bpdi_bx, sub_siidx_bx, sub_diidx_bx, sub_disp16_bx, sub_bxidx_bx
	.word sub_bxsi_sp, sub_bxdi_sp, sub_bpsi_sp, sub_bpdi_sp, sub_siidx_sp, sub_diidx_sp, sub_disp16_sp, sub_bxidx_sp
	.word sub_bxsi_bp, sub_bxdi_bp, sub_bpsi_bp, sub_bpdi_bp, sub_siidx_bp, sub_diidx_bp, sub_disp16_bp, sub_bxidx_bp
	.word sub_bxsi_si, sub_bxdi_si, sub_bpsi_si, sub_bpdi_si, sub_siidx_si, sub_diidx_si, sub_disp16_si, sub_bxidx_si
	.word sub_bxsi_di, sub_bxdi_di, sub_bpsi_di, sub_bpdi_di, sub_siidx_di, sub_diidx_di, sub_disp16_di, sub_bxidx_di
//0x40
	.word sub_bxsid8_ax, sub_bxdid8_ax, sub_bpsid8_ax, sub_bpdid8_ax, sub_sidisp8_ax, sub_didisp8_ax, sub_bpdisp8_ax, sub_bxdisp8_ax
	.word sub_bxsid8_cx, sub_bxdid8_cx, sub_bpsid8_cx, sub_bpdid8_cx, sub_sidisp8_cx, sub_didisp8_cx, sub_bpdisp8_cx, sub_bxdisp8_cx
	.word sub_bxsid8_dx, sub_bxdid8_dx, sub_bpsid8_dx, sub_bpdid8_dx, sub_sidisp8_dx, sub_didisp8_dx, sub_bpdisp8_dx, sub_bxdisp8_dx
	.word sub_bxsid8_bx, sub_bxdid8_bx, sub_bpsid8_bx, sub_bpdid8_bx, sub_sidisp8_bx, sub_didisp8_bx, sub_bpdisp8_bx, sub_bxdisp8_bx
	.word sub_bxsid8_sp, sub_bxdid8_sp, sub_bpsid8_sp, sub_bpdid8_sp, sub_sidisp8_sp, sub_didisp8_sp, sub_bpdisp8_sp, sub_bxdisp8_sp
	.word sub_bxsid8_bp, sub_bxdid8_bp, sub_bpsid8_bp, sub_bpdid8_bp, sub_sidisp8_bp, sub_didisp8_bp, sub_bpdisp8_bp, sub_bxdisp8_bp
	.word sub_bxsid8_si, sub_bxdid8_si, sub_bpsid8_si, sub_bpdid8_si, sub_sidisp8_si, sub_didisp8_si, sub_bpdisp8_si, sub_bxdisp8_si
	.word sub_bxsid8_di, sub_bxdid8_di, sub_bpsid8_di, sub_bpdid8_di, sub_sidisp8_di, sub_didisp8_di, sub_bpdisp8_di, sub_bxdisp8_di
//0x80
	.word sub_bxsid16_ax, sub_bxdid16_ax, sub_bpsid16_ax, sub_bpdid16_ax, sub_sidisp16_ax, sub_didisp16_ax, sub_bpdisp16_ax, sub_bxdisp16_ax
	.word sub_bxsid16_cx, sub_bxdid16_cx, sub_bpsid16_cx, sub_bpdid16_cx, sub_sidisp16_cx, sub_didisp16_cx, sub_bpdisp16_cx, sub_bxdisp16_cx
	.word sub_bxsid16_dx, sub_bxdid16_dx, sub_bpsid16_dx, sub_bpdid16_dx, sub_sidisp16_dx, sub_didisp16_dx, sub_bpdisp16_dx, sub_bxdisp16_dx
	.word sub_bxsid16_bx, sub_bxdid16_bx, sub_bpsid16_bx, sub_bpdid16_bx, sub_sidisp16_bx, sub_didisp16_bx, sub_bpdisp16_bx, sub_bxdisp16_bx
	.word sub_bxsid16_sp, sub_bxdid16_sp, sub_bpsid16_sp, sub_bpdid16_sp, sub_sidisp16_sp, sub_didisp16_sp, sub_bpdisp16_sp, sub_bxdisp16_sp
	.word sub_bxsid16_bp, sub_bxdid16_bp, sub_bpsid16_bp, sub_bpdid16_bp, sub_sidisp16_bp, sub_didisp16_bp, sub_bpdisp16_bp, sub_bxdisp16_bp
	.word sub_bxsid16_si, sub_bxdid16_si, sub_bpsid16_si, sub_bpdid16_si, sub_sidisp16_si, sub_didisp16_si, sub_bpdisp16_si, sub_bxdisp16_si
	.word sub_bxsid16_di, sub_bxdid16_di, sub_bpsid16_di, sub_bpdid16_di, sub_sidisp16_di, sub_didisp16_di, sub_bpdisp16_di, sub_bxdisp16_di
// 0xC0 = two register operands
	.word sub_ax_ax, sub_cx_ax, sub_dx_ax, sub_bx_ax, sub_sp_ax, sub_bp_ax, sub_si_ax, sub_di_ax
	.word sub_ax_cx, sub_cx_cx, sub_dx_cx, sub_bx_cx, sub_sp_cx, sub_bp_cx, sub_si_cx, sub_di_cx
	.word sub_ax_dx, sub_cx_dx, sub_dx_dx, sub_bx_dx, sub_sp_dx, sub_bp_dx, sub_si_dx, sub_di_dx
	.word sub_ax_bx, sub_cx_bx, sub_dx_bx, sub_bx_bx, sub_sp_bx, sub_bp_bx, sub_si_bx, sub_di_bx
	.word sub_ax_sp, sub_cx_sp, sub_dx_sp, sub_bx_sp, sub_sp_sp, sub_bp_sp, sub_si_sp, sub_di_sp
	.word sub_ax_bp, sub_cx_bp, sub_dx_bp, sub_bx_bp, sub_sp_bp, sub_bp_bp, sub_si_bp, sub_di_bp
	.word sub_ax_si, sub_cx_si, sub_dx_si, sub_bx_si, sub_sp_si, sub_bp_si, sub_si_si, sub_di_si
	.word sub_ax_di, sub_cx_di, sub_dx_di, sub_bx_di, sub_sp_di, sub_bp_di, sub_si_di, sub_di_di

// These are called from "cpu_67.s":

	.global sub_siidx_ax, sub_diidx_ax, sub_bxidx_ax
	.global sub_siidx_cx, sub_diidx_cx, sub_bxidx_cx
	.global sub_siidx_dx, sub_diidx_dx, sub_bxidx_dx
	.global sub_siidx_bx, sub_diidx_bx, sub_bxidx_bx
	.global sub_siidx_sp, sub_diidx_sp, sub_bxidx_sp
	.global sub_siidx_bp, sub_diidx_bp, sub_bxidx_bp
	.global sub_siidx_si, sub_diidx_si, sub_bxidx_si
	.global sub_siidx_di, sub_diidx_di, sub_bxidx_di
	.global sub_sidisp8_ax, sub_didisp8_ax, sub_bpdisp8_ax, sub_bxdisp8_ax
	.global sub_sidisp8_cx, sub_didisp8_cx, sub_bpdisp8_cx, sub_bxdisp8_cx
	.global sub_sidisp8_dx, sub_didisp8_dx, sub_bpdisp8_dx, sub_bxdisp8_dx
	.global sub_sidisp8_bx, sub_didisp8_bx, sub_bpdisp8_bx, sub_bxdisp8_bx
	.global sub_sidisp8_sp, sub_didisp8_sp, sub_bpdisp8_sp, sub_bxdisp8_sp
	.global sub_sidisp8_bp, sub_didisp8_bp, sub_bpdisp8_bp, sub_bxdisp8_bp
	.global sub_sidisp8_si, sub_didisp8_si, sub_bpdisp8_si, sub_bxdisp8_si
	.global sub_sidisp8_di, sub_didisp8_di, sub_bpdisp8_di, sub_bxdisp8_di
	.global sub_ax_ax, sub_cx_ax, sub_dx_ax, sub_bx_ax, sub_sp_ax, sub_bp_ax, sub_si_ax, sub_di_ax
	.global sub_ax_cx, sub_cx_cx, sub_dx_cx, sub_bx_cx, sub_sp_cx, sub_bp_cx, sub_si_cx, sub_di_cx
	.global sub_ax_dx, sub_cx_dx, sub_dx_dx, sub_bx_dx, sub_sp_dx, sub_bp_dx, sub_si_dx, sub_di_dx
	.global sub_ax_bx, sub_cx_bx, sub_dx_bx, sub_bx_bx, sub_sp_bx, sub_bp_bx, sub_si_bx, sub_di_bx
	.global sub_ax_sp, sub_cx_sp, sub_dx_sp, sub_bx_sp, sub_sp_sp, sub_bp_sp, sub_si_sp, sub_di_sp
	.global sub_ax_bp, sub_cx_bp, sub_dx_bp, sub_bx_bp, sub_sp_bp, sub_bp_bp, sub_si_bp, sub_di_bp
	.global sub_ax_si, sub_cx_si, sub_dx_si, sub_bx_si, sub_sp_si, sub_bp_si, sub_si_si, sub_di_si
	.global sub_ax_di, sub_cx_di, sub_dx_di, sub_bx_di, sub_sp_di, sub_bp_di, sub_si_di, sub_di_di
	.global	sub_r0_r16_bp_r4, sub_r0_r16_bp_r5, sub_r0_r16_bp_r6, sub_r0_r16_bp_r7, sub_r0_r16_bp_r8, sub_r0_r16_bp_r9, sub_r0_r16_bp_r10, sub_r0_r16_bp_r11, sub_r0_r16_bp_r4
	.global	sub_r0_r16_r4, sub_r0_r16_r5, sub_r0_r16_r6, sub_r0_r16_r7, sub_r0_r16_r8, sub_r0_r16_r9, sub_r0_r16_r10, sub_r0_r16_r11, sub_r0_r16_r4


.macro sub_r0_r16_reg reg
sub_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
sub_r0_r16_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_29_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_29_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	lsl		r0, #16
	orr		r0, r1, lsl #24			// r0 = low byte | (high byte << 8)
	subs	r0, \reg, lsl #16		// r0 = [disp16] - reg
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		complement_carry
.endm

	sub_r0_r16_reg r4
	sub_r0_r16_reg r5
	sub_r0_r16_reg r6
	sub_r0_r16_reg r7
	sub_r0_r16_reg r8
	sub_r0_r16_reg r9
	sub_r0_r16_reg r10
	sub_r0_r16_reg r11

	.ltorg

// --- [idx] ----

.macro sub_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		sub_r0_r16_\reg
.endm

sub_bxsi_ax:
	sub_bxidx_reg16 r10 r4
sub_bxsi_cx:
	sub_bxidx_reg16 r10 r5
sub_bxsi_dx:
	sub_bxidx_reg16 r10 r6
sub_bxsi_bx:
	sub_bxidx_reg16 r10 r7
sub_bxsi_sp:
	sub_bxidx_reg16 r10 r8
sub_bxsi_bp:
	sub_bxidx_reg16 r10 r9
sub_bxsi_si:
	sub_bxidx_reg16 r10 r10
sub_bxsi_di:
	sub_bxidx_reg16 r10 r11

sub_bxdi_ax:
	sub_bxidx_reg16 r11 r4
sub_bxdi_cx:
	sub_bxidx_reg16 r11 r5
sub_bxdi_dx:
	sub_bxidx_reg16 r11 r6
sub_bxdi_bx:
	sub_bxidx_reg16 r11 r7
sub_bxdi_sp:
	sub_bxidx_reg16 r11 r8
sub_bxdi_bp:
	sub_bxidx_reg16 r11 r9
sub_bxdi_si:
	sub_bxidx_reg16 r11 r10
sub_bxdi_di:
	sub_bxidx_reg16 r11 r11

.macro sub_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		sub_r0_r16_bp_\reg
.endm

sub_bpsi_ax:
	sub_bpidx_reg16 r10 r4
sub_bpsi_cx:
	sub_bpidx_reg16 r10 r5
sub_bpsi_dx:
	sub_bpidx_reg16 r10 r6
sub_bpsi_bx:
	sub_bpidx_reg16 r10 r7
sub_bpsi_sp:
	sub_bpidx_reg16 r10 r8
sub_bpsi_bp:
	sub_bpidx_reg16 r10 r9
sub_bpsi_si:
	sub_bpidx_reg16 r10 r10
sub_bpsi_di:
	sub_bpidx_reg16 r10 r11

sub_bpdi_ax:
	sub_bpidx_reg16 r11 r4
sub_bpdi_cx:
	sub_bpidx_reg16 r11 r5
sub_bpdi_dx:
	sub_bpidx_reg16 r11 r6
sub_bpdi_bx:
	sub_bpidx_reg16 r11 r7
sub_bpdi_sp:
	sub_bpidx_reg16 r11 r8
sub_bpdi_bp:
	sub_bpidx_reg16 r11 r9
sub_bpdi_si:
	sub_bpidx_reg16 r11 r10
sub_bpdi_di:
	sub_bpidx_reg16 r11 r11

.macro sub_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		sub_r0_r16_\reg
.endm

sub_siidx_ax:
	sub_idx_reg16 r10 r4
sub_siidx_cx:
	sub_idx_reg16 r10 r5
sub_siidx_dx:
	sub_idx_reg16 r10 r6
sub_siidx_bx:
	sub_idx_reg16 r10 r7
sub_siidx_sp:
	sub_idx_reg16 r10 r8
sub_siidx_bp:
	sub_idx_reg16 r10 r9
sub_siidx_si:
	sub_idx_reg16 r10 r10
sub_siidx_di:
	sub_idx_reg16 r10 r11

sub_diidx_ax:
	sub_idx_reg16 r11 r4
sub_diidx_cx:
	sub_idx_reg16 r11 r5
sub_diidx_dx:
	sub_idx_reg16 r11 r6
sub_diidx_bx:
	sub_idx_reg16 r11 r7
sub_diidx_sp:
	sub_idx_reg16 r11 r8
sub_diidx_bp:
	sub_idx_reg16 r11 r9
sub_diidx_si:
	sub_idx_reg16 r11 r10
sub_diidx_di:
	sub_idx_reg16 r11 r11

sub_bxidx_ax:
	sub_idx_reg16 r7 r4
sub_bxidx_cx:
	sub_idx_reg16 r7 r5
sub_bxidx_dx:
	sub_idx_reg16 r7 r6
sub_bxidx_bx:
	sub_idx_reg16 r7 r7
sub_bxidx_sp:
	sub_idx_reg16 r7 r8
sub_bxidx_bp:
	sub_idx_reg16 r7 r9
sub_bxidx_si:
	sub_idx_reg16 r7 r10
sub_bxidx_di:
	sub_idx_reg16 r7 r11
	
.macro sub_disp16_reg16 reg
	r0_from_disp16
	b		sub_r0_r16_\reg
.endm

sub_disp16_ax:
	sub_disp16_reg16 r4
sub_disp16_cx:
	sub_disp16_reg16 r5
sub_disp16_dx:
	sub_disp16_reg16 r6
sub_disp16_bx:
	sub_disp16_reg16 r7
sub_disp16_sp:
	sub_disp16_reg16 r8
sub_disp16_bp:
	sub_disp16_reg16 r9
sub_disp16_si:
	sub_disp16_reg16 r10
sub_disp16_di:
	sub_disp16_reg16 r11

// --- [idx+disp8] ----

.macro sub_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		sub_r0_r16_\reg
.endm

sub_bxsid8_ax:
	sub_bxidxd8_reg16 r10 r4
sub_bxsid8_cx:
	sub_bxidxd8_reg16 r10 r5
sub_bxsid8_dx:
	sub_bxidxd8_reg16 r10 r6
sub_bxsid8_bx:
	sub_bxidxd8_reg16 r10 r7
sub_bxsid8_sp:
	sub_bxidxd8_reg16 r10 r8
sub_bxsid8_bp:
	sub_bxidxd8_reg16 r10 r9
sub_bxsid8_si:
	sub_bxidxd8_reg16 r10 r10
sub_bxsid8_di:
	sub_bxidxd8_reg16 r10 r11

sub_bxdid8_ax:
	sub_bxidxd8_reg16 r11 r4
sub_bxdid8_cx:
	sub_bxidxd8_reg16 r11 r5
sub_bxdid8_dx:
	sub_bxidxd8_reg16 r11 r6
sub_bxdid8_bx:
	sub_bxidxd8_reg16 r11 r7
sub_bxdid8_sp:
	sub_bxidxd8_reg16 r11 r8
sub_bxdid8_bp:
	sub_bxidxd8_reg16 r11 r9
sub_bxdid8_si:
	sub_bxidxd8_reg16 r11 r10
sub_bxdid8_di:
	sub_bxidxd8_reg16 r11 r11

.macro sub_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		sub_r0_r16_bp_\reg
.endm

sub_bpsid8_ax:
	sub_bpidxd8_reg16 r10 r4
sub_bpsid8_cx:
	sub_bpidxd8_reg16 r10 r5
sub_bpsid8_dx:
	sub_bpidxd8_reg16 r10 r6
sub_bpsid8_bx:
	sub_bpidxd8_reg16 r10 r7
sub_bpsid8_sp:
	sub_bpidxd8_reg16 r10 r8
sub_bpsid8_bp:
	sub_bpidxd8_reg16 r10 r9
sub_bpsid8_si:
	sub_bpidxd8_reg16 r10 r10
sub_bpsid8_di:
	sub_bpidxd8_reg16 r10 r11

sub_bpdid8_ax:
	sub_bpidxd8_reg16 r11 r4
sub_bpdid8_cx:
	sub_bpidxd8_reg16 r11 r5
sub_bpdid8_dx:
	sub_bpidxd8_reg16 r11 r6
sub_bpdid8_bx:
	sub_bpidxd8_reg16 r11 r7
sub_bpdid8_sp:
	sub_bpidxd8_reg16 r11 r8
sub_bpdid8_bp:
	sub_bpidxd8_reg16 r11 r9
sub_bpdid8_si:
	sub_bpidxd8_reg16 r11 r10
sub_bpdid8_di:
	sub_bpidxd8_reg16 r11 r11

.macro sub_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		sub_r0_r16_\reg
.endm

sub_sidisp8_ax:
	sub_idxdisp8_reg16 r10 r4
sub_sidisp8_cx:
	sub_idxdisp8_reg16 r10 r5
sub_sidisp8_dx:
	sub_idxdisp8_reg16 r10 r6
sub_sidisp8_bx:
	sub_idxdisp8_reg16 r10 r7
sub_sidisp8_sp:
	sub_idxdisp8_reg16 r10 r8
sub_sidisp8_bp:
	sub_idxdisp8_reg16 r10 r9
sub_sidisp8_si:
	sub_idxdisp8_reg16 r10 r10
sub_sidisp8_di:
	sub_idxdisp8_reg16 r10 r11

sub_didisp8_ax:
	sub_idxdisp8_reg16 r11 r4
sub_didisp8_cx:
	sub_idxdisp8_reg16 r11 r5
sub_didisp8_dx:
	sub_idxdisp8_reg16 r11 r6
sub_didisp8_bx:
	sub_idxdisp8_reg16 r11 r7
sub_didisp8_sp:
	sub_idxdisp8_reg16 r11 r8
sub_didisp8_bp:
	sub_idxdisp8_reg16 r11 r9
sub_didisp8_si:
	sub_idxdisp8_reg16 r11 r10
sub_didisp8_di:
	sub_idxdisp8_reg16 r11 r11

sub_bxdisp8_ax:
	sub_idxdisp8_reg16 r7 r4
sub_bxdisp8_cx:
	sub_idxdisp8_reg16 r7 r5
sub_bxdisp8_dx:
	sub_idxdisp8_reg16 r7 r6
sub_bxdisp8_bx:
	sub_idxdisp8_reg16 r7 r7
sub_bxdisp8_sp:
	sub_idxdisp8_reg16 r7 r8
sub_bxdisp8_bp:
	sub_idxdisp8_reg16 r7 r9
sub_bxdisp8_si:
	sub_idxdisp8_reg16 r7 r10
sub_bxdisp8_di:
	sub_idxdisp8_reg16 r7 r11
	
.macro sub_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		sub_r0_r16_bp_\reg
.endm
	
sub_bpdisp8_ax:
	sub_bpdisp8_reg16 r4
sub_bpdisp8_cx:
	sub_bpdisp8_reg16 r5
sub_bpdisp8_dx:
	sub_bpdisp8_reg16 r6
sub_bpdisp8_bx:
	sub_bpdisp8_reg16 r7
sub_bpdisp8_sp:
	sub_bpdisp8_reg16 r8
sub_bpdisp8_bp:
	sub_bpdisp8_reg16 r9
sub_bpdisp8_si:
	sub_bpdisp8_reg16 r10
sub_bpdisp8_di:
	sub_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro sub_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		sub_r0_r16_\reg
.endm

sub_bxsid16_ax:
	sub_bxidxd16_reg16 r10 r4
sub_bxsid16_cx:
	sub_bxidxd16_reg16 r10 r5
sub_bxsid16_dx:
	sub_bxidxd16_reg16 r10 r6
sub_bxsid16_bx:
	sub_bxidxd16_reg16 r10 r7
sub_bxsid16_sp:
	sub_bxidxd16_reg16 r10 r8
sub_bxsid16_bp:
	sub_bxidxd16_reg16 r10 r9
sub_bxsid16_si:
	sub_bxidxd16_reg16 r10 r10
sub_bxsid16_di:
	sub_bxidxd16_reg16 r10 r11

sub_bxdid16_ax:
	sub_bxidxd16_reg16 r11 r4
sub_bxdid16_cx:
	sub_bxidxd16_reg16 r11 r5
sub_bxdid16_dx:
	sub_bxidxd16_reg16 r11 r6
sub_bxdid16_bx:
	sub_bxidxd16_reg16 r11 r7
sub_bxdid16_sp:
	sub_bxidxd16_reg16 r11 r8
sub_bxdid16_bp:
	sub_bxidxd16_reg16 r11 r9
sub_bxdid16_si:
	sub_bxidxd16_reg16 r11 r10
sub_bxdid16_di:
	sub_bxidxd16_reg16 r11 r11

.macro sub_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		sub_r0_r16_bp_\reg
.endm

sub_bpsid16_ax:
	sub_bpidxd16_reg16 r10 r4
sub_bpsid16_cx:
	sub_bpidxd16_reg16 r10 r5
sub_bpsid16_dx:
	sub_bpidxd16_reg16 r10 r6
sub_bpsid16_bx:
	sub_bpidxd16_reg16 r10 r7
sub_bpsid16_sp:
	sub_bpidxd16_reg16 r10 r8
sub_bpsid16_bp:
	sub_bpidxd16_reg16 r10 r9
sub_bpsid16_si:
	sub_bpidxd16_reg16 r10 r10
sub_bpsid16_di:
	sub_bpidxd16_reg16 r10 r11

sub_bpdid16_ax:
	sub_bpidxd16_reg16 r11 r4
sub_bpdid16_cx:
	sub_bpidxd16_reg16 r11 r5
sub_bpdid16_dx:
	sub_bpidxd16_reg16 r11 r6
sub_bpdid16_bx:
	sub_bpidxd16_reg16 r11 r7
sub_bpdid16_sp:
	sub_bpidxd16_reg16 r11 r8
sub_bpdid16_bp:
	sub_bpidxd16_reg16 r11 r9
sub_bpdid16_si:
	sub_bpidxd16_reg16 r11 r10
sub_bpdid16_di:
	sub_bpidxd16_reg16 r11 r11

.macro sub_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		sub_r0_r16_\reg
.endm

sub_sidisp16_ax:
	sub_idxdisp16_reg16 r10 r4
sub_sidisp16_cx:
	sub_idxdisp16_reg16 r10 r5
sub_sidisp16_dx:
	sub_idxdisp16_reg16 r10 r6
sub_sidisp16_bx:
	sub_idxdisp16_reg16 r10 r7
sub_sidisp16_sp:
	sub_idxdisp16_reg16 r10 r8
sub_sidisp16_bp:
	sub_idxdisp16_reg16 r10 r9
sub_sidisp16_si:
	sub_idxdisp16_reg16 r10 r10
sub_sidisp16_di:
	sub_idxdisp16_reg16 r10 r11

sub_didisp16_ax:
	sub_idxdisp16_reg16 r11 r4
sub_didisp16_cx:
	sub_idxdisp16_reg16 r11 r5
sub_didisp16_dx:
	sub_idxdisp16_reg16 r11 r6
sub_didisp16_bx:
	sub_idxdisp16_reg16 r11 r7
sub_didisp16_sp:
	sub_idxdisp16_reg16 r11 r8
sub_didisp16_bp:
	sub_idxdisp16_reg16 r11 r9
sub_didisp16_si:
	sub_idxdisp16_reg16 r11 r10
sub_didisp16_di:
	sub_idxdisp16_reg16 r11 r11

sub_bxdisp16_ax:
	sub_idxdisp16_reg16 r7 r4
sub_bxdisp16_cx:
	sub_idxdisp16_reg16 r7 r5
sub_bxdisp16_dx:
	sub_idxdisp16_reg16 r7 r6
sub_bxdisp16_bx:
	sub_idxdisp16_reg16 r7 r7
sub_bxdisp16_sp:
	sub_idxdisp16_reg16 r7 r8
sub_bxdisp16_bp:
	sub_idxdisp16_reg16 r7 r9
sub_bxdisp16_si:
	sub_idxdisp16_reg16 r7 r10
sub_bxdisp16_di:
	sub_idxdisp16_reg16 r7 r11

.macro sub_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		sub_r0_r16_bp_\reg
.endm

sub_bpdisp16_ax:
	sub_bpdisp16_reg16 r4
sub_bpdisp16_cx:
	sub_bpdisp16_reg16 r5
sub_bpdisp16_dx:
	sub_bpdisp16_reg16 r6
sub_bpdisp16_bx:
	sub_bpdisp16_reg16 r7
sub_bpdisp16_sp:
	sub_bpdisp16_reg16 r8
sub_bpdisp16_bp:
	sub_bpdisp16_reg16 r9
sub_bpdisp16_si:
	sub_bpdisp16_reg16 r10
sub_bpdisp16_di:
	sub_bpdisp16_reg16 r11


// ------------------- 2A = SUB r8, r/m8 -------------------------------
//
// All modrm variations supported!
//
//
op_2a:
	modrm_jump_16
// 0
	.word sub_al_bxsi, sub_al_bxdi, sub_al_bpsi, sub_al_bpdi, sub_al_siidx, sub_al_diidx, sub_al_disp16, sub_al_bxidx
	.word sub_cl_bxsi, sub_cl_bxdi, sub_cl_bpsi, sub_cl_bpdi, sub_cl_siidx, sub_cl_diidx, sub_cl_disp16, sub_cl_bxidx
	.word sub_dl_bxsi, sub_dl_bxdi, sub_dl_bpsi, sub_dl_bpdi, sub_dl_siidx, sub_dl_diidx, sub_dl_disp16, sub_dl_bxidx
	.word sub_bl_bxsi, sub_bl_bxdi, sub_bl_bpsi, sub_bl_bpdi, sub_bl_siidx, sub_bl_diidx, sub_bl_disp16, sub_bl_bxidx
	.word sub_ah_bxsi, sub_ah_bxdi, sub_ah_bpsi, sub_ah_bpdi, sub_ah_siidx, sub_ah_diidx, sub_ah_disp16, sub_ah_bxidx
	.word sub_ch_bxsi, sub_ch_bxdi, sub_ch_bpsi, sub_ch_bpdi, sub_ch_siidx, sub_ch_diidx, sub_ch_disp16, sub_ch_bxidx
	.word sub_dh_bxsi, sub_dh_bxdi, sub_dh_bpsi, sub_dh_bpdi, sub_dh_siidx, sub_dh_diidx, sub_dh_disp16, sub_dh_bxidx
	.word sub_bh_bxsi, sub_bh_bxdi, sub_bh_bpsi, sub_bh_bpdi, sub_bh_siidx, sub_bh_diidx, sub_bh_disp16, sub_bh_bxidx
//0x40
	.word sub_al_bxsid8, sub_al_bxdid8, sub_al_bpsid8, sub_al_bpdid8, sub_al_sidisp8, sub_al_didisp8, sub_al_bpdisp8, sub_al_bxdisp8
	.word sub_cl_bxsid8, sub_cl_bxdid8, sub_cl_bpsid8, sub_cl_bpdid8, sub_cl_sidisp8, sub_cl_didisp8, sub_cl_bpdisp8, sub_cl_bxdisp8
	.word sub_dl_bxsid8, sub_dl_bxdid8, sub_dl_bpsid8, sub_dl_bpdid8, sub_dl_sidisp8, sub_dl_didisp8, sub_dl_bpdisp8, sub_dl_bxdisp8
	.word sub_bl_bxsid8, sub_bl_bxdid8, sub_bl_bpsid8, sub_bl_bpdid8, sub_bl_sidisp8, sub_bl_didisp8, sub_bl_bpdisp8, sub_bl_bxdisp8
	.word sub_ah_bxsid8, sub_ah_bxdid8, sub_ah_bpsid8, sub_ah_bpdid8, sub_ah_sidisp8, sub_ah_didisp8, sub_ah_bpdisp8, sub_ah_bxdisp8
	.word sub_ch_bxsid8, sub_ch_bxdid8, sub_ch_bpsid8, sub_ch_bpdid8, sub_ch_sidisp8, sub_ch_didisp8, sub_ch_bpdisp8, sub_ch_bxdisp8
	.word sub_dh_bxsid8, sub_dh_bxdid8, sub_dh_bpsid8, sub_dh_bpdid8, sub_dh_sidisp8, sub_dh_didisp8, sub_dh_bpdisp8, sub_dh_bxdisp8
	.word sub_bh_bxsid8, sub_bh_bxdid8, sub_bh_bpsid8, sub_bh_bpdid8, sub_bh_sidisp8, sub_bh_didisp8, sub_bh_bpdisp8, sub_bh_bxdisp8
//0x80
	.word sub_al_bxsid16, sub_al_bxdid16, sub_al_bpsid16, sub_al_bpdid16, sub_al_sidisp16, sub_al_didisp16, sub_al_bpdisp16, sub_al_bxdisp16
	.word sub_cl_bxsid16, sub_cl_bxdid16, sub_cl_bpsid16, sub_cl_bpdid16, sub_cl_sidisp16, sub_cl_didisp16, sub_cl_bpdisp16, sub_cl_bxdisp16
	.word sub_dl_bxsid16, sub_dl_bxdid16, sub_dl_bpsid16, sub_dl_bpdid16, sub_dl_sidisp16, sub_dl_didisp16, sub_dl_bpdisp16, sub_dl_bxdisp16
	.word sub_bl_bxsid16, sub_bl_bxdid16, sub_bl_bpsid16, sub_bl_bpdid16, sub_bl_sidisp16, sub_bl_didisp16, sub_bl_bpdisp16, sub_bl_bxdisp16
	.word sub_ah_bxsid16, sub_ah_bxdid16, sub_ah_bpsid16, sub_ah_bpdid16, sub_ah_sidisp16, sub_ah_didisp16, sub_ah_bpdisp16, sub_ah_bxdisp16
	.word sub_ch_bxsid16, sub_ch_bxdid16, sub_ch_bpsid16, sub_ch_bpdid16, sub_ch_sidisp16, sub_ch_didisp16, sub_ch_bpdisp16, sub_ch_bxdisp16
	.word sub_dh_bxsid16, sub_dh_bxdid16, sub_dh_bpsid16, sub_dh_bpdid16, sub_dh_sidisp16, sub_dh_didisp16, sub_dh_bpdisp16, sub_dh_bxdisp16
	.word sub_bh_bxsid16, sub_bh_bxdid16, sub_bh_bpsid16, sub_bh_bpdid16, sub_bh_sidisp16, sub_bh_didisp16, sub_bh_bpdisp16, sub_bh_bxdisp16
// 0xC0 = two register operands
	.word sub_al_al, sub_al_cl, sub_al_dl, sub_al_bl, sub_al_ah, sub_al_ch, sub_al_dh, sub_al_bh
	.word sub_cl_al, sub_cl_cl, sub_cl_dl, sub_cl_bl, sub_cl_ah, sub_cl_ch, sub_cl_dh, sub_cl_bh
	.word sub_dl_al, sub_dl_cl, sub_dl_dl, sub_dl_bl, sub_dl_ah, sub_dl_ch, sub_dl_dh, sub_dl_bh
	.word sub_bl_al, sub_bl_cl, sub_bl_dl, sub_bl_bl, sub_bl_ah, sub_bl_ch, sub_bl_dh, sub_bl_bh
	.word sub_ah_al, sub_ah_cl, sub_ah_dl, sub_ah_bl, sub_ah_ah, sub_ah_ch, sub_ah_dh, sub_ah_bh
	.word sub_ch_al, sub_ch_cl, sub_ch_dl, sub_ch_bl, sub_ch_ah, sub_ch_ch, sub_ch_dh, sub_ch_bh
	.word sub_dh_al, sub_dh_cl, sub_dh_dl, sub_dh_bl, sub_dh_ah, sub_dh_ch, sub_dh_dh, sub_dh_bh
	.word sub_bh_al, sub_bh_cl, sub_bh_dl, sub_bh_bl, sub_bh_ah, sub_bh_ch, sub_bh_dh, sub_bh_bh

// These are called from "cpu_386.s":

	.global sub_al_siidx, sub_cl_siidx, sub_dl_siidx, sub_bl_siidx, sub_ah_siidx, sub_ch_siidx, sub_dh_siidx, sub_bh_siidx
	.global sub_al_diidx, sub_cl_diidx, sub_dl_diidx, sub_bl_diidx, sub_ah_diidx, sub_ch_diidx, sub_dh_diidx, sub_bh_diidx
	.global sub_al_bxidx, sub_cl_bxidx, sub_dl_bxidx, sub_bl_bxidx, sub_ah_bxidx, sub_ch_bxidx, sub_dh_bxidx, sub_bh_bxidx
	.global sub_al_sidisp8, sub_al_didisp8, sub_al_bpdisp8, sub_al_bxdisp8
	.global sub_cl_sidisp8, sub_cl_didisp8, sub_cl_bpdisp8, sub_cl_bxdisp8
	.global sub_dl_sidisp8, sub_dl_didisp8, sub_dl_bpdisp8, sub_dl_bxdisp8
	.global sub_bl_sidisp8, sub_bl_didisp8, sub_bl_bpdisp8, sub_bl_bxdisp8
	.global sub_ah_sidisp8, sub_ah_didisp8, sub_ah_bpdisp8, sub_ah_bxdisp8
	.global sub_ch_sidisp8, sub_ch_didisp8, sub_ch_bpdisp8, sub_ch_bxdisp8
	.global sub_dh_sidisp8, sub_dh_didisp8, sub_dh_bpdisp8, sub_dh_bxdisp8
	.global sub_bh_sidisp8, sub_bh_didisp8, sub_bh_bpdisp8, sub_bh_bxdisp8
	.global sub_al_al, sub_cl_al, sub_dl_al, sub_bl_al, sub_ah_al, sub_ch_al, sub_dh_al, sub_bh_al
	.global sub_al_cl, sub_cl_cl, sub_dl_cl, sub_bl_cl, sub_ah_cl, sub_ch_cl, sub_dh_cl, sub_bh_cl
	.global sub_al_dl, sub_cl_dl, sub_dl_dl, sub_bl_dl, sub_ah_dl, sub_ch_dl, sub_dh_dl, sub_bh_dl
	.global sub_al_bl, sub_cl_bl, sub_dl_bl, sub_bl_bl, sub_ah_bl, sub_ch_bl, sub_dh_bl, sub_bh_bl
	.global sub_al_ah, sub_cl_ah, sub_dl_ah, sub_bl_ah, sub_ah_ah, sub_ch_ah, sub_dh_ah, sub_bh_ah
	.global sub_al_ch, sub_cl_ch, sub_dl_ch, sub_bl_ch, sub_ah_ch, sub_ch_ch, sub_dh_ch, sub_bh_ch
	.global sub_al_dh, sub_cl_dh, sub_dl_dh, sub_bl_dh, sub_ah_dh, sub_ch_dh, sub_dh_dh, sub_bh_dh
	.global sub_al_bh, sub_cl_bh, sub_dl_bh, sub_bl_bh, sub_ah_bh, sub_ch_bh, sub_dh_bh, sub_bh_bh

.macro sub_reg8l_r0high reg
	.global	sub_r8l_r0_bp_\reg
sub_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	sub_r8l_r0_\reg
sub_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_2a_RAM_l_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_2a_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	subs	r1, r0, lsl #24			// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	b		complement_carry
.endm
.macro sub_reg8h_r0high reg
	.global	sub_r8h_r0_bp_\reg
sub_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global sub_r8h_r0_\reg
sub_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_2a_RAM_h_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_2a_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00		// Left operand already uses just the rightmost byte
	lsl		r1, #16
	subs	r1, r0, lsl #24			// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsr #16
	b		complement_carry
.endm

	sub_reg8l_r0high r4
	sub_reg8l_r0high r5
	sub_reg8l_r0high r6
	sub_reg8l_r0high r7
	sub_reg8h_r0high r4
	sub_reg8h_r0high r5
	sub_reg8h_r0high r6
	sub_reg8h_r0high r7

	.ltorg

// --- [idx] ---

.macro sub_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		sub_r8l_r0_\reg
.endm
.macro sub_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		sub_r8h_r0_\reg
.endm

sub_al_bxsi:
	sub_reg8l_bxidx r4 r10
sub_cl_bxsi:
	sub_reg8l_bxidx r5 r10
sub_dl_bxsi:
	sub_reg8l_bxidx r6 r10
sub_bl_bxsi:
	sub_reg8l_bxidx r7 r10
sub_ah_bxsi:
	sub_reg8h_bxidx r4 r10
sub_ch_bxsi:
	sub_reg8h_bxidx r5 r10
sub_dh_bxsi:
	sub_reg8h_bxidx r6 r10
sub_bh_bxsi:
	sub_reg8h_bxidx r7 r10

sub_al_bxdi:
	sub_reg8l_bxidx r4 r11
sub_cl_bxdi:
	sub_reg8l_bxidx r5 r11
sub_dl_bxdi:
	sub_reg8l_bxidx r6 r11
sub_bl_bxdi:
	sub_reg8l_bxidx r7 r11
sub_ah_bxdi:
	sub_reg8h_bxidx r4 r11
sub_ch_bxdi:
	sub_reg8h_bxidx r5 r11
sub_dh_bxdi:
	sub_reg8h_bxidx r6 r11
sub_bh_bxdi:
	sub_reg8h_bxidx r7 r11

.macro sub_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		sub_r8l_r0_bp_\reg
.endm
.macro sub_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		sub_r8h_r0_bp_\reg
.endm

sub_al_bpsi:
	sub_reg8l_bpidx r4 r10
sub_cl_bpsi:
	sub_reg8l_bpidx r5 r10
sub_dl_bpsi:
	sub_reg8l_bpidx r6 r10
sub_bl_bpsi:
	sub_reg8l_bpidx r7 r10
sub_ah_bpsi:
	sub_reg8h_bpidx r4 r10
sub_ch_bpsi:
	sub_reg8h_bpidx r5 r10
sub_dh_bpsi:
	sub_reg8h_bpidx r6 r10
sub_bh_bpsi:
	sub_reg8h_bpidx r7 r10

sub_al_bpdi:
	sub_reg8l_bpidx r4 r11
sub_cl_bpdi:
	sub_reg8l_bpidx r5 r11
sub_dl_bpdi:
	sub_reg8l_bpidx r6 r11
sub_bl_bpdi:
	sub_reg8l_bpidx r7 r11
sub_ah_bpdi:
	sub_reg8h_bpidx r4 r11
sub_ch_bpdi:
	sub_reg8h_bpidx r5 r11
sub_dh_bpdi:
	sub_reg8h_bpidx r6 r11
sub_bh_bpdi:
	sub_reg8h_bpidx r7 r11

.macro sub_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		sub_r8l_r0_\reg
.endm
.macro sub_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		sub_r8h_r0_\reg
.endm

sub_al_siidx:
	sub_reg8l_idx r4 r10
sub_cl_siidx:
	sub_reg8l_idx r5 r10
sub_dl_siidx:
	sub_reg8l_idx r6 r10
sub_bl_siidx:
	sub_reg8l_idx r7 r10
sub_ah_siidx:
	sub_reg8h_idx r4 r10
sub_ch_siidx:
	sub_reg8h_idx r5 r10
sub_dh_siidx:
	sub_reg8h_idx r6 r10
sub_bh_siidx:
	sub_reg8h_idx r7 r10

sub_al_diidx:
	sub_reg8l_idx r4 r11
sub_cl_diidx:
	sub_reg8l_idx r5 r11
sub_dl_diidx:
	sub_reg8l_idx r6 r11
sub_bl_diidx:
	sub_reg8l_idx r7 r11
sub_ah_diidx:
	sub_reg8h_idx r4 r11
sub_ch_diidx:
	sub_reg8h_idx r5 r11
sub_dh_diidx:
	sub_reg8h_idx r6 r11
sub_bh_diidx:
	sub_reg8h_idx r7 r11

sub_al_bxidx:
	sub_reg8l_idx r4 r7
sub_cl_bxidx:
	sub_reg8l_idx r5 r7
sub_dl_bxidx:
	sub_reg8l_idx r6 r7
sub_bl_bxidx:
	sub_reg8l_idx r7 r7
sub_ah_bxidx:
	sub_reg8h_idx r4 r7
sub_ch_bxidx:
	sub_reg8h_idx r5 r7
sub_dh_bxidx:
	sub_reg8h_idx r6 r7
sub_bh_bxidx:
	sub_reg8h_idx r7 r7

.macro sub_reg8l_disp16 reg
	r0_from_disp16
	b		sub_r8l_r0_\reg
.endm
.macro sub_reg8h_disp16 reg
	r0_from_disp16
	b		sub_r8h_r0_\reg
.endm

sub_al_disp16:
	sub_reg8l_disp16 r4
sub_cl_disp16:
	sub_reg8l_disp16 r5
sub_dl_disp16:
	sub_reg8l_disp16 r6
sub_bl_disp16:
	sub_reg8l_disp16 r7
sub_ah_disp16:
	sub_reg8h_disp16 r4
sub_ch_disp16:
	sub_reg8h_disp16 r5
sub_dh_disp16:
	sub_reg8h_disp16 r6
sub_bh_disp16:
	sub_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro sub_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		sub_r8l_r0_\reg
.endm
.macro sub_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		sub_r8h_r0_\reg
.endm

sub_al_bxsid8:
	sub_reg8l_bxidxd8 r4 r10
sub_cl_bxsid8:
	sub_reg8l_bxidxd8 r5 r10
sub_dl_bxsid8:
	sub_reg8l_bxidxd8 r6 r10
sub_bl_bxsid8:
	sub_reg8l_bxidxd8 r7 r10
sub_ah_bxsid8:
	sub_reg8h_bxidxd8 r4 r10
sub_ch_bxsid8:
	sub_reg8h_bxidxd8 r5 r10
sub_dh_bxsid8:
	sub_reg8h_bxidxd8 r6 r10
sub_bh_bxsid8:
	sub_reg8h_bxidxd8 r7 r10

sub_al_bxdid8:
	sub_reg8l_bxidxd8 r4 r11
sub_cl_bxdid8:
	sub_reg8l_bxidxd8 r5 r11
sub_dl_bxdid8:
	sub_reg8l_bxidxd8 r6 r11
sub_bl_bxdid8:
	sub_reg8l_bxidxd8 r7 r11
sub_ah_bxdid8:
	sub_reg8h_bxidxd8 r4 r11
sub_ch_bxdid8:
	sub_reg8h_bxidxd8 r5 r11
sub_dh_bxdid8:
	sub_reg8h_bxidxd8 r6 r11
sub_bh_bxdid8:
	sub_reg8h_bxidxd8 r7 r11

.macro sub_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		sub_r8l_r0_bp_\reg
.endm
.macro sub_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		sub_r8h_r0_bp_\reg
.endm

sub_al_bpsid8:
	sub_reg8l_bpidxd8 r4 r10
sub_cl_bpsid8:
	sub_reg8l_bpidxd8 r5 r10
sub_dl_bpsid8:
	sub_reg8l_bpidxd8 r6 r10
sub_bl_bpsid8:
	sub_reg8l_bpidxd8 r7 r10
sub_ah_bpsid8:
	sub_reg8h_bpidxd8 r4 r10
sub_ch_bpsid8:
	sub_reg8h_bpidxd8 r5 r10
sub_dh_bpsid8:
	sub_reg8h_bpidxd8 r6 r10
sub_bh_bpsid8:
	sub_reg8h_bpidxd8 r7 r10

sub_al_bpdid8:
	sub_reg8l_bpidxd8 r4 r11
sub_cl_bpdid8:
	sub_reg8l_bpidxd8 r5 r11
sub_dl_bpdid8:
	sub_reg8l_bpidxd8 r6 r11
sub_bl_bpdid8:
	sub_reg8l_bpidxd8 r7 r11
sub_ah_bpdid8:
	sub_reg8h_bpidxd8 r4 r11
sub_ch_bpdid8:
	sub_reg8h_bpidxd8 r5 r11
sub_dh_bpdid8:
	sub_reg8h_bpidxd8 r6 r11
sub_bh_bpdid8:
	sub_reg8h_bpidxd8 r7 r11

.macro sub_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		sub_r8l_r0_\reg
.endm
.macro sub_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		sub_r8h_r0_\reg
.endm

sub_al_sidisp8:
	sub_reg8l_idxdisp8 r4 r10
sub_cl_sidisp8:
	sub_reg8l_idxdisp8 r5 r10
sub_dl_sidisp8:
	sub_reg8l_idxdisp8 r6 r10
sub_bl_sidisp8:
	sub_reg8l_idxdisp8 r7 r10
sub_ah_sidisp8:
	sub_reg8h_idxdisp8 r4 r10
sub_ch_sidisp8:
	sub_reg8h_idxdisp8 r5 r10
sub_dh_sidisp8:
	sub_reg8h_idxdisp8 r6 r10
sub_bh_sidisp8:
	sub_reg8h_idxdisp8 r7 r10
	
sub_al_didisp8:
	sub_reg8l_idxdisp8 r4 r11
sub_cl_didisp8:
	sub_reg8l_idxdisp8 r5 r11
sub_dl_didisp8:
	sub_reg8l_idxdisp8 r6 r11
sub_bl_didisp8:
	sub_reg8l_idxdisp8 r7 r11
sub_ah_didisp8:
	sub_reg8h_idxdisp8 r4 r11
sub_ch_didisp8:
	sub_reg8h_idxdisp8 r5 r11
sub_dh_didisp8:
	sub_reg8h_idxdisp8 r6 r11
sub_bh_didisp8:
	sub_reg8h_idxdisp8 r7 r11

sub_al_bxdisp8:
	sub_reg8l_idxdisp8 r4 r7
sub_cl_bxdisp8:
	sub_reg8l_idxdisp8 r5 r7
sub_dl_bxdisp8:
	sub_reg8l_idxdisp8 r6 r7
sub_bl_bxdisp8:
	sub_reg8l_idxdisp8 r7 r7
sub_ah_bxdisp8:
	sub_reg8h_idxdisp8 r4 r7
sub_ch_bxdisp8:
	sub_reg8h_idxdisp8 r5 r7
sub_dh_bxdisp8:
	sub_reg8h_idxdisp8 r6 r7
sub_bh_bxdisp8:
	sub_reg8h_idxdisp8 r7 r7

.macro sub_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		sub_r8l_r0_bp_\reg
.endm
.macro sub_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		sub_r8h_r0_bp_\reg
.endm

sub_al_bpdisp8:
	sub_reg8l_bpdisp8 r4
sub_cl_bpdisp8:
	sub_reg8l_bpdisp8 r5
sub_dl_bpdisp8:
	sub_reg8l_bpdisp8 r6
sub_bl_bpdisp8:
	sub_reg8l_bpdisp8 r7
sub_ah_bpdisp8:
	sub_reg8h_bpdisp8 r4
sub_ch_bpdisp8:
	sub_reg8h_bpdisp8 r5
sub_dh_bpdisp8:
	sub_reg8h_bpdisp8 r6
sub_bh_bpdisp8:
	sub_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro sub_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		sub_r8l_r0_\reg
.endm
.macro sub_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		sub_r8h_r0_\reg
.endm

sub_al_bxsid16:
	sub_reg8l_bxidxd16 r4 r10
sub_cl_bxsid16:
	sub_reg8l_bxidxd16 r5 r10
sub_dl_bxsid16:
	sub_reg8l_bxidxd16 r6 r10
sub_bl_bxsid16:
	sub_reg8l_bxidxd16 r7 r10
sub_ah_bxsid16:
	sub_reg8h_bxidxd16 r4 r10
sub_ch_bxsid16:
	sub_reg8h_bxidxd16 r5 r10
sub_dh_bxsid16:
	sub_reg8h_bxidxd16 r6 r10
sub_bh_bxsid16:
	sub_reg8h_bxidxd16 r7 r10

sub_al_bxdid16:
	sub_reg8l_bxidxd16 r4 r11
sub_cl_bxdid16:
	sub_reg8l_bxidxd16 r5 r11
sub_dl_bxdid16:
	sub_reg8l_bxidxd16 r6 r11
sub_bl_bxdid16:
	sub_reg8l_bxidxd16 r7 r11
sub_ah_bxdid16:
	sub_reg8h_bxidxd16 r4 r11
sub_ch_bxdid16:
	sub_reg8h_bxidxd16 r5 r11
sub_dh_bxdid16:
	sub_reg8h_bxidxd16 r6 r11
sub_bh_bxdid16:
	sub_reg8h_bxidxd16 r7 r11

.macro sub_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		sub_r8l_r0_bp_\reg
.endm
.macro sub_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		sub_r8h_r0_bp_\reg
.endm

sub_al_bpsid16:
	sub_reg8l_bpidxd16 r4 r10
sub_cl_bpsid16:
	sub_reg8l_bpidxd16 r5 r10
sub_dl_bpsid16:
	sub_reg8l_bpidxd16 r6 r10
sub_bl_bpsid16:
	sub_reg8l_bpidxd16 r7 r10
sub_ah_bpsid16:
	sub_reg8h_bpidxd16 r4 r10
sub_ch_bpsid16:
	sub_reg8h_bpidxd16 r5 r10
sub_dh_bpsid16:
	sub_reg8h_bpidxd16 r6 r10
sub_bh_bpsid16:
	sub_reg8h_bpidxd16 r7 r10

sub_al_bpdid16:
	sub_reg8l_bpidxd16 r4 r11
sub_cl_bpdid16:
	sub_reg8l_bpidxd16 r5 r11
sub_dl_bpdid16:
	sub_reg8l_bpidxd16 r6 r11
sub_bl_bpdid16:
	sub_reg8l_bpidxd16 r7 r11
sub_ah_bpdid16:
	sub_reg8h_bpidxd16 r4 r11
sub_ch_bpdid16:
	sub_reg8h_bpidxd16 r5 r11
sub_dh_bpdid16:
	sub_reg8h_bpidxd16 r6 r11
sub_bh_bpdid16:
	sub_reg8h_bpidxd16 r7 r11

.macro sub_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		sub_r8l_r0_\reg
.endm
.macro sub_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		sub_r8h_r0_\reg
.endm

sub_al_sidisp16:
	sub_reg8l_idxdisp16 r4 r10
sub_cl_sidisp16:
	sub_reg8l_idxdisp16 r5 r10
sub_dl_sidisp16:
	sub_reg8l_idxdisp16 r6 r10
sub_bl_sidisp16:
	sub_reg8l_idxdisp16 r7 r10
sub_ah_sidisp16:
	sub_reg8h_idxdisp16 r4 r10
sub_ch_sidisp16:
	sub_reg8h_idxdisp16 r5 r10
sub_dh_sidisp16:
	sub_reg8h_idxdisp16 r6 r10
sub_bh_sidisp16:
	sub_reg8h_idxdisp16 r7 r10

sub_al_didisp16:
	sub_reg8l_idxdisp16 r4 r11
sub_cl_didisp16:
	sub_reg8l_idxdisp16 r5 r11
sub_dl_didisp16:
	sub_reg8l_idxdisp16 r6 r11
sub_bl_didisp16:
	sub_reg8l_idxdisp16 r7 r11
sub_ah_didisp16:
	sub_reg8h_idxdisp16 r4 r11
sub_ch_didisp16:
	sub_reg8h_idxdisp16 r5 r11
sub_dh_didisp16:
	sub_reg8h_idxdisp16 r6 r11
sub_bh_didisp16:
	sub_reg8h_idxdisp16 r7 r11

sub_al_bxdisp16:
	sub_reg8l_idxdisp16 r4 r7
sub_cl_bxdisp16:
	sub_reg8l_idxdisp16 r5 r7
sub_dl_bxdisp16:
	sub_reg8l_idxdisp16 r6 r7
sub_bl_bxdisp16:
	sub_reg8l_idxdisp16 r7 r7
sub_ah_bxdisp16:
	sub_reg8h_idxdisp16 r4 r7
sub_ch_bxdisp16:
	sub_reg8h_idxdisp16 r5 r7
sub_dh_bxdisp16:
	sub_reg8h_idxdisp16 r6 r7
sub_bh_bxdisp16:
	sub_reg8h_idxdisp16 r7 r7
	
.macro sub_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		sub_r8l_r0_bp_\reg
.endm
.macro sub_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		sub_r8h_r0_bp_\reg
.endm

sub_al_bpdisp16:
	sub_reg8l_bpdisp16 r4 
sub_cl_bpdisp16:
	sub_reg8l_bpdisp16 r5 
sub_dl_bpdisp16:
	sub_reg8l_bpdisp16 r6 
sub_bl_bpdisp16:
	sub_reg8l_bpdisp16 r7 
sub_ah_bpdisp16:
	sub_reg8h_bpdisp16 r4 
sub_ch_bpdisp16:
	sub_reg8h_bpdisp16 r5 
sub_dh_bpdisp16:
	sub_reg8h_bpdisp16 r6 
sub_bh_bpdisp16:
	sub_reg8h_bpdisp16 r7 


// --- registers ---

.macro sub_reg8l_reg8l reg1 reg2
	mov		r0, \reg1, lsl #24
	mov		r1, \reg2, lsl #24
	subs	r0, r1
	bic		\reg1, #0xFF			// Clear the current reg8l value
	orr		\reg1, r0, lsr #24		// and replace it with r0
	b		complement_carry
.endm

sub_al_al:
	sub_reg8l_reg8l r4 r4
sub_al_cl:	
	sub_reg8l_reg8l r4 r5
sub_al_dl:
	sub_reg8l_reg8l r4 r6
sub_al_bl:	
	sub_reg8l_reg8l r4 r7

sub_cl_al:
	sub_reg8l_reg8l r5 r4
sub_cl_cl:	
	sub_reg8l_reg8l r5 r5
sub_cl_dl:
	sub_reg8l_reg8l r5 r6
sub_cl_bl:	
	sub_reg8l_reg8l r5 r7
	
sub_dl_al:
	sub_reg8l_reg8l r6 r4
sub_dl_cl:	
	sub_reg8l_reg8l r6 r5
sub_dl_dl:
	sub_reg8l_reg8l r6 r6
sub_dl_bl:	
	sub_reg8l_reg8l r6 r7
	
sub_bl_al:
	sub_reg8l_reg8l r7 r4
sub_bl_cl:	
	sub_reg8l_reg8l r7 r5
sub_bl_dl:
	sub_reg8l_reg8l r7 r6
sub_bl_bl:	
	sub_reg8l_reg8l r7 r7

.macro sub_reg8l_reg8h reg1 reg2
	mov		r0, \reg1, lsl #24
	and		r1, \reg2, #0xFF00
	subs	r0, r1, lsl #16
	bic		\reg1, #0xFF			// Clear the current reg8l value
	orr		\reg1, r0, lsr #24		// and replace it with r0
	b		complement_carry
.endm

sub_al_ah:
	sub_reg8l_reg8h r4 r4
sub_al_ch:	
	sub_reg8l_reg8h r4 r5
sub_al_dh:
	sub_reg8l_reg8h r4 r6
sub_al_bh:	
	sub_reg8l_reg8h r4 r7

sub_cl_ah:
	sub_reg8l_reg8h r5 r4
sub_cl_ch:	
	sub_reg8l_reg8h r5 r5
sub_cl_dh:
	sub_reg8l_reg8h r5 r6
sub_cl_bh:	
	sub_reg8l_reg8h r5 r7
	
sub_dl_ah:
	sub_reg8l_reg8h r6 r4
sub_dl_ch:	
	sub_reg8l_reg8h r6 r5
sub_dl_dh:
	sub_reg8l_reg8h r6 r6
sub_dl_bh:	
	sub_reg8l_reg8h r6 r7
	
sub_bl_ah:
	sub_reg8l_reg8h r7 r4
sub_bl_ch:	
	sub_reg8l_reg8h r7 r5
sub_bl_dh:
	sub_reg8l_reg8h r7 r6
sub_bl_bh:	
	sub_reg8l_reg8h r7 r7

.macro sub_reg8h_reg8l reg1 reg2
	and		r0, \reg1, #0xFF00
	mov		r1, \reg2, lsl #24
	rsbs	r0, r1, r0, lsl #16
	bic		\reg1, #0xFF00			// Clear the current reg8h value
	orr		\reg1, r0, lsr #16		// and replace it with r0
	b		complement_carry
.endm

sub_ah_al:
	sub_reg8h_reg8l r4 r4
sub_ah_cl:	
	sub_reg8h_reg8l r4 r5
sub_ah_dl:
	sub_reg8h_reg8l r4 r6
sub_ah_bl:	
	sub_reg8h_reg8l r4 r7

sub_ch_al:
	sub_reg8h_reg8l r5 r4
sub_ch_cl:	
	sub_reg8h_reg8l r5 r5
sub_ch_dl:
	sub_reg8h_reg8l r5 r6
sub_ch_bl:	
	sub_reg8h_reg8l r5 r7
	
sub_dh_al:
	sub_reg8h_reg8l r6 r4
sub_dh_cl:	
	sub_reg8h_reg8l r6 r5
sub_dh_dl:
	sub_reg8h_reg8l r6 r6
sub_dh_bl:	
	sub_reg8h_reg8l r6 r7
	
sub_bh_al:
	sub_reg8h_reg8l r7 r4
sub_bh_cl:	
	sub_reg8h_reg8l r7 r5
sub_bh_dl:
	sub_reg8h_reg8l r7 r6
sub_bh_bl:	
	sub_reg8h_reg8l r7 r7

.macro sub_reg8h_reg8h reg1 reg2
	and		r0, \reg1, #0xFF00
	and		r1, \reg2, #0xFF00
	lsl		r0, #16
	subs	r0, r1, lsl #16
	bic		\reg1, #0xFF00			// Clear the current reg8h value
	orr		\reg1, r0, lsr #16		// and replace it with r0
	b		complement_carry
.endm
	
sub_ah_ah:
	sub_reg8h_reg8h r4 r4
sub_ah_ch:	
	sub_reg8h_reg8h r4 r5
sub_ah_dh:
	sub_reg8h_reg8h r4 r6
sub_ah_bh:	
	sub_reg8h_reg8h r4 r7

sub_ch_ah:
	sub_reg8h_reg8h r5 r4
sub_ch_ch:	
	sub_reg8h_reg8h r5 r5
sub_ch_dh:
	sub_reg8h_reg8h r5 r6
sub_ch_bh:	
	sub_reg8h_reg8h r5 r7
	
sub_dh_ah:
	sub_reg8h_reg8h r6 r4
sub_dh_ch:	
	sub_reg8h_reg8h r6 r5
sub_dh_dh:
	sub_reg8h_reg8h r6 r6
sub_dh_bh:	
	sub_reg8h_reg8h r6 r7
	
sub_bh_ah:
	sub_reg8h_reg8h r7 r4
sub_bh_ch:	
	sub_reg8h_reg8h r7 r5
sub_bh_dh:
	sub_reg8h_reg8h r7 r6
sub_bh_bh:	
	sub_reg8h_reg8h r7 r7
	
// ------------------- 2B = SUB r16, r/m16 -----------------------------
//
// All modrm variations supported!
//
//
op_2b:
	modrm_jump_16
// 0
	.word sub_ax_bxsi, sub_ax_bxdi, sub_ax_bpsi, sub_ax_bpdi, sub_ax_siidx, sub_ax_diidx, sub_ax_disp16, sub_ax_bxidx
	.word sub_cx_bxsi, sub_cx_bxdi, sub_cx_bpsi, sub_cx_bpdi, sub_cx_siidx, sub_cx_diidx, sub_cx_disp16, sub_cx_bxidx
	.word sub_dx_bxsi, sub_dx_bxdi, sub_dx_bpsi, sub_dx_bpdi, sub_dx_siidx, sub_dx_diidx, sub_dx_disp16, sub_dx_bxidx
	.word sub_bx_bxsi, sub_bx_bxdi, sub_bx_bpsi, sub_bx_bpdi, sub_bx_siidx, sub_bx_diidx, sub_bx_disp16, sub_bx_bxidx
	.word sub_sp_bxsi, sub_sp_bxdi, sub_sp_bpsi, sub_sp_bpdi, sub_sp_siidx, sub_sp_diidx, sub_sp_disp16, sub_sp_bxidx
	.word sub_bp_bxsi, sub_bp_bxdi, sub_bp_bpsi, sub_bp_bpdi, sub_bp_siidx, sub_bp_diidx, sub_bp_disp16, sub_bp_bxidx
	.word sub_si_bxsi, sub_si_bxdi, sub_si_bpsi, sub_si_bpdi, sub_si_siidx, sub_si_diidx, sub_si_disp16, sub_si_bxidx
	.word sub_di_bxsi, sub_di_bxdi, sub_di_bpsi, sub_di_bpdi, sub_di_siidx, sub_di_diidx, sub_di_disp16, sub_di_bxidx
//0x40
	.word sub_ax_bxsid8, sub_ax_bxdid8, sub_ax_bpsid8, sub_ax_bpdid8, sub_ax_sidisp8, sub_ax_didisp8, sub_ax_bpdisp8, sub_ax_bxdisp8
	.word sub_cx_bxsid8, sub_cx_bxdid8, sub_cx_bpsid8, sub_cx_bpdid8, sub_cx_sidisp8, sub_cx_didisp8, sub_cx_bpdisp8, sub_cx_bxdisp8
	.word sub_dx_bxsid8, sub_dx_bxdid8, sub_dx_bpsid8, sub_dx_bpdid8, sub_dx_sidisp8, sub_dx_didisp8, sub_dx_bpdisp8, sub_dx_bxdisp8
	.word sub_bx_bxsid8, sub_bx_bxdid8, sub_bx_bpsid8, sub_bx_bpdid8, sub_bx_sidisp8, sub_bx_didisp8, sub_bx_bpdisp8, sub_bx_bxdisp8
	.word sub_sp_bxsid8, sub_sp_bxdid8, sub_sp_bpsid8, sub_sp_bpdid8, sub_sp_sidisp8, sub_sp_didisp8, sub_sp_bpdisp8, sub_sp_bxdisp8
	.word sub_bp_bxsid8, sub_bp_bxdid8, sub_bp_bpsid8, sub_bp_bpdid8, sub_bp_sidisp8, sub_bp_didisp8, sub_bp_bpdisp8, sub_bp_bxdisp8
	.word sub_si_bxsid8, sub_si_bxdid8, sub_si_bpsid8, sub_si_bpdid8, sub_si_sidisp8, sub_si_didisp8, sub_si_bpdisp8, sub_si_bxdisp8
	.word sub_di_bxsid8, sub_di_bxdid8, sub_di_bpsid8, sub_di_bpdid8, sub_di_sidisp8, sub_di_didisp8, sub_di_bpdisp8, sub_di_bxdisp8
//0x80
	.word sub_ax_bxsid16, sub_ax_bxdid16, sub_ax_bpsid16, sub_ax_bpdid16, sub_ax_sidisp16, sub_ax_didisp16, sub_ax_bpdisp16, sub_ax_bxdisp16
	.word sub_cx_bxsid16, sub_cx_bxdid16, sub_cx_bpsid16, sub_cx_bpdid16, sub_cx_sidisp16, sub_cx_didisp16, sub_cx_bpdisp16, sub_cx_bxdisp16
	.word sub_dx_bxsid16, sub_dx_bxdid16, sub_dx_bpsid16, sub_dx_bpdid16, sub_dx_sidisp16, sub_dx_didisp16, sub_dx_bpdisp16, sub_dx_bxdisp16
	.word sub_bx_bxsid16, sub_bx_bxdid16, sub_bx_bpsid16, sub_bx_bpdid16, sub_bx_sidisp16, sub_bx_didisp16, sub_bx_bpdisp16, sub_bx_bxdisp16
	.word sub_sp_bxsid16, sub_sp_bxdid16, sub_sp_bpsid16, sub_sp_bpdid16, sub_sp_sidisp16, sub_sp_didisp16, sub_sp_bpdisp16, sub_sp_bxdisp16
	.word sub_bp_bxsid16, sub_bp_bxdid16, sub_bp_bpsid16, sub_bp_bpdid16, sub_bp_sidisp16, sub_bp_didisp16, sub_bp_bpdisp16, sub_bp_bxdisp16
	.word sub_si_bxsid16, sub_si_bxdid16, sub_si_bpsid16, sub_si_bpdid16, sub_si_sidisp16, sub_si_didisp16, sub_si_bpdisp16, sub_si_bxdisp16
	.word sub_di_bxsid16, sub_di_bxdid16, sub_di_bpsid16, sub_di_bpdid16, sub_di_sidisp16, sub_di_didisp16, sub_di_bpdisp16, sub_di_bxdisp16
// 0xC0 = two register operands
	.word sub_ax_ax, sub_ax_cx, sub_ax_dx, sub_ax_bx, sub_ax_sp, sub_ax_bp, sub_ax_si, sub_ax_di
	.word sub_cx_ax, sub_cx_cx, sub_cx_dx, sub_cx_bx, sub_cx_sp, sub_cx_bp, sub_cx_si, sub_cx_di
	.word sub_dx_ax, sub_dx_cx, sub_dx_dx, sub_dx_bx, sub_dx_sp, sub_dx_bp, sub_dx_si, sub_dx_di
	.word sub_bx_ax, sub_bx_cx, sub_bx_dx, sub_bx_bx, sub_bx_sp, sub_bx_bp, sub_bx_si, sub_bx_di
	.word sub_sp_ax, sub_sp_cx, sub_sp_dx, sub_sp_bx, sub_sp_sp, sub_sp_bp, sub_sp_si, sub_sp_di
	.word sub_bp_ax, sub_bp_cx, sub_bp_dx, sub_bp_bx, sub_bp_sp, sub_bp_bp, sub_bp_si, sub_bp_di
	.word sub_si_ax, sub_si_cx, sub_si_dx, sub_si_bx, sub_si_sp, sub_si_bp, sub_si_si, sub_si_di
	.word sub_di_ax, sub_di_cx, sub_di_dx, sub_di_bx, sub_di_sp, sub_di_bp, sub_di_si, sub_di_di

// These are called from "cpu_67.s":

	.global sub_ax_siidx, sub_ax_diidx, sub_ax_bxidx
	.global sub_cx_siidx, sub_cx_diidx, sub_cx_bxidx
	.global sub_dx_siidx, sub_dx_diidx, sub_dx_bxidx
	.global sub_bx_siidx, sub_bx_diidx, sub_bx_bxidx
	.global sub_sp_siidx, sub_sp_diidx, sub_sp_bxidx
	.global sub_bp_siidx, sub_bp_diidx, sub_bp_bxidx
	.global sub_si_siidx, sub_si_diidx, sub_si_bxidx
	.global sub_di_siidx, sub_di_diidx, sub_di_bxidx
	.global sub_ax_sidisp8, sub_ax_didisp8, sub_ax_bpdisp8, sub_ax_bxdisp8
	.global sub_cx_sidisp8, sub_cx_didisp8, sub_cx_bpdisp8, sub_cx_bxdisp8
	.global sub_dx_sidisp8, sub_dx_didisp8, sub_dx_bpdisp8, sub_dx_bxdisp8
	.global sub_bx_sidisp8, sub_bx_didisp8, sub_bx_bpdisp8, sub_bx_bxdisp8
	.global sub_sp_sidisp8, sub_sp_didisp8, sub_sp_bpdisp8, sub_sp_bxdisp8
	.global sub_bp_sidisp8, sub_bp_didisp8, sub_bp_bpdisp8, sub_bp_bxdisp8
	.global sub_si_sidisp8, sub_si_didisp8, sub_si_bpdisp8, sub_si_bxdisp8
	.global sub_di_sidisp8, sub_di_didisp8, sub_di_bpdisp8, sub_di_bxdisp8
	.global	sub_r16_r0_bp_r4, sub_r16_r0_bp_r5, sub_r16_r0_bp_r6, sub_r16_r0_bp_r7, sub_r16_r0_bp_r8, sub_r16_r0_bp_r9, sub_r16_r0_bp_r10, sub_r16_r0_bp_r11
	.global	sub_r16_r0_r4, sub_r16_r0_r5, sub_r16_r0_r6, sub_r16_r0_r7, sub_r16_r0_r8, sub_r16_r0_r9, sub_r16_r0_r10, sub_r16_r0_r11

.macro sub_reg16_r0high reg
sub_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
sub_r16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_2b_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_2b_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r2, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	eor		\reg, r2, lsr #16
	subs	r0, r2, r0, lsl #16
	orr		\reg, r0, lsr #16
	b		complement_carry
.endm

	sub_reg16_r0high r4
	sub_reg16_r0high r5
	sub_reg16_r0high r6
	sub_reg16_r0high r7
	sub_reg16_r0high r8
	sub_reg16_r0high r9
	sub_reg16_r0high r10
	sub_reg16_r0high r11

	.ltorg

// --- [idx] ---

.macro sub_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		sub_r16_r0_\reg
.endm

sub_ax_bxsi:
	sub_reg16_bxidx r4 r10
sub_cx_bxsi:
	sub_reg16_bxidx r5 r10
sub_dx_bxsi:
	sub_reg16_bxidx r6 r10
sub_bx_bxsi:
	sub_reg16_bxidx r7 r10
sub_bp_bxsi:
	sub_reg16_bxidx r9 r10
sub_sp_bxsi:
	sub_reg16_bxidx r8 r10
sub_si_bxsi:
	sub_reg16_bxidx r10 r10
sub_di_bxsi:
	sub_reg16_bxidx r11 r10

sub_ax_bxdi:
	sub_reg16_bxidx r4 r11
sub_cx_bxdi:
	sub_reg16_bxidx r5 r11
sub_dx_bxdi:
	sub_reg16_bxidx r6 r11
sub_bx_bxdi:
	sub_reg16_bxidx r7 r11
sub_sp_bxdi:
	sub_reg16_bxidx r8 r11
sub_bp_bxdi:
	sub_reg16_bxidx r9 r11
sub_si_bxdi:
	sub_reg16_bxidx r10 r11
sub_di_bxdi:
	sub_reg16_bxidx r11 r11

.macro sub_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		sub_r16_r0_bp_\reg
.endm

sub_ax_bpsi:
	sub_reg16_bpidx r4 r10
sub_cx_bpsi:
	sub_reg16_bpidx r5 r10
sub_dx_bpsi:
	sub_reg16_bpidx r6 r10
sub_bx_bpsi:
	sub_reg16_bpidx r7 r10
sub_sp_bpsi:
	sub_reg16_bpidx r8 r10
sub_bp_bpsi:
	sub_reg16_bpidx r9 r10
sub_si_bpsi:
	sub_reg16_bpidx r10 r10
sub_di_bpsi:
	sub_reg16_bpidx r11 r10

sub_ax_bpdi:
	sub_reg16_bpidx r4 r11
sub_cx_bpdi:
	sub_reg16_bpidx r5 r11
sub_dx_bpdi:
	sub_reg16_bpidx r6 r11
sub_bx_bpdi:
	sub_reg16_bpidx r7 r11
sub_sp_bpdi:
	sub_reg16_bpidx r8 r11
sub_bp_bpdi:
	sub_reg16_bpidx r9 r11
sub_si_bpdi:
	sub_reg16_bpidx r10 r11
sub_di_bpdi:
	sub_reg16_bpidx r11 r11

.macro sub_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		sub_r16_r0_\reg
.endm

sub_ax_siidx:
	sub_reg16_idx r4 r10
sub_cx_siidx:
	sub_reg16_idx r5 r10
sub_dx_siidx:
	sub_reg16_idx r6 r10
sub_bx_siidx:
	sub_reg16_idx r7 r10
sub_sp_siidx:
	sub_reg16_idx r8 r10
sub_bp_siidx:
	sub_reg16_idx r9 r10
sub_si_siidx:
	sub_reg16_idx r10 r10
sub_di_siidx:
	sub_reg16_idx r11 r10

sub_ax_diidx:
	sub_reg16_idx r4 r11
sub_cx_diidx:
	sub_reg16_idx r5 r11
sub_dx_diidx:
	sub_reg16_idx r6 r11
sub_bx_diidx:
	sub_reg16_idx r7 r11
sub_sp_diidx:
	sub_reg16_idx r8 r11
sub_bp_diidx:
	sub_reg16_idx r9 r11
sub_si_diidx:
	sub_reg16_idx r10 r11
sub_di_diidx:
	sub_reg16_idx r11 r11

sub_ax_bxidx:
	sub_reg16_idx r4 r7
sub_cx_bxidx:
	sub_reg16_idx r5 r7
sub_dx_bxidx:
	sub_reg16_idx r6 r7
sub_bx_bxidx:
	sub_reg16_idx r7 r7
sub_sp_bxidx:
	sub_reg16_idx r8 r7
sub_bp_bxidx:
	sub_reg16_idx r9 r7
sub_si_bxidx:
	sub_reg16_idx r10 r7
sub_di_bxidx:
	sub_reg16_idx r11 r7

.macro sub_reg16_disp16 reg
	r0_from_disp16
	b		sub_r16_r0_\reg
.endm

sub_ax_disp16:
	sub_reg16_disp16 r4
sub_cx_disp16:
	sub_reg16_disp16 r5
sub_dx_disp16:
	sub_reg16_disp16 r6
sub_bx_disp16:
	sub_reg16_disp16 r7
sub_sp_disp16:
	sub_reg16_disp16 r8
sub_bp_disp16:
	sub_reg16_disp16 r9
sub_si_disp16:
	sub_reg16_disp16 r10
sub_di_disp16:
	sub_reg16_disp16 r11

// --- [idx+disp8] ---

.macro sub_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		sub_r16_r0_\reg
.endm

sub_ax_bxsid8:
	sub_reg16_bxidxdisp8 r4 r10
sub_cx_bxsid8:
	sub_reg16_bxidxdisp8 r5 r10
sub_dx_bxsid8:
	sub_reg16_bxidxdisp8 r6 r10
sub_bx_bxsid8:
	sub_reg16_bxidxdisp8 r7 r10
sub_sp_bxsid8:
	sub_reg16_bxidxdisp8 r8 r10
sub_bp_bxsid8:
	sub_reg16_bxidxdisp8 r9 r10
sub_si_bxsid8:
	sub_reg16_bxidxdisp8 r10 r10
sub_di_bxsid8:
	sub_reg16_bxidxdisp8 r11 r10

sub_ax_bxdid8:
	sub_reg16_bxidxdisp8 r4 r11
sub_cx_bxdid8:
	sub_reg16_bxidxdisp8 r5 r11
sub_dx_bxdid8:
	sub_reg16_bxidxdisp8 r6 r11
sub_bx_bxdid8:
	sub_reg16_bxidxdisp8 r7 r11
sub_sp_bxdid8:
	sub_reg16_bxidxdisp8 r8 r11
sub_bp_bxdid8:
	sub_reg16_bxidxdisp8 r9 r11
sub_si_bxdid8:
	sub_reg16_bxidxdisp8 r10 r11
sub_di_bxdid8:
	sub_reg16_bxidxdisp8 r11 r11

.macro sub_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		sub_r16_r0_bp_\reg
.endm

sub_ax_bpsid8:
	sub_reg16_bpidxdisp8 r4 r10
sub_cx_bpsid8:
	sub_reg16_bpidxdisp8 r5 r10
sub_dx_bpsid8:
	sub_reg16_bpidxdisp8 r6 r10
sub_bx_bpsid8:
	sub_reg16_bpidxdisp8 r7 r10
sub_sp_bpsid8:
	sub_reg16_bpidxdisp8 r8 r10
sub_bp_bpsid8:
	sub_reg16_bpidxdisp8 r9 r10
sub_si_bpsid8:
	sub_reg16_bpidxdisp8 r10 r10
sub_di_bpsid8:
	sub_reg16_bpidxdisp8 r11 r10

sub_ax_bpdid8:
	sub_reg16_bpidxdisp8 r4 r11
sub_cx_bpdid8:
	sub_reg16_bpidxdisp8 r5 r11
sub_dx_bpdid8:
	sub_reg16_bpidxdisp8 r6 r11
sub_bx_bpdid8:
	sub_reg16_bpidxdisp8 r7 r11
sub_sp_bpdid8:
	sub_reg16_bpidxdisp8 r8 r11
sub_bp_bpdid8:
	sub_reg16_bpidxdisp8 r9 r11
sub_si_bpdid8:
	sub_reg16_bpidxdisp8 r10 r11
sub_di_bpdid8:
	sub_reg16_bpidxdisp8 r11 r11

.macro sub_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		sub_r16_r0_\reg
.endm

sub_ax_sidisp8:
	sub_reg16_idxdisp8 r4 r10
sub_cx_sidisp8:
	sub_reg16_idxdisp8 r5 r10
sub_dx_sidisp8:
	sub_reg16_idxdisp8 r6 r10
sub_bx_sidisp8:
	sub_reg16_idxdisp8 r7 r10
sub_sp_sidisp8:
	sub_reg16_idxdisp8 r8 r10
sub_bp_sidisp8:
	sub_reg16_idxdisp8 r9 r10
sub_si_sidisp8:
	sub_reg16_idxdisp8 r10 r10
sub_di_sidisp8:
	sub_reg16_idxdisp8 r11 r10

sub_ax_didisp8:
	sub_reg16_idxdisp8 r4 r11
sub_cx_didisp8:
	sub_reg16_idxdisp8 r5 r11
sub_dx_didisp8:
	sub_reg16_idxdisp8 r6 r11
sub_bx_didisp8:
	sub_reg16_idxdisp8 r7 r11
sub_sp_didisp8:
	sub_reg16_idxdisp8 r8 r11
sub_bp_didisp8:
	sub_reg16_idxdisp8 r9 r11
sub_si_didisp8:
	sub_reg16_idxdisp8 r10 r11
sub_di_didisp8:
	sub_reg16_idxdisp8 r11 r11

sub_ax_bxdisp8:
	sub_reg16_idxdisp8 r4 r7
sub_cx_bxdisp8:
	sub_reg16_idxdisp8 r5 r7
sub_dx_bxdisp8:
	sub_reg16_idxdisp8 r6 r7
sub_bx_bxdisp8:
	sub_reg16_idxdisp8 r7 r7
sub_sp_bxdisp8:
	sub_reg16_idxdisp8 r8 r7
sub_bp_bxdisp8:
	sub_reg16_idxdisp8 r9 r7
sub_si_bxdisp8:
	sub_reg16_idxdisp8 r10 r7
sub_di_bxdisp8:
	sub_reg16_idxdisp8 r11 r7

.macro sub_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		sub_r16_r0_bp_\reg
.endm

sub_ax_bpdisp8:
	sub_reg16_bpdisp8 r4
sub_cx_bpdisp8:
	sub_reg16_bpdisp8 r5
sub_dx_bpdisp8:
	sub_reg16_bpdisp8 r6
sub_bx_bpdisp8:
	sub_reg16_bpdisp8 r7
sub_sp_bpdisp8:
	sub_reg16_bpdisp8 r8
sub_bp_bpdisp8:
	sub_reg16_bpdisp8 r9
sub_si_bpdisp8:
	sub_reg16_bpdisp8 r10
sub_di_bpdisp8:
	sub_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro sub_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		sub_r16_r0_\reg
.endm

sub_ax_bxsid16:
	sub_reg16_bxidxdisp16 r4 r10
sub_cx_bxsid16:
	sub_reg16_bxidxdisp16 r5 r10
sub_dx_bxsid16:
	sub_reg16_bxidxdisp16 r6 r10
sub_bx_bxsid16:
	sub_reg16_bxidxdisp16 r7 r10
sub_sp_bxsid16:
	sub_reg16_bxidxdisp16 r8 r10
sub_bp_bxsid16:
	sub_reg16_bxidxdisp16 r9 r10
sub_si_bxsid16:
	sub_reg16_bxidxdisp16 r10 r10
sub_di_bxsid16:
	sub_reg16_bxidxdisp16 r11 r10

sub_ax_bxdid16:
	sub_reg16_bxidxdisp16 r4 r11
sub_cx_bxdid16:
	sub_reg16_bxidxdisp16 r5 r11
sub_dx_bxdid16:
	sub_reg16_bxidxdisp16 r6 r11
sub_bx_bxdid16:
	sub_reg16_bxidxdisp16 r7 r11
sub_sp_bxdid16:
	sub_reg16_bxidxdisp16 r8 r11
sub_bp_bxdid16:
	sub_reg16_bxidxdisp16 r9 r11
sub_si_bxdid16:
	sub_reg16_bxidxdisp16 r10 r11
sub_di_bxdid16:
	sub_reg16_bxidxdisp16 r11 r11

.macro sub_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		sub_r16_r0_bp_\reg
.endm

sub_ax_bpsid16:
	sub_reg16_bpidxdisp16 r4 r10
sub_cx_bpsid16:
	sub_reg16_bpidxdisp16 r5 r10
sub_dx_bpsid16:
	sub_reg16_bpidxdisp16 r6 r10
sub_bx_bpsid16:
	sub_reg16_bpidxdisp16 r7 r10
sub_sp_bpsid16:
	sub_reg16_bpidxdisp16 r8 r10
sub_bp_bpsid16:
	sub_reg16_bpidxdisp16 r9 r10
sub_si_bpsid16:
	sub_reg16_bpidxdisp16 r10 r10
sub_di_bpsid16:
	sub_reg16_bpidxdisp16 r11 r10

sub_ax_bpdid16:
	sub_reg16_bpidxdisp16 r4 r11
sub_cx_bpdid16:
	sub_reg16_bpidxdisp16 r5 r11
sub_dx_bpdid16:
	sub_reg16_bpidxdisp16 r6 r11
sub_bx_bpdid16:
	sub_reg16_bpidxdisp16 r7 r11
sub_sp_bpdid16:
	sub_reg16_bpidxdisp16 r8 r11
sub_bp_bpdid16:
	sub_reg16_bpidxdisp16 r9 r11
sub_si_bpdid16:
	sub_reg16_bpidxdisp16 r10 r11
sub_di_bpdid16:
	sub_reg16_bpidxdisp16 r11 r11

.macro sub_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		sub_r16_r0_\reg
.endm

sub_ax_sidisp16:
	sub_reg16_idxdisp16 r4 r10
sub_cx_sidisp16:
	sub_reg16_idxdisp16 r5 r10
sub_dx_sidisp16:
	sub_reg16_idxdisp16 r6 r10
sub_bx_sidisp16:
	sub_reg16_idxdisp16 r7 r10
sub_sp_sidisp16:
	sub_reg16_idxdisp16 r8 r10
sub_bp_sidisp16:
	sub_reg16_idxdisp16 r9 r10
sub_si_sidisp16:
	sub_reg16_idxdisp16 r10 r10
sub_di_sidisp16:
	sub_reg16_idxdisp16 r11 r10

sub_ax_didisp16:
	sub_reg16_idxdisp16 r4 r11
sub_cx_didisp16:
	sub_reg16_idxdisp16 r5 r11
sub_dx_didisp16:
	sub_reg16_idxdisp16 r6 r11
sub_bx_didisp16:
	sub_reg16_idxdisp16 r7 r11
sub_sp_didisp16:
	sub_reg16_idxdisp16 r8 r11
sub_bp_didisp16:
	sub_reg16_idxdisp16 r9 r11
sub_si_didisp16:
	sub_reg16_idxdisp16 r10 r11
sub_di_didisp16:
	sub_reg16_idxdisp16 r11 r11

sub_ax_bxdisp16:
	sub_reg16_idxdisp16 r4 r7
sub_cx_bxdisp16:
	sub_reg16_idxdisp16 r5 r7
sub_dx_bxdisp16:
	sub_reg16_idxdisp16 r6 r7
sub_bx_bxdisp16:
	sub_reg16_idxdisp16 r7 r7
sub_sp_bxdisp16:
	sub_reg16_idxdisp16 r8 r7
sub_bp_bxdisp16:
	sub_reg16_idxdisp16 r9 r7
sub_si_bxdisp16:
	sub_reg16_idxdisp16 r10 r7
sub_di_bxdisp16:
	sub_reg16_idxdisp16 r11 r7

.macro sub_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		sub_r16_r0_bp_\reg
.endm

sub_ax_bpdisp16:
	sub_reg16_bpdisp16 r4
sub_cx_bpdisp16:
	sub_reg16_bpdisp16 r5
sub_dx_bpdisp16:
	sub_reg16_bpdisp16 r6
sub_bx_bpdisp16:
	sub_reg16_bpdisp16 r7
sub_sp_bpdisp16:
	sub_reg16_bpdisp16 r8
sub_bp_bpdisp16:
	sub_reg16_bpdisp16 r9
sub_si_bpdisp16:
	sub_reg16_bpdisp16 r10
sub_di_bpdisp16:
	sub_reg16_bpdisp16 r11


// --- registers ---

.macro sub_reg16_reg16 rl rr
	mov		r1, \rl, lsl #16
	subs	r0, r1, \rr, lsl #16
	eor		\rl, r1, lsr #16
	orr		\rl, r0, lsr #16
	b		complement_carry
.endm
	
sub_ax_ax:
	sub_reg16_reg16		r4 r4
sub_ax_cx:
	sub_reg16_reg16		r4 r5
sub_ax_dx:
	sub_reg16_reg16		r4 r6
sub_ax_bx:
	sub_reg16_reg16		r4 r7
sub_ax_sp:
	sub_reg16_reg16		r4 r8
sub_ax_bp:
	sub_reg16_reg16		r4 r9
sub_ax_si:
	sub_reg16_reg16		r4 r10
sub_ax_di:
	sub_reg16_reg16		r4 r11
sub_cx_ax:
	sub_reg16_reg16		r5 r4
sub_cx_cx:
	sub_reg16_reg16		r5 r5
sub_cx_dx:
	sub_reg16_reg16		r5 r6
sub_cx_bx:
	sub_reg16_reg16		r5 r7
sub_cx_sp:
	sub_reg16_reg16		r5 r8
sub_cx_bp:
	sub_reg16_reg16		r5 r9
sub_cx_si:
	sub_reg16_reg16		r5 r10
sub_cx_di:
	sub_reg16_reg16		r5 r11
sub_dx_ax:
	sub_reg16_reg16		r6 r4
sub_dx_cx:
	sub_reg16_reg16		r6 r5
sub_dx_dx:
	sub_reg16_reg16		r6 r6
sub_dx_bx:
	sub_reg16_reg16		r6 r7
sub_dx_sp:
	sub_reg16_reg16		r6 r8
sub_dx_bp:
	sub_reg16_reg16		r6 r9
sub_dx_si:
	sub_reg16_reg16		r6 r10
sub_dx_di:
	sub_reg16_reg16		r6 r11
sub_bx_ax:
	sub_reg16_reg16		r7 r4
sub_bx_cx:
	sub_reg16_reg16		r7 r5
sub_bx_dx:
	sub_reg16_reg16		r7 r6
sub_bx_bx:
	sub_reg16_reg16		r7 r7
sub_bx_sp:
	sub_reg16_reg16		r7 r8
sub_bx_bp:
	sub_reg16_reg16		r7 r9
sub_bx_si:
	sub_reg16_reg16		r7 r10
sub_bx_di:
	sub_reg16_reg16		r7 r11
sub_sp_ax:
	sub_reg16_reg16		r8 r4
sub_sp_cx:
	sub_reg16_reg16		r8 r5
sub_sp_dx:
	sub_reg16_reg16		r8 r6
sub_sp_bx:
	sub_reg16_reg16		r8 r7
sub_sp_sp:
	sub_reg16_reg16		r8 r8
sub_sp_bp:
	sub_reg16_reg16		r8 r9
sub_sp_si:
	sub_reg16_reg16		r8 r10
sub_sp_di:
	sub_reg16_reg16		r8 r11
sub_bp_ax:
	sub_reg16_reg16		r9 r4
sub_bp_cx:
	sub_reg16_reg16		r9 r5
sub_bp_dx:
	sub_reg16_reg16		r9 r6
sub_bp_bx:
	sub_reg16_reg16		r9 r7
sub_bp_sp:
	sub_reg16_reg16		r9 r8
sub_bp_bp:
	sub_reg16_reg16		r9 r9
sub_bp_si:
	sub_reg16_reg16		r9 r10
sub_bp_di:
	sub_reg16_reg16		r9 r11
sub_si_ax:
	sub_reg16_reg16		r10 r4
sub_si_cx:
	sub_reg16_reg16		r10 r5
sub_si_dx:
	sub_reg16_reg16		r10 r6
sub_si_bx:
	sub_reg16_reg16		r10 r7
sub_si_sp:
	sub_reg16_reg16		r10 r8
sub_si_bp:
	sub_reg16_reg16		r10 r9
sub_si_si:
	sub_reg16_reg16		r10 r10
sub_si_di:
	sub_reg16_reg16		r10 r11
sub_di_ax:
	sub_reg16_reg16		r11 r4
sub_di_cx:
	sub_reg16_reg16		r11 r5
sub_di_dx:
	sub_reg16_reg16		r11 r6
sub_di_bx:
	sub_reg16_reg16		r11 r7
sub_di_sp:
	sub_reg16_reg16		r11 r8
sub_di_bp:
	sub_reg16_reg16		r11 r9
sub_di_si:
	sub_reg16_reg16		r11 r10
sub_di_di:
	sub_reg16_reg16		r11 r11


#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	
	
// ------------------- 2C = SUB AL, imm8 -------------------------------
op_2c:
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r1, eax, lsl #24		// r1 = AL
	subs	r1, r0, lsl #24			// r1 = AL - imm8
	bic		eax, #0xFF
	orr		eax, r1, lsr #24		// Put result into AL
	b		complement_carry
	
// ------------------- 2D = SUB AX, imm16 ------------------------------
op_2d:
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r1, increment r12 by 1
	mov		r2, eax, lsl #16
	eor		eax, r2, lsr #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	subs	r0, r2, r0, lsl #16		// Here we can safely use the shifter
	orr		eax, r0, lsr #16
	b		complement_carry

	.text
	.align 2

// ------------------- 2F = DAS ----------------------------------------
//
// TODO! AC/PF handling!
//
// OldAL = AL;
// OldCF = CF;
// CF = 0;
//
// if(AL & 0xF > 9 || AF == 1) {
//	CF = OldCF | GetBorrow(AL = AL - 6);
//	AF = 1;
// }
// else AF = 0;
//
// if(OldAL > 0x99 || OldCF == 1) {
//	AL = AL - 0x60;
//	CF = 1;
// }
// else CF = 0;
op_2f:
	ldr		r2, [sp, #SP_FLAGS]					// r2 = current x86 flags (for FLAG_AF)
	mrs		r0, cpsr							// r0 = current ARM flags (for other flags)
	and		r1, eax, #0x0F						//	if (((reg_al & 0x0F)>0x09) || get_AF()) {
	cmp		r1, #0x09
	and		r1, eax, #0xFF
	bgt		1f
	tst		r2, #FLAG_AF
	beq		2f
1:cmp		r1, #0x99							//		if ((reg_al > 0x99) || get_CF()) {
	bgt		6f
	tst		r0, #ARM_CARRY
	beq		7f
6:	sub		r1, #0x60							//			reg_al-=0x60;
	orr		r0, #ARM_CARRY						//			SETFLAGBIT(CF,true);
	b		8f									//		} else
7:	cmp		r1, #0x06
	bicge	r0, #ARM_CARRY						//			SETFLAGBIT(CF,(reg_al<0x06));
	orrlt	r0, #ARM_CARRY
8:	sub		r1, #0x06							//		reg_al-=0x06;
	orr		r2, #FLAG_AF						//		SETFLAGBIT(AF,true);
	b		9f									//	} else {
2:	cmp		r1, #0x99							//		if ((reg_al > 0x99) || get_CF()) {
	bgt		3f
	tst		r0, #ARM_CARRY
	beq		4f
3:	sub		r1, #0x60							//			reg_al-=0x60;
	orr		r0, #ARM_CARRY						//			SETFLAGBIT(CF,true);
	b		5f									//		} else
4:	bic		r0, #ARM_CARRY						//			SETFLAGBIT(CF,false);
5:	bic		r2, #FLAG_AF						//		SETFLAGBIT(AF,false);
9:	bic		r0, #(ARM_OVER|ARM_NEG|ARM_ZERO)
	//------
	// SETFLAGBIT(ZF,(reg_al==0));
	//------
	ands	r1, #0xFF
	orreq	r0, #ARM_ZERO
	//------
	// SETFLAGBIT(SF,(reg_al&0x80));
	//------
	tst		r1, #0x80
	orrne	r0, #ARM_NEG
	//------
	// SETFLAGBIT(OF,osigned && ((reg_al&0x80)==0))
	//------
	tst		eax, #0x80							// osigned == original AL highest bit
	beq		1f
	tst		r1, #0x80
	orreq	r0, #ARM_OVER
1:	
	//------
	// SETFLAGBIT(PF,parity_lookup[reg_al]);
	//------
	//------
	// Put the result into EAX low byte
	//------
	bic		eax, #0xFF
	orr		eax, r1
	str		r2, [sp, #SP_FLAGS]					// Save new x86 flags (for FLAG_AF)
	b		restore_flags_from_r0
	
// ------------------- 30 = XOR r/m8, r8 -------------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual eors operation, so C and O work like in x86.
//
// All modrm variations supported!
//
//
	.global	op_30
op_30:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word xor_bxsi_al, xor_bxdi_al, xor_bpsi_al, xor_bpdi_al, xor_siidx_al, xor_diidx_al, xor_disp16_al, xor_bxidx_al
	.word xor_bxsi_cl, xor_bxdi_cl, xor_bpsi_cl, xor_bpdi_cl, xor_siidx_cl, xor_diidx_cl, xor_disp16_cl, xor_bxidx_cl
	.word xor_bxsi_dl, xor_bxdi_dl, xor_bpsi_dl, xor_bpdi_dl, xor_siidx_dl, xor_diidx_dl, xor_disp16_dl, xor_bxidx_dl
	.word xor_bxsi_bl, xor_bxdi_bl, xor_bpsi_bl, xor_bpdi_bl, xor_siidx_bl, xor_diidx_bl, xor_disp16_bl, xor_bxidx_bl
	.word xor_bxsi_ah, xor_bxdi_ah, xor_bpsi_ah, xor_bpdi_ah, xor_siidx_ah, xor_diidx_ah, xor_disp16_ah, xor_bxidx_ah
	.word xor_bxsi_ch, xor_bxdi_ch, xor_bpsi_ch, xor_bpdi_ch, xor_siidx_ch, xor_diidx_ch, xor_disp16_ch, xor_bxidx_ch
	.word xor_bxsi_dh, xor_bxdi_dh, xor_bpsi_dh, xor_bpdi_dh, xor_siidx_dh, xor_diidx_dh, xor_disp16_dh, xor_bxidx_dh
	.word xor_bxsi_bh, xor_bxdi_bh, xor_bpsi_bh, xor_bpdi_bh, xor_siidx_bh, xor_diidx_bh, xor_disp16_bh, xor_bxidx_bh
//0x40
	.word xor_bxsid8_al, xor_bxdid8_al, xor_bpsid8_al, xor_bpdid8_al, xor_sidisp8_al, xor_didisp8_al, xor_bpdisp8_al, xor_bxdisp8_al
	.word xor_bxsid8_cl, xor_bxdid8_cl, xor_bpsid8_cl, xor_bpdid8_cl, xor_sidisp8_cl, xor_didisp8_cl, xor_bpdisp8_cl, xor_bxdisp8_cl
	.word xor_bxsid8_dl, xor_bxdid8_dl, xor_bpsid8_dl, xor_bpdid8_dl, xor_sidisp8_dl, xor_didisp8_dl, xor_bpdisp8_dl, xor_bxdisp8_dl
	.word xor_bxsid8_bl, xor_bxdid8_bl, xor_bpsid8_bl, xor_bpdid8_bl, xor_sidisp8_bl, xor_didisp8_bl, xor_bpdisp8_bl, xor_bxdisp8_bl
	.word xor_bxsid8_ah, xor_bxdid8_ah, xor_bpsid8_ah, xor_bpdid8_ah, xor_sidisp8_ah, xor_didisp8_ah, xor_bpdisp8_ah, xor_bxdisp8_ah
	.word xor_bxsid8_ch, xor_bxdid8_ch, xor_bpsid8_ch, xor_bpdid8_ch, xor_sidisp8_ch, xor_didisp8_ch, xor_bpdisp8_ch, xor_bxdisp8_ch
	.word xor_bxsid8_dh, xor_bxdid8_dh, xor_bpsid8_dh, xor_bpdid8_dh, xor_sidisp8_dh, xor_didisp8_dh, xor_bpdisp8_dh, xor_bxdisp8_dh
	.word xor_bxsid8_bh, xor_bxdid8_bh, xor_bpsid8_bh, xor_bpdid8_bh, xor_sidisp8_bh, xor_didisp8_bh, xor_bpdisp8_bh, xor_bxdisp8_bh
//0x80
	.word xor_bxsid16_al, xor_bxdid16_al, xor_bpsid16_al, xor_bpdid16_al, xor_sidisp16_al, xor_didisp16_al, xor_bpdisp16_al, xor_bxdisp16_al
	.word xor_bxsid16_cl, xor_bxdid16_cl, xor_bpsid16_cl, xor_bpdid16_cl, xor_sidisp16_cl, xor_didisp16_cl, xor_bpdisp16_cl, xor_bxdisp16_cl
	.word xor_bxsid16_dl, xor_bxdid16_dl, xor_bpsid16_dl, xor_bpdid16_dl, xor_sidisp16_dl, xor_didisp16_dl, xor_bpdisp16_dl, xor_bxdisp16_dl
	.word xor_bxsid16_bl, xor_bxdid16_bl, xor_bpsid16_bl, xor_bpdid16_bl, xor_sidisp16_bl, xor_didisp16_bl, xor_bpdisp16_bl, xor_bxdisp16_bl
	.word xor_bxsid16_ah, xor_bxdid16_ah, xor_bpsid16_ah, xor_bpdid16_ah, xor_sidisp16_ah, xor_didisp16_ah, xor_bpdisp16_ah, xor_bxdisp16_ah
	.word xor_bxsid16_ch, xor_bxdid16_ch, xor_bpsid16_ch, xor_bpdid16_ch, xor_sidisp16_ch, xor_didisp16_ch, xor_bpdisp16_ch, xor_bxdisp16_ch
	.word xor_bxsid16_dh, xor_bxdid16_dh, xor_bpsid16_dh, xor_bpdid16_dh, xor_sidisp16_dh, xor_didisp16_dh, xor_bpdisp16_dh, xor_bxdisp16_dh
	.word xor_bxsid16_bh, xor_bxdid16_bh, xor_bpsid16_bh, xor_bpdid16_bh, xor_sidisp16_bh, xor_didisp16_bh, xor_bpdisp16_bh, xor_bxdisp16_bh
// 0xC0 = two register operands
	.word xor_al_al, xor_cl_al, xor_dl_al, xor_bl_al, xor_ah_al, xor_ch_al, xor_dh_al, xor_bh_al
	.word xor_al_cl, xor_cl_cl, xor_dl_cl, xor_bl_cl, xor_ah_cl, xor_ch_cl, xor_dh_cl, xor_bh_cl
	.word xor_al_dl, xor_cl_dl, xor_dl_dl, xor_bl_dl, xor_ah_dl, xor_ch_dl, xor_dh_dl, xor_bh_dl
	.word xor_al_bl, xor_cl_bl, xor_dl_bl, xor_bl_bl, xor_ah_bl, xor_ch_bl, xor_dh_bl, xor_bh_bl
	.word xor_al_ah, xor_cl_ah, xor_dl_ah, xor_bl_ah, xor_ah_ah, xor_ch_ah, xor_dh_ah, xor_bh_ah
	.word xor_al_ch, xor_cl_ch, xor_dl_ch, xor_bl_ch, xor_ah_ch, xor_ch_ch, xor_dh_ch, xor_bh_ch
	.word xor_al_dh, xor_cl_dh, xor_dl_dh, xor_bl_dh, xor_ah_dh, xor_ch_dh, xor_dh_dh, xor_bh_dh
	.word xor_al_bh, xor_cl_bh, xor_dl_bh, xor_bl_bh, xor_ah_bh, xor_ch_bh, xor_dh_bh, xor_bh_bh

// These are called from "cpu_386.s":

	.global	xor_siidx_al, xor_siidx_cl, xor_siidx_dl, xor_siidx_bl, xor_siidx_ah, xor_siidx_ch, xor_siidx_dh, xor_siidx_bh
	.global	xor_diidx_al, xor_diidx_cl, xor_diidx_dl, xor_diidx_bl, xor_diidx_ah, xor_diidx_ch, xor_diidx_dh, xor_diidx_bh
	.global	xor_bxidx_al, xor_bxidx_cl, xor_bxidx_dl, xor_bxidx_bl, xor_bxidx_ah, xor_bxidx_ch, xor_bxidx_dh, xor_bxidx_bh
	.global	xor_sidisp8_al, xor_sidisp8_cl, xor_sidisp8_dl, xor_sidisp8_bl, xor_sidisp8_ah, xor_sidisp8_ch, xor_sidisp8_dh, xor_sidisp8_bh
	.global	xor_didisp8_al, xor_didisp8_cl, xor_didisp8_dl, xor_didisp8_bl, xor_didisp8_ah, xor_didisp8_ch, xor_didisp8_dh, xor_didisp8_bh
	.global	xor_bpdisp8_al, xor_bpdisp8_cl, xor_bpdisp8_dl, xor_bpdisp8_bl, xor_bpdisp8_ah, xor_bpdisp8_ch, xor_bpdisp8_dh, xor_bpdisp8_bh
	.global	xor_bxdisp8_al, xor_bxdisp8_cl, xor_bxdisp8_dl, xor_bxdisp8_bl, xor_bxdisp8_ah, xor_bxdisp8_ch, xor_bxdisp8_dh, xor_bxdisp8_bh

.macro xor_r0_reg8l reg
	.global	xor_r0_r8l_bp_\reg
xor_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	xor_r0_r8l_\reg
xor_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_30_RAM_l_\reg op_30_EGA_l_\reg op_30_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_30_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	eors	r0, r1, r0, lsl #24		// Perform the operation using the highest bytes to get the correct flags
	lsr		r0, #24
	strb	r0,[r2]					// Store the byte back
	b		loop
.endm
.macro xor_r0_reg8h reg
	.global	xor_r0_r8h_bp_\reg
xor_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	xor_r0_r8h_\reg
xor_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_30_RAM_h_\reg op_30_EGA_h_\reg op_30_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_30_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r1, #16
	eors	r0, r1, r0, lsl #24		// Perform the operation using the highest bytes to get the correct flags
	lsr		r0, #24
	strb	r0,[r2]					// Store the byte back
	b		loop
.endm

	xor_r0_reg8l r4
	xor_r0_reg8l r5
	xor_r0_reg8l r6
	xor_r0_reg8l r7
	xor_r0_reg8h r4
	xor_r0_reg8h r5
	xor_r0_reg8h r6
	xor_r0_reg8h r7

	.ltorg
	
// --- [idx] ---

.macro xor_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		xor_r0_r8l_\reg
.endm
.macro xor_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		xor_r0_r8h_\reg
.endm

xor_bxsi_al:
	xor_bxidx_reg8l r10 r4
xor_bxsi_cl:
	xor_bxidx_reg8l r10 r5
xor_bxsi_dl:
	xor_bxidx_reg8l r10 r6
xor_bxsi_bl:
	xor_bxidx_reg8l r10 r7
xor_bxsi_ah:
	xor_bxidx_reg8h r10 r4
xor_bxsi_ch:
	xor_bxidx_reg8h r10 r5
xor_bxsi_dh:
	xor_bxidx_reg8h r10 r6
xor_bxsi_bh:
	xor_bxidx_reg8h r10 r7

xor_bxdi_al:
	xor_bxidx_reg8l r11 r4
xor_bxdi_cl:
	xor_bxidx_reg8l r11 r5
xor_bxdi_dl:
	xor_bxidx_reg8l r11 r6
xor_bxdi_bl:
	xor_bxidx_reg8l r11 r7
xor_bxdi_ah:
	xor_bxidx_reg8h r11 r4
xor_bxdi_ch:
	xor_bxidx_reg8h r11 r5
xor_bxdi_dh:
	xor_bxidx_reg8h r11 r6
xor_bxdi_bh:
	xor_bxidx_reg8h r11 r7

.macro xor_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		xor_r0_r8l_bp_\reg
.endm
.macro xor_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		xor_r0_r8h_bp_\reg
.endm

xor_bpsi_al:
	xor_bpidx_reg8l r10 r4
xor_bpsi_cl:
	xor_bpidx_reg8l r10 r5
xor_bpsi_dl:
	xor_bpidx_reg8l r10 r6
xor_bpsi_bl:
	xor_bpidx_reg8l r10 r7
xor_bpsi_ah:
	xor_bpidx_reg8h r10 r4
xor_bpsi_ch:
	xor_bpidx_reg8h r10 r5
xor_bpsi_dh:
	xor_bpidx_reg8h r10 r6
xor_bpsi_bh:
	xor_bpidx_reg8h r10 r7

xor_bpdi_al:
	xor_bpidx_reg8l r11 r4
xor_bpdi_cl:
	xor_bpidx_reg8l r11 r5
xor_bpdi_dl:
	xor_bpidx_reg8l r11 r6
xor_bpdi_bl:
	xor_bpidx_reg8l r11 r7
xor_bpdi_ah:
	xor_bpidx_reg8h r11 r4
xor_bpdi_ch:
	xor_bpidx_reg8h r11 r5
xor_bpdi_dh:
	xor_bpidx_reg8h r11 r6
xor_bpdi_bh:
	xor_bpidx_reg8h r11 r7

.macro xor_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		xor_r0_r8l_\reg
.endm
.macro xor_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		xor_r0_r8h_\reg
.endm

xor_siidx_al:
	xor_idx_reg8l r10 r4
xor_siidx_cl:
	xor_idx_reg8l r10 r5
xor_siidx_dl:
	xor_idx_reg8l r10 r6
xor_siidx_bl:
	xor_idx_reg8l r10 r7
xor_siidx_ah:
	xor_idx_reg8h r10 r4
xor_siidx_ch:
	xor_idx_reg8h r10 r5
xor_siidx_dh:
	xor_idx_reg8h r10 r6
xor_siidx_bh:
	xor_idx_reg8h r10 r7

xor_diidx_al:
	xor_idx_reg8l r11 r4
xor_diidx_cl:
	xor_idx_reg8l r11 r5
xor_diidx_dl:
	xor_idx_reg8l r11 r6
xor_diidx_bl:
	xor_idx_reg8l r11 r7
xor_diidx_ah:
	xor_idx_reg8h r11 r4
xor_diidx_ch:
	xor_idx_reg8h r11 r5
xor_diidx_dh:
	xor_idx_reg8h r11 r6
xor_diidx_bh:
	xor_idx_reg8h r11 r7

xor_bxidx_al:
	xor_idx_reg8l r7 r4
xor_bxidx_cl:
	xor_idx_reg8l r7 r5
xor_bxidx_dl:
	xor_idx_reg8l r7 r6
xor_bxidx_bl:
	xor_idx_reg8l r7 r7
xor_bxidx_ah:
	xor_idx_reg8h r7 r4
xor_bxidx_ch:
	xor_idx_reg8h r7 r5
xor_bxidx_dh:
	xor_idx_reg8h r7 r6
xor_bxidx_bh:
	xor_idx_reg8h r7 r7
	
.macro xor_disp16_reg8l reg
	r0_from_disp16
	b		xor_r0_r8l_\reg
.endm

.macro xor_disp16_reg8h reg
	r0_from_disp16
	b		xor_r0_r8h_\reg
.endm

xor_disp16_al:
	xor_disp16_reg8l r4
xor_disp16_cl:
	xor_disp16_reg8l r5
xor_disp16_dl:
	xor_disp16_reg8l r6
xor_disp16_bl:
	xor_disp16_reg8l r7
xor_disp16_ah:
	xor_disp16_reg8h r4
xor_disp16_ch:
	xor_disp16_reg8h r5
xor_disp16_dh:
	xor_disp16_reg8h r6
xor_disp16_bh:
	xor_disp16_reg8h r7

// --- [idx+disp8] ---

.macro xor_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		xor_r0_r8l_\reg
.endm
.macro xor_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		xor_r0_r8h_\reg
.endm

xor_bxsid8_al:
	xor_bxidxd8_reg8l r10 r4
xor_bxsid8_cl:
	xor_bxidxd8_reg8l r10 r5
xor_bxsid8_dl:
	xor_bxidxd8_reg8l r10 r6
xor_bxsid8_bl:
	xor_bxidxd8_reg8l r10 r7
xor_bxsid8_ah:
	xor_bxidxd8_reg8h r10 r4
xor_bxsid8_ch:
	xor_bxidxd8_reg8h r10 r5
xor_bxsid8_dh:
	xor_bxidxd8_reg8h r10 r6
xor_bxsid8_bh:
	xor_bxidxd8_reg8h r10 r7

xor_bxdid8_al:
	xor_bxidxd8_reg8l r11 r4
xor_bxdid8_cl:
	xor_bxidxd8_reg8l r11 r5
xor_bxdid8_dl:
	xor_bxidxd8_reg8l r11 r6
xor_bxdid8_bl:
	xor_bxidxd8_reg8l r11 r7
xor_bxdid8_ah:
	xor_bxidxd8_reg8h r11 r4
xor_bxdid8_ch:
	xor_bxidxd8_reg8h r11 r5
xor_bxdid8_dh:
	xor_bxidxd8_reg8h r11 r6
xor_bxdid8_bh:
	xor_bxidxd8_reg8h r11 r7

.macro xor_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		xor_r0_r8l_bp_\reg
.endm
.macro xor_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		xor_r0_r8h_bp_\reg
.endm

xor_bpsid8_al:
	xor_bpidxd8_reg8l r10 r4
xor_bpsid8_cl:
	xor_bpidxd8_reg8l r10 r5
xor_bpsid8_dl:
	xor_bpidxd8_reg8l r10 r6
xor_bpsid8_bl:
	xor_bpidxd8_reg8l r10 r7
xor_bpsid8_ah:
	xor_bpidxd8_reg8h r10 r4
xor_bpsid8_ch:
	xor_bpidxd8_reg8h r10 r5
xor_bpsid8_dh:
	xor_bpidxd8_reg8h r10 r6
xor_bpsid8_bh:
	xor_bpidxd8_reg8h r10 r7

xor_bpdid8_al:
	xor_bpidxd8_reg8l r11 r4
xor_bpdid8_cl:
	xor_bpidxd8_reg8l r11 r5
xor_bpdid8_dl:
	xor_bpidxd8_reg8l r11 r6
xor_bpdid8_bl:
	xor_bpidxd8_reg8l r11 r7
xor_bpdid8_ah:
	xor_bpidxd8_reg8h r11 r4
xor_bpdid8_ch:
	xor_bpidxd8_reg8h r11 r5
xor_bpdid8_dh:
	xor_bpidxd8_reg8h r11 r6
xor_bpdid8_bh:
	xor_bpidxd8_reg8h r11 r7

.macro xor_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		xor_r0_r8l_\reg
.endm
.macro xor_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		xor_r0_r8h_\reg
.endm

xor_sidisp8_al:
	xor_idxdisp8_reg8l r10 r4
xor_sidisp8_cl:
	xor_idxdisp8_reg8l r10 r5
xor_sidisp8_dl:
	xor_idxdisp8_reg8l r10 r6
xor_sidisp8_bl:
	xor_idxdisp8_reg8l r10 r7
xor_sidisp8_ah:
	xor_idxdisp8_reg8h r10 r4
xor_sidisp8_ch:
	xor_idxdisp8_reg8h r10 r5
xor_sidisp8_dh:
	xor_idxdisp8_reg8h r10 r6
xor_sidisp8_bh:
	xor_idxdisp8_reg8h r10 r7

xor_didisp8_al:
	xor_idxdisp8_reg8l r11 r4
xor_didisp8_cl:
	xor_idxdisp8_reg8l r11 r5
xor_didisp8_dl:
	xor_idxdisp8_reg8l r11 r6
xor_didisp8_bl:
	xor_idxdisp8_reg8l r11 r7
xor_didisp8_ah:
	xor_idxdisp8_reg8h r11 r4
xor_didisp8_ch:
	xor_idxdisp8_reg8h r11 r5
xor_didisp8_dh:
	xor_idxdisp8_reg8h r11 r6
xor_didisp8_bh:
	xor_idxdisp8_reg8h r11 r7

xor_bxdisp8_al:
	xor_idxdisp8_reg8l r7 r4
xor_bxdisp8_cl:
	xor_idxdisp8_reg8l r7 r5
xor_bxdisp8_dl:
	xor_idxdisp8_reg8l r7 r6
xor_bxdisp8_bl:
	xor_idxdisp8_reg8l r7 r7
xor_bxdisp8_ah:
	xor_idxdisp8_reg8h r7 r4
xor_bxdisp8_ch:
	xor_idxdisp8_reg8h r7 r5
xor_bxdisp8_dh:
	xor_idxdisp8_reg8h r7 r6
xor_bxdisp8_bh:
	xor_idxdisp8_reg8h r7 r7

.macro xor_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		xor_r0_r8l_bp_\reg
.endm
.macro xor_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		xor_r0_r8h_bp_\reg
.endm

xor_bpdisp8_al:
	xor_bpdisp8_reg8l r4
xor_bpdisp8_cl:
	xor_bpdisp8_reg8l r5
xor_bpdisp8_dl:
	xor_bpdisp8_reg8l r6
xor_bpdisp8_bl:
	xor_bpdisp8_reg8l r7
xor_bpdisp8_ah:
	xor_bpdisp8_reg8h r4
xor_bpdisp8_ch:
	xor_bpdisp8_reg8h r5
xor_bpdisp8_dh:
	xor_bpdisp8_reg8h r6
xor_bpdisp8_bh:
	xor_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro xor_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		xor_r0_r8l_\reg
.endm
.macro xor_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		xor_r0_r8h_\reg
.endm

xor_bxsid16_al:
	xor_bxidxdisp16_reg8l r10 r4
xor_bxsid16_cl:
	xor_bxidxdisp16_reg8l r10 r5
xor_bxsid16_dl:
	xor_bxidxdisp16_reg8l r10 r6
xor_bxsid16_bl:
	xor_bxidxdisp16_reg8l r10 r7
xor_bxsid16_ah:
	xor_bxidxdisp16_reg8h r10 r4
xor_bxsid16_ch:
	xor_bxidxdisp16_reg8h r10 r5
xor_bxsid16_dh:
	xor_bxidxdisp16_reg8h r10 r6
xor_bxsid16_bh:
	xor_bxidxdisp16_reg8h r10 r7

xor_bxdid16_al:
	xor_bxidxdisp16_reg8l r11 r4
xor_bxdid16_cl:
	xor_bxidxdisp16_reg8l r11 r5
xor_bxdid16_dl:
	xor_bxidxdisp16_reg8l r11 r6
xor_bxdid16_bl:
	xor_bxidxdisp16_reg8l r11 r7
xor_bxdid16_ah:
	xor_bxidxdisp16_reg8h r11 r4
xor_bxdid16_ch:
	xor_bxidxdisp16_reg8h r11 r5
xor_bxdid16_dh:
	xor_bxidxdisp16_reg8h r11 r6
xor_bxdid16_bh:
	xor_bxidxdisp16_reg8h r11 r7

.macro xor_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		xor_r0_r8l_bp_\reg
.endm
.macro xor_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		xor_r0_r8h_bp_\reg
.endm

xor_bpsid16_al:
	xor_bpidxd16_reg8l r10 r4
xor_bpsid16_cl:
	xor_bpidxd16_reg8l r10 r5
xor_bpsid16_dl:
	xor_bpidxd16_reg8l r10 r6
xor_bpsid16_bl:
	xor_bpidxd16_reg8l r10 r7
xor_bpsid16_ah:
	xor_bpidxd16_reg8h r10 r4
xor_bpsid16_ch:
	xor_bpidxd16_reg8h r10 r5
xor_bpsid16_dh:
	xor_bpidxd16_reg8h r10 r6
xor_bpsid16_bh:
	xor_bpidxd16_reg8h r10 r7

xor_bpdid16_al:
	xor_bpidxd16_reg8l r11 r4
xor_bpdid16_cl:
	xor_bpidxd16_reg8l r11 r5
xor_bpdid16_dl:
	xor_bpidxd16_reg8l r11 r6
xor_bpdid16_bl:
	xor_bpidxd16_reg8l r11 r7
xor_bpdid16_ah:
	xor_bpidxd16_reg8h r11 r4
xor_bpdid16_ch:
	xor_bpidxd16_reg8h r11 r5
xor_bpdid16_dh:
	xor_bpidxd16_reg8h r11 r6
xor_bpdid16_bh:
	xor_bpidxd16_reg8h r11 r7

.macro xor_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		xor_r0_r8l_\reg
.endm
.macro xor_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		xor_r0_r8h_\reg
.endm

xor_sidisp16_al:
	xor_idxdisp16_reg8l r10 r4
xor_sidisp16_cl:
	xor_idxdisp16_reg8l r10 r5
xor_sidisp16_dl:
	xor_idxdisp16_reg8l r10 r6
xor_sidisp16_bl:
	xor_idxdisp16_reg8l r10 r7
xor_sidisp16_ah:
	xor_idxdisp16_reg8h r10 r4
xor_sidisp16_ch:
	xor_idxdisp16_reg8h r10 r5
xor_sidisp16_dh:
	xor_idxdisp16_reg8h r10 r6
xor_sidisp16_bh:
	xor_idxdisp16_reg8h r10 r7

xor_didisp16_al:
	xor_idxdisp16_reg8l r11 r4
xor_didisp16_cl:
	xor_idxdisp16_reg8l r11 r5
xor_didisp16_dl:
	xor_idxdisp16_reg8l r11 r6
xor_didisp16_bl:
	xor_idxdisp16_reg8l r11 r7
xor_didisp16_ah:
	xor_idxdisp16_reg8h r11 r4
xor_didisp16_ch:
	xor_idxdisp16_reg8h r11 r5
xor_didisp16_dh:
	xor_idxdisp16_reg8h r11 r6
xor_didisp16_bh:
	xor_idxdisp16_reg8h r11 r7

xor_bxdisp16_al:
	xor_idxdisp16_reg8l r7 r4
xor_bxdisp16_cl:
	xor_idxdisp16_reg8l r7 r5
xor_bxdisp16_dl:
	xor_idxdisp16_reg8l r7 r6
xor_bxdisp16_bl:
	xor_idxdisp16_reg8l r7 r7
xor_bxdisp16_ah:
	xor_idxdisp16_reg8h r7 r4
xor_bxdisp16_ch:
	xor_idxdisp16_reg8h r7 r5
xor_bxdisp16_dh:
	xor_idxdisp16_reg8h r7 r6
xor_bxdisp16_bh:
	xor_idxdisp16_reg8h r7 r7

.macro xor_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		xor_r0_r8l_bp_\reg
.endm
.macro xor_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		xor_r0_r8h_bp_\reg
.endm

xor_bpdisp16_al:
	xor_bpdisp16_reg8l r4
xor_bpdisp16_cl:
	xor_bpdisp16_reg8l r5
xor_bpdisp16_dl:
	xor_bpdisp16_reg8l r6
xor_bpdisp16_bl:
	xor_bpdisp16_reg8l r7
xor_bpdisp16_ah:
	xor_bpdisp16_reg8h r4
xor_bpdisp16_ch:
	xor_bpdisp16_reg8h r5
xor_bpdisp16_dh:
	xor_bpdisp16_reg8h r6
xor_bpdisp16_bh:
	xor_bpdisp16_reg8h r7

// ------------------- 31 = XOR r/m16, r16 -----------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual eors operation, so C and O work like in x86.
//
// All modrm variations supported!
//
//
	.global	op_31
op_31:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word xor_bxsi_ax, xor_bxdi_ax, xor_bpsi_ax, xor_bpdi_ax, xor_siidx_ax, xor_diidx_ax, xor_disp16_ax, xor_bxidx_ax
	.word xor_bxsi_cx, xor_bxdi_cx, xor_bpsi_cx, xor_bpdi_cx, xor_siidx_cx, xor_diidx_cx, xor_disp16_cx, xor_bxidx_cx
	.word xor_bxsi_dx, xor_bxdi_dx, xor_bpsi_dx, xor_bpdi_dx, xor_siidx_dx, xor_diidx_dx, xor_disp16_dx, xor_bxidx_dx
	.word xor_bxsi_bx, xor_bxdi_bx, xor_bpsi_bx, xor_bpdi_bx, xor_siidx_bx, xor_diidx_bx, xor_disp16_bx, xor_bxidx_bx
	.word xor_bxsi_sp, xor_bxdi_sp, xor_bpsi_sp, xor_bpdi_sp, xor_siidx_sp, xor_diidx_sp, xor_disp16_sp, xor_bxidx_sp
	.word xor_bxsi_bp, xor_bxdi_bp, xor_bpsi_bp, xor_bpdi_bp, xor_siidx_bp, xor_diidx_bp, xor_disp16_bp, xor_bxidx_bp
	.word xor_bxsi_si, xor_bxdi_si, xor_bpsi_si, xor_bpdi_si, xor_siidx_si, xor_diidx_si, xor_disp16_si, xor_bxidx_si
	.word xor_bxsi_di, xor_bxdi_di, xor_bpsi_di, xor_bpdi_di, xor_siidx_di, xor_diidx_di, xor_disp16_di, xor_bxidx_di
//0x40
	.word xor_bxsid8_ax, xor_bxdid8_ax, xor_bpsid8_ax, xor_bpdid8_ax, xor_sidisp8_ax, xor_didisp8_ax, xor_bpdisp8_ax, xor_bxdisp8_ax
	.word xor_bxsid8_cx, xor_bxdid8_cx, xor_bpsid8_cx, xor_bpdid8_cx, xor_sidisp8_cx, xor_didisp8_cx, xor_bpdisp8_cx, xor_bxdisp8_cx
	.word xor_bxsid8_dx, xor_bxdid8_dx, xor_bpsid8_dx, xor_bpdid8_dx, xor_sidisp8_dx, xor_didisp8_dx, xor_bpdisp8_dx, xor_bxdisp8_dx
	.word xor_bxsid8_bx, xor_bxdid8_bx, xor_bpsid8_bx, xor_bpdid8_bx, xor_sidisp8_bx, xor_didisp8_bx, xor_bpdisp8_bx, xor_bxdisp8_bx
	.word xor_bxsid8_sp, xor_bxdid8_sp, xor_bpsid8_sp, xor_bpdid8_sp, xor_sidisp8_sp, xor_didisp8_sp, xor_bpdisp8_sp, xor_bxdisp8_sp
	.word xor_bxsid8_bp, xor_bxdid8_bp, xor_bpsid8_bp, xor_bpdid8_bp, xor_sidisp8_bp, xor_didisp8_bp, xor_bpdisp8_bp, xor_bxdisp8_bp
	.word xor_bxsid8_si, xor_bxdid8_si, xor_bpsid8_si, xor_bpdid8_si, xor_sidisp8_si, xor_didisp8_si, xor_bpdisp8_si, xor_bxdisp8_si
	.word xor_bxsid8_di, xor_bxdid8_di, xor_bpsid8_di, xor_bpdid8_di, xor_sidisp8_di, xor_didisp8_di, xor_bpdisp8_di, xor_bxdisp8_di
//0x80
	.word xor_bxsid16_ax, xor_bxdid16_ax, xor_bpsid16_ax, xor_bpdid16_ax, xor_sidisp16_ax, xor_didisp16_ax, xor_bpdisp16_ax, xor_bxdisp16_ax
	.word xor_bxsid16_cx, xor_bxdid16_cx, xor_bpsid16_cx, xor_bpdid16_cx, xor_sidisp16_cx, xor_didisp16_cx, xor_bpdisp16_cx, xor_bxdisp16_cx
	.word xor_bxsid16_dx, xor_bxdid16_dx, xor_bpsid16_dx, xor_bpdid16_dx, xor_sidisp16_dx, xor_didisp16_dx, xor_bpdisp16_dx, xor_bxdisp16_dx
	.word xor_bxsid16_bx, xor_bxdid16_bx, xor_bpsid16_bx, xor_bpdid16_bx, xor_sidisp16_bx, xor_didisp16_bx, xor_bpdisp16_bx, xor_bxdisp16_bx
	.word xor_bxsid16_sp, xor_bxdid16_sp, xor_bpsid16_sp, xor_bpdid16_sp, xor_sidisp16_sp, xor_didisp16_sp, xor_bpdisp16_sp, xor_bxdisp16_sp
	.word xor_bxsid16_bp, xor_bxdid16_bp, xor_bpsid16_bp, xor_bpdid16_bp, xor_sidisp16_bp, xor_didisp16_bp, xor_bpdisp16_bp, xor_bxdisp16_bp
	.word xor_bxsid16_si, xor_bxdid16_si, xor_bpsid16_si, xor_bpdid16_si, xor_sidisp16_si, xor_didisp16_si, xor_bpdisp16_si, xor_bxdisp16_si
	.word xor_bxsid16_di, xor_bxdid16_di, xor_bpsid16_di, xor_bpdid16_di, xor_sidisp16_di, xor_didisp16_di, xor_bpdisp16_di, xor_bxdisp16_di
// 0xC0 = two register operands
	.word xor_ax_ax, xor_cx_ax, xor_dx_ax, xor_bx_ax, xor_sp_ax, xor_bp_ax, xor_si_ax, xor_di_ax
	.word xor_ax_cx, xor_cx_cx, xor_dx_cx, xor_bx_cx, xor_sp_cx, xor_bp_cx, xor_si_cx, xor_di_cx
	.word xor_ax_dx, xor_cx_dx, xor_dx_dx, xor_bx_dx, xor_sp_dx, xor_bp_dx, xor_si_dx, xor_di_dx
	.word xor_ax_bx, xor_cx_bx, xor_dx_bx, xor_bx_bx, xor_sp_bx, xor_bp_bx, xor_si_bx, xor_di_bx
	.word xor_ax_sp, xor_cx_sp, xor_dx_sp, xor_bx_sp, xor_sp_sp, xor_bp_sp, xor_si_sp, xor_di_sp
	.word xor_ax_bp, xor_cx_bp, xor_dx_bp, xor_bx_bp, xor_sp_bp, xor_bp_bp, xor_si_bp, xor_di_bp
	.word xor_ax_si, xor_cx_si, xor_dx_si, xor_bx_si, xor_sp_si, xor_bp_si, xor_si_si, xor_di_si
	.word xor_ax_di, xor_cx_di, xor_dx_di, xor_bx_di, xor_sp_di, xor_bp_di, xor_si_di, xor_di_di

// These are called from "cpu_67.s":

	.global xor_siidx_ax, xor_diidx_ax, xor_bxidx_ax
	.global xor_siidx_cx, xor_diidx_cx, xor_bxidx_cx
	.global xor_siidx_dx, xor_diidx_dx, xor_bxidx_dx
	.global xor_siidx_bx, xor_diidx_bx, xor_bxidx_bx
	.global xor_siidx_sp, xor_diidx_sp, xor_bxidx_sp
	.global xor_siidx_bp, xor_diidx_bp, xor_bxidx_bp
	.global xor_siidx_si, xor_diidx_si, xor_bxidx_si
	.global xor_siidx_di, xor_diidx_di, xor_bxidx_di
	.global xor_sidisp8_ax, xor_didisp8_ax, xor_bpdisp8_ax, xor_bxdisp8_ax
	.global xor_sidisp8_cx, xor_didisp8_cx, xor_bpdisp8_cx, xor_bxdisp8_cx
	.global xor_sidisp8_dx, xor_didisp8_dx, xor_bpdisp8_dx, xor_bxdisp8_dx
	.global xor_sidisp8_bx, xor_didisp8_bx, xor_bpdisp8_bx, xor_bxdisp8_bx
	.global xor_sidisp8_sp, xor_didisp8_sp, xor_bpdisp8_sp, xor_bxdisp8_sp
	.global xor_sidisp8_bp, xor_didisp8_bp, xor_bpdisp8_bp, xor_bxdisp8_bp
	.global xor_sidisp8_si, xor_didisp8_si, xor_bpdisp8_si, xor_bxdisp8_si
	.global xor_sidisp8_di, xor_didisp8_di, xor_bpdisp8_di, xor_bxdisp8_di
	.global xor_ax_ax, xor_cx_ax, xor_dx_ax, xor_bx_ax, xor_sp_ax, xor_bp_ax, xor_si_ax, xor_di_ax
	.global xor_ax_cx, xor_cx_cx, xor_dx_cx, xor_bx_cx, xor_sp_cx, xor_bp_cx, xor_si_cx, xor_di_cx
	.global xor_ax_dx, xor_cx_dx, xor_dx_dx, xor_bx_dx, xor_sp_dx, xor_bp_dx, xor_si_dx, xor_di_dx
	.global xor_ax_bx, xor_cx_bx, xor_dx_bx, xor_bx_bx, xor_sp_bx, xor_bp_bx, xor_si_bx, xor_di_bx
	.global xor_ax_sp, xor_cx_sp, xor_dx_sp, xor_bx_sp, xor_sp_sp, xor_bp_sp, xor_si_sp, xor_di_sp
	.global xor_ax_bp, xor_cx_bp, xor_dx_bp, xor_bx_bp, xor_sp_bp, xor_bp_bp, xor_si_bp, xor_di_bp
	.global xor_ax_si, xor_cx_si, xor_dx_si, xor_bx_si, xor_sp_si, xor_bp_si, xor_si_si, xor_di_si
	.global xor_ax_di, xor_cx_di, xor_dx_di, xor_bx_di, xor_sp_di, xor_bp_di, xor_si_di, xor_di_di
	.global	xor_r0_r16_bp_r4, xor_r0_r16_bp_r5, xor_r0_r16_bp_r6, xor_r0_r16_bp_r7, xor_r0_r16_bp_r8, xor_r0_r16_bp_r9, xor_r0_r16_bp_r10, xor_r0_r16_bp_r11, xor_r0_r16_bp_r4
	.global	xor_r0_r16_r4, xor_r0_r16_r5, xor_r0_r16_r6, xor_r0_r16_r7, xor_r0_r16_r8, xor_r0_r16_r9, xor_r0_r16_r10, xor_r0_r16_r11, xor_r0_r16_r4


.macro xor_r0_r16_reg reg
xor_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
xor_r0_r16_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_31_RAM_\reg op_31_EGA_r2_\reg bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_31_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r3, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	eors	r0, r3, r0, lsl #16
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		loop
.endm

	xor_r0_r16_reg r4
	xor_r0_r16_reg r5
	xor_r0_r16_reg r6
	xor_r0_r16_reg r7
	xor_r0_r16_reg r8
	xor_r0_r16_reg r9
	xor_r0_r16_reg r10
	xor_r0_r16_reg r11

	.ltorg
	
// --- [idx] ----

.macro xor_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		xor_r0_r16_\reg
.endm

xor_bxsi_ax:
	xor_bxidx_reg16 r10 r4
xor_bxsi_cx:
	xor_bxidx_reg16 r10 r5
xor_bxsi_dx:
	xor_bxidx_reg16 r10 r6
xor_bxsi_bx:
	xor_bxidx_reg16 r10 r7
xor_bxsi_sp:
	xor_bxidx_reg16 r10 r8
xor_bxsi_bp:
	xor_bxidx_reg16 r10 r9
xor_bxsi_si:
	xor_bxidx_reg16 r10 r10
xor_bxsi_di:
	xor_bxidx_reg16 r10 r11

xor_bxdi_ax:
	xor_bxidx_reg16 r11 r4
xor_bxdi_cx:
	xor_bxidx_reg16 r11 r5
xor_bxdi_dx:
	xor_bxidx_reg16 r11 r6
xor_bxdi_bx:
	xor_bxidx_reg16 r11 r7
xor_bxdi_sp:
	xor_bxidx_reg16 r11 r8
xor_bxdi_bp:
	xor_bxidx_reg16 r11 r9
xor_bxdi_si:
	xor_bxidx_reg16 r11 r10
xor_bxdi_di:
	xor_bxidx_reg16 r11 r11

.macro xor_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		xor_r0_r16_bp_\reg
.endm

xor_bpsi_ax:
	xor_bpidx_reg16 r10 r4
xor_bpsi_cx:
	xor_bpidx_reg16 r10 r5
xor_bpsi_dx:
	xor_bpidx_reg16 r10 r6
xor_bpsi_bx:
	xor_bpidx_reg16 r10 r7
xor_bpsi_sp:
	xor_bpidx_reg16 r10 r8
xor_bpsi_bp:
	xor_bpidx_reg16 r10 r9
xor_bpsi_si:
	xor_bpidx_reg16 r10 r10
xor_bpsi_di:
	xor_bpidx_reg16 r10 r11

xor_bpdi_ax:
	xor_bpidx_reg16 r11 r4
xor_bpdi_cx:
	xor_bpidx_reg16 r11 r5
xor_bpdi_dx:
	xor_bpidx_reg16 r11 r6
xor_bpdi_bx:
	xor_bpidx_reg16 r11 r7
xor_bpdi_sp:
	xor_bpidx_reg16 r11 r8
xor_bpdi_bp:
	xor_bpidx_reg16 r11 r9
xor_bpdi_si:
	xor_bpidx_reg16 r11 r10
xor_bpdi_di:
	xor_bpidx_reg16 r11 r11

.macro xor_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		xor_r0_r16_\reg
.endm

xor_siidx_ax:
	xor_idx_reg16 r10 r4
xor_siidx_cx:
	xor_idx_reg16 r10 r5
xor_siidx_dx:
	xor_idx_reg16 r10 r6
xor_siidx_bx:
	xor_idx_reg16 r10 r7
xor_siidx_sp:
	xor_idx_reg16 r10 r8
xor_siidx_bp:
	xor_idx_reg16 r10 r9
xor_siidx_si:
	xor_idx_reg16 r10 r10
xor_siidx_di:
	xor_idx_reg16 r10 r11

xor_diidx_ax:
	xor_idx_reg16 r11 r4
xor_diidx_cx:
	xor_idx_reg16 r11 r5
xor_diidx_dx:
	xor_idx_reg16 r11 r6
xor_diidx_bx:
	xor_idx_reg16 r11 r7
xor_diidx_sp:
	xor_idx_reg16 r11 r8
xor_diidx_bp:
	xor_idx_reg16 r11 r9
xor_diidx_si:
	xor_idx_reg16 r11 r10
xor_diidx_di:
	xor_idx_reg16 r11 r11

xor_bxidx_ax:
	xor_idx_reg16 r7 r4
xor_bxidx_cx:
	xor_idx_reg16 r7 r5
xor_bxidx_dx:
	xor_idx_reg16 r7 r6
xor_bxidx_bx:
	xor_idx_reg16 r7 r7
xor_bxidx_sp:
	xor_idx_reg16 r7 r8
xor_bxidx_bp:
	xor_idx_reg16 r7 r9
xor_bxidx_si:
	xor_idx_reg16 r7 r10
xor_bxidx_di:
	xor_idx_reg16 r7 r11
	
.macro xor_disp16_reg16 reg
	r0_from_disp16
	b		xor_r0_r16_\reg
.endm

xor_disp16_ax:
	xor_disp16_reg16 r4
xor_disp16_cx:
	xor_disp16_reg16 r5
xor_disp16_dx:
	xor_disp16_reg16 r6
xor_disp16_bx:
	xor_disp16_reg16 r7
xor_disp16_sp:
	xor_disp16_reg16 r8
xor_disp16_bp:
	xor_disp16_reg16 r9
xor_disp16_si:
	xor_disp16_reg16 r10
xor_disp16_di:
	xor_disp16_reg16 r11

// --- [idx+disp8] ----

.macro xor_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		xor_r0_r16_\reg
.endm

xor_bxsid8_ax:
	xor_bxidxd8_reg16 r10 r4
xor_bxsid8_cx:
	xor_bxidxd8_reg16 r10 r5
xor_bxsid8_dx:
	xor_bxidxd8_reg16 r10 r6
xor_bxsid8_bx:
	xor_bxidxd8_reg16 r10 r7
xor_bxsid8_sp:
	xor_bxidxd8_reg16 r10 r8
xor_bxsid8_bp:
	xor_bxidxd8_reg16 r10 r9
xor_bxsid8_si:
	xor_bxidxd8_reg16 r10 r10
xor_bxsid8_di:
	xor_bxidxd8_reg16 r10 r11

xor_bxdid8_ax:
	xor_bxidxd8_reg16 r11 r4
xor_bxdid8_cx:
	xor_bxidxd8_reg16 r11 r5
xor_bxdid8_dx:
	xor_bxidxd8_reg16 r11 r6
xor_bxdid8_bx:
	xor_bxidxd8_reg16 r11 r7
xor_bxdid8_sp:
	xor_bxidxd8_reg16 r11 r8
xor_bxdid8_bp:
	xor_bxidxd8_reg16 r11 r9
xor_bxdid8_si:
	xor_bxidxd8_reg16 r11 r10
xor_bxdid8_di:
	xor_bxidxd8_reg16 r11 r11

.macro xor_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		xor_r0_r16_bp_\reg
.endm

xor_bpsid8_ax:
	xor_bpidxd8_reg16 r10 r4
xor_bpsid8_cx:
	xor_bpidxd8_reg16 r10 r5
xor_bpsid8_dx:
	xor_bpidxd8_reg16 r10 r6
xor_bpsid8_bx:
	xor_bpidxd8_reg16 r10 r7
xor_bpsid8_sp:
	xor_bpidxd8_reg16 r10 r8
xor_bpsid8_bp:
	xor_bpidxd8_reg16 r10 r9
xor_bpsid8_si:
	xor_bpidxd8_reg16 r10 r10
xor_bpsid8_di:
	xor_bpidxd8_reg16 r10 r11

xor_bpdid8_ax:
	xor_bpidxd8_reg16 r11 r4
xor_bpdid8_cx:
	xor_bpidxd8_reg16 r11 r5
xor_bpdid8_dx:
	xor_bpidxd8_reg16 r11 r6
xor_bpdid8_bx:
	xor_bpidxd8_reg16 r11 r7
xor_bpdid8_sp:
	xor_bpidxd8_reg16 r11 r8
xor_bpdid8_bp:
	xor_bpidxd8_reg16 r11 r9
xor_bpdid8_si:
	xor_bpidxd8_reg16 r11 r10
xor_bpdid8_di:
	xor_bpidxd8_reg16 r11 r11

.macro xor_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		xor_r0_r16_\reg
.endm

xor_sidisp8_ax:
	xor_idxdisp8_reg16 r10 r4
xor_sidisp8_cx:
	xor_idxdisp8_reg16 r10 r5
xor_sidisp8_dx:
	xor_idxdisp8_reg16 r10 r6
xor_sidisp8_bx:
	xor_idxdisp8_reg16 r10 r7
xor_sidisp8_sp:
	xor_idxdisp8_reg16 r10 r8
xor_sidisp8_bp:
	xor_idxdisp8_reg16 r10 r9
xor_sidisp8_si:
	xor_idxdisp8_reg16 r10 r10
xor_sidisp8_di:
	xor_idxdisp8_reg16 r10 r11

xor_didisp8_ax:
	xor_idxdisp8_reg16 r11 r4
xor_didisp8_cx:
	xor_idxdisp8_reg16 r11 r5
xor_didisp8_dx:
	xor_idxdisp8_reg16 r11 r6
xor_didisp8_bx:
	xor_idxdisp8_reg16 r11 r7
xor_didisp8_sp:
	xor_idxdisp8_reg16 r11 r8
xor_didisp8_bp:
	xor_idxdisp8_reg16 r11 r9
xor_didisp8_si:
	xor_idxdisp8_reg16 r11 r10
xor_didisp8_di:
	xor_idxdisp8_reg16 r11 r11

xor_bxdisp8_ax:
	xor_idxdisp8_reg16 r7 r4
xor_bxdisp8_cx:
	xor_idxdisp8_reg16 r7 r5
xor_bxdisp8_dx:
	xor_idxdisp8_reg16 r7 r6
xor_bxdisp8_bx:
	xor_idxdisp8_reg16 r7 r7
xor_bxdisp8_sp:
	xor_idxdisp8_reg16 r7 r8
xor_bxdisp8_bp:
	xor_idxdisp8_reg16 r7 r9
xor_bxdisp8_si:
	xor_idxdisp8_reg16 r7 r10
xor_bxdisp8_di:
	xor_idxdisp8_reg16 r7 r11
	
.macro xor_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		xor_r0_r16_bp_\reg
.endm
	
xor_bpdisp8_ax:
	xor_bpdisp8_reg16 r4
xor_bpdisp8_cx:
	xor_bpdisp8_reg16 r5
xor_bpdisp8_dx:
	xor_bpdisp8_reg16 r6
xor_bpdisp8_bx:
	xor_bpdisp8_reg16 r7
xor_bpdisp8_sp:
	xor_bpdisp8_reg16 r8
xor_bpdisp8_bp:
	xor_bpdisp8_reg16 r9
xor_bpdisp8_si:
	xor_bpdisp8_reg16 r10
xor_bpdisp8_di:
	xor_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro xor_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		xor_r0_r16_\reg
.endm

xor_bxsid16_ax:
	xor_bxidxd16_reg16 r10 r4
xor_bxsid16_cx:
	xor_bxidxd16_reg16 r10 r5
xor_bxsid16_dx:
	xor_bxidxd16_reg16 r10 r6
xor_bxsid16_bx:
	xor_bxidxd16_reg16 r10 r7
xor_bxsid16_sp:
	xor_bxidxd16_reg16 r10 r8
xor_bxsid16_bp:
	xor_bxidxd16_reg16 r10 r9
xor_bxsid16_si:
	xor_bxidxd16_reg16 r10 r10
xor_bxsid16_di:
	xor_bxidxd16_reg16 r10 r11

xor_bxdid16_ax:
	xor_bxidxd16_reg16 r11 r4
xor_bxdid16_cx:
	xor_bxidxd16_reg16 r11 r5
xor_bxdid16_dx:
	xor_bxidxd16_reg16 r11 r6
xor_bxdid16_bx:
	xor_bxidxd16_reg16 r11 r7
xor_bxdid16_sp:
	xor_bxidxd16_reg16 r11 r8
xor_bxdid16_bp:
	xor_bxidxd16_reg16 r11 r9
xor_bxdid16_si:
	xor_bxidxd16_reg16 r11 r10
xor_bxdid16_di:
	xor_bxidxd16_reg16 r11 r11

.macro xor_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		xor_r0_r16_bp_\reg
.endm

xor_bpsid16_ax:
	xor_bpidxd16_reg16 r10 r4
xor_bpsid16_cx:
	xor_bpidxd16_reg16 r10 r5
xor_bpsid16_dx:
	xor_bpidxd16_reg16 r10 r6
xor_bpsid16_bx:
	xor_bpidxd16_reg16 r10 r7
xor_bpsid16_sp:
	xor_bpidxd16_reg16 r10 r8
xor_bpsid16_bp:
	xor_bpidxd16_reg16 r10 r9
xor_bpsid16_si:
	xor_bpidxd16_reg16 r10 r10
xor_bpsid16_di:
	xor_bpidxd16_reg16 r10 r11

xor_bpdid16_ax:
	xor_bpidxd16_reg16 r11 r4
xor_bpdid16_cx:
	xor_bpidxd16_reg16 r11 r5
xor_bpdid16_dx:
	xor_bpidxd16_reg16 r11 r6
xor_bpdid16_bx:
	xor_bpidxd16_reg16 r11 r7
xor_bpdid16_sp:
	xor_bpidxd16_reg16 r11 r8
xor_bpdid16_bp:
	xor_bpidxd16_reg16 r11 r9
xor_bpdid16_si:
	xor_bpidxd16_reg16 r11 r10
xor_bpdid16_di:
	xor_bpidxd16_reg16 r11 r11

.macro xor_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		xor_r0_r16_\reg
.endm

xor_sidisp16_ax:
	xor_idxdisp16_reg16 r10 r4
xor_sidisp16_cx:
	xor_idxdisp16_reg16 r10 r5
xor_sidisp16_dx:
	xor_idxdisp16_reg16 r10 r6
xor_sidisp16_bx:
	xor_idxdisp16_reg16 r10 r7
xor_sidisp16_sp:
	xor_idxdisp16_reg16 r10 r8
xor_sidisp16_bp:
	xor_idxdisp16_reg16 r10 r9
xor_sidisp16_si:
	xor_idxdisp16_reg16 r10 r10
xor_sidisp16_di:
	xor_idxdisp16_reg16 r10 r11

xor_didisp16_ax:
	xor_idxdisp16_reg16 r11 r4
xor_didisp16_cx:
	xor_idxdisp16_reg16 r11 r5
xor_didisp16_dx:
	xor_idxdisp16_reg16 r11 r6
xor_didisp16_bx:
	xor_idxdisp16_reg16 r11 r7
xor_didisp16_sp:
	xor_idxdisp16_reg16 r11 r8
xor_didisp16_bp:
	xor_idxdisp16_reg16 r11 r9
xor_didisp16_si:
	xor_idxdisp16_reg16 r11 r10
xor_didisp16_di:
	xor_idxdisp16_reg16 r11 r11

xor_bxdisp16_ax:
	xor_idxdisp16_reg16 r7 r4
xor_bxdisp16_cx:
	xor_idxdisp16_reg16 r7 r5
xor_bxdisp16_dx:
	xor_idxdisp16_reg16 r7 r6
xor_bxdisp16_bx:
	xor_idxdisp16_reg16 r7 r7
xor_bxdisp16_sp:
	xor_idxdisp16_reg16 r7 r8
xor_bxdisp16_bp:
	xor_idxdisp16_reg16 r7 r9
xor_bxdisp16_si:
	xor_idxdisp16_reg16 r7 r10
xor_bxdisp16_di:
	xor_idxdisp16_reg16 r7 r11

.macro xor_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		xor_r0_r16_bp_\reg
.endm

xor_bpdisp16_ax:
	xor_bpdisp16_reg16 r4
xor_bpdisp16_cx:
	xor_bpdisp16_reg16 r5
xor_bpdisp16_dx:
	xor_bpdisp16_reg16 r6
xor_bpdisp16_bx:
	xor_bpdisp16_reg16 r7
xor_bpdisp16_sp:
	xor_bpdisp16_reg16 r8
xor_bpdisp16_bp:
	xor_bpdisp16_reg16 r9
xor_bpdisp16_si:
	xor_bpdisp16_reg16 r10
xor_bpdisp16_di:
	xor_bpdisp16_reg16 r11

	
// ------------------- 32 = XOR r8, r/m8 -----------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual eors operation, so C and O work like in x86.
//
// All modrm variations supported!
//
//
	.global	op_32
op_32:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word xor_al_bxsi, xor_al_bxdi, xor_al_bpsi, xor_al_bpdi, xor_al_siidx, xor_al_diidx, xor_al_disp16, xor_al_bxidx
	.word xor_cl_bxsi, xor_cl_bxdi, xor_cl_bpsi, xor_cl_bpdi, xor_cl_siidx, xor_cl_diidx, xor_cl_disp16, xor_cl_bxidx
	.word xor_dl_bxsi, xor_dl_bxdi, xor_dl_bpsi, xor_dl_bpdi, xor_dl_siidx, xor_dl_diidx, xor_dl_disp16, xor_dl_bxidx
	.word xor_bl_bxsi, xor_bl_bxdi, xor_bl_bpsi, xor_bl_bpdi, xor_bl_siidx, xor_bl_diidx, xor_bl_disp16, xor_bl_bxidx
	.word xor_ah_bxsi, xor_ah_bxdi, xor_ah_bpsi, xor_ah_bpdi, xor_ah_siidx, xor_ah_diidx, xor_ah_disp16, xor_ah_bxidx
	.word xor_ch_bxsi, xor_ch_bxdi, xor_ch_bpsi, xor_ch_bpdi, xor_ch_siidx, xor_ch_diidx, xor_ch_disp16, xor_ch_bxidx
	.word xor_dh_bxsi, xor_dh_bxdi, xor_dh_bpsi, xor_dh_bpdi, xor_dh_siidx, xor_dh_diidx, xor_dh_disp16, xor_dh_bxidx
	.word xor_bh_bxsi, xor_bh_bxdi, xor_bh_bpsi, xor_bh_bpdi, xor_bh_siidx, xor_bh_diidx, xor_bh_disp16, xor_bh_bxidx
//0x40
	.word xor_al_bxsid8, xor_al_bxdid8, xor_al_bpsid8, xor_al_bpdid8, xor_al_sidisp8, xor_al_didisp8, xor_al_bpdisp8, xor_al_bxdisp8
	.word xor_cl_bxsid8, xor_cl_bxdid8, xor_cl_bpsid8, xor_cl_bpdid8, xor_cl_sidisp8, xor_cl_didisp8, xor_cl_bpdisp8, xor_cl_bxdisp8
	.word xor_dl_bxsid8, xor_dl_bxdid8, xor_dl_bpsid8, xor_dl_bpdid8, xor_dl_sidisp8, xor_dl_didisp8, xor_dl_bpdisp8, xor_dl_bxdisp8
	.word xor_bl_bxsid8, xor_bl_bxdid8, xor_bl_bpsid8, xor_bl_bpdid8, xor_bl_sidisp8, xor_bl_didisp8, xor_bl_bpdisp8, xor_bl_bxdisp8
	.word xor_ah_bxsid8, xor_ah_bxdid8, xor_ah_bpsid8, xor_ah_bpdid8, xor_ah_sidisp8, xor_ah_didisp8, xor_ah_bpdisp8, xor_ah_bxdisp8
	.word xor_ch_bxsid8, xor_ch_bxdid8, xor_ch_bpsid8, xor_ch_bpdid8, xor_ch_sidisp8, xor_ch_didisp8, xor_ch_bpdisp8, xor_ch_bxdisp8
	.word xor_dh_bxsid8, xor_dh_bxdid8, xor_dh_bpsid8, xor_dh_bpdid8, xor_dh_sidisp8, xor_dh_didisp8, xor_dh_bpdisp8, xor_dh_bxdisp8
	.word xor_bh_bxsid8, xor_bh_bxdid8, xor_bh_bpsid8, xor_bh_bpdid8, xor_bh_sidisp8, xor_bh_didisp8, xor_bh_bpdisp8, xor_bh_bxdisp8
//0x80
	.word xor_al_bxsid16, xor_al_bxdid16, xor_al_bpsid16, xor_al_bpdid16, xor_al_sidisp16, xor_al_didisp16, xor_al_bpdisp16, xor_al_bxdisp16
	.word xor_cl_bxsid16, xor_cl_bxdid16, xor_cl_bpsid16, xor_cl_bpdid16, xor_cl_sidisp16, xor_cl_didisp16, xor_cl_bpdisp16, xor_cl_bxdisp16
	.word xor_dl_bxsid16, xor_dl_bxdid16, xor_dl_bpsid16, xor_dl_bpdid16, xor_dl_sidisp16, xor_dl_didisp16, xor_dl_bpdisp16, xor_dl_bxdisp16
	.word xor_bl_bxsid16, xor_bl_bxdid16, xor_bl_bpsid16, xor_bl_bpdid16, xor_bl_sidisp16, xor_bl_didisp16, xor_bl_bpdisp16, xor_bl_bxdisp16
	.word xor_ah_bxsid16, xor_ah_bxdid16, xor_ah_bpsid16, xor_ah_bpdid16, xor_ah_sidisp16, xor_ah_didisp16, xor_ah_bpdisp16, xor_ah_bxdisp16
	.word xor_ch_bxsid16, xor_ch_bxdid16, xor_ch_bpsid16, xor_ch_bpdid16, xor_ch_sidisp16, xor_ch_didisp16, xor_ch_bpdisp16, xor_ch_bxdisp16
	.word xor_dh_bxsid16, xor_dh_bxdid16, xor_dh_bpsid16, xor_dh_bpdid16, xor_dh_sidisp16, xor_dh_didisp16, xor_dh_bpdisp16, xor_dh_bxdisp16
	.word xor_bh_bxsid16, xor_bh_bxdid16, xor_bh_bpsid16, xor_bh_bpdid16, xor_bh_sidisp16, xor_bh_didisp16, xor_bh_bpdisp16, xor_bh_bxdisp16
// 0xC0 = two register operands
	.word xor_al_al, xor_al_cl, xor_al_dl, xor_al_bl, xor_al_ah, xor_al_ch, xor_al_dh, xor_al_bh
	.word xor_cl_al, xor_cl_cl, xor_cl_dl, xor_cl_bl, xor_cl_ah, xor_cl_ch, xor_cl_dh, xor_cl_bh
	.word xor_dl_al, xor_dl_cl, xor_dl_dl, xor_dl_bl, xor_dl_ah, xor_dl_ch, xor_dl_dh, xor_dl_bh
	.word xor_bl_al, xor_bl_cl, xor_bl_dl, xor_bl_bl, xor_bl_ah, xor_bl_ch, xor_bl_dh, xor_bl_bh
	.word xor_ah_al, xor_ah_cl, xor_ah_dl, xor_ah_bl, xor_ah_ah, xor_ah_ch, xor_ah_dh, xor_ah_bh
	.word xor_ch_al, xor_ch_cl, xor_ch_dl, xor_ch_bl, xor_ch_ah, xor_ch_ch, xor_ch_dh, xor_ch_bh
	.word xor_dh_al, xor_dh_cl, xor_dh_dl, xor_dh_bl, xor_dh_ah, xor_dh_ch, xor_dh_dh, xor_dh_bh
	.word xor_bh_al, xor_bh_cl, xor_bh_dl, xor_bh_bl, xor_bh_ah, xor_bh_ch, xor_bh_dh, xor_bh_bh

// These are called from "cpu_386.s":

	.global xor_al_siidx, xor_cl_siidx, xor_dl_siidx, xor_bl_siidx, xor_ah_siidx, xor_ch_siidx, xor_dh_siidx, xor_bh_siidx
	.global xor_al_diidx, xor_cl_diidx, xor_dl_diidx, xor_bl_diidx, xor_ah_diidx, xor_ch_diidx, xor_dh_diidx, xor_bh_diidx
	.global xor_al_bxidx, xor_cl_bxidx, xor_dl_bxidx, xor_bl_bxidx, xor_ah_bxidx, xor_ch_bxidx, xor_dh_bxidx, xor_bh_bxidx
	.global xor_al_sidisp8, xor_al_didisp8, xor_al_bpdisp8, xor_al_bxdisp8
	.global xor_cl_sidisp8, xor_cl_didisp8, xor_cl_bpdisp8, xor_cl_bxdisp8
	.global xor_dl_sidisp8, xor_dl_didisp8, xor_dl_bpdisp8, xor_dl_bxdisp8
	.global xor_bl_sidisp8, xor_bl_didisp8, xor_bl_bpdisp8, xor_bl_bxdisp8
	.global xor_ah_sidisp8, xor_ah_didisp8, xor_ah_bpdisp8, xor_ah_bxdisp8
	.global xor_ch_sidisp8, xor_ch_didisp8, xor_ch_bpdisp8, xor_ch_bxdisp8
	.global xor_dh_sidisp8, xor_dh_didisp8, xor_dh_bpdisp8, xor_dh_bxdisp8
	.global xor_bh_sidisp8, xor_bh_didisp8, xor_bh_bpdisp8, xor_bh_bxdisp8
	.global xor_al_al, xor_cl_al, xor_dl_al, xor_bl_al, xor_ah_al, xor_ch_al, xor_dh_al, xor_bh_al
	.global xor_al_cl, xor_cl_cl, xor_dl_cl, xor_bl_cl, xor_ah_cl, xor_ch_cl, xor_dh_cl, xor_bh_cl
	.global xor_al_dl, xor_cl_dl, xor_dl_dl, xor_bl_dl, xor_ah_dl, xor_ch_dl, xor_dh_dl, xor_bh_dl
	.global xor_al_bl, xor_cl_bl, xor_dl_bl, xor_bl_bl, xor_ah_bl, xor_ch_bl, xor_dh_bl, xor_bh_bl
	.global xor_al_ah, xor_cl_ah, xor_dl_ah, xor_bl_ah, xor_ah_ah, xor_ch_ah, xor_dh_ah, xor_bh_ah
	.global xor_al_ch, xor_cl_ch, xor_dl_ch, xor_bl_ch, xor_ah_ch, xor_ch_ch, xor_dh_ch, xor_bh_ch
	.global xor_al_dh, xor_cl_dh, xor_dl_dh, xor_bl_dh, xor_ah_dh, xor_ch_dh, xor_dh_dh, xor_bh_dh
	.global xor_al_bh, xor_cl_bh, xor_dl_bh, xor_bl_bh, xor_ah_bh, xor_ch_bh, xor_dh_bh, xor_bh_bh

.macro xor_reg8l_r0high reg
	.global	xor_r8l_r0_bp_\reg
xor_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	xor_r8l_r0_\reg
xor_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_32_RAM_l_\reg op_32_EGA_l_\reg op_32_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_32_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1,\reg, lsl #24
	eors	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	b		loop
.endm
.macro xor_reg8h_r0high reg
	.global	xor_r8h_r0_bp_\reg
xor_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	xor_r8h_r0_\reg
xor_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_32_RAM_h_\reg op_32_EGA_h_\reg op_32_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_32_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1,\reg,#0xFF00
	lsl		r1, #16
	eors	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsr #16
	b		loop
.endm

	xor_reg8l_r0high r4
	xor_reg8l_r0high r5
	xor_reg8l_r0high r6
	xor_reg8l_r0high r7
	xor_reg8h_r0high r4
	xor_reg8h_r0high r5
	xor_reg8h_r0high r6
	xor_reg8h_r0high r7

	.ltorg


// --- [idx] ---

.macro xor_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		xor_r8l_r0_\reg
.endm
.macro xor_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		xor_r8h_r0_\reg
.endm

xor_al_bxsi:
	xor_reg8l_bxidx r4 r10
xor_cl_bxsi:
	xor_reg8l_bxidx r5 r10
xor_dl_bxsi:
	xor_reg8l_bxidx r6 r10
xor_bl_bxsi:
	xor_reg8l_bxidx r7 r10
xor_ah_bxsi:
	xor_reg8h_bxidx r4 r10
xor_ch_bxsi:
	xor_reg8h_bxidx r5 r10
xor_dh_bxsi:
	xor_reg8h_bxidx r6 r10
xor_bh_bxsi:
	xor_reg8h_bxidx r7 r10

xor_al_bxdi:
	xor_reg8l_bxidx r4 r11
xor_cl_bxdi:
	xor_reg8l_bxidx r5 r11
xor_dl_bxdi:
	xor_reg8l_bxidx r6 r11
xor_bl_bxdi:
	xor_reg8l_bxidx r7 r11
xor_ah_bxdi:
	xor_reg8h_bxidx r4 r11
xor_ch_bxdi:
	xor_reg8h_bxidx r5 r11
xor_dh_bxdi:
	xor_reg8h_bxidx r6 r11
xor_bh_bxdi:
	xor_reg8h_bxidx r7 r11

.macro xor_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		xor_r8l_r0_bp_\reg
.endm
.macro xor_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		xor_r8h_r0_bp_\reg
.endm

xor_al_bpsi:
	xor_reg8l_bpidx r4 r10
xor_cl_bpsi:
	xor_reg8l_bpidx r5 r10
xor_dl_bpsi:
	xor_reg8l_bpidx r6 r10
xor_bl_bpsi:
	xor_reg8l_bpidx r7 r10
xor_ah_bpsi:
	xor_reg8h_bpidx r4 r10
xor_ch_bpsi:
	xor_reg8h_bpidx r5 r10
xor_dh_bpsi:
	xor_reg8h_bpidx r6 r10
xor_bh_bpsi:
	xor_reg8h_bpidx r7 r10

xor_al_bpdi:
	xor_reg8l_bpidx r4 r11
xor_cl_bpdi:
	xor_reg8l_bpidx r5 r11
xor_dl_bpdi:
	xor_reg8l_bpidx r6 r11
xor_bl_bpdi:
	xor_reg8l_bpidx r7 r11
xor_ah_bpdi:
	xor_reg8h_bpidx r4 r11
xor_ch_bpdi:
	xor_reg8h_bpidx r5 r11
xor_dh_bpdi:
	xor_reg8h_bpidx r6 r11
xor_bh_bpdi:
	xor_reg8h_bpidx r7 r11

.macro xor_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		xor_r8l_r0_\reg
.endm
.macro xor_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		xor_r8h_r0_\reg
.endm

xor_al_siidx:
	xor_reg8l_idx r4 r10
xor_cl_siidx:
	xor_reg8l_idx r5 r10
xor_dl_siidx:
	xor_reg8l_idx r6 r10
xor_bl_siidx:
	xor_reg8l_idx r7 r10
xor_ah_siidx:
	xor_reg8h_idx r4 r10
xor_ch_siidx:
	xor_reg8h_idx r5 r10
xor_dh_siidx:
	xor_reg8h_idx r6 r10
xor_bh_siidx:
	xor_reg8h_idx r7 r10

xor_al_diidx:
	xor_reg8l_idx r4 r11
xor_cl_diidx:
	xor_reg8l_idx r5 r11
xor_dl_diidx:
	xor_reg8l_idx r6 r11
xor_bl_diidx:
	xor_reg8l_idx r7 r11
xor_ah_diidx:
	xor_reg8h_idx r4 r11
xor_ch_diidx:
	xor_reg8h_idx r5 r11
xor_dh_diidx:
	xor_reg8h_idx r6 r11
xor_bh_diidx:
	xor_reg8h_idx r7 r11

xor_al_bxidx:
	xor_reg8l_idx r4 r7
xor_cl_bxidx:
	xor_reg8l_idx r5 r7
xor_dl_bxidx:
	xor_reg8l_idx r6 r7
xor_bl_bxidx:
	xor_reg8l_idx r7 r7
xor_ah_bxidx:
	xor_reg8h_idx r4 r7
xor_ch_bxidx:
	xor_reg8h_idx r5 r7
xor_dh_bxidx:
	xor_reg8h_idx r6 r7
xor_bh_bxidx:
	xor_reg8h_idx r7 r7

.macro xor_reg8l_disp16 reg
	r0_from_disp16
	b		xor_r8l_r0_\reg
.endm
.macro xor_reg8h_disp16 reg
	r0_from_disp16
	b		xor_r8h_r0_\reg
.endm

xor_al_disp16:
	xor_reg8l_disp16 r4
xor_cl_disp16:
	xor_reg8l_disp16 r5
xor_dl_disp16:
	xor_reg8l_disp16 r6
xor_bl_disp16:
	xor_reg8l_disp16 r7
xor_ah_disp16:
	xor_reg8h_disp16 r4
xor_ch_disp16:
	xor_reg8h_disp16 r5
xor_dh_disp16:
	xor_reg8h_disp16 r6
xor_bh_disp16:
	xor_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro xor_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		xor_r8l_r0_\reg
.endm
.macro xor_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		xor_r8h_r0_\reg
.endm

xor_al_bxsid8:
	xor_reg8l_bxidxd8 r4 r10
xor_cl_bxsid8:
	xor_reg8l_bxidxd8 r5 r10
xor_dl_bxsid8:
	xor_reg8l_bxidxd8 r6 r10
xor_bl_bxsid8:
	xor_reg8l_bxidxd8 r7 r10
xor_ah_bxsid8:
	xor_reg8h_bxidxd8 r4 r10
xor_ch_bxsid8:
	xor_reg8h_bxidxd8 r5 r10
xor_dh_bxsid8:
	xor_reg8h_bxidxd8 r6 r10
xor_bh_bxsid8:
	xor_reg8h_bxidxd8 r7 r10

xor_al_bxdid8:
	xor_reg8l_bxidxd8 r4 r11
xor_cl_bxdid8:
	xor_reg8l_bxidxd8 r5 r11
xor_dl_bxdid8:
	xor_reg8l_bxidxd8 r6 r11
xor_bl_bxdid8:
	xor_reg8l_bxidxd8 r7 r11
xor_ah_bxdid8:
	xor_reg8h_bxidxd8 r4 r11
xor_ch_bxdid8:
	xor_reg8h_bxidxd8 r5 r11
xor_dh_bxdid8:
	xor_reg8h_bxidxd8 r6 r11
xor_bh_bxdid8:
	xor_reg8h_bxidxd8 r7 r11

.macro xor_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		xor_r8l_r0_bp_\reg
.endm
.macro xor_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		xor_r8h_r0_bp_\reg
.endm

xor_al_bpsid8:
	xor_reg8l_bpidxd8 r4 r10
xor_cl_bpsid8:
	xor_reg8l_bpidxd8 r5 r10
xor_dl_bpsid8:
	xor_reg8l_bpidxd8 r6 r10
xor_bl_bpsid8:
	xor_reg8l_bpidxd8 r7 r10
xor_ah_bpsid8:
	xor_reg8h_bpidxd8 r4 r10
xor_ch_bpsid8:
	xor_reg8h_bpidxd8 r5 r10
xor_dh_bpsid8:
	xor_reg8h_bpidxd8 r6 r10
xor_bh_bpsid8:
	xor_reg8h_bpidxd8 r7 r10

xor_al_bpdid8:
	xor_reg8l_bpidxd8 r4 r11
xor_cl_bpdid8:
	xor_reg8l_bpidxd8 r5 r11
xor_dl_bpdid8:
	xor_reg8l_bpidxd8 r6 r11
xor_bl_bpdid8:
	xor_reg8l_bpidxd8 r7 r11
xor_ah_bpdid8:
	xor_reg8h_bpidxd8 r4 r11
xor_ch_bpdid8:
	xor_reg8h_bpidxd8 r5 r11
xor_dh_bpdid8:
	xor_reg8h_bpidxd8 r6 r11
xor_bh_bpdid8:
	xor_reg8h_bpidxd8 r7 r11

.macro xor_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		xor_r8l_r0_\reg
.endm
.macro xor_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		xor_r8h_r0_\reg
.endm

xor_al_sidisp8:
	xor_reg8l_idxdisp8 r4 r10
xor_cl_sidisp8:
	xor_reg8l_idxdisp8 r5 r10
xor_dl_sidisp8:
	xor_reg8l_idxdisp8 r6 r10
xor_bl_sidisp8:
	xor_reg8l_idxdisp8 r7 r10
xor_ah_sidisp8:
	xor_reg8h_idxdisp8 r4 r10
xor_ch_sidisp8:
	xor_reg8h_idxdisp8 r5 r10
xor_dh_sidisp8:
	xor_reg8h_idxdisp8 r6 r10
xor_bh_sidisp8:
	xor_reg8h_idxdisp8 r7 r10
	
xor_al_didisp8:
	xor_reg8l_idxdisp8 r4 r11
xor_cl_didisp8:
	xor_reg8l_idxdisp8 r5 r11
xor_dl_didisp8:
	xor_reg8l_idxdisp8 r6 r11
xor_bl_didisp8:
	xor_reg8l_idxdisp8 r7 r11
xor_ah_didisp8:
	xor_reg8h_idxdisp8 r4 r11
xor_ch_didisp8:
	xor_reg8h_idxdisp8 r5 r11
xor_dh_didisp8:
	xor_reg8h_idxdisp8 r6 r11
xor_bh_didisp8:
	xor_reg8h_idxdisp8 r7 r11

xor_al_bxdisp8:
	xor_reg8l_idxdisp8 r4 r7
xor_cl_bxdisp8:
	xor_reg8l_idxdisp8 r5 r7
xor_dl_bxdisp8:
	xor_reg8l_idxdisp8 r6 r7
xor_bl_bxdisp8:
	xor_reg8l_idxdisp8 r7 r7
xor_ah_bxdisp8:
	xor_reg8h_idxdisp8 r4 r7
xor_ch_bxdisp8:
	xor_reg8h_idxdisp8 r5 r7
xor_dh_bxdisp8:
	xor_reg8h_idxdisp8 r6 r7
xor_bh_bxdisp8:
	xor_reg8h_idxdisp8 r7 r7

.macro xor_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		xor_r8l_r0_bp_\reg
.endm
.macro xor_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		xor_r8h_r0_bp_\reg
.endm

xor_al_bpdisp8:
	xor_reg8l_bpdisp8 r4
xor_cl_bpdisp8:
	xor_reg8l_bpdisp8 r5
xor_dl_bpdisp8:
	xor_reg8l_bpdisp8 r6
xor_bl_bpdisp8:
	xor_reg8l_bpdisp8 r7
xor_ah_bpdisp8:
	xor_reg8h_bpdisp8 r4
xor_ch_bpdisp8:
	xor_reg8h_bpdisp8 r5
xor_dh_bpdisp8:
	xor_reg8h_bpdisp8 r6
xor_bh_bpdisp8:
	xor_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro xor_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		xor_r8l_r0_\reg
.endm
.macro xor_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		xor_r8h_r0_\reg
.endm

xor_al_bxsid16:
	xor_reg8l_bxidxd16 r4 r10
xor_cl_bxsid16:
	xor_reg8l_bxidxd16 r5 r10
xor_dl_bxsid16:
	xor_reg8l_bxidxd16 r6 r10
xor_bl_bxsid16:
	xor_reg8l_bxidxd16 r7 r10
xor_ah_bxsid16:
	xor_reg8h_bxidxd16 r4 r10
xor_ch_bxsid16:
	xor_reg8h_bxidxd16 r5 r10
xor_dh_bxsid16:
	xor_reg8h_bxidxd16 r6 r10
xor_bh_bxsid16:
	xor_reg8h_bxidxd16 r7 r10

xor_al_bxdid16:
	xor_reg8l_bxidxd16 r4 r11
xor_cl_bxdid16:
	xor_reg8l_bxidxd16 r5 r11
xor_dl_bxdid16:
	xor_reg8l_bxidxd16 r6 r11
xor_bl_bxdid16:
	xor_reg8l_bxidxd16 r7 r11
xor_ah_bxdid16:
	xor_reg8h_bxidxd16 r4 r11
xor_ch_bxdid16:
	xor_reg8h_bxidxd16 r5 r11
xor_dh_bxdid16:
	xor_reg8h_bxidxd16 r6 r11
xor_bh_bxdid16:
	xor_reg8h_bxidxd16 r7 r11

.macro xor_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		xor_r8l_r0_bp_\reg
.endm
.macro xor_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		xor_r8h_r0_bp_\reg
.endm

xor_al_bpsid16:
	xor_reg8l_bpidxd16 r4 r10
xor_cl_bpsid16:
	xor_reg8l_bpidxd16 r5 r10
xor_dl_bpsid16:
	xor_reg8l_bpidxd16 r6 r10
xor_bl_bpsid16:
	xor_reg8l_bpidxd16 r7 r10
xor_ah_bpsid16:
	xor_reg8h_bpidxd16 r4 r10
xor_ch_bpsid16:
	xor_reg8h_bpidxd16 r5 r10
xor_dh_bpsid16:
	xor_reg8h_bpidxd16 r6 r10
xor_bh_bpsid16:
	xor_reg8h_bpidxd16 r7 r10

xor_al_bpdid16:
	xor_reg8l_bpidxd16 r4 r11
xor_cl_bpdid16:
	xor_reg8l_bpidxd16 r5 r11
xor_dl_bpdid16:
	xor_reg8l_bpidxd16 r6 r11
xor_bl_bpdid16:
	xor_reg8l_bpidxd16 r7 r11
xor_ah_bpdid16:
	xor_reg8h_bpidxd16 r4 r11
xor_ch_bpdid16:
	xor_reg8h_bpidxd16 r5 r11
xor_dh_bpdid16:
	xor_reg8h_bpidxd16 r6 r11
xor_bh_bpdid16:
	xor_reg8h_bpidxd16 r7 r11

.macro xor_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		xor_r8l_r0_\reg
.endm
.macro xor_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		xor_r8h_r0_\reg
.endm

xor_al_sidisp16:
	xor_reg8l_idxdisp16 r4 r10
xor_cl_sidisp16:
	xor_reg8l_idxdisp16 r5 r10
xor_dl_sidisp16:
	xor_reg8l_idxdisp16 r6 r10
xor_bl_sidisp16:
	xor_reg8l_idxdisp16 r7 r10
xor_ah_sidisp16:
	xor_reg8h_idxdisp16 r4 r10
xor_ch_sidisp16:
	xor_reg8h_idxdisp16 r5 r10
xor_dh_sidisp16:
	xor_reg8h_idxdisp16 r6 r10
xor_bh_sidisp16:
	xor_reg8h_idxdisp16 r7 r10

xor_al_didisp16:
	xor_reg8l_idxdisp16 r4 r11
xor_cl_didisp16:
	xor_reg8l_idxdisp16 r5 r11
xor_dl_didisp16:
	xor_reg8l_idxdisp16 r6 r11
xor_bl_didisp16:
	xor_reg8l_idxdisp16 r7 r11
xor_ah_didisp16:
	xor_reg8h_idxdisp16 r4 r11
xor_ch_didisp16:
	xor_reg8h_idxdisp16 r5 r11
xor_dh_didisp16:
	xor_reg8h_idxdisp16 r6 r11
xor_bh_didisp16:
	xor_reg8h_idxdisp16 r7 r11

xor_al_bxdisp16:
	xor_reg8l_idxdisp16 r4 r7
xor_cl_bxdisp16:
	xor_reg8l_idxdisp16 r5 r7
xor_dl_bxdisp16:
	xor_reg8l_idxdisp16 r6 r7
xor_bl_bxdisp16:
	xor_reg8l_idxdisp16 r7 r7
xor_ah_bxdisp16:
	xor_reg8h_idxdisp16 r4 r7
xor_ch_bxdisp16:
	xor_reg8h_idxdisp16 r5 r7
xor_dh_bxdisp16:
	xor_reg8h_idxdisp16 r6 r7
xor_bh_bxdisp16:
	xor_reg8h_idxdisp16 r7 r7
	
.macro xor_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		xor_r8l_r0_bp_\reg
.endm
.macro xor_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		xor_r8h_r0_bp_\reg
.endm

xor_al_bpdisp16:
	xor_reg8l_bpdisp16 r4 
xor_cl_bpdisp16:
	xor_reg8l_bpdisp16 r5 
xor_dl_bpdisp16:
	xor_reg8l_bpdisp16 r6 
xor_bl_bpdisp16:
	xor_reg8l_bpdisp16 r7 
xor_ah_bpdisp16:
	xor_reg8h_bpdisp16 r4 
xor_ch_bpdisp16:
	xor_reg8h_bpdisp16 r5 
xor_dh_bpdisp16:
	xor_reg8h_bpdisp16 r6 
xor_bh_bpdisp16:
	xor_reg8h_bpdisp16 r7 

// --- Register operands ---

.macro xor_reg8l_reg8l reg1 reg2
	mov		r0, \reg1, lsl #24
	mov		r1, \reg2, lsl #24
	eors	r0, r1
	bic		\reg1, #0xFF			// Clear the current reg8l value
	orr		\reg1, r0, lsr #24		// and replace it with r0
	b		loop
.endm
.macro xor_reg8l_reg8h reg1 reg2
	mov		r0, \reg1, lsl #24
	and		r1, \reg2, #0xFF00
	eors	r0, r1, lsl #16
	bic		\reg1, #0xFF			// Clear the current reg8l value
	orr		\reg1, r0, lsr #24		// and replace it with r0
	b		loop
.endm
.macro xor_reg8h_reg8l reg1 reg2
	and		r0, \reg1, #0xFF00
	mov		r1, \reg2, lsl #24
	eors	r0, r1, r0, lsl #16
	bic		\reg1, #0xFF00			// Clear the current reg8h value
	orr		\reg1, r0, lsr #16		// and replace it with r0
	b		loop
.endm
.macro xor_reg8h_reg8h reg1 reg2
	and		r0, \reg1, #0xFF00
	and		r1, \reg2, #0xFF00
	lsl		r0, #16
	eors	r0, r1, lsl #16
	bic		\reg1, #0xFF00			// Clear the current reg8h value
	orr		\reg1, r0, lsr #16		// and replace it with r0
	b		loop
.endm

xor_al_al:
	xor_reg8l_reg8l r4 r4
xor_al_cl:	
	xor_reg8l_reg8l r4 r5
xor_al_dl:
	xor_reg8l_reg8l r4 r6
xor_al_bl:	
	xor_reg8l_reg8l r4 r7
xor_al_ah:
	xor_reg8l_reg8h r4 r4
xor_al_ch:	
	xor_reg8l_reg8h r4 r5
xor_al_dh:
	xor_reg8l_reg8h r4 r6
xor_al_bh:	
	xor_reg8l_reg8h r4 r7

xor_cl_al:
	xor_reg8l_reg8l r5 r4
xor_cl_cl:	
	xor_reg8l_reg8l r5 r5
xor_cl_dl:
	xor_reg8l_reg8l r5 r6
xor_cl_bl:	
	xor_reg8l_reg8l r5 r7
xor_cl_ah:
	xor_reg8l_reg8h r5 r4
xor_cl_ch:	
	xor_reg8l_reg8h r5 r5
xor_cl_dh:
	xor_reg8l_reg8h r5 r6
xor_cl_bh:	
	xor_reg8l_reg8h r5 r7
	
xor_dl_al:
	xor_reg8l_reg8l r6 r4
xor_dl_cl:	
	xor_reg8l_reg8l r6 r5
xor_dl_dl:
	xor_reg8l_reg8l r6 r6
xor_dl_bl:	
	xor_reg8l_reg8l r6 r7
xor_dl_ah:
	xor_reg8l_reg8h r6 r4
xor_dl_ch:	
	xor_reg8l_reg8h r6 r5
xor_dl_dh:
	xor_reg8l_reg8h r6 r6
xor_dl_bh:	
	xor_reg8l_reg8h r6 r7
	
xor_bl_al:
	xor_reg8l_reg8l r7 r4
xor_bl_cl:	
	xor_reg8l_reg8l r7 r5
xor_bl_dl:
	xor_reg8l_reg8l r7 r6
xor_bl_bl:	
	xor_reg8l_reg8l r7 r7
xor_bl_ah:
	xor_reg8l_reg8h r7 r4
xor_bl_ch:	
	xor_reg8l_reg8h r7 r5
xor_bl_dh:
	xor_reg8l_reg8h r7 r6
xor_bl_bh:	
	xor_reg8l_reg8h r7 r7
	
xor_ah_al:
	xor_reg8h_reg8l r4 r4
xor_ah_cl:
	xor_reg8h_reg8l r4 r5
xor_ah_dl:
	xor_reg8h_reg8l r4 r6
xor_ah_bl:
	xor_reg8h_reg8l r4 r7
xor_ah_ah:
	xor_reg8h_reg8h r4 r4
xor_ah_ch:	
	xor_reg8h_reg8h r4 r5
xor_ah_dh:
	xor_reg8h_reg8h r4 r6
xor_ah_bh:	
	xor_reg8h_reg8h r4 r7

xor_ch_al:
	xor_reg8h_reg8l r5 r4
xor_ch_cl:
	xor_reg8h_reg8l r5 r5
xor_ch_dl:
	xor_reg8h_reg8l r5 r6
xor_ch_bl:
	xor_reg8h_reg8l r5 r7
xor_ch_ah:
	xor_reg8h_reg8h r5 r4
xor_ch_ch:	
	xor_reg8h_reg8h r5 r5
xor_ch_dh:
	xor_reg8h_reg8h r5 r6
xor_ch_bh:	
	xor_reg8h_reg8h r5 r7
	
xor_dh_al:
	xor_reg8h_reg8l r6 r4
xor_dh_cl:
	xor_reg8h_reg8l r6 r5
xor_dh_dl:
	xor_reg8h_reg8l r6 r6
xor_dh_bl:
	xor_reg8h_reg8l r6 r7
xor_dh_ah:
	xor_reg8h_reg8h r6 r4
xor_dh_ch:	
	xor_reg8h_reg8h r6 r5
xor_dh_dh:
	xor_reg8h_reg8h r6 r6
xor_dh_bh:	
	xor_reg8h_reg8h r6 r7
	
xor_bh_al:
	xor_reg8h_reg8l r7 r4
xor_bh_cl:
	xor_reg8h_reg8l r7 r5
xor_bh_dl:
	xor_reg8h_reg8l r7 r6
xor_bh_bl:
	xor_reg8h_reg8l r7 r7
xor_bh_ah:
	xor_reg8h_reg8h r7 r4
xor_bh_ch:	
	xor_reg8h_reg8h r7 r5
xor_bh_dh:
	xor_reg8h_reg8h r7 r6
xor_bh_bh:	
	xor_reg8h_reg8h r7 r7
	
// ------------------- 33 = XOR r16, r/m16 -----------------------------
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual eors operation, so C and O work like in x86.
//
// All modrm variations supported!
//
//
	.global	op_33
op_33:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word xor_ax_bxsi, xor_ax_bxdi, xor_ax_bpsi, xor_ax_bpdi, xor_ax_siidx, xor_ax_diidx, xor_ax_disp16, xor_ax_bxidx
	.word xor_cx_bxsi, xor_cx_bxdi, xor_cx_bpsi, xor_cx_bpdi, xor_cx_siidx, xor_cx_diidx, xor_cx_disp16, xor_cx_bxidx
	.word xor_dx_bxsi, xor_dx_bxdi, xor_dx_bpsi, xor_dx_bpdi, xor_dx_siidx, xor_dx_diidx, xor_dx_disp16, xor_dx_bxidx
	.word xor_bx_bxsi, xor_bx_bxdi, xor_bx_bpsi, xor_bx_bpdi, xor_bx_siidx, xor_bx_diidx, xor_bx_disp16, xor_bx_bxidx
	.word xor_sp_bxsi, xor_sp_bxdi, xor_sp_bpsi, xor_sp_bpdi, xor_sp_siidx, xor_sp_diidx, xor_sp_disp16, xor_sp_bxidx
	.word xor_bp_bxsi, xor_bp_bxdi, xor_bp_bpsi, xor_bp_bpdi, xor_bp_siidx, xor_bp_diidx, xor_bp_disp16, xor_bp_bxidx
	.word xor_si_bxsi, xor_si_bxdi, xor_si_bpsi, xor_si_bpdi, xor_si_siidx, xor_si_diidx, xor_si_disp16, xor_si_bxidx
	.word xor_di_bxsi, xor_di_bxdi, xor_di_bpsi, xor_di_bpdi, xor_di_siidx, xor_di_diidx, xor_di_disp16, xor_di_bxidx
//0x40
	.word xor_ax_bxsid8, xor_ax_bxdid8, xor_ax_bpsid8, xor_ax_bpdid8, xor_ax_sidisp8, xor_ax_didisp8, xor_ax_bpdisp8, xor_ax_bxdisp8
	.word xor_cx_bxsid8, xor_cx_bxdid8, xor_cx_bpsid8, xor_cx_bpdid8, xor_cx_sidisp8, xor_cx_didisp8, xor_cx_bpdisp8, xor_cx_bxdisp8
	.word xor_dx_bxsid8, xor_dx_bxdid8, xor_dx_bpsid8, xor_dx_bpdid8, xor_dx_sidisp8, xor_dx_didisp8, xor_dx_bpdisp8, xor_dx_bxdisp8
	.word xor_bx_bxsid8, xor_bx_bxdid8, xor_bx_bpsid8, xor_bx_bpdid8, xor_bx_sidisp8, xor_bx_didisp8, xor_bx_bpdisp8, xor_bx_bxdisp8
	.word xor_sp_bxsid8, xor_sp_bxdid8, xor_sp_bpsid8, xor_sp_bpdid8, xor_sp_sidisp8, xor_sp_didisp8, xor_sp_bpdisp8, xor_sp_bxdisp8
	.word xor_bp_bxsid8, xor_bp_bxdid8, xor_bp_bpsid8, xor_bp_bpdid8, xor_bp_sidisp8, xor_bp_didisp8, xor_bp_bpdisp8, xor_bp_bxdisp8
	.word xor_si_bxsid8, xor_si_bxdid8, xor_si_bpsid8, xor_si_bpdid8, xor_si_sidisp8, xor_si_didisp8, xor_si_bpdisp8, xor_si_bxdisp8
	.word xor_di_bxsid8, xor_di_bxdid8, xor_di_bpsid8, xor_di_bpdid8, xor_di_sidisp8, xor_di_didisp8, xor_di_bpdisp8, xor_di_bxdisp8
//0x80
	.word xor_ax_bxsid16, xor_ax_bxdid16, xor_ax_bpsid16, xor_ax_bpdid16, xor_ax_sidisp16, xor_ax_didisp16, xor_ax_bpdisp16, xor_ax_bxdisp16
	.word xor_cx_bxsid16, xor_cx_bxdid16, xor_cx_bpsid16, xor_cx_bpdid16, xor_cx_sidisp16, xor_cx_didisp16, xor_cx_bpdisp16, xor_cx_bxdisp16
	.word xor_dx_bxsid16, xor_dx_bxdid16, xor_dx_bpsid16, xor_dx_bpdid16, xor_dx_sidisp16, xor_dx_didisp16, xor_dx_bpdisp16, xor_dx_bxdisp16
	.word xor_bx_bxsid16, xor_bx_bxdid16, xor_bx_bpsid16, xor_bx_bpdid16, xor_bx_sidisp16, xor_bx_didisp16, xor_bx_bpdisp16, xor_bx_bxdisp16
	.word xor_sp_bxsid16, xor_sp_bxdid16, xor_sp_bpsid16, xor_sp_bpdid16, xor_sp_sidisp16, xor_sp_didisp16, xor_sp_bpdisp16, xor_sp_bxdisp16
	.word xor_bp_bxsid16, xor_bp_bxdid16, xor_bp_bpsid16, xor_bp_bpdid16, xor_bp_sidisp16, xor_bp_didisp16, xor_bp_bpdisp16, xor_bp_bxdisp16
	.word xor_si_bxsid16, xor_si_bxdid16, xor_si_bpsid16, xor_si_bpdid16, xor_si_sidisp16, xor_si_didisp16, xor_si_bpdisp16, xor_si_bxdisp16
	.word xor_di_bxsid16, xor_di_bxdid16, xor_di_bpsid16, xor_di_bpdid16, xor_di_sidisp16, xor_di_didisp16, xor_di_bpdisp16, xor_di_bxdisp16
// 0xC0 = two register operands
	.word xor_ax_ax, xor_ax_cx, xor_ax_dx, xor_ax_bx, xor_ax_sp, xor_ax_bp, xor_ax_si, xor_ax_di
	.word xor_cx_ax, xor_cx_cx, xor_cx_dx, xor_cx_bx, xor_cx_sp, xor_cx_bp, xor_cx_si, xor_cx_di
	.word xor_dx_ax, xor_dx_cx, xor_dx_dx, xor_dx_bx, xor_dx_sp, xor_dx_bp, xor_dx_si, xor_dx_di
	.word xor_bx_ax, xor_bx_cx, xor_bx_dx, xor_bx_bx, xor_bx_sp, xor_bx_bp, xor_bx_si, xor_bx_di
	.word xor_sp_ax, xor_sp_cx, xor_sp_dx, xor_sp_bx, xor_sp_sp, xor_sp_bp, xor_sp_si, xor_sp_di
	.word xor_bp_ax, xor_bp_cx, xor_bp_dx, xor_bp_bx, xor_bp_sp, xor_bp_bp, xor_bp_si, xor_bp_di
	.word xor_si_ax, xor_si_cx, xor_si_dx, xor_si_bx, xor_si_sp, xor_si_bp, xor_si_si, xor_si_di
	.word xor_di_ax, xor_di_cx, xor_di_dx, xor_di_bx, xor_di_sp, xor_di_bp, xor_di_si, xor_di_di

// These are called from "cpu_67.s":

	.global xor_ax_siidx, xor_ax_diidx, xor_ax_bxidx
	.global xor_cx_siidx, xor_cx_diidx, xor_cx_bxidx
	.global xor_dx_siidx, xor_dx_diidx, xor_dx_bxidx
	.global xor_bx_siidx, xor_bx_diidx, xor_bx_bxidx
	.global xor_sp_siidx, xor_sp_diidx, xor_sp_bxidx
	.global xor_bp_siidx, xor_bp_diidx, xor_bp_bxidx
	.global xor_si_siidx, xor_si_diidx, xor_si_bxidx
	.global xor_di_siidx, xor_di_diidx, xor_di_bxidx
	.global xor_ax_sidisp8, xor_ax_didisp8, xor_ax_bpdisp8, xor_ax_bxdisp8
	.global xor_cx_sidisp8, xor_cx_didisp8, xor_cx_bpdisp8, xor_cx_bxdisp8
	.global xor_dx_sidisp8, xor_dx_didisp8, xor_dx_bpdisp8, xor_dx_bxdisp8
	.global xor_bx_sidisp8, xor_bx_didisp8, xor_bx_bpdisp8, xor_bx_bxdisp8
	.global xor_sp_sidisp8, xor_sp_didisp8, xor_sp_bpdisp8, xor_sp_bxdisp8
	.global xor_bp_sidisp8, xor_bp_didisp8, xor_bp_bpdisp8, xor_bp_bxdisp8
	.global xor_si_sidisp8, xor_si_didisp8, xor_si_bpdisp8, xor_si_bxdisp8
	.global xor_di_sidisp8, xor_di_didisp8, xor_di_bpdisp8, xor_di_bxdisp8
	.global	xor_r16_r0_bp_r4, xor_r16_r0_bp_r5, xor_r16_r0_bp_r6, xor_r16_r0_bp_r7, xor_r16_r0_bp_r8, xor_r16_r0_bp_r9, xor_r16_r0_bp_r10, xor_r16_r0_bp_r11
	.global	xor_r16_r0_r4, xor_r16_r0_r5, xor_r16_r0_r6, xor_r16_r0_r7, xor_r16_r0_r8, xor_r16_r0_r9, xor_r16_r0_r10, xor_r16_r0_r11

.macro xor_reg16_r0high reg
xor_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
xor_r16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_33_RAM_\reg op_33_EGA_\reg bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_33_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	eors	r0, r2, r0, lsl #16
	orr		\reg, r0, lsr #16
	b		loop
.endm

	xor_reg16_r0high r4
	xor_reg16_r0high r5
	xor_reg16_r0high r6
	xor_reg16_r0high r7
	xor_reg16_r0high r8
	xor_reg16_r0high r9
	xor_reg16_r0high r10
	xor_reg16_r0high r11

	.ltorg

.macro xor_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		xor_r16_r0_\reg
.endm

xor_ax_bxsi:
	xor_reg16_bxidx r4 r10
xor_cx_bxsi:
	xor_reg16_bxidx r5 r10
xor_dx_bxsi:
	xor_reg16_bxidx r6 r10
xor_bx_bxsi:
	xor_reg16_bxidx r7 r10
xor_bp_bxsi:
	xor_reg16_bxidx r9 r10
xor_sp_bxsi:
	xor_reg16_bxidx r8 r10
xor_si_bxsi:
	xor_reg16_bxidx r10 r10
xor_di_bxsi:
	xor_reg16_bxidx r11 r10

xor_ax_bxdi:
	xor_reg16_bxidx r4 r11
xor_cx_bxdi:
	xor_reg16_bxidx r5 r11
xor_dx_bxdi:
	xor_reg16_bxidx r6 r11
xor_bx_bxdi:
	xor_reg16_bxidx r7 r11
xor_sp_bxdi:
	xor_reg16_bxidx r8 r11
xor_bp_bxdi:
	xor_reg16_bxidx r9 r11
xor_si_bxdi:
	xor_reg16_bxidx r10 r11
xor_di_bxdi:
	xor_reg16_bxidx r11 r11

.macro xor_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		xor_r16_r0_bp_\reg
.endm

xor_ax_bpsi:
	xor_reg16_bpidx r4 r10
xor_cx_bpsi:
	xor_reg16_bpidx r5 r10
xor_dx_bpsi:
	xor_reg16_bpidx r6 r10
xor_bx_bpsi:
	xor_reg16_bpidx r7 r10
xor_sp_bpsi:
	xor_reg16_bpidx r8 r10
xor_bp_bpsi:
	xor_reg16_bpidx r9 r10
xor_si_bpsi:
	xor_reg16_bpidx r10 r10
xor_di_bpsi:
	xor_reg16_bpidx r11 r10

xor_ax_bpdi:
	xor_reg16_bpidx r4 r11
xor_cx_bpdi:
	xor_reg16_bpidx r5 r11
xor_dx_bpdi:
	xor_reg16_bpidx r6 r11
xor_bx_bpdi:
	xor_reg16_bpidx r7 r11
xor_sp_bpdi:
	xor_reg16_bpidx r8 r11
xor_bp_bpdi:
	xor_reg16_bpidx r9 r11
xor_si_bpdi:
	xor_reg16_bpidx r10 r11
xor_di_bpdi:
	xor_reg16_bpidx r11 r11

.macro xor_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		xor_r16_r0_\reg
.endm

xor_ax_siidx:
	xor_reg16_idx r4 r10
xor_cx_siidx:
	xor_reg16_idx r5 r10
xor_dx_siidx:
	xor_reg16_idx r6 r10
xor_bx_siidx:
	xor_reg16_idx r7 r10
xor_sp_siidx:
	xor_reg16_idx r8 r10
xor_bp_siidx:
	xor_reg16_idx r9 r10
xor_si_siidx:
	xor_reg16_idx r10 r10
xor_di_siidx:
	xor_reg16_idx r11 r10

xor_ax_diidx:
	xor_reg16_idx r4 r11
xor_cx_diidx:
	xor_reg16_idx r5 r11
xor_dx_diidx:
	xor_reg16_idx r6 r11
xor_bx_diidx:
	xor_reg16_idx r7 r11
xor_sp_diidx:
	xor_reg16_idx r8 r11
xor_bp_diidx:
	xor_reg16_idx r9 r11
xor_si_diidx:
	xor_reg16_idx r10 r11
xor_di_diidx:
	xor_reg16_idx r11 r11

xor_ax_bxidx:
	xor_reg16_idx r4 r7
xor_cx_bxidx:
	xor_reg16_idx r5 r7
xor_dx_bxidx:
	xor_reg16_idx r6 r7
xor_bx_bxidx:
	xor_reg16_idx r7 r7
xor_sp_bxidx:
	xor_reg16_idx r8 r7
xor_bp_bxidx:
	xor_reg16_idx r9 r7
xor_si_bxidx:
	xor_reg16_idx r10 r7
xor_di_bxidx:
	xor_reg16_idx r11 r7

.macro xor_reg16_disp16 reg
	r0_from_disp16
	b		xor_r16_r0_\reg
.endm

xor_ax_disp16:
	xor_reg16_disp16 r4
xor_cx_disp16:
	xor_reg16_disp16 r5
xor_dx_disp16:
	xor_reg16_disp16 r6
xor_bx_disp16:
	xor_reg16_disp16 r7
xor_sp_disp16:
	xor_reg16_disp16 r8
xor_bp_disp16:
	xor_reg16_disp16 r9
xor_si_disp16:
	xor_reg16_disp16 r10
xor_di_disp16:
	xor_reg16_disp16 r11

// --- [idx+disp8] ---

.macro xor_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		xor_r16_r0_\reg
.endm

xor_ax_bxsid8:
	xor_reg16_bxidxdisp8 r4 r10
xor_cx_bxsid8:
	xor_reg16_bxidxdisp8 r5 r10
xor_dx_bxsid8:
	xor_reg16_bxidxdisp8 r6 r10
xor_bx_bxsid8:
	xor_reg16_bxidxdisp8 r7 r10
xor_sp_bxsid8:
	xor_reg16_bxidxdisp8 r8 r10
xor_bp_bxsid8:
	xor_reg16_bxidxdisp8 r9 r10
xor_si_bxsid8:
	xor_reg16_bxidxdisp8 r10 r10
xor_di_bxsid8:
	xor_reg16_bxidxdisp8 r11 r10

xor_ax_bxdid8:
	xor_reg16_bxidxdisp8 r4 r11
xor_cx_bxdid8:
	xor_reg16_bxidxdisp8 r5 r11
xor_dx_bxdid8:
	xor_reg16_bxidxdisp8 r6 r11
xor_bx_bxdid8:
	xor_reg16_bxidxdisp8 r7 r11
xor_sp_bxdid8:
	xor_reg16_bxidxdisp8 r8 r11
xor_bp_bxdid8:
	xor_reg16_bxidxdisp8 r9 r11
xor_si_bxdid8:
	xor_reg16_bxidxdisp8 r10 r11
xor_di_bxdid8:
	xor_reg16_bxidxdisp8 r11 r11

.macro xor_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		xor_r16_r0_bp_\reg
.endm

xor_ax_bpsid8:
	xor_reg16_bpidxdisp8 r4 r10
xor_cx_bpsid8:
	xor_reg16_bpidxdisp8 r5 r10
xor_dx_bpsid8:
	xor_reg16_bpidxdisp8 r6 r10
xor_bx_bpsid8:
	xor_reg16_bpidxdisp8 r7 r10
xor_sp_bpsid8:
	xor_reg16_bpidxdisp8 r8 r10
xor_bp_bpsid8:
	xor_reg16_bpidxdisp8 r9 r10
xor_si_bpsid8:
	xor_reg16_bpidxdisp8 r10 r10
xor_di_bpsid8:
	xor_reg16_bpidxdisp8 r11 r10

xor_ax_bpdid8:
	xor_reg16_bpidxdisp8 r4 r11
xor_cx_bpdid8:
	xor_reg16_bpidxdisp8 r5 r11
xor_dx_bpdid8:
	xor_reg16_bpidxdisp8 r6 r11
xor_bx_bpdid8:
	xor_reg16_bpidxdisp8 r7 r11
xor_sp_bpdid8:
	xor_reg16_bpidxdisp8 r8 r11
xor_bp_bpdid8:
	xor_reg16_bpidxdisp8 r9 r11
xor_si_bpdid8:
	xor_reg16_bpidxdisp8 r10 r11
xor_di_bpdid8:
	xor_reg16_bpidxdisp8 r11 r11

.macro xor_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		xor_r16_r0_\reg
.endm

xor_ax_sidisp8:
	xor_reg16_idxdisp8 r4 r10
xor_cx_sidisp8:
	xor_reg16_idxdisp8 r5 r10
xor_dx_sidisp8:
	xor_reg16_idxdisp8 r6 r10
xor_bx_sidisp8:
	xor_reg16_idxdisp8 r7 r10
xor_sp_sidisp8:
	xor_reg16_idxdisp8 r8 r10
xor_bp_sidisp8:
	xor_reg16_idxdisp8 r9 r10
xor_si_sidisp8:
	xor_reg16_idxdisp8 r10 r10
xor_di_sidisp8:
	xor_reg16_idxdisp8 r11 r10

xor_ax_didisp8:
	xor_reg16_idxdisp8 r4 r11
xor_cx_didisp8:
	xor_reg16_idxdisp8 r5 r11
xor_dx_didisp8:
	xor_reg16_idxdisp8 r6 r11
xor_bx_didisp8:
	xor_reg16_idxdisp8 r7 r11
xor_sp_didisp8:
	xor_reg16_idxdisp8 r8 r11
xor_bp_didisp8:
	xor_reg16_idxdisp8 r9 r11
xor_si_didisp8:
	xor_reg16_idxdisp8 r10 r11
xor_di_didisp8:
	xor_reg16_idxdisp8 r11 r11

xor_ax_bxdisp8:
	xor_reg16_idxdisp8 r4 r7
xor_cx_bxdisp8:
	xor_reg16_idxdisp8 r5 r7
xor_dx_bxdisp8:
	xor_reg16_idxdisp8 r6 r7
xor_bx_bxdisp8:
	xor_reg16_idxdisp8 r7 r7
xor_sp_bxdisp8:
	xor_reg16_idxdisp8 r8 r7
xor_bp_bxdisp8:
	xor_reg16_idxdisp8 r9 r7
xor_si_bxdisp8:
	xor_reg16_idxdisp8 r10 r7
xor_di_bxdisp8:
	xor_reg16_idxdisp8 r11 r7

.macro xor_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		xor_r16_r0_bp_\reg
.endm

xor_ax_bpdisp8:
	xor_reg16_bpdisp8 r4
xor_cx_bpdisp8:
	xor_reg16_bpdisp8 r5
xor_dx_bpdisp8:
	xor_reg16_bpdisp8 r6
xor_bx_bpdisp8:
	xor_reg16_bpdisp8 r7
xor_sp_bpdisp8:
	xor_reg16_bpdisp8 r8
xor_bp_bpdisp8:
	xor_reg16_bpdisp8 r9
xor_si_bpdisp8:
	xor_reg16_bpdisp8 r10
xor_di_bpdisp8:
	xor_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro xor_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		xor_r16_r0_\reg
.endm

xor_ax_bxsid16:
	xor_reg16_bxidxdisp16 r4 r10
xor_cx_bxsid16:
	xor_reg16_bxidxdisp16 r5 r10
xor_dx_bxsid16:
	xor_reg16_bxidxdisp16 r6 r10
xor_bx_bxsid16:
	xor_reg16_bxidxdisp16 r7 r10
xor_sp_bxsid16:
	xor_reg16_bxidxdisp16 r8 r10
xor_bp_bxsid16:
	xor_reg16_bxidxdisp16 r9 r10
xor_si_bxsid16:
	xor_reg16_bxidxdisp16 r10 r10
xor_di_bxsid16:
	xor_reg16_bxidxdisp16 r11 r10

xor_ax_bxdid16:
	xor_reg16_bxidxdisp16 r4 r11
xor_cx_bxdid16:
	xor_reg16_bxidxdisp16 r5 r11
xor_dx_bxdid16:
	xor_reg16_bxidxdisp16 r6 r11
xor_bx_bxdid16:
	xor_reg16_bxidxdisp16 r7 r11
xor_sp_bxdid16:
	xor_reg16_bxidxdisp16 r8 r11
xor_bp_bxdid16:
	xor_reg16_bxidxdisp16 r9 r11
xor_si_bxdid16:
	xor_reg16_bxidxdisp16 r10 r11
xor_di_bxdid16:
	xor_reg16_bxidxdisp16 r11 r11

.macro xor_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		xor_r16_r0_bp_\reg
.endm

xor_ax_bpsid16:
	xor_reg16_bpidxdisp16 r4 r10
xor_cx_bpsid16:
	xor_reg16_bpidxdisp16 r5 r10
xor_dx_bpsid16:
	xor_reg16_bpidxdisp16 r6 r10
xor_bx_bpsid16:
	xor_reg16_bpidxdisp16 r7 r10
xor_sp_bpsid16:
	xor_reg16_bpidxdisp16 r8 r10
xor_bp_bpsid16:
	xor_reg16_bpidxdisp16 r9 r10
xor_si_bpsid16:
	xor_reg16_bpidxdisp16 r10 r10
xor_di_bpsid16:
	xor_reg16_bpidxdisp16 r11 r10

xor_ax_bpdid16:
	xor_reg16_bpidxdisp16 r4 r11
xor_cx_bpdid16:
	xor_reg16_bpidxdisp16 r5 r11
xor_dx_bpdid16:
	xor_reg16_bpidxdisp16 r6 r11
xor_bx_bpdid16:
	xor_reg16_bpidxdisp16 r7 r11
xor_sp_bpdid16:
	xor_reg16_bpidxdisp16 r8 r11
xor_bp_bpdid16:
	xor_reg16_bpidxdisp16 r9 r11
xor_si_bpdid16:
	xor_reg16_bpidxdisp16 r10 r11
xor_di_bpdid16:
	xor_reg16_bpidxdisp16 r11 r11

.macro xor_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		xor_r16_r0_\reg
.endm

xor_ax_sidisp16:
	xor_reg16_idxdisp16 r4 r10
xor_cx_sidisp16:
	xor_reg16_idxdisp16 r5 r10
xor_dx_sidisp16:
	xor_reg16_idxdisp16 r6 r10
xor_bx_sidisp16:
	xor_reg16_idxdisp16 r7 r10
xor_sp_sidisp16:
	xor_reg16_idxdisp16 r8 r10
xor_bp_sidisp16:
	xor_reg16_idxdisp16 r9 r10
xor_si_sidisp16:
	xor_reg16_idxdisp16 r10 r10
xor_di_sidisp16:
	xor_reg16_idxdisp16 r11 r10

xor_ax_didisp16:
	xor_reg16_idxdisp16 r4 r11
xor_cx_didisp16:
	xor_reg16_idxdisp16 r5 r11
xor_dx_didisp16:
	xor_reg16_idxdisp16 r6 r11
xor_bx_didisp16:
	xor_reg16_idxdisp16 r7 r11
xor_sp_didisp16:
	xor_reg16_idxdisp16 r8 r11
xor_bp_didisp16:
	xor_reg16_idxdisp16 r9 r11
xor_si_didisp16:
	xor_reg16_idxdisp16 r10 r11
xor_di_didisp16:
	xor_reg16_idxdisp16 r11 r11

xor_ax_bxdisp16:
	xor_reg16_idxdisp16 r4 r7
xor_cx_bxdisp16:
	xor_reg16_idxdisp16 r5 r7
xor_dx_bxdisp16:
	xor_reg16_idxdisp16 r6 r7
xor_bx_bxdisp16:
	xor_reg16_idxdisp16 r7 r7
xor_sp_bxdisp16:
	xor_reg16_idxdisp16 r8 r7
xor_bp_bxdisp16:
	xor_reg16_idxdisp16 r9 r7
xor_si_bxdisp16:
	xor_reg16_idxdisp16 r10 r7
xor_di_bxdisp16:
	xor_reg16_idxdisp16 r11 r7

.macro xor_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		xor_r16_r0_bp_\reg
.endm

xor_ax_bpdisp16:
	xor_reg16_bpdisp16 r4
xor_cx_bpdisp16:
	xor_reg16_bpdisp16 r5
xor_dx_bpdisp16:
	xor_reg16_bpdisp16 r6
xor_bx_bpdisp16:
	xor_reg16_bpdisp16 r7
xor_sp_bpdisp16:
	xor_reg16_bpdisp16 r8
xor_bp_bpdisp16:
	xor_reg16_bpdisp16 r9
xor_si_bpdisp16:
	xor_reg16_bpdisp16 r10
xor_di_bpdisp16:
	xor_reg16_bpdisp16 r11


// --- registers ---
	
.macro xor_reg16_reg16 rl rr
	mov		r0, \rl, lsl #16
	mov		r1, \rr, lsl #16
	eor		\rl, r0, lsr #16
	eors	r0, r1
	orr		\rl, r0, lsr #16
	b		loop
.endm

xor_ax_ax:
	xor_reg16_reg16		r4 r4
xor_ax_cx:
	xor_reg16_reg16		r4 r5
xor_ax_dx:
	xor_reg16_reg16		r4 r6
xor_ax_bx:
	xor_reg16_reg16		r4 r7
xor_ax_sp:
	xor_reg16_reg16		r4 r8
xor_ax_bp:
	xor_reg16_reg16		r4 r9
xor_ax_si:
	xor_reg16_reg16		r4 r10
xor_ax_di:
	xor_reg16_reg16		r4 r11
xor_cx_ax:
	xor_reg16_reg16		r5 r4
xor_cx_cx:
	xor_reg16_reg16		r5 r5
xor_cx_dx:
	xor_reg16_reg16		r5 r6
xor_cx_bx:
	xor_reg16_reg16		r5 r7
xor_cx_sp:
	xor_reg16_reg16		r5 r8
xor_cx_bp:
	xor_reg16_reg16		r5 r9
xor_cx_si:
	xor_reg16_reg16		r5 r10
xor_cx_di:
	xor_reg16_reg16		r5 r11
xor_dx_ax:
	xor_reg16_reg16		r6 r4
xor_dx_cx:
	xor_reg16_reg16		r6 r5
xor_dx_dx:
	xor_reg16_reg16		r6 r6
xor_dx_bx:
	xor_reg16_reg16		r6 r7
xor_dx_sp:
	xor_reg16_reg16		r6 r8
xor_dx_bp:
	xor_reg16_reg16		r6 r9
xor_dx_si:
	xor_reg16_reg16		r6 r10
xor_dx_di:
	xor_reg16_reg16		r6 r11
xor_bx_ax:
	xor_reg16_reg16		r7 r4
xor_bx_cx:
	xor_reg16_reg16		r7 r5
xor_bx_dx:
	xor_reg16_reg16		r7 r6
xor_bx_bx:
	xor_reg16_reg16		r7 r7
xor_bx_sp:
	xor_reg16_reg16		r7 r8
xor_bx_bp:
	xor_reg16_reg16		r7 r9
xor_bx_si:
	xor_reg16_reg16		r7 r10
xor_bx_di:
	xor_reg16_reg16		r7 r11

xor_sp_ax:
	xor_reg16_reg16		r8 r4
xor_sp_cx:
	xor_reg16_reg16		r8 r5
xor_sp_dx:
	xor_reg16_reg16		r8 r6
xor_sp_bx:
	xor_reg16_reg16		r8 r7
xor_sp_sp:
	xor_reg16_reg16		r8 r8
xor_sp_bp:
	xor_reg16_reg16		r8 r9
xor_sp_si:
	xor_reg16_reg16		r8 r10
xor_sp_di:
	xor_reg16_reg16		r8 r11

xor_bp_ax:
	xor_reg16_reg16		r9 r4
xor_bp_cx:
	xor_reg16_reg16		r9 r5
xor_bp_dx:
	xor_reg16_reg16		r9 r6
xor_bp_bx:
	xor_reg16_reg16		r9 r7
xor_bp_sp:
	xor_reg16_reg16		r9 r8
xor_bp_bp:
	xor_reg16_reg16		r9 r9
xor_bp_si:
	xor_reg16_reg16		r9 r10
xor_bp_di:
	xor_reg16_reg16		r9 r11
xor_si_ax:
	xor_reg16_reg16		r10 r4
xor_si_cx:
	xor_reg16_reg16		r10 r5
xor_si_dx:
	xor_reg16_reg16		r10 r6
xor_si_bx:
	xor_reg16_reg16		r10 r7
xor_si_sp:
	xor_reg16_reg16		r10 r8
xor_si_bp:
	xor_reg16_reg16		r10 r9
xor_si_si:
	xor_reg16_reg16		r10 r10
xor_si_di:
	xor_reg16_reg16		r10 r11
xor_di_ax:
	xor_reg16_reg16		r11 r4
xor_di_cx:
	xor_reg16_reg16		r11 r5
xor_di_dx:
	xor_reg16_reg16		r11 r6
xor_di_bx:
	xor_reg16_reg16		r11 r7
xor_di_sp:
	xor_reg16_reg16		r11 r8
xor_di_bp:
	xor_reg16_reg16		r11 r9
xor_di_si:
	xor_reg16_reg16		r11 r10
xor_di_di:
	xor_reg16_reg16		r11 r11

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

// ------------------- 34 = XOR AL,imm8 --------------------------------
//
op_34:
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	ldrb	r1,[r12],#1				// Load the second opcode byte to r1, increment r12 by 1
	mov		r0, eax, lsl #24
	bic		eax, #0xFF				// Clear the current AL value
	eors	r0, r1, lsl #24
	orr		eax, r0, lsr #24		// and replace it with r0
	b		loop

// ------------------- 35 = XOR AX,imm16 --------------------------------
//
op_35:
	ldrb	r0,[r12],#1				// Load low byte of imm16
	ldrb	r1,[r12],#1				// Load high byte
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	mov		r1, eax, lsl #16
	eor		eax, r1, lsr #16
	eors	r0, r1, r0, lsl #16
	orr		eax, r0, lsr #16
	b		loop

	.text
	.align 2

// ------------------- 37 = AAA ----------------------------------------
//
// Adjusts the sum of two unpacked BCD values to create an unpacked BCD result.
//
// if((AL & 0xF) > 9 || AF == 1) {
//	AL = AL + 6;
//	AH = AH + 1;
//	AF = 1;
//	CF = 1
// }
// else {
//	AF = 0;
//	CF = 0;
// }
// AL = AL & 0xF;
//
op_37:
#if 1
	mov		r0, #0								// Default to all ARM flags being clear
	//------
	// SETFLAGBIT(SF,((reg_al>=0x7a) && (reg_al<=0xf9)));
	//------
	and		r1, eax, #0xFF
	cmp		r1, #0xF9
	bgt		1f
	cmp		r1, #0x7A
	orrge	r0, #ARM_NEG
	//------
	// if ((reg_al & 0xf) > 9)
	//------
1:	and		r1, eax, #0x0F
	cmp		r1, #0x09
	ble		5f									//	{
	and		r1, eax, #0xF0
	cmp		r1, #0x70							//		SETFLAGBIT(OF,(reg_al&0xf0)==0x70);
	orreq	r0, #ARM_OVER
	add		eax, #0x0100
	add		eax, #0x0006						//		reg_ax += 0x106;
	orr		r0, #ARM_CARRY						//		SETFLAGBIT(CF,true);
5:	tst		eax, #0xFF
	orreq	r0, #ARM_ZERO						//	} SETFLAGBIT(ZF,(reg_al == 0));
	//------
	// SETFLAGBIT(PF,parity_lookup[reg_al]);
	//------
	//------
	// reg_al &= 0x0F;
	//------
	bic		eax, #0x00F0
	b		restore_flags_from_r0
#else
	ldr		r2, [sp, #SP_FLAGS]					// r2 = current x86 flags (for FLAG_AF)
	mov		r0, #0								// Default to all ARM flags being clear
	//------
	// SETFLAGBIT(SF,((reg_al>=0x7a) && (reg_al<=0xf9)));
	//------
	and		r1, eax, #0xFF
	cmp		r1, #0xF9
	bgt		1f
	cmp		r1, #0x7A
	orrge	r0, #ARM_NEG
	//------
	// if ((reg_al & 0xf) > 9)
	//------
1:	and		r1, eax, #0x0F
	cmp		r1, #9
	ble		2f									//	{
	and		r1, eax, #0xF0
	cmp		r1, #0x70							//		SETFLAGBIT(OF,(reg_al&0xf0)==0x70);
	orreq	r0, #ARM_OVER
	ror		eax, #16
	add		eax, #0x01000000
	add		eax, #0x00060000					//		reg_ax += 0x106;
	ror		eax, #16
	orr		r0, #ARM_CARRY						//		SETFLAGBIT(CF,true);
	orr		r2, #FLAG_AF						//		SETFLAGBIT(AF,true);
	tst		eax, #0xFF
	orreq	r0, #ARM_ZERO						//		SETFLAGBIT(ZF,(reg_al == 0));
	b		4f									//	}
	//------
	// else if (get_AF())
	//------
2:	tst		r2, #FLAG_AF
	beq		5f									//	{
	ror		eax, #16
	add		eax, #0x01000000
	add		eax, #0x00060000					//		reg_ax += 0x106;
	ror		eax, #16
	orr		r0, #ARM_CARRY						//		SETFLAGBIT(CF,true);
	orr		r2, #FLAG_AF						//		SETFLAGBIT(AF,true);
	b		4f
	//------
	// else
	//------
5:	tst		eax, #0xFF
	orreq	r0, #ARM_ZERO						//		SETFLAGBIT(ZF,(reg_al == 0)); }
	//------
	// SETFLAGBIT(PF,parity_lookup[reg_al]);
	//------
4:	
	//------
	// reg_al &= 0x0F;
	//------
	bic		eax, #0xF0
	str		r2, [sp, #SP_FLAGS]					// Save FLAG_AF
	b		restore_flags_from_r0
#endif
	
// ------------------- 38 = CMP r/m8,r8 --------------------------------
//
// All modrm variations supported!
//
//
// ARM uses the Carry flag in the opposite sense to x86, so we need to swap it.
//
	.global	op_38
op_38:
	modrm_jump_16
// 0
	.word cmp_bxsi_al, cmp_bxdi_al, cmp_bpsi_al, cmp_bpdi_al, cmp_siidx_al, cmp_diidx_al, cmp_disp16_al, cmp_bxidx_al
	.word cmp_bxsi_cl, cmp_bxdi_cl, cmp_bpsi_cl, cmp_bpdi_cl, cmp_siidx_cl, cmp_diidx_cl, cmp_disp16_cl, cmp_bxidx_cl
	.word cmp_bxsi_dl, cmp_bxdi_dl, cmp_bpsi_dl, cmp_bpdi_dl, cmp_siidx_dl, cmp_diidx_dl, cmp_disp16_dl, cmp_bxidx_dl
	.word cmp_bxsi_bl, cmp_bxdi_bl, cmp_bpsi_bl, cmp_bpdi_bl, cmp_siidx_bl, cmp_diidx_bl, cmp_disp16_bl, cmp_bxidx_bl
	.word cmp_bxsi_ah, cmp_bxdi_ah, cmp_bpsi_ah, cmp_bpdi_ah, cmp_siidx_ah, cmp_diidx_ah, cmp_disp16_ah, cmp_bxidx_ah
	.word cmp_bxsi_ch, cmp_bxdi_ch, cmp_bpsi_ch, cmp_bpdi_ch, cmp_siidx_ch, cmp_diidx_ch, cmp_disp16_ch, cmp_bxidx_ch
	.word cmp_bxsi_dh, cmp_bxdi_dh, cmp_bpsi_dh, cmp_bpdi_dh, cmp_siidx_dh, cmp_diidx_dh, cmp_disp16_dh, cmp_bxidx_dh
	.word cmp_bxsi_bh, cmp_bxdi_bh, cmp_bpsi_bh, cmp_bpdi_bh, cmp_siidx_bh, cmp_diidx_bh, cmp_disp16_bh, cmp_bxidx_bh
//0x40
	.word cmp_bxsid8_al, cmp_bxdid8_al, cmp_bpsid8_al, cmp_bpdid8_al, cmp_sidisp8_al, cmp_didisp8_al, cmp_bpdisp8_al, cmp_bxdisp8_al
	.word cmp_bxsid8_cl, cmp_bxdid8_cl, cmp_bpsid8_cl, cmp_bpdid8_cl, cmp_sidisp8_cl, cmp_didisp8_cl, cmp_bpdisp8_cl, cmp_bxdisp8_cl
	.word cmp_bxsid8_dl, cmp_bxdid8_dl, cmp_bpsid8_dl, cmp_bpdid8_dl, cmp_sidisp8_dl, cmp_didisp8_dl, cmp_bpdisp8_dl, cmp_bxdisp8_dl
	.word cmp_bxsid8_bl, cmp_bxdid8_bl, cmp_bpsid8_bl, cmp_bpdid8_bl, cmp_sidisp8_bl, cmp_didisp8_bl, cmp_bpdisp8_bl, cmp_bxdisp8_bl
	.word cmp_bxsid8_ah, cmp_bxdid8_ah, cmp_bpsid8_ah, cmp_bpdid8_ah, cmp_sidisp8_ah, cmp_didisp8_ah, cmp_bpdisp8_ah, cmp_bxdisp8_ah
	.word cmp_bxsid8_ch, cmp_bxdid8_ch, cmp_bpsid8_ch, cmp_bpdid8_ch, cmp_sidisp8_ch, cmp_didisp8_ch, cmp_bpdisp8_ch, cmp_bxdisp8_ch
	.word cmp_bxsid8_dh, cmp_bxdid8_dh, cmp_bpsid8_dh, cmp_bpdid8_dh, cmp_sidisp8_dh, cmp_didisp8_dh, cmp_bpdisp8_dh, cmp_bxdisp8_dh
	.word cmp_bxsid8_bh, cmp_bxdid8_bh, cmp_bpsid8_bh, cmp_bpdid8_bh, cmp_sidisp8_bh, cmp_didisp8_bh, cmp_bpdisp8_bh, cmp_bxdisp8_bh
//0x80
	.word cmp_bxsid16_al, cmp_bxdid16_al, cmp_bpsid16_al, cmp_bpdid16_al, cmp_sidisp16_al, cmp_didisp16_al, cmp_bpdisp16_al, cmp_bxdisp16_al
	.word cmp_bxsid16_cl, cmp_bxdid16_cl, cmp_bpsid16_cl, cmp_bpdid16_cl, cmp_sidisp16_cl, cmp_didisp16_cl, cmp_bpdisp16_cl, cmp_bxdisp16_cl
	.word cmp_bxsid16_dl, cmp_bxdid16_dl, cmp_bpsid16_dl, cmp_bpdid16_dl, cmp_sidisp16_dl, cmp_didisp16_dl, cmp_bpdisp16_dl, cmp_bxdisp16_dl
	.word cmp_bxsid16_bl, cmp_bxdid16_bl, cmp_bpsid16_bl, cmp_bpdid16_bl, cmp_sidisp16_bl, cmp_didisp16_bl, cmp_bpdisp16_bl, cmp_bxdisp16_bl
	.word cmp_bxsid16_ah, cmp_bxdid16_ah, cmp_bpsid16_ah, cmp_bpdid16_ah, cmp_sidisp16_ah, cmp_didisp16_ah, cmp_bpdisp16_ah, cmp_bxdisp16_ah
	.word cmp_bxsid16_ch, cmp_bxdid16_ch, cmp_bpsid16_ch, cmp_bpdid16_ch, cmp_sidisp16_ch, cmp_didisp16_ch, cmp_bpdisp16_ch, cmp_bxdisp16_ch
	.word cmp_bxsid16_dh, cmp_bxdid16_dh, cmp_bpsid16_dh, cmp_bpdid16_dh, cmp_sidisp16_dh, cmp_didisp16_dh, cmp_bpdisp16_dh, cmp_bxdisp16_dh
	.word cmp_bxsid16_bh, cmp_bxdid16_bh, cmp_bpsid16_bh, cmp_bpdid16_bh, cmp_sidisp16_bh, cmp_didisp16_bh, cmp_bpdisp16_bh, cmp_bxdisp16_bh
//0xc0 = mod = 11b => two register operands
	.word cmp_al_al, cmp_cl_al, cmp_dl_al, cmp_bl_al, cmp_ah_al, cmp_ch_al, cmp_dh_al, cmp_bh_al
	.word cmp_al_cl, cmp_cl_cl, cmp_dl_cl, cmp_bl_cl, cmp_ah_cl, cmp_ch_cl, cmp_dh_cl, cmp_bh_cl
	.word cmp_al_dl, cmp_cl_dl, cmp_dl_dl, cmp_bl_dl, cmp_ah_dl, cmp_ch_dl, cmp_dh_dl, cmp_bh_dl
	.word cmp_al_bl, cmp_cl_bl, cmp_dl_bl, cmp_bl_bl, cmp_ah_bl, cmp_ch_bl, cmp_dh_bl, cmp_bh_bl
	.word cmp_al_ah, cmp_cl_ah, cmp_dl_ah, cmp_bl_ah, cmp_ah_ah, cmp_ch_ah, cmp_dh_ah, cmp_bh_ah
	.word cmp_al_ch, cmp_cl_ch, cmp_dl_ch, cmp_bl_ch, cmp_ah_ch, cmp_ch_ch, cmp_dh_ch, cmp_bh_ch
	.word cmp_al_dh, cmp_cl_dh, cmp_dl_dh, cmp_bl_dh, cmp_ah_dh, cmp_ch_dh, cmp_dh_dh, cmp_bh_dh
	.word cmp_al_bh, cmp_cl_bh, cmp_dl_bh, cmp_bl_bh, cmp_ah_bh, cmp_ch_bh, cmp_dh_bh, cmp_bh_bh

// These are called from "cpu_386.s":

	.global	cmp_siidx_al, cmp_siidx_cl, cmp_siidx_dl, cmp_siidx_bl, cmp_siidx_ah, cmp_siidx_ch, cmp_siidx_dh, cmp_siidx_bh
	.global	cmp_diidx_al, cmp_diidx_cl, cmp_diidx_dl, cmp_diidx_bl, cmp_diidx_ah, cmp_diidx_ch, cmp_diidx_dh, cmp_diidx_bh
	.global	cmp_bxidx_al, cmp_bxidx_cl, cmp_bxidx_dl, cmp_bxidx_bl, cmp_bxidx_ah, cmp_bxidx_ch, cmp_bxidx_dh, cmp_bxidx_bh
	.global	cmp_sidisp8_al, cmp_sidisp8_cl, cmp_sidisp8_dl, cmp_sidisp8_bl, cmp_sidisp8_ah, cmp_sidisp8_ch, cmp_sidisp8_dh, cmp_sidisp8_bh
	.global	cmp_didisp8_al, cmp_didisp8_cl, cmp_didisp8_dl, cmp_didisp8_bl, cmp_didisp8_ah, cmp_didisp8_ch, cmp_didisp8_dh, cmp_didisp8_bh
	.global	cmp_bpdisp8_al, cmp_bpdisp8_cl, cmp_bpdisp8_dl, cmp_bpdisp8_bl, cmp_bpdisp8_ah, cmp_bpdisp8_ch, cmp_bpdisp8_dh, cmp_bpdisp8_bh
	.global	cmp_bxdisp8_al, cmp_bxdisp8_cl, cmp_bxdisp8_dl, cmp_bxdisp8_bl, cmp_bxdisp8_ah, cmp_bxdisp8_ch, cmp_bxdisp8_dh, cmp_bxdisp8_bh

.macro cmp_r0_reg8l reg
	.global	cmp_r0_r8l_bp_\reg
cmp_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	cmp_r0_r8l_\reg
cmp_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_38_RAM_l_\reg op_38_EGA_l_\reg op_38_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_38_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	rsbs	r1, r0, lsl #24
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm
.macro cmp_r0_reg8h reg
	.global	cmp_r0_r8h_bp_\reg
cmp_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	cmp_r0_r8h_\reg
cmp_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_38_RAM_h_\reg op_38_EGA_h_\reg op_38_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_38_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r1, #16
	rsbs	r1, r0, lsl #24
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm

	cmp_r0_reg8l r4
	cmp_r0_reg8l r5
	cmp_r0_reg8l r6
	cmp_r0_reg8l r7
	cmp_r0_reg8h r4
	cmp_r0_reg8h r5
	cmp_r0_reg8h r6
	cmp_r0_reg8h r7

// --- [idx] ---

.macro cmp_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		cmp_r0_r8l_\reg
.endm
.macro cmp_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		cmp_r0_r8h_\reg
.endm

cmp_bxsi_al:
	cmp_bxidx_reg8l r10 r4
cmp_bxsi_cl:
	cmp_bxidx_reg8l r10 r5
cmp_bxsi_dl:
	cmp_bxidx_reg8l r10 r6
cmp_bxsi_bl:
	cmp_bxidx_reg8l r10 r7
cmp_bxsi_ah:
	cmp_bxidx_reg8h r10 r4
cmp_bxsi_ch:
	cmp_bxidx_reg8h r10 r5
cmp_bxsi_dh:
	cmp_bxidx_reg8h r10 r6
cmp_bxsi_bh:
	cmp_bxidx_reg8h r10 r7

cmp_bxdi_al:
	cmp_bxidx_reg8l r11 r4
cmp_bxdi_cl:
	cmp_bxidx_reg8l r11 r5
cmp_bxdi_dl:
	cmp_bxidx_reg8l r11 r6
cmp_bxdi_bl:
	cmp_bxidx_reg8l r11 r7
cmp_bxdi_ah:
	cmp_bxidx_reg8h r11 r4
cmp_bxdi_ch:
	cmp_bxidx_reg8h r11 r5
cmp_bxdi_dh:
	cmp_bxidx_reg8h r11 r6
cmp_bxdi_bh:
	cmp_bxidx_reg8h r11 r7

.macro cmp_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		cmp_r0_r8l_bp_\reg
.endm
.macro cmp_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		cmp_r0_r8h_bp_\reg
.endm

cmp_bpsi_al:
	cmp_bpidx_reg8l r10 r4
cmp_bpsi_cl:
	cmp_bpidx_reg8l r10 r5
cmp_bpsi_dl:
	cmp_bpidx_reg8l r10 r6
cmp_bpsi_bl:
	cmp_bpidx_reg8l r10 r7
cmp_bpsi_ah:
	cmp_bpidx_reg8h r10 r4
cmp_bpsi_ch:
	cmp_bpidx_reg8h r10 r5
cmp_bpsi_dh:
	cmp_bpidx_reg8h r10 r6
cmp_bpsi_bh:
	cmp_bpidx_reg8h r10 r7

cmp_bpdi_al:
	cmp_bpidx_reg8l r11 r4
cmp_bpdi_cl:
	cmp_bpidx_reg8l r11 r5
cmp_bpdi_dl:
	cmp_bpidx_reg8l r11 r6
cmp_bpdi_bl:
	cmp_bpidx_reg8l r11 r7
cmp_bpdi_ah:
	cmp_bpidx_reg8h r11 r4
cmp_bpdi_ch:
	cmp_bpidx_reg8h r11 r5
cmp_bpdi_dh:
	cmp_bpidx_reg8h r11 r6
cmp_bpdi_bh:
	cmp_bpidx_reg8h r11 r7

.macro cmp_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		cmp_r0_r8l_\reg
.endm
.macro cmp_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		cmp_r0_r8h_\reg
.endm

cmp_siidx_al:
	cmp_idx_reg8l r10 r4
cmp_siidx_cl:
	cmp_idx_reg8l r10 r5
cmp_siidx_dl:
	cmp_idx_reg8l r10 r6
cmp_siidx_bl:
	cmp_idx_reg8l r10 r7
cmp_siidx_ah:
	cmp_idx_reg8h r10 r4
cmp_siidx_ch:
	cmp_idx_reg8h r10 r5
cmp_siidx_dh:
	cmp_idx_reg8h r10 r6
cmp_siidx_bh:
	cmp_idx_reg8h r10 r7

cmp_diidx_al:
	cmp_idx_reg8l r11 r4
cmp_diidx_cl:
	cmp_idx_reg8l r11 r5
cmp_diidx_dl:
	cmp_idx_reg8l r11 r6
cmp_diidx_bl:
	cmp_idx_reg8l r11 r7
cmp_diidx_ah:
	cmp_idx_reg8h r11 r4
cmp_diidx_ch:
	cmp_idx_reg8h r11 r5
cmp_diidx_dh:
	cmp_idx_reg8h r11 r6
cmp_diidx_bh:
	cmp_idx_reg8h r11 r7

cmp_bxidx_al:
	cmp_idx_reg8l r7 r4
cmp_bxidx_cl:
	cmp_idx_reg8l r7 r5
cmp_bxidx_dl:
	cmp_idx_reg8l r7 r6
cmp_bxidx_bl:
	cmp_idx_reg8l r7 r7
cmp_bxidx_ah:
	cmp_idx_reg8h r7 r4
cmp_bxidx_ch:
	cmp_idx_reg8h r7 r5
cmp_bxidx_dh:
	cmp_idx_reg8h r7 r6
cmp_bxidx_bh:
	cmp_idx_reg8h r7 r7
	
.macro cmp_disp16_reg8l reg
	r0_from_disp16
	b		cmp_r0_r8l_\reg
.endm

.macro cmp_disp16_reg8h reg
	r0_from_disp16
	b		cmp_r0_r8h_\reg
.endm

cmp_disp16_al:
	cmp_disp16_reg8l r4
cmp_disp16_cl:
	cmp_disp16_reg8l r5
cmp_disp16_dl:
	cmp_disp16_reg8l r6
cmp_disp16_bl:
	cmp_disp16_reg8l r7
cmp_disp16_ah:
	cmp_disp16_reg8h r4
cmp_disp16_ch:
	cmp_disp16_reg8h r5
cmp_disp16_dh:
	cmp_disp16_reg8h r6
cmp_disp16_bh:
	cmp_disp16_reg8h r7

// --- [idx+disp8] ---

.macro cmp_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		cmp_r0_r8l_\reg
.endm
.macro cmp_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		cmp_r0_r8h_\reg
.endm

cmp_bxsid8_al:
	cmp_bxidxd8_reg8l r10 r4
cmp_bxsid8_cl:
	cmp_bxidxd8_reg8l r10 r5
cmp_bxsid8_dl:
	cmp_bxidxd8_reg8l r10 r6
cmp_bxsid8_bl:
	cmp_bxidxd8_reg8l r10 r7
cmp_bxsid8_ah:
	cmp_bxidxd8_reg8h r10 r4
cmp_bxsid8_ch:
	cmp_bxidxd8_reg8h r10 r5
cmp_bxsid8_dh:
	cmp_bxidxd8_reg8h r10 r6
cmp_bxsid8_bh:
	cmp_bxidxd8_reg8h r10 r7

cmp_bxdid8_al:
	cmp_bxidxd8_reg8l r11 r4
cmp_bxdid8_cl:
	cmp_bxidxd8_reg8l r11 r5
cmp_bxdid8_dl:
	cmp_bxidxd8_reg8l r11 r6
cmp_bxdid8_bl:
	cmp_bxidxd8_reg8l r11 r7
cmp_bxdid8_ah:
	cmp_bxidxd8_reg8h r11 r4
cmp_bxdid8_ch:
	cmp_bxidxd8_reg8h r11 r5
cmp_bxdid8_dh:
	cmp_bxidxd8_reg8h r11 r6
cmp_bxdid8_bh:
	cmp_bxidxd8_reg8h r11 r7

.macro cmp_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		cmp_r0_r8l_bp_\reg
.endm
.macro cmp_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		cmp_r0_r8h_bp_\reg
.endm

cmp_bpsid8_al:
	cmp_bpidxd8_reg8l r10 r4
cmp_bpsid8_cl:
	cmp_bpidxd8_reg8l r10 r5
cmp_bpsid8_dl:
	cmp_bpidxd8_reg8l r10 r6
cmp_bpsid8_bl:
	cmp_bpidxd8_reg8l r10 r7
cmp_bpsid8_ah:
	cmp_bpidxd8_reg8h r10 r4
cmp_bpsid8_ch:
	cmp_bpidxd8_reg8h r10 r5
cmp_bpsid8_dh:
	cmp_bpidxd8_reg8h r10 r6
cmp_bpsid8_bh:
	cmp_bpidxd8_reg8h r10 r7

cmp_bpdid8_al:
	cmp_bpidxd8_reg8l r11 r4
cmp_bpdid8_cl:
	cmp_bpidxd8_reg8l r11 r5
cmp_bpdid8_dl:
	cmp_bpidxd8_reg8l r11 r6
cmp_bpdid8_bl:
	cmp_bpidxd8_reg8l r11 r7
cmp_bpdid8_ah:
	cmp_bpidxd8_reg8h r11 r4
cmp_bpdid8_ch:
	cmp_bpidxd8_reg8h r11 r5
cmp_bpdid8_dh:
	cmp_bpidxd8_reg8h r11 r6
cmp_bpdid8_bh:
	cmp_bpidxd8_reg8h r11 r7

.macro cmp_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		cmp_r0_r8l_\reg
.endm
.macro cmp_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		cmp_r0_r8h_\reg
.endm

cmp_sidisp8_al:
	cmp_idxdisp8_reg8l r10 r4
cmp_sidisp8_cl:
	cmp_idxdisp8_reg8l r10 r5
cmp_sidisp8_dl:
	cmp_idxdisp8_reg8l r10 r6
cmp_sidisp8_bl:
	cmp_idxdisp8_reg8l r10 r7
cmp_sidisp8_ah:
	cmp_idxdisp8_reg8h r10 r4
cmp_sidisp8_ch:
	cmp_idxdisp8_reg8h r10 r5
cmp_sidisp8_dh:
	cmp_idxdisp8_reg8h r10 r6
cmp_sidisp8_bh:
	cmp_idxdisp8_reg8h r10 r7

cmp_didisp8_al:
	cmp_idxdisp8_reg8l r11 r4
cmp_didisp8_cl:
	cmp_idxdisp8_reg8l r11 r5
cmp_didisp8_dl:
	cmp_idxdisp8_reg8l r11 r6
cmp_didisp8_bl:
	cmp_idxdisp8_reg8l r11 r7
cmp_didisp8_ah:
	cmp_idxdisp8_reg8h r11 r4
cmp_didisp8_ch:
	cmp_idxdisp8_reg8h r11 r5
cmp_didisp8_dh:
	cmp_idxdisp8_reg8h r11 r6
cmp_didisp8_bh:
	cmp_idxdisp8_reg8h r11 r7

cmp_bxdisp8_al:
	cmp_idxdisp8_reg8l r7 r4
cmp_bxdisp8_cl:
	cmp_idxdisp8_reg8l r7 r5
cmp_bxdisp8_dl:
	cmp_idxdisp8_reg8l r7 r6
cmp_bxdisp8_bl:
	cmp_idxdisp8_reg8l r7 r7
cmp_bxdisp8_ah:
	cmp_idxdisp8_reg8h r7 r4
cmp_bxdisp8_ch:
	cmp_idxdisp8_reg8h r7 r5
cmp_bxdisp8_dh:
	cmp_idxdisp8_reg8h r7 r6
cmp_bxdisp8_bh:
	cmp_idxdisp8_reg8h r7 r7

.macro cmp_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		cmp_r0_r8l_bp_\reg
.endm
.macro cmp_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		cmp_r0_r8h_bp_\reg
.endm

cmp_bpdisp8_al:
	cmp_bpdisp8_reg8l r4
cmp_bpdisp8_cl:
	cmp_bpdisp8_reg8l r5
cmp_bpdisp8_dl:
	cmp_bpdisp8_reg8l r6
cmp_bpdisp8_bl:
	cmp_bpdisp8_reg8l r7
cmp_bpdisp8_ah:
	cmp_bpdisp8_reg8h r4
cmp_bpdisp8_ch:
	cmp_bpdisp8_reg8h r5
cmp_bpdisp8_dh:
	cmp_bpdisp8_reg8h r6
cmp_bpdisp8_bh:
	cmp_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro cmp_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		cmp_r0_r8l_\reg
.endm
.macro cmp_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		cmp_r0_r8h_\reg
.endm

cmp_bxsid16_al:
	cmp_bxidxdisp16_reg8l r10 r4
cmp_bxsid16_cl:
	cmp_bxidxdisp16_reg8l r10 r5
cmp_bxsid16_dl:
	cmp_bxidxdisp16_reg8l r10 r6
cmp_bxsid16_bl:
	cmp_bxidxdisp16_reg8l r10 r7
cmp_bxsid16_ah:
	cmp_bxidxdisp16_reg8h r10 r4
cmp_bxsid16_ch:
	cmp_bxidxdisp16_reg8h r10 r5
cmp_bxsid16_dh:
	cmp_bxidxdisp16_reg8h r10 r6
cmp_bxsid16_bh:
	cmp_bxidxdisp16_reg8h r10 r7

cmp_bxdid16_al:
	cmp_bxidxdisp16_reg8l r11 r4
cmp_bxdid16_cl:
	cmp_bxidxdisp16_reg8l r11 r5
cmp_bxdid16_dl:
	cmp_bxidxdisp16_reg8l r11 r6
cmp_bxdid16_bl:
	cmp_bxidxdisp16_reg8l r11 r7
cmp_bxdid16_ah:
	cmp_bxidxdisp16_reg8h r11 r4
cmp_bxdid16_ch:
	cmp_bxidxdisp16_reg8h r11 r5
cmp_bxdid16_dh:
	cmp_bxidxdisp16_reg8h r11 r6
cmp_bxdid16_bh:
	cmp_bxidxdisp16_reg8h r11 r7

.macro cmp_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		cmp_r0_r8l_bp_\reg
.endm
.macro cmp_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		cmp_r0_r8h_bp_\reg
.endm

cmp_bpsid16_al:
	cmp_bpidxd16_reg8l r10 r4
cmp_bpsid16_cl:
	cmp_bpidxd16_reg8l r10 r5
cmp_bpsid16_dl:
	cmp_bpidxd16_reg8l r10 r6
cmp_bpsid16_bl:
	cmp_bpidxd16_reg8l r10 r7
cmp_bpsid16_ah:
	cmp_bpidxd16_reg8h r10 r4
cmp_bpsid16_ch:
	cmp_bpidxd16_reg8h r10 r5
cmp_bpsid16_dh:
	cmp_bpidxd16_reg8h r10 r6
cmp_bpsid16_bh:
	cmp_bpidxd16_reg8h r10 r7

cmp_bpdid16_al:
	cmp_bpidxd16_reg8l r11 r4
cmp_bpdid16_cl:
	cmp_bpidxd16_reg8l r11 r5
cmp_bpdid16_dl:
	cmp_bpidxd16_reg8l r11 r6
cmp_bpdid16_bl:
	cmp_bpidxd16_reg8l r11 r7
cmp_bpdid16_ah:
	cmp_bpidxd16_reg8h r11 r4
cmp_bpdid16_ch:
	cmp_bpidxd16_reg8h r11 r5
cmp_bpdid16_dh:
	cmp_bpidxd16_reg8h r11 r6
cmp_bpdid16_bh:
	cmp_bpidxd16_reg8h r11 r7

.macro cmp_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		cmp_r0_r8l_\reg
.endm
.macro cmp_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		cmp_r0_r8h_\reg
.endm

cmp_sidisp16_al:
	cmp_idxdisp16_reg8l r10 r4
cmp_sidisp16_cl:
	cmp_idxdisp16_reg8l r10 r5
cmp_sidisp16_dl:
	cmp_idxdisp16_reg8l r10 r6
cmp_sidisp16_bl:
	cmp_idxdisp16_reg8l r10 r7
cmp_sidisp16_ah:
	cmp_idxdisp16_reg8h r10 r4
cmp_sidisp16_ch:
	cmp_idxdisp16_reg8h r10 r5
cmp_sidisp16_dh:
	cmp_idxdisp16_reg8h r10 r6
cmp_sidisp16_bh:
	cmp_idxdisp16_reg8h r10 r7

cmp_didisp16_al:
	cmp_idxdisp16_reg8l r11 r4
cmp_didisp16_cl:
	cmp_idxdisp16_reg8l r11 r5
cmp_didisp16_dl:
	cmp_idxdisp16_reg8l r11 r6
cmp_didisp16_bl:
	cmp_idxdisp16_reg8l r11 r7
cmp_didisp16_ah:
	cmp_idxdisp16_reg8h r11 r4
cmp_didisp16_ch:
	cmp_idxdisp16_reg8h r11 r5
cmp_didisp16_dh:
	cmp_idxdisp16_reg8h r11 r6
cmp_didisp16_bh:
	cmp_idxdisp16_reg8h r11 r7

cmp_bxdisp16_al:
	cmp_idxdisp16_reg8l r7 r4
cmp_bxdisp16_cl:
	cmp_idxdisp16_reg8l r7 r5
cmp_bxdisp16_dl:
	cmp_idxdisp16_reg8l r7 r6
cmp_bxdisp16_bl:
	cmp_idxdisp16_reg8l r7 r7
cmp_bxdisp16_ah:
	cmp_idxdisp16_reg8h r7 r4
cmp_bxdisp16_ch:
	cmp_idxdisp16_reg8h r7 r5
cmp_bxdisp16_dh:
	cmp_idxdisp16_reg8h r7 r6
cmp_bxdisp16_bh:
	cmp_idxdisp16_reg8h r7 r7

.macro cmp_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		cmp_r0_r8l_bp_\reg
.endm
.macro cmp_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		cmp_r0_r8h_bp_\reg
.endm

cmp_bpdisp16_al:
	cmp_bpdisp16_reg8l r4
cmp_bpdisp16_cl:
	cmp_bpdisp16_reg8l r5
cmp_bpdisp16_dl:
	cmp_bpdisp16_reg8l r6
cmp_bpdisp16_bl:
	cmp_bpdisp16_reg8l r7
cmp_bpdisp16_ah:
	cmp_bpdisp16_reg8h r4
cmp_bpdisp16_ch:
	cmp_bpdisp16_reg8h r5
cmp_bpdisp16_dh:
	cmp_bpdisp16_reg8h r6
cmp_bpdisp16_bh:
	cmp_bpdisp16_reg8h r7


// ------------------- 39 = CMP r/m16,r16 --------------------------------
//
// All modrm variations supported!
//
//
	.global	op_39
op_39:
	modrm_jump_16
// 0
	.word cmp_bxsi_ax, cmp_bxdi_ax, cmp_bpsi_ax, cmp_bpdi_ax, cmp_siidx_ax, cmp_diidx_ax, cmp_disp16_ax, cmp_bxidx_ax
	.word cmp_bxsi_cx, cmp_bxdi_cx, cmp_bpsi_cx, cmp_bpdi_cx, cmp_siidx_cx, cmp_diidx_cx, cmp_disp16_cx, cmp_bxidx_cx
	.word cmp_bxsi_dx, cmp_bxdi_dx, cmp_bpsi_dx, cmp_bpdi_dx, cmp_siidx_dx, cmp_diidx_dx, cmp_disp16_dx, cmp_bxidx_dx
	.word cmp_bxsi_bx, cmp_bxdi_bx, cmp_bpsi_bx, cmp_bpdi_bx, cmp_siidx_bx, cmp_diidx_bx, cmp_disp16_bx, cmp_bxidx_bx
	.word cmp_bxsi_sp, cmp_bxdi_sp, cmp_bpsi_sp, cmp_bpdi_sp, cmp_siidx_sp, cmp_diidx_sp, cmp_disp16_sp, cmp_bxidx_sp
	.word cmp_bxsi_bp, cmp_bxdi_bp, cmp_bpsi_bp, cmp_bpdi_bp, cmp_siidx_bp, cmp_diidx_bp, cmp_disp16_bp, cmp_bxidx_bp
	.word cmp_bxsi_si, cmp_bxdi_si, cmp_bpsi_si, cmp_bpdi_si, cmp_siidx_si, cmp_diidx_si, cmp_disp16_si, cmp_bxidx_si
	.word cmp_bxsi_di, cmp_bxdi_di, cmp_bpsi_di, cmp_bpdi_di, cmp_siidx_di, cmp_diidx_di, cmp_disp16_di, cmp_bxidx_di
//0x40 (+disp8)
	.word cmp_bxsid8_ax, cmp_bxdid8_ax, cmp_bpsid8_ax, cmp_bpdid8_ax, cmp_sidisp8_ax, cmp_didisp8_ax, cmp_bpdisp8_ax, cmp_bxdisp8_ax
	.word cmp_bxsid8_cx, cmp_bxdid8_cx, cmp_bpsid8_cx, cmp_bpdid8_cx, cmp_sidisp8_cx, cmp_didisp8_cx, cmp_bpdisp8_cx, cmp_bxdisp8_cx
	.word cmp_bxsid8_dx, cmp_bxdid8_dx, cmp_bpsid8_dx, cmp_bpdid8_dx, cmp_sidisp8_dx, cmp_didisp8_dx, cmp_bpdisp8_dx, cmp_bxdisp8_dx
	.word cmp_bxsid8_bx, cmp_bxdid8_bx, cmp_bpsid8_bx, cmp_bpdid8_bx, cmp_sidisp8_bx, cmp_didisp8_bx, cmp_bpdisp8_bx, cmp_bxdisp8_bx
	.word cmp_bxsid8_sp, cmp_bxdid8_sp, cmp_bpsid8_sp, cmp_bpdid8_sp, cmp_sidisp8_sp, cmp_didisp8_sp, cmp_bpdisp8_sp, cmp_bxdisp8_sp
	.word cmp_bxsid8_bp, cmp_bxdid8_bp, cmp_bpsid8_bp, cmp_bpdid8_bp, cmp_sidisp8_bp, cmp_didisp8_bp, cmp_bpdisp8_bp, cmp_bxdisp8_bp
	.word cmp_bxsid8_si, cmp_bxdid8_si, cmp_bpsid8_si, cmp_bpdid8_si, cmp_sidisp8_si, cmp_didisp8_si, cmp_bpdisp8_si, cmp_bxdisp8_si
	.word cmp_bxsid8_di, cmp_bxdid8_di, cmp_bpsid8_di, cmp_bpdid8_di, cmp_sidisp8_di, cmp_didisp8_di, cmp_bpdisp8_di, cmp_bxdisp8_di
//0x80
	.word cmp_bxsid16_ax, cmp_bxdid16_ax, cmp_bpsid16_ax, cmp_bpdid16_ax, cmp_sidisp16_ax, cmp_didisp16_ax, cmp_bpdisp16_ax, cmp_bxdisp16_ax
	.word cmp_bxsid16_cx, cmp_bxdid16_cx, cmp_bpsid16_cx, cmp_bpdid16_cx, cmp_sidisp16_cx, cmp_didisp16_cx, cmp_bpdisp16_cx, cmp_bxdisp16_cx
	.word cmp_bxsid16_dx, cmp_bxdid16_dx, cmp_bpsid16_dx, cmp_bpdid16_dx, cmp_sidisp16_dx, cmp_didisp16_dx, cmp_bpdisp16_dx, cmp_bxdisp16_dx
	.word cmp_bxsid16_bx, cmp_bxdid16_bx, cmp_bpsid16_bx, cmp_bpdid16_bx, cmp_sidisp16_bx, cmp_didisp16_bx, cmp_bpdisp16_bx, cmp_bxdisp16_bx
	.word cmp_bxsid16_sp, cmp_bxdid16_sp, cmp_bpsid16_sp, cmp_bpdid16_sp, cmp_sidisp16_sp, cmp_didisp16_sp, cmp_bpdisp16_sp, cmp_bxdisp16_sp
	.word cmp_bxsid16_bp, cmp_bxdid16_bp, cmp_bpsid16_bp, cmp_bpdid16_bp, cmp_sidisp16_bp, cmp_didisp16_bp, cmp_bpdisp16_bp, cmp_bxdisp16_bp
	.word cmp_bxsid16_si, cmp_bxdid16_si, cmp_bpsid16_si, cmp_bpdid16_si, cmp_sidisp16_si, cmp_didisp16_si, cmp_bpdisp16_si, cmp_bxdisp16_si
	.word cmp_bxsid16_di, cmp_bxdid16_di, cmp_bpsid16_di, cmp_bpdid16_di, cmp_sidisp16_di, cmp_didisp16_di, cmp_bpdisp16_di, cmp_bxdisp16_di
//0xc0 = mod = 11b => two register operands
	.word cmp_ax_ax, cmp_cx_ax, cmp_dx_ax, cmp_bx_ax, cmp_sp_ax, cmp_bp_ax, cmp_si_ax, cmp_di_ax
	.word cmp_ax_cx, cmp_cx_cx, cmp_dx_cx, cmp_bx_cx, cmp_sp_cx, cmp_bp_cx, cmp_si_cx, cmp_di_cx
	.word cmp_ax_dx, cmp_cx_dx, cmp_dx_dx, cmp_bx_dx, cmp_sp_dx, cmp_bp_dx, cmp_si_dx, cmp_di_dx
	.word cmp_ax_bx, cmp_cx_bx, cmp_dx_bx, cmp_bx_bx, cmp_sp_bx, cmp_bp_bx, cmp_si_bx, cmp_di_bx
	.word cmp_ax_sp, cmp_cx_sp, cmp_dx_sp, cmp_bx_sp, cmp_sp_sp, cmp_bp_sp, cmp_si_sp, cmp_di_sp
	.word cmp_ax_bp, cmp_cx_bp, cmp_dx_bp, cmp_bx_bp, cmp_sp_bp, cmp_bp_bp, cmp_si_bp, cmp_di_bp
	.word cmp_ax_si, cmp_cx_si, cmp_dx_si, cmp_bx_si, cmp_sp_si, cmp_bp_si, cmp_si_si, cmp_di_si
	.word cmp_ax_di, cmp_cx_di, cmp_dx_di, cmp_bx_di, cmp_sp_di, cmp_bp_di, cmp_si_di, cmp_di_di

// These are called from "cpu_67.s":

	.global cmp_siidx_ax, cmp_diidx_ax, cmp_bxidx_ax
	.global cmp_siidx_cx, cmp_diidx_cx, cmp_bxidx_cx
	.global cmp_siidx_dx, cmp_diidx_dx, cmp_bxidx_dx
	.global cmp_siidx_bx, cmp_diidx_bx, cmp_bxidx_bx
	.global cmp_siidx_sp, cmp_diidx_sp, cmp_bxidx_sp
	.global cmp_siidx_bp, cmp_diidx_bp, cmp_bxidx_bp
	.global cmp_siidx_si, cmp_diidx_si, cmp_bxidx_si
	.global cmp_siidx_di, cmp_diidx_di, cmp_bxidx_di
	.global cmp_sidisp8_ax, cmp_didisp8_ax, cmp_bpdisp8_ax, cmp_bxdisp8_ax
	.global cmp_sidisp8_cx, cmp_didisp8_cx, cmp_bpdisp8_cx, cmp_bxdisp8_cx
	.global cmp_sidisp8_dx, cmp_didisp8_dx, cmp_bpdisp8_dx, cmp_bxdisp8_dx
	.global cmp_sidisp8_bx, cmp_didisp8_bx, cmp_bpdisp8_bx, cmp_bxdisp8_bx
	.global cmp_sidisp8_sp, cmp_didisp8_sp, cmp_bpdisp8_sp, cmp_bxdisp8_sp
	.global cmp_sidisp8_bp, cmp_didisp8_bp, cmp_bpdisp8_bp, cmp_bxdisp8_bp
	.global cmp_sidisp8_si, cmp_didisp8_si, cmp_bpdisp8_si, cmp_bxdisp8_si
	.global cmp_sidisp8_di, cmp_didisp8_di, cmp_bpdisp8_di, cmp_bxdisp8_di
	.global cmp_ax_ax, cmp_cx_ax, cmp_dx_ax, cmp_bx_ax, cmp_sp_ax, cmp_bp_ax, cmp_si_ax, cmp_di_ax
	.global cmp_ax_cx, cmp_cx_cx, cmp_dx_cx, cmp_bx_cx, cmp_sp_cx, cmp_bp_cx, cmp_si_cx, cmp_di_cx
	.global cmp_ax_dx, cmp_cx_dx, cmp_dx_dx, cmp_bx_dx, cmp_sp_dx, cmp_bp_dx, cmp_si_dx, cmp_di_dx
	.global cmp_ax_bx, cmp_cx_bx, cmp_dx_bx, cmp_bx_bx, cmp_sp_bx, cmp_bp_bx, cmp_si_bx, cmp_di_bx
	.global cmp_ax_sp, cmp_cx_sp, cmp_dx_sp, cmp_bx_sp, cmp_sp_sp, cmp_bp_sp, cmp_si_sp, cmp_di_sp
	.global cmp_ax_bp, cmp_cx_bp, cmp_dx_bp, cmp_bx_bp, cmp_sp_bp, cmp_bp_bp, cmp_si_bp, cmp_di_bp
	.global cmp_ax_si, cmp_cx_si, cmp_dx_si, cmp_bx_si, cmp_sp_si, cmp_bp_si, cmp_si_si, cmp_di_si
	.global cmp_ax_di, cmp_cx_di, cmp_dx_di, cmp_bx_di, cmp_sp_di, cmp_bp_di, cmp_si_di, cmp_di_di
	.global	cmp_r0_r16_bp_r4, cmp_r0_r16_bp_r5, cmp_r0_r16_bp_r6, cmp_r0_r16_bp_r7, cmp_r0_r16_bp_r8, cmp_r0_r16_bp_r9, cmp_r0_r16_bp_r10, cmp_r0_r16_bp_r11, cmp_r0_r16_bp_r4
	.global	cmp_r0_r16_r4, cmp_r0_r16_r5, cmp_r0_r16_r6, cmp_r0_r16_r7, cmp_r0_r16_r8, cmp_r0_r16_r9, cmp_r0_r16_r10, cmp_r0_r16_r11, cmp_r0_r16_r4


.macro cmp_r0_r16_reg reg
cmp_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
cmp_r0_r16_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_39_RAM_\reg op_39_EGA_r2_\reg op_39_MODEX_r2_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_39_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r2, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	rsbs	r0, r2, r0, lsl #16		// Compare the values
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm

	cmp_r0_r16_reg r4
	cmp_r0_r16_reg r5
	cmp_r0_r16_reg r6
	cmp_r0_r16_reg r7
	cmp_r0_r16_reg r8
	cmp_r0_r16_reg r9
	cmp_r0_r16_reg r10
	cmp_r0_r16_reg r11

	.ltorg

// --- [idx] ----

.macro cmp_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		cmp_r0_r16_\reg
.endm

cmp_bxsi_ax:
	cmp_bxidx_reg16 r10 r4
cmp_bxsi_cx:
	cmp_bxidx_reg16 r10 r5
cmp_bxsi_dx:
	cmp_bxidx_reg16 r10 r6
cmp_bxsi_bx:
	cmp_bxidx_reg16 r10 r7
cmp_bxsi_sp:
	cmp_bxidx_reg16 r10 r8
cmp_bxsi_bp:
	cmp_bxidx_reg16 r10 r9
cmp_bxsi_si:
	cmp_bxidx_reg16 r10 r10
cmp_bxsi_di:
	cmp_bxidx_reg16 r10 r11

cmp_bxdi_ax:
	cmp_bxidx_reg16 r11 r4
cmp_bxdi_cx:
	cmp_bxidx_reg16 r11 r5
cmp_bxdi_dx:
	cmp_bxidx_reg16 r11 r6
cmp_bxdi_bx:
	cmp_bxidx_reg16 r11 r7
cmp_bxdi_sp:
	cmp_bxidx_reg16 r11 r8
cmp_bxdi_bp:
	cmp_bxidx_reg16 r11 r9
cmp_bxdi_si:
	cmp_bxidx_reg16 r11 r10
cmp_bxdi_di:
	cmp_bxidx_reg16 r11 r11

.macro cmp_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		cmp_r0_r16_bp_\reg
.endm

cmp_bpsi_ax:
	cmp_bpidx_reg16 r10 r4
cmp_bpsi_cx:
	cmp_bpidx_reg16 r10 r5
cmp_bpsi_dx:
	cmp_bpidx_reg16 r10 r6
cmp_bpsi_bx:
	cmp_bpidx_reg16 r10 r7
cmp_bpsi_sp:
	cmp_bpidx_reg16 r10 r8
cmp_bpsi_bp:
	cmp_bpidx_reg16 r10 r9
cmp_bpsi_si:
	cmp_bpidx_reg16 r10 r10
cmp_bpsi_di:
	cmp_bpidx_reg16 r10 r11

cmp_bpdi_ax:
	cmp_bpidx_reg16 r11 r4
cmp_bpdi_cx:
	cmp_bpidx_reg16 r11 r5
cmp_bpdi_dx:
	cmp_bpidx_reg16 r11 r6
cmp_bpdi_bx:
	cmp_bpidx_reg16 r11 r7
cmp_bpdi_sp:
	cmp_bpidx_reg16 r11 r8
cmp_bpdi_bp:
	cmp_bpidx_reg16 r11 r9
cmp_bpdi_si:
	cmp_bpidx_reg16 r11 r10
cmp_bpdi_di:
	cmp_bpidx_reg16 r11 r11

.macro cmp_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		cmp_r0_r16_\reg
.endm

cmp_siidx_ax:
	cmp_idx_reg16 r10 r4
cmp_siidx_cx:
	cmp_idx_reg16 r10 r5
cmp_siidx_dx:
	cmp_idx_reg16 r10 r6
cmp_siidx_bx:
	cmp_idx_reg16 r10 r7
cmp_siidx_sp:
	cmp_idx_reg16 r10 r8
cmp_siidx_bp:
	cmp_idx_reg16 r10 r9
cmp_siidx_si:
	cmp_idx_reg16 r10 r10
cmp_siidx_di:
	cmp_idx_reg16 r10 r11

cmp_diidx_ax:
	cmp_idx_reg16 r11 r4
cmp_diidx_cx:
	cmp_idx_reg16 r11 r5
cmp_diidx_dx:
	cmp_idx_reg16 r11 r6
cmp_diidx_bx:
	cmp_idx_reg16 r11 r7
cmp_diidx_sp:
	cmp_idx_reg16 r11 r8
cmp_diidx_bp:
	cmp_idx_reg16 r11 r9
cmp_diidx_si:
	cmp_idx_reg16 r11 r10
cmp_diidx_di:
	cmp_idx_reg16 r11 r11

cmp_bxidx_ax:
	cmp_idx_reg16 r7 r4
cmp_bxidx_cx:
	cmp_idx_reg16 r7 r5
cmp_bxidx_dx:
	cmp_idx_reg16 r7 r6
cmp_bxidx_bx:
	cmp_idx_reg16 r7 r7
cmp_bxidx_sp:
	cmp_idx_reg16 r7 r8
cmp_bxidx_bp:
	cmp_idx_reg16 r7 r9
cmp_bxidx_si:
	cmp_idx_reg16 r7 r10
cmp_bxidx_di:
	cmp_idx_reg16 r7 r11
	
.macro cmp_disp16_reg16 reg
	r0_from_disp16
	b		cmp_r0_r16_\reg
.endm

cmp_disp16_ax:
	cmp_disp16_reg16 r4
cmp_disp16_cx:
	cmp_disp16_reg16 r5
cmp_disp16_dx:
	cmp_disp16_reg16 r6
cmp_disp16_bx:
	cmp_disp16_reg16 r7
cmp_disp16_sp:
	cmp_disp16_reg16 r8
cmp_disp16_bp:
	cmp_disp16_reg16 r9
cmp_disp16_si:
	cmp_disp16_reg16 r10
cmp_disp16_di:
	cmp_disp16_reg16 r11

// --- [idx+disp8] ----

.macro cmp_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		cmp_r0_r16_\reg
.endm

cmp_bxsid8_ax:
	cmp_bxidxd8_reg16 r10 r4
cmp_bxsid8_cx:
	cmp_bxidxd8_reg16 r10 r5
cmp_bxsid8_dx:
	cmp_bxidxd8_reg16 r10 r6
cmp_bxsid8_bx:
	cmp_bxidxd8_reg16 r10 r7
cmp_bxsid8_sp:
	cmp_bxidxd8_reg16 r10 r8
cmp_bxsid8_bp:
	cmp_bxidxd8_reg16 r10 r9
cmp_bxsid8_si:
	cmp_bxidxd8_reg16 r10 r10
cmp_bxsid8_di:
	cmp_bxidxd8_reg16 r10 r11

cmp_bxdid8_ax:
	cmp_bxidxd8_reg16 r11 r4
cmp_bxdid8_cx:
	cmp_bxidxd8_reg16 r11 r5
cmp_bxdid8_dx:
	cmp_bxidxd8_reg16 r11 r6
cmp_bxdid8_bx:
	cmp_bxidxd8_reg16 r11 r7
cmp_bxdid8_sp:
	cmp_bxidxd8_reg16 r11 r8
cmp_bxdid8_bp:
	cmp_bxidxd8_reg16 r11 r9
cmp_bxdid8_si:
	cmp_bxidxd8_reg16 r11 r10
cmp_bxdid8_di:
	cmp_bxidxd8_reg16 r11 r11

.macro cmp_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		cmp_r0_r16_bp_\reg
.endm

cmp_bpsid8_ax:
	cmp_bpidxd8_reg16 r10 r4
cmp_bpsid8_cx:
	cmp_bpidxd8_reg16 r10 r5
cmp_bpsid8_dx:
	cmp_bpidxd8_reg16 r10 r6
cmp_bpsid8_bx:
	cmp_bpidxd8_reg16 r10 r7
cmp_bpsid8_sp:
	cmp_bpidxd8_reg16 r10 r8
cmp_bpsid8_bp:
	cmp_bpidxd8_reg16 r10 r9
cmp_bpsid8_si:
	cmp_bpidxd8_reg16 r10 r10
cmp_bpsid8_di:
	cmp_bpidxd8_reg16 r10 r11

cmp_bpdid8_ax:
	cmp_bpidxd8_reg16 r11 r4
cmp_bpdid8_cx:
	cmp_bpidxd8_reg16 r11 r5
cmp_bpdid8_dx:
	cmp_bpidxd8_reg16 r11 r6
cmp_bpdid8_bx:
	cmp_bpidxd8_reg16 r11 r7
cmp_bpdid8_sp:
	cmp_bpidxd8_reg16 r11 r8
cmp_bpdid8_bp:
	cmp_bpidxd8_reg16 r11 r9
cmp_bpdid8_si:
	cmp_bpidxd8_reg16 r11 r10
cmp_bpdid8_di:
	cmp_bpidxd8_reg16 r11 r11

.macro cmp_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		cmp_r0_r16_\reg
.endm

cmp_sidisp8_ax:
	cmp_idxdisp8_reg16 r10 r4
cmp_sidisp8_cx:
	cmp_idxdisp8_reg16 r10 r5
cmp_sidisp8_dx:
	cmp_idxdisp8_reg16 r10 r6
cmp_sidisp8_bx:
	cmp_idxdisp8_reg16 r10 r7
cmp_sidisp8_sp:
	cmp_idxdisp8_reg16 r10 r8
cmp_sidisp8_bp:
	cmp_idxdisp8_reg16 r10 r9
cmp_sidisp8_si:
	cmp_idxdisp8_reg16 r10 r10
cmp_sidisp8_di:
	cmp_idxdisp8_reg16 r10 r11

cmp_didisp8_ax:
	cmp_idxdisp8_reg16 r11 r4
cmp_didisp8_cx:
	cmp_idxdisp8_reg16 r11 r5
cmp_didisp8_dx:
	cmp_idxdisp8_reg16 r11 r6
cmp_didisp8_bx:
	cmp_idxdisp8_reg16 r11 r7
cmp_didisp8_sp:
	cmp_idxdisp8_reg16 r11 r8
cmp_didisp8_bp:
	cmp_idxdisp8_reg16 r11 r9
cmp_didisp8_si:
	cmp_idxdisp8_reg16 r11 r10
cmp_didisp8_di:
	cmp_idxdisp8_reg16 r11 r11

cmp_bxdisp8_ax:
	cmp_idxdisp8_reg16 r7 r4
cmp_bxdisp8_cx:
	cmp_idxdisp8_reg16 r7 r5
cmp_bxdisp8_dx:
	cmp_idxdisp8_reg16 r7 r6
cmp_bxdisp8_bx:
	cmp_idxdisp8_reg16 r7 r7
cmp_bxdisp8_sp:
	cmp_idxdisp8_reg16 r7 r8
cmp_bxdisp8_bp:
	cmp_idxdisp8_reg16 r7 r9
cmp_bxdisp8_si:
	cmp_idxdisp8_reg16 r7 r10
cmp_bxdisp8_di:
	cmp_idxdisp8_reg16 r7 r11
	
.macro cmp_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		cmp_r0_r16_bp_\reg
.endm
	
cmp_bpdisp8_ax:
	cmp_bpdisp8_reg16 r4
cmp_bpdisp8_cx:
	cmp_bpdisp8_reg16 r5
cmp_bpdisp8_dx:
	cmp_bpdisp8_reg16 r6
cmp_bpdisp8_bx:
	cmp_bpdisp8_reg16 r7
cmp_bpdisp8_sp:
	cmp_bpdisp8_reg16 r8
cmp_bpdisp8_bp:
	cmp_bpdisp8_reg16 r9
cmp_bpdisp8_si:
	cmp_bpdisp8_reg16 r10
cmp_bpdisp8_di:
	cmp_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro cmp_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		cmp_r0_r16_\reg
.endm

cmp_bxsid16_ax:
	cmp_bxidxd16_reg16 r10 r4
cmp_bxsid16_cx:
	cmp_bxidxd16_reg16 r10 r5
cmp_bxsid16_dx:
	cmp_bxidxd16_reg16 r10 r6
cmp_bxsid16_bx:
	cmp_bxidxd16_reg16 r10 r7
cmp_bxsid16_sp:
	cmp_bxidxd16_reg16 r10 r8
cmp_bxsid16_bp:
	cmp_bxidxd16_reg16 r10 r9
cmp_bxsid16_si:
	cmp_bxidxd16_reg16 r10 r10
cmp_bxsid16_di:
	cmp_bxidxd16_reg16 r10 r11

cmp_bxdid16_ax:
	cmp_bxidxd16_reg16 r11 r4
cmp_bxdid16_cx:
	cmp_bxidxd16_reg16 r11 r5
cmp_bxdid16_dx:
	cmp_bxidxd16_reg16 r11 r6
cmp_bxdid16_bx:
	cmp_bxidxd16_reg16 r11 r7
cmp_bxdid16_sp:
	cmp_bxidxd16_reg16 r11 r8
cmp_bxdid16_bp:
	cmp_bxidxd16_reg16 r11 r9
cmp_bxdid16_si:
	cmp_bxidxd16_reg16 r11 r10
cmp_bxdid16_di:
	cmp_bxidxd16_reg16 r11 r11

.macro cmp_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		cmp_r0_r16_bp_\reg
.endm

cmp_bpsid16_ax:
	cmp_bpidxd16_reg16 r10 r4
cmp_bpsid16_cx:
	cmp_bpidxd16_reg16 r10 r5
cmp_bpsid16_dx:
	cmp_bpidxd16_reg16 r10 r6
cmp_bpsid16_bx:
	cmp_bpidxd16_reg16 r10 r7
cmp_bpsid16_sp:
	cmp_bpidxd16_reg16 r10 r8
cmp_bpsid16_bp:
	cmp_bpidxd16_reg16 r10 r9
cmp_bpsid16_si:
	cmp_bpidxd16_reg16 r10 r10
cmp_bpsid16_di:
	cmp_bpidxd16_reg16 r10 r11

cmp_bpdid16_ax:
	cmp_bpidxd16_reg16 r11 r4
cmp_bpdid16_cx:
	cmp_bpidxd16_reg16 r11 r5
cmp_bpdid16_dx:
	cmp_bpidxd16_reg16 r11 r6
cmp_bpdid16_bx:
	cmp_bpidxd16_reg16 r11 r7
cmp_bpdid16_sp:
	cmp_bpidxd16_reg16 r11 r8
cmp_bpdid16_bp:
	cmp_bpidxd16_reg16 r11 r9
cmp_bpdid16_si:
	cmp_bpidxd16_reg16 r11 r10
cmp_bpdid16_di:
	cmp_bpidxd16_reg16 r11 r11

.macro cmp_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		cmp_r0_r16_\reg
.endm

cmp_sidisp16_ax:
	cmp_idxdisp16_reg16 r10 r4
cmp_sidisp16_cx:
	cmp_idxdisp16_reg16 r10 r5
cmp_sidisp16_dx:
	cmp_idxdisp16_reg16 r10 r6
cmp_sidisp16_bx:
	cmp_idxdisp16_reg16 r10 r7
cmp_sidisp16_sp:
	cmp_idxdisp16_reg16 r10 r8
cmp_sidisp16_bp:
	cmp_idxdisp16_reg16 r10 r9
cmp_sidisp16_si:
	cmp_idxdisp16_reg16 r10 r10
cmp_sidisp16_di:
	cmp_idxdisp16_reg16 r10 r11

cmp_didisp16_ax:
	cmp_idxdisp16_reg16 r11 r4
cmp_didisp16_cx:
	cmp_idxdisp16_reg16 r11 r5
cmp_didisp16_dx:
	cmp_idxdisp16_reg16 r11 r6
cmp_didisp16_bx:
	cmp_idxdisp16_reg16 r11 r7
cmp_didisp16_sp:
	cmp_idxdisp16_reg16 r11 r8
cmp_didisp16_bp:
	cmp_idxdisp16_reg16 r11 r9
cmp_didisp16_si:
	cmp_idxdisp16_reg16 r11 r10
cmp_didisp16_di:
	cmp_idxdisp16_reg16 r11 r11

cmp_bxdisp16_ax:
	cmp_idxdisp16_reg16 r7 r4
cmp_bxdisp16_cx:
	cmp_idxdisp16_reg16 r7 r5
cmp_bxdisp16_dx:
	cmp_idxdisp16_reg16 r7 r6
cmp_bxdisp16_bx:
	cmp_idxdisp16_reg16 r7 r7
cmp_bxdisp16_sp:
	cmp_idxdisp16_reg16 r7 r8
cmp_bxdisp16_bp:
	cmp_idxdisp16_reg16 r7 r9
cmp_bxdisp16_si:
	cmp_idxdisp16_reg16 r7 r10
cmp_bxdisp16_di:
	cmp_idxdisp16_reg16 r7 r11

.macro cmp_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		cmp_r0_r16_bp_\reg
.endm

cmp_bpdisp16_ax:
	cmp_bpdisp16_reg16 r4
cmp_bpdisp16_cx:
	cmp_bpdisp16_reg16 r5
cmp_bpdisp16_dx:
	cmp_bpdisp16_reg16 r6
cmp_bpdisp16_bx:
	cmp_bpdisp16_reg16 r7
cmp_bpdisp16_sp:
	cmp_bpdisp16_reg16 r8
cmp_bpdisp16_bp:
	cmp_bpdisp16_reg16 r9
cmp_bpdisp16_si:
	cmp_bpdisp16_reg16 r10
cmp_bpdisp16_di:
	cmp_bpdisp16_reg16 r11


// ------------------- 3A = CMP r8,r/m8 ------------------------------
//
// All modrm variations supported!
//
//
// ARM uses the Carry flag in the opposite sense to x86, so we need to swap it.
//
	.global	op_3a
op_3a:
	modrm_jump_16
// 0
	.word cmp_al_bxsi, cmp_al_bxdi, cmp_al_bpsi, cmp_al_bpdi, cmp_al_siidx, cmp_al_diidx, cmp_al_disp16, cmp_al_bxidx
	.word cmp_cl_bxsi, cmp_cl_bxdi, cmp_cl_bpsi, cmp_cl_bpdi, cmp_cl_siidx, cmp_cl_diidx, cmp_cl_disp16, cmp_cl_bxidx
	.word cmp_dl_bxsi, cmp_dl_bxdi, cmp_dl_bpsi, cmp_dl_bpdi, cmp_dl_siidx, cmp_dl_diidx, cmp_dl_disp16, cmp_dl_bxidx
	.word cmp_bl_bxsi, cmp_bl_bxdi, cmp_bl_bpsi, cmp_bl_bpdi, cmp_bl_siidx, cmp_bl_diidx, cmp_bl_disp16, cmp_bl_bxidx
	.word cmp_ah_bxsi, cmp_ah_bxdi, cmp_ah_bpsi, cmp_ah_bpdi, cmp_ah_siidx, cmp_ah_diidx, cmp_ah_disp16, cmp_ah_bxidx
	.word cmp_ch_bxsi, cmp_ch_bxdi, cmp_ch_bpsi, cmp_ch_bpdi, cmp_ch_siidx, cmp_ch_diidx, cmp_ch_disp16, cmp_ch_bxidx
	.word cmp_dh_bxsi, cmp_dh_bxdi, cmp_dh_bpsi, cmp_dh_bpdi, cmp_dh_siidx, cmp_dh_diidx, cmp_dh_disp16, cmp_dh_bxidx
	.word cmp_bh_bxsi, cmp_bh_bxdi, cmp_bh_bpsi, cmp_bh_bpdi, cmp_bh_siidx, cmp_bh_diidx, cmp_bh_disp16, cmp_bh_bxidx
//0x40
	.word cmp_al_bxsid8, cmp_al_bxdid8, cmp_al_bpsid8, cmp_al_bpdid8, cmp_al_sidisp8, cmp_al_didisp8, cmp_al_bpdisp8, cmp_al_bxdisp8
	.word cmp_cl_bxsid8, cmp_cl_bxdid8, cmp_cl_bpsid8, cmp_cl_bpdid8, cmp_cl_sidisp8, cmp_cl_didisp8, cmp_cl_bpdisp8, cmp_cl_bxdisp8
	.word cmp_dl_bxsid8, cmp_dl_bxdid8, cmp_dl_bpsid8, cmp_dl_bpdid8, cmp_dl_sidisp8, cmp_dl_didisp8, cmp_dl_bpdisp8, cmp_dl_bxdisp8
	.word cmp_bl_bxsid8, cmp_bl_bxdid8, cmp_bl_bpsid8, cmp_bl_bpdid8, cmp_bl_sidisp8, cmp_bl_didisp8, cmp_bl_bpdisp8, cmp_bl_bxdisp8
	.word cmp_ah_bxsid8, cmp_ah_bxdid8, cmp_ah_bpsid8, cmp_ah_bpdid8, cmp_ah_sidisp8, cmp_ah_didisp8, cmp_ah_bpdisp8, cmp_ah_bxdisp8
	.word cmp_ch_bxsid8, cmp_ch_bxdid8, cmp_ch_bpsid8, cmp_ch_bpdid8, cmp_ch_sidisp8, cmp_ch_didisp8, cmp_ch_bpdisp8, cmp_ch_bxdisp8
	.word cmp_dh_bxsid8, cmp_dh_bxdid8, cmp_dh_bpsid8, cmp_dh_bpdid8, cmp_dh_sidisp8, cmp_dh_didisp8, cmp_dh_bpdisp8, cmp_dh_bxdisp8
	.word cmp_bh_bxsid8, cmp_bh_bxdid8, cmp_bh_bpsid8, cmp_bh_bpdid8, cmp_bh_sidisp8, cmp_bh_didisp8, cmp_bh_bpdisp8, cmp_bh_bxdisp8
//0x80
	.word cmp_al_bxsid16, cmp_al_bxdid16, cmp_al_bpsid16, cmp_al_bpdid16, cmp_al_sidisp16, cmp_al_didisp16, cmp_al_bpdisp16, cmp_al_bxdisp16
	.word cmp_cl_bxsid16, cmp_cl_bxdid16, cmp_cl_bpsid16, cmp_cl_bpdid16, cmp_cl_sidisp16, cmp_cl_didisp16, cmp_cl_bpdisp16, cmp_cl_bxdisp16
	.word cmp_dl_bxsid16, cmp_dl_bxdid16, cmp_dl_bpsid16, cmp_dl_bpdid16, cmp_dl_sidisp16, cmp_dl_didisp16, cmp_dl_bpdisp16, cmp_dl_bxdisp16
	.word cmp_bl_bxsid16, cmp_bl_bxdid16, cmp_bl_bpsid16, cmp_bl_bpdid16, cmp_bl_sidisp16, cmp_bl_didisp16, cmp_bl_bpdisp16, cmp_bl_bxdisp16
	.word cmp_ah_bxsid16, cmp_ah_bxdid16, cmp_ah_bpsid16, cmp_ah_bpdid16, cmp_ah_sidisp16, cmp_ah_didisp16, cmp_ah_bpdisp16, cmp_ah_bxdisp16
	.word cmp_ch_bxsid16, cmp_ch_bxdid16, cmp_ch_bpsid16, cmp_ch_bpdid16, cmp_ch_sidisp16, cmp_ch_didisp16, cmp_ch_bpdisp16, cmp_ch_bxdisp16
	.word cmp_dh_bxsid16, cmp_dh_bxdid16, cmp_dh_bpsid16, cmp_dh_bpdid16, cmp_dh_sidisp16, cmp_dh_didisp16, cmp_dh_bpdisp16, cmp_dh_bxdisp16
	.word cmp_bh_bxsid16, cmp_bh_bxdid16, cmp_bh_bpsid16, cmp_bh_bpdid16, cmp_bh_sidisp16, cmp_bh_didisp16, cmp_bh_bpdisp16, cmp_bh_bxdisp16
//0xc0 = mod = 11b => two register operands
	.word cmp_al_al, cmp_al_cl, cmp_al_dl, cmp_al_bl, cmp_al_ah, cmp_al_ch, cmp_al_dh, cmp_al_bh
	.word cmp_cl_al, cmp_cl_cl, cmp_cl_dl, cmp_cl_bl, cmp_cl_ah, cmp_cl_ch, cmp_cl_dh, cmp_cl_bh
	.word cmp_dl_al, cmp_dl_cl, cmp_dl_dl, cmp_dl_bl, cmp_dl_ah, cmp_dl_ch, cmp_dl_dh, cmp_dl_bh
	.word cmp_bl_al, cmp_bl_cl, cmp_bl_dl, cmp_bl_bl, cmp_bl_ah, cmp_bl_ch, cmp_bl_dh, cmp_bl_bh
	.word cmp_ah_al, cmp_ah_cl, cmp_ah_dl, cmp_ah_bl, cmp_ah_ah, cmp_ah_ch, cmp_ah_dh, cmp_ah_bh
	.word cmp_ch_al, cmp_ch_cl, cmp_ch_dl, cmp_ch_bl, cmp_ch_ah, cmp_ch_ch, cmp_ch_dh, cmp_ch_bh
	.word cmp_dh_al, cmp_dh_cl, cmp_dh_dl, cmp_dh_bl, cmp_dh_ah, cmp_dh_ch, cmp_dh_dh, cmp_dh_bh
	.word cmp_bh_al, cmp_bh_cl, cmp_bh_dl, cmp_bh_bl, cmp_bh_ah, cmp_bh_ch, cmp_bh_dh, cmp_bh_bh

// These are called from "cpu_386.s":

	.global cmp_al_siidx, cmp_cl_siidx, cmp_dl_siidx, cmp_bl_siidx, cmp_ah_siidx, cmp_ch_siidx, cmp_dh_siidx, cmp_bh_siidx
	.global cmp_al_diidx, cmp_cl_diidx, cmp_dl_diidx, cmp_bl_diidx, cmp_ah_diidx, cmp_ch_diidx, cmp_dh_diidx, cmp_bh_diidx
	.global cmp_al_bxidx, cmp_cl_bxidx, cmp_dl_bxidx, cmp_bl_bxidx, cmp_ah_bxidx, cmp_ch_bxidx, cmp_dh_bxidx, cmp_bh_bxidx
	.global cmp_al_sidisp8, cmp_al_didisp8, cmp_al_bpdisp8, cmp_al_bxdisp8
	.global cmp_cl_sidisp8, cmp_cl_didisp8, cmp_cl_bpdisp8, cmp_cl_bxdisp8
	.global cmp_dl_sidisp8, cmp_dl_didisp8, cmp_dl_bpdisp8, cmp_dl_bxdisp8
	.global cmp_bl_sidisp8, cmp_bl_didisp8, cmp_bl_bpdisp8, cmp_bl_bxdisp8
	.global cmp_ah_sidisp8, cmp_ah_didisp8, cmp_ah_bpdisp8, cmp_ah_bxdisp8
	.global cmp_ch_sidisp8, cmp_ch_didisp8, cmp_ch_bpdisp8, cmp_ch_bxdisp8
	.global cmp_dh_sidisp8, cmp_dh_didisp8, cmp_dh_bpdisp8, cmp_dh_bxdisp8
	.global cmp_bh_sidisp8, cmp_bh_didisp8, cmp_bh_bpdisp8, cmp_bh_bxdisp8
	.global cmp_al_al, cmp_cl_al, cmp_dl_al, cmp_bl_al, cmp_ah_al, cmp_ch_al, cmp_dh_al, cmp_bh_al
	.global cmp_al_cl, cmp_cl_cl, cmp_dl_cl, cmp_bl_cl, cmp_ah_cl, cmp_ch_cl, cmp_dh_cl, cmp_bh_cl
	.global cmp_al_dl, cmp_cl_dl, cmp_dl_dl, cmp_bl_dl, cmp_ah_dl, cmp_ch_dl, cmp_dh_dl, cmp_bh_dl
	.global cmp_al_bl, cmp_cl_bl, cmp_dl_bl, cmp_bl_bl, cmp_ah_bl, cmp_ch_bl, cmp_dh_bl, cmp_bh_bl
	.global cmp_al_ah, cmp_cl_ah, cmp_dl_ah, cmp_bl_ah, cmp_ah_ah, cmp_ch_ah, cmp_dh_ah, cmp_bh_ah
	.global cmp_al_ch, cmp_cl_ch, cmp_dl_ch, cmp_bl_ch, cmp_ah_ch, cmp_ch_ch, cmp_dh_ch, cmp_bh_ch
	.global cmp_al_dh, cmp_cl_dh, cmp_dl_dh, cmp_bl_dh, cmp_ah_dh, cmp_ch_dh, cmp_dh_dh, cmp_bh_dh
	.global cmp_al_bh, cmp_cl_bh, cmp_dl_bh, cmp_bl_bh, cmp_ah_bh, cmp_ch_bh, cmp_dh_bh, cmp_bh_bh

.macro cmp_reg8l_r0high reg
	.global	cmp_r8l_r0_bp_\reg
cmp_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	cmp_r8l_r0_\reg
cmp_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_3a_RAM_l_\reg op_3a_EGA_l_\reg op_3a_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_3a_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1,\reg, lsl #24
	cmp		r1, r0, lsl #24
	b		complement_carry
.endm
.macro cmp_reg8h_r0high reg
	.global	cmp_r8h_r0_bp_\reg
cmp_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	cmp_r8h_r0_\reg
cmp_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_3a_RAM_h_\reg op_3a_EGA_h_\reg op_3a_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_3a_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00		// Left operand already uses just the rightmost byte
	lsl		r1, #16
	cmp		r1, r0, lsl #24			// Perform the addition using the highest bytes to get the correct flags
	b		complement_carry
.endm

	cmp_reg8l_r0high r4
	cmp_reg8l_r0high r5
	cmp_reg8l_r0high r6
	cmp_reg8l_r0high r7
	cmp_reg8h_r0high r4
	cmp_reg8h_r0high r5
	cmp_reg8h_r0high r6
	cmp_reg8h_r0high r7

	.ltorg


// --- [idx] ---

.macro cmp_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		cmp_r8l_r0_\reg
.endm
.macro cmp_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		cmp_r8h_r0_\reg
.endm

cmp_al_bxsi:
	cmp_reg8l_bxidx r4 r10
cmp_cl_bxsi:
	cmp_reg8l_bxidx r5 r10
cmp_dl_bxsi:
	cmp_reg8l_bxidx r6 r10
cmp_bl_bxsi:
	cmp_reg8l_bxidx r7 r10
cmp_ah_bxsi:
	cmp_reg8h_bxidx r4 r10
cmp_ch_bxsi:
	cmp_reg8h_bxidx r5 r10
cmp_dh_bxsi:
	cmp_reg8h_bxidx r6 r10
cmp_bh_bxsi:
	cmp_reg8h_bxidx r7 r10

cmp_al_bxdi:
	cmp_reg8l_bxidx r4 r11
cmp_cl_bxdi:
	cmp_reg8l_bxidx r5 r11
cmp_dl_bxdi:
	cmp_reg8l_bxidx r6 r11
cmp_bl_bxdi:
	cmp_reg8l_bxidx r7 r11
cmp_ah_bxdi:
	cmp_reg8h_bxidx r4 r11
cmp_ch_bxdi:
	cmp_reg8h_bxidx r5 r11
cmp_dh_bxdi:
	cmp_reg8h_bxidx r6 r11
cmp_bh_bxdi:
	cmp_reg8h_bxidx r7 r11

.macro cmp_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		cmp_r8l_r0_bp_\reg
.endm
.macro cmp_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		cmp_r8h_r0_bp_\reg
.endm

cmp_al_bpsi:
	cmp_reg8l_bpidx r4 r10
cmp_cl_bpsi:
	cmp_reg8l_bpidx r5 r10
cmp_dl_bpsi:
	cmp_reg8l_bpidx r6 r10
cmp_bl_bpsi:
	cmp_reg8l_bpidx r7 r10
cmp_ah_bpsi:
	cmp_reg8h_bpidx r4 r10
cmp_ch_bpsi:
	cmp_reg8h_bpidx r5 r10
cmp_dh_bpsi:
	cmp_reg8h_bpidx r6 r10
cmp_bh_bpsi:
	cmp_reg8h_bpidx r7 r10

cmp_al_bpdi:
	cmp_reg8l_bpidx r4 r11
cmp_cl_bpdi:
	cmp_reg8l_bpidx r5 r11
cmp_dl_bpdi:
	cmp_reg8l_bpidx r6 r11
cmp_bl_bpdi:
	cmp_reg8l_bpidx r7 r11
cmp_ah_bpdi:
	cmp_reg8h_bpidx r4 r11
cmp_ch_bpdi:
	cmp_reg8h_bpidx r5 r11
cmp_dh_bpdi:
	cmp_reg8h_bpidx r6 r11
cmp_bh_bpdi:
	cmp_reg8h_bpidx r7 r11

.macro cmp_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		cmp_r8l_r0_\reg
.endm
.macro cmp_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		cmp_r8h_r0_\reg
.endm

cmp_al_siidx:
	cmp_reg8l_idx r4 r10
cmp_cl_siidx:
	cmp_reg8l_idx r5 r10
cmp_dl_siidx:
	cmp_reg8l_idx r6 r10
cmp_bl_siidx:
	cmp_reg8l_idx r7 r10
cmp_ah_siidx:
	cmp_reg8h_idx r4 r10
cmp_ch_siidx:
	cmp_reg8h_idx r5 r10
cmp_dh_siidx:
	cmp_reg8h_idx r6 r10
cmp_bh_siidx:
	cmp_reg8h_idx r7 r10

cmp_al_diidx:
	cmp_reg8l_idx r4 r11
cmp_cl_diidx:
	cmp_reg8l_idx r5 r11
cmp_dl_diidx:
	cmp_reg8l_idx r6 r11
cmp_bl_diidx:
	cmp_reg8l_idx r7 r11
cmp_ah_diidx:
	cmp_reg8h_idx r4 r11
cmp_ch_diidx:
	cmp_reg8h_idx r5 r11
cmp_dh_diidx:
	cmp_reg8h_idx r6 r11
cmp_bh_diidx:
	cmp_reg8h_idx r7 r11

cmp_al_bxidx:
	cmp_reg8l_idx r4 r7
cmp_cl_bxidx:
	cmp_reg8l_idx r5 r7
cmp_dl_bxidx:
	cmp_reg8l_idx r6 r7
cmp_bl_bxidx:
	cmp_reg8l_idx r7 r7
cmp_ah_bxidx:
	cmp_reg8h_idx r4 r7
cmp_ch_bxidx:
	cmp_reg8h_idx r5 r7
cmp_dh_bxidx:
	cmp_reg8h_idx r6 r7
cmp_bh_bxidx:
	cmp_reg8h_idx r7 r7

.macro cmp_reg8l_disp16 reg
	r0_from_disp16
	b		cmp_r8l_r0_\reg
.endm
.macro cmp_reg8h_disp16 reg
	r0_from_disp16
	b		cmp_r8h_r0_\reg
.endm

cmp_al_disp16:
	cmp_reg8l_disp16 r4
cmp_cl_disp16:
	cmp_reg8l_disp16 r5
cmp_dl_disp16:
	cmp_reg8l_disp16 r6
cmp_bl_disp16:
	cmp_reg8l_disp16 r7
cmp_ah_disp16:
	cmp_reg8h_disp16 r4
cmp_ch_disp16:
	cmp_reg8h_disp16 r5
cmp_dh_disp16:
	cmp_reg8h_disp16 r6
cmp_bh_disp16:
	cmp_reg8h_disp16 r7

// --- [idx+disp8] ---

.macro cmp_reg8l_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		cmp_r8l_r0_\reg
.endm
.macro cmp_reg8h_bxidxd8 reg idx
	r0_from_bxidxdisp8 \idx
	b		cmp_r8h_r0_\reg
.endm

cmp_al_bxsid8:
	cmp_reg8l_bxidxd8 r4 r10
cmp_cl_bxsid8:
	cmp_reg8l_bxidxd8 r5 r10
cmp_dl_bxsid8:
	cmp_reg8l_bxidxd8 r6 r10
cmp_bl_bxsid8:
	cmp_reg8l_bxidxd8 r7 r10
cmp_ah_bxsid8:
	cmp_reg8h_bxidxd8 r4 r10
cmp_ch_bxsid8:
	cmp_reg8h_bxidxd8 r5 r10
cmp_dh_bxsid8:
	cmp_reg8h_bxidxd8 r6 r10
cmp_bh_bxsid8:
	cmp_reg8h_bxidxd8 r7 r10

cmp_al_bxdid8:
	cmp_reg8l_bxidxd8 r4 r11
cmp_cl_bxdid8:
	cmp_reg8l_bxidxd8 r5 r11
cmp_dl_bxdid8:
	cmp_reg8l_bxidxd8 r6 r11
cmp_bl_bxdid8:
	cmp_reg8l_bxidxd8 r7 r11
cmp_ah_bxdid8:
	cmp_reg8h_bxidxd8 r4 r11
cmp_ch_bxdid8:
	cmp_reg8h_bxidxd8 r5 r11
cmp_dh_bxdid8:
	cmp_reg8h_bxidxd8 r6 r11
cmp_bh_bxdid8:
	cmp_reg8h_bxidxd8 r7 r11

.macro cmp_reg8l_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		cmp_r8l_r0_bp_\reg
.endm
.macro cmp_reg8h_bpidxd8 reg idx
	r0_from_bpidxdisp8 \idx
	b		cmp_r8h_r0_bp_\reg
.endm

cmp_al_bpsid8:
	cmp_reg8l_bpidxd8 r4 r10
cmp_cl_bpsid8:
	cmp_reg8l_bpidxd8 r5 r10
cmp_dl_bpsid8:
	cmp_reg8l_bpidxd8 r6 r10
cmp_bl_bpsid8:
	cmp_reg8l_bpidxd8 r7 r10
cmp_ah_bpsid8:
	cmp_reg8h_bpidxd8 r4 r10
cmp_ch_bpsid8:
	cmp_reg8h_bpidxd8 r5 r10
cmp_dh_bpsid8:
	cmp_reg8h_bpidxd8 r6 r10
cmp_bh_bpsid8:
	cmp_reg8h_bpidxd8 r7 r10

cmp_al_bpdid8:
	cmp_reg8l_bpidxd8 r4 r11
cmp_cl_bpdid8:
	cmp_reg8l_bpidxd8 r5 r11
cmp_dl_bpdid8:
	cmp_reg8l_bpidxd8 r6 r11
cmp_bl_bpdid8:
	cmp_reg8l_bpidxd8 r7 r11
cmp_ah_bpdid8:
	cmp_reg8h_bpidxd8 r4 r11
cmp_ch_bpdid8:
	cmp_reg8h_bpidxd8 r5 r11
cmp_dh_bpdid8:
	cmp_reg8h_bpidxd8 r6 r11
cmp_bh_bpdid8:
	cmp_reg8h_bpidxd8 r7 r11

.macro cmp_reg8l_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		cmp_r8l_r0_\reg
.endm
.macro cmp_reg8h_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		cmp_r8h_r0_\reg
.endm

cmp_al_sidisp8:
	cmp_reg8l_idxdisp8 r4 r10
cmp_cl_sidisp8:
	cmp_reg8l_idxdisp8 r5 r10
cmp_dl_sidisp8:
	cmp_reg8l_idxdisp8 r6 r10
cmp_bl_sidisp8:
	cmp_reg8l_idxdisp8 r7 r10
cmp_ah_sidisp8:
	cmp_reg8h_idxdisp8 r4 r10
cmp_ch_sidisp8:
	cmp_reg8h_idxdisp8 r5 r10
cmp_dh_sidisp8:
	cmp_reg8h_idxdisp8 r6 r10
cmp_bh_sidisp8:
	cmp_reg8h_idxdisp8 r7 r10
	
cmp_al_didisp8:
	cmp_reg8l_idxdisp8 r4 r11
cmp_cl_didisp8:
	cmp_reg8l_idxdisp8 r5 r11
cmp_dl_didisp8:
	cmp_reg8l_idxdisp8 r6 r11
cmp_bl_didisp8:
	cmp_reg8l_idxdisp8 r7 r11
cmp_ah_didisp8:
	cmp_reg8h_idxdisp8 r4 r11
cmp_ch_didisp8:
	cmp_reg8h_idxdisp8 r5 r11
cmp_dh_didisp8:
	cmp_reg8h_idxdisp8 r6 r11
cmp_bh_didisp8:
	cmp_reg8h_idxdisp8 r7 r11

cmp_al_bxdisp8:
	cmp_reg8l_idxdisp8 r4 r7
cmp_cl_bxdisp8:
	cmp_reg8l_idxdisp8 r5 r7
cmp_dl_bxdisp8:
	cmp_reg8l_idxdisp8 r6 r7
cmp_bl_bxdisp8:
	cmp_reg8l_idxdisp8 r7 r7
cmp_ah_bxdisp8:
	cmp_reg8h_idxdisp8 r4 r7
cmp_ch_bxdisp8:
	cmp_reg8h_idxdisp8 r5 r7
cmp_dh_bxdisp8:
	cmp_reg8h_idxdisp8 r6 r7
cmp_bh_bxdisp8:
	cmp_reg8h_idxdisp8 r7 r7

.macro cmp_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		cmp_r8l_r0_bp_\reg
.endm
.macro cmp_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		cmp_r8h_r0_bp_\reg
.endm

cmp_al_bpdisp8:
	cmp_reg8l_bpdisp8 r4
cmp_cl_bpdisp8:
	cmp_reg8l_bpdisp8 r5
cmp_dl_bpdisp8:
	cmp_reg8l_bpdisp8 r6
cmp_bl_bpdisp8:
	cmp_reg8l_bpdisp8 r7
cmp_ah_bpdisp8:
	cmp_reg8h_bpdisp8 r4
cmp_ch_bpdisp8:
	cmp_reg8h_bpdisp8 r5
cmp_dh_bpdisp8:
	cmp_reg8h_bpdisp8 r6
cmp_bh_bpdisp8:
	cmp_reg8h_bpdisp8 r7

// --- [idx+disp16] ---

.macro cmp_reg8l_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		cmp_r8l_r0_\reg
.endm
.macro cmp_reg8h_bxidxd16 reg idx
	r0_from_bxidxdisp16 \idx
	b		cmp_r8h_r0_\reg
.endm

cmp_al_bxsid16:
	cmp_reg8l_bxidxd16 r4 r10
cmp_cl_bxsid16:
	cmp_reg8l_bxidxd16 r5 r10
cmp_dl_bxsid16:
	cmp_reg8l_bxidxd16 r6 r10
cmp_bl_bxsid16:
	cmp_reg8l_bxidxd16 r7 r10
cmp_ah_bxsid16:
	cmp_reg8h_bxidxd16 r4 r10
cmp_ch_bxsid16:
	cmp_reg8h_bxidxd16 r5 r10
cmp_dh_bxsid16:
	cmp_reg8h_bxidxd16 r6 r10
cmp_bh_bxsid16:
	cmp_reg8h_bxidxd16 r7 r10

cmp_al_bxdid16:
	cmp_reg8l_bxidxd16 r4 r11
cmp_cl_bxdid16:
	cmp_reg8l_bxidxd16 r5 r11
cmp_dl_bxdid16:
	cmp_reg8l_bxidxd16 r6 r11
cmp_bl_bxdid16:
	cmp_reg8l_bxidxd16 r7 r11
cmp_ah_bxdid16:
	cmp_reg8h_bxidxd16 r4 r11
cmp_ch_bxdid16:
	cmp_reg8h_bxidxd16 r5 r11
cmp_dh_bxdid16:
	cmp_reg8h_bxidxd16 r6 r11
cmp_bh_bxdid16:
	cmp_reg8h_bxidxd16 r7 r11

.macro cmp_reg8l_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		cmp_r8l_r0_bp_\reg
.endm
.macro cmp_reg8h_bpidxd16 reg idx
	r0_from_bpidxdisp16 \idx
	b		cmp_r8h_r0_bp_\reg
.endm

cmp_al_bpsid16:
	cmp_reg8l_bpidxd16 r4 r10
cmp_cl_bpsid16:
	cmp_reg8l_bpidxd16 r5 r10
cmp_dl_bpsid16:
	cmp_reg8l_bpidxd16 r6 r10
cmp_bl_bpsid16:
	cmp_reg8l_bpidxd16 r7 r10
cmp_ah_bpsid16:
	cmp_reg8h_bpidxd16 r4 r10
cmp_ch_bpsid16:
	cmp_reg8h_bpidxd16 r5 r10
cmp_dh_bpsid16:
	cmp_reg8h_bpidxd16 r6 r10
cmp_bh_bpsid16:
	cmp_reg8h_bpidxd16 r7 r10

cmp_al_bpdid16:
	cmp_reg8l_bpidxd16 r4 r11
cmp_cl_bpdid16:
	cmp_reg8l_bpidxd16 r5 r11
cmp_dl_bpdid16:
	cmp_reg8l_bpidxd16 r6 r11
cmp_bl_bpdid16:
	cmp_reg8l_bpidxd16 r7 r11
cmp_ah_bpdid16:
	cmp_reg8h_bpidxd16 r4 r11
cmp_ch_bpdid16:
	cmp_reg8h_bpidxd16 r5 r11
cmp_dh_bpdid16:
	cmp_reg8h_bpidxd16 r6 r11
cmp_bh_bpdid16:
	cmp_reg8h_bpidxd16 r7 r11

.macro cmp_reg8l_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		cmp_r8l_r0_\reg
.endm
.macro cmp_reg8h_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		cmp_r8h_r0_\reg
.endm

cmp_al_sidisp16:
	cmp_reg8l_idxdisp16 r4 r10
cmp_cl_sidisp16:
	cmp_reg8l_idxdisp16 r5 r10
cmp_dl_sidisp16:
	cmp_reg8l_idxdisp16 r6 r10
cmp_bl_sidisp16:
	cmp_reg8l_idxdisp16 r7 r10
cmp_ah_sidisp16:
	cmp_reg8h_idxdisp16 r4 r10
cmp_ch_sidisp16:
	cmp_reg8h_idxdisp16 r5 r10
cmp_dh_sidisp16:
	cmp_reg8h_idxdisp16 r6 r10
cmp_bh_sidisp16:
	cmp_reg8h_idxdisp16 r7 r10

cmp_al_didisp16:
	cmp_reg8l_idxdisp16 r4 r11
cmp_cl_didisp16:
	cmp_reg8l_idxdisp16 r5 r11
cmp_dl_didisp16:
	cmp_reg8l_idxdisp16 r6 r11
cmp_bl_didisp16:
	cmp_reg8l_idxdisp16 r7 r11
cmp_ah_didisp16:
	cmp_reg8h_idxdisp16 r4 r11
cmp_ch_didisp16:
	cmp_reg8h_idxdisp16 r5 r11
cmp_dh_didisp16:
	cmp_reg8h_idxdisp16 r6 r11
cmp_bh_didisp16:
	cmp_reg8h_idxdisp16 r7 r11

cmp_al_bxdisp16:
	cmp_reg8l_idxdisp16 r4 r7
cmp_cl_bxdisp16:
	cmp_reg8l_idxdisp16 r5 r7
cmp_dl_bxdisp16:
	cmp_reg8l_idxdisp16 r6 r7
cmp_bl_bxdisp16:
	cmp_reg8l_idxdisp16 r7 r7
cmp_ah_bxdisp16:
	cmp_reg8h_idxdisp16 r4 r7
cmp_ch_bxdisp16:
	cmp_reg8h_idxdisp16 r5 r7
cmp_dh_bxdisp16:
	cmp_reg8h_idxdisp16 r6 r7
cmp_bh_bxdisp16:
	cmp_reg8h_idxdisp16 r7 r7
	
.macro cmp_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		cmp_r8l_r0_bp_\reg
.endm
.macro cmp_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		cmp_r8h_r0_bp_\reg
.endm

cmp_al_bpdisp16:
	cmp_reg8l_bpdisp16 r4 
cmp_cl_bpdisp16:
	cmp_reg8l_bpdisp16 r5 
cmp_dl_bpdisp16:
	cmp_reg8l_bpdisp16 r6 
cmp_bl_bpdisp16:
	cmp_reg8l_bpdisp16 r7 
cmp_ah_bpdisp16:
	cmp_reg8h_bpdisp16 r4 
cmp_ch_bpdisp16:
	cmp_reg8h_bpdisp16 r5 
cmp_dh_bpdisp16:
	cmp_reg8h_bpdisp16 r6 
cmp_bh_bpdisp16:
	cmp_reg8h_bpdisp16 r7 

// --- registers ---

.macro cmp_reg8l_reg8l rl rr
	mov		r1, \rl, lsl #24
	cmp		r1, \rr, lsl #24
	b		complement_carry
.endm

cmp_al_al:
	cmp_reg8l_reg8l r4 r4
cmp_al_cl:
	cmp_reg8l_reg8l r4 r5
cmp_al_dl:
	cmp_reg8l_reg8l r4 r6
cmp_al_bl:
	cmp_reg8l_reg8l r4 r7

cmp_cl_al:
	cmp_reg8l_reg8l r5 r4
cmp_cl_cl:
	cmp_reg8l_reg8l r5 r5
cmp_cl_dl:
	cmp_reg8l_reg8l r5 r6
cmp_cl_bl:
	cmp_reg8l_reg8l r5 r7

cmp_dl_al:
	cmp_reg8l_reg8l r6 r4
cmp_dl_cl:
	cmp_reg8l_reg8l r6 r5
cmp_dl_dl:
	cmp_reg8l_reg8l r6 r6
cmp_dl_bl:
	cmp_reg8l_reg8l r6 r7

cmp_bl_al:
	cmp_reg8l_reg8l r7 r4
cmp_bl_cl:
	cmp_reg8l_reg8l r7 r5
cmp_bl_dl:
	cmp_reg8l_reg8l r7 r6
cmp_bl_bl:
	cmp_reg8l_reg8l r7 r7

.macro cmp_reg8l_reg8h rl rr
	mov		r0, \rl, lsl #24
	and		r1, \rr, #0xFF00
	cmp		r0, r1, lsl #16
	b		complement_carry
.endm

cmp_al_ah:
	cmp_reg8l_reg8h r4 r4
cmp_al_ch:
	cmp_reg8l_reg8h r4 r5
cmp_al_dh:
	cmp_reg8l_reg8h r4 r6
cmp_al_bh:
	cmp_reg8l_reg8h r4 r7

cmp_cl_ah:
	cmp_reg8l_reg8h r5 r4
cmp_cl_ch:
	cmp_reg8l_reg8h r5 r5
cmp_cl_dh:
	cmp_reg8l_reg8h r5 r6
cmp_cl_bh:
	cmp_reg8l_reg8h r5 r7

cmp_dl_ah:
	cmp_reg8l_reg8h r6 r4
cmp_dl_ch:
	cmp_reg8l_reg8h r6 r5
cmp_dl_dh:
	cmp_reg8l_reg8h r6 r6
cmp_dl_bh:
	cmp_reg8l_reg8h r6 r7

cmp_bl_ah:
	cmp_reg8l_reg8h r7 r4
cmp_bl_ch:
	cmp_reg8l_reg8h r7 r5
cmp_bl_dh:
	cmp_reg8l_reg8h r7 r6
cmp_bl_bh:
	cmp_reg8l_reg8h r7 r7

.macro cmp_reg8h_reg8l rl rr
	and		r1, \rl, #0xFF00
	lsl		r1, #16
	cmp		r1, \rr, lsl #24
	b		complement_carry
.endm

cmp_ah_al:
	cmp_reg8h_reg8l r4 r4
cmp_ah_cl:
	cmp_reg8h_reg8l r4 r5
cmp_ah_dl:
	cmp_reg8h_reg8l r4 r6
cmp_ah_bl:
	cmp_reg8h_reg8l r4 r7

cmp_ch_al:
	cmp_reg8h_reg8l r5 r4
cmp_ch_cl:
	cmp_reg8h_reg8l r5 r5
cmp_ch_dl:
	cmp_reg8h_reg8l r5 r6
cmp_ch_bl:
	cmp_reg8h_reg8l r5 r7

cmp_dh_al:
	cmp_reg8h_reg8l r6 r4
cmp_dh_cl:
	cmp_reg8h_reg8l r6 r5
cmp_dh_dl:
	cmp_reg8h_reg8l r6 r6
cmp_dh_bl:
	cmp_reg8h_reg8l r6 r7

cmp_bh_al:
	cmp_reg8h_reg8l r7 r4
cmp_bh_cl:
	cmp_reg8h_reg8l r7 r5
cmp_bh_dl:
	cmp_reg8h_reg8l r7 r6
cmp_bh_bl:
	cmp_reg8h_reg8l r7 r7

.macro cmp_reg8h_reg8h rl rr
	and		r0, \rl, #0xFF00
	lsl		r0, #16
	and		r1, \rr, #0xFF00
	cmp		r0, r1, lsl #16
	b		complement_carry
.endm

cmp_ah_ah:
	cmp_reg8h_reg8h r4 r4
cmp_ah_ch:
	cmp_reg8h_reg8h r4 r5
cmp_ah_dh:
	cmp_reg8h_reg8h r4 r6
cmp_ah_bh:
	cmp_reg8h_reg8h r4 r7

cmp_ch_ah:
	cmp_reg8h_reg8h r5 r4
cmp_ch_ch:
	cmp_reg8h_reg8h r5 r5
cmp_ch_dh:
	cmp_reg8h_reg8h r5 r6
cmp_ch_bh:
	cmp_reg8h_reg8h r5 r7

cmp_dh_ah:
	cmp_reg8h_reg8h r6 r4
cmp_dh_ch:
	cmp_reg8h_reg8h r6 r5
cmp_dh_dh:
	cmp_reg8h_reg8h r6 r6
cmp_dh_bh:
	cmp_reg8h_reg8h r6 r7

cmp_bh_ah:
	cmp_reg8h_reg8h r7 r4
cmp_bh_ch:
	cmp_reg8h_reg8h r7 r5
cmp_bh_dh:
	cmp_reg8h_reg8h r7 r6
cmp_bh_bh:
	cmp_reg8h_reg8h r7 r7
	
// ------------------- 3B = CMP r16,r/m16 ------------------------------
//
// All modrm variations supported!
//
//
// ARM uses the Carry flag in the opposite sense to x86, so we need to swap it.
//
op_3b:
	modrm_jump_16
// 0
	.word cmp_ax_bxsi, cmp_ax_bxdi, cmp_ax_bpsi, cmp_ax_bpdi, cmp_ax_siidx, cmp_ax_diidx, cmp_ax_disp16, cmp_ax_bxidx
	.word cmp_cx_bxsi, cmp_cx_bxdi, cmp_cx_bpsi, cmp_cx_bpdi, cmp_cx_siidx, cmp_cx_diidx, cmp_cx_disp16, cmp_cx_bxidx
	.word cmp_dx_bxsi, cmp_dx_bxdi, cmp_dx_bpsi, cmp_dx_bpdi, cmp_dx_siidx, cmp_dx_diidx, cmp_dx_disp16, cmp_dx_bxidx
	.word cmp_bx_bxsi, cmp_bx_bxdi, cmp_bx_bpsi, cmp_bx_bpdi, cmp_bx_siidx, cmp_bx_diidx, cmp_bx_disp16, cmp_bx_bxidx
	.word cmp_sp_bxsi, cmp_sp_bxdi, cmp_sp_bpsi, cmp_sp_bpdi, cmp_sp_siidx, cmp_sp_diidx, cmp_sp_disp16, cmp_sp_bxidx
	.word cmp_bp_bxsi, cmp_bp_bxdi, cmp_bp_bpsi, cmp_bp_bpdi, cmp_bp_siidx, cmp_bp_diidx, cmp_bp_disp16, cmp_bp_bxidx
	.word cmp_si_bxsi, cmp_si_bxdi, cmp_si_bpsi, cmp_si_bpdi, cmp_si_siidx, cmp_si_diidx, cmp_si_disp16, cmp_si_bxidx
	.word cmp_di_bxsi, cmp_di_bxdi, cmp_di_bpsi, cmp_di_bpdi, cmp_di_siidx, cmp_di_diidx, cmp_di_disp16, cmp_di_bxidx
//0x40
	.word cmp_ax_bxsid8, cmp_ax_bxdid8, cmp_ax_bpsid8, cmp_ax_bpdid8, cmp_ax_sidisp8, cmp_ax_didisp8, cmp_ax_bpdisp8, cmp_ax_bxdisp8
	.word cmp_cx_bxsid8, cmp_cx_bxdid8, cmp_cx_bpsid8, cmp_cx_bpdid8, cmp_cx_sidisp8, cmp_cx_didisp8, cmp_cx_bpdisp8, cmp_cx_bxdisp8
	.word cmp_dx_bxsid8, cmp_dx_bxdid8, cmp_dx_bpsid8, cmp_dx_bpdid8, cmp_dx_sidisp8, cmp_dx_didisp8, cmp_dx_bpdisp8, cmp_dx_bxdisp8
	.word cmp_bx_bxsid8, cmp_bx_bxdid8, cmp_bx_bpsid8, cmp_bx_bpdid8, cmp_bx_sidisp8, cmp_bx_didisp8, cmp_bx_bpdisp8, cmp_bx_bxdisp8
	.word cmp_sp_bxsid8, cmp_sp_bxdid8, cmp_sp_bpsid8, cmp_sp_bpdid8, cmp_sp_sidisp8, cmp_sp_didisp8, cmp_sp_bpdisp8, cmp_sp_bxdisp8
	.word cmp_bp_bxsid8, cmp_bp_bxdid8, cmp_bp_bpsid8, cmp_bp_bpdid8, cmp_bp_sidisp8, cmp_bp_didisp8, cmp_bp_bpdisp8, cmp_bp_bxdisp8
	.word cmp_si_bxsid8, cmp_si_bxdid8, cmp_si_bpsid8, cmp_si_bpdid8, cmp_si_sidisp8, cmp_si_didisp8, cmp_si_bpdisp8, cmp_si_bxdisp8
	.word cmp_di_bxsid8, cmp_di_bxdid8, cmp_di_bpsid8, cmp_di_bpdid8, cmp_di_sidisp8, cmp_di_didisp8, cmp_di_bpdisp8, cmp_di_bxdisp8
//0x80
	.word cmp_ax_bxsid16, cmp_ax_bxdid16, cmp_ax_bpsid16, cmp_ax_bpdid16, cmp_ax_sidisp16, cmp_ax_didisp16, cmp_ax_bpdisp16, cmp_ax_bxdisp16
	.word cmp_cx_bxsid16, cmp_cx_bxdid16, cmp_cx_bpsid16, cmp_cx_bpdid16, cmp_cx_sidisp16, cmp_cx_didisp16, cmp_cx_bpdisp16, cmp_cx_bxdisp16
	.word cmp_dx_bxsid16, cmp_dx_bxdid16, cmp_dx_bpsid16, cmp_dx_bpdid16, cmp_dx_sidisp16, cmp_dx_didisp16, cmp_dx_bpdisp16, cmp_dx_bxdisp16
	.word cmp_bx_bxsid16, cmp_bx_bxdid16, cmp_bx_bpsid16, cmp_bx_bpdid16, cmp_bx_sidisp16, cmp_bx_didisp16, cmp_bx_bpdisp16, cmp_bx_bxdisp16
	.word cmp_sp_bxsid16, cmp_sp_bxdid16, cmp_sp_bpsid16, cmp_sp_bpdid16, cmp_sp_sidisp16, cmp_sp_didisp16, cmp_sp_bpdisp16, cmp_sp_bxdisp16
	.word cmp_bp_bxsid16, cmp_bp_bxdid16, cmp_bp_bpsid16, cmp_bp_bpdid16, cmp_bp_sidisp16, cmp_bp_didisp16, cmp_bp_bpdisp16, cmp_bp_bxdisp16
	.word cmp_si_bxsid16, cmp_si_bxdid16, cmp_si_bpsid16, cmp_si_bpdid16, cmp_si_sidisp16, cmp_si_didisp16, cmp_si_bpdisp16, cmp_si_bxdisp16
	.word cmp_di_bxsid16, cmp_di_bxdid16, cmp_di_bpsid16, cmp_di_bpdid16, cmp_di_sidisp16, cmp_di_didisp16, cmp_di_bpdisp16, cmp_di_bxdisp16
//0xc0 = mod = 11b => two register operands
	.word cmp_ax_ax, cmp_ax_cx, cmp_ax_dx, cmp_ax_bx, cmp_ax_sp, cmp_ax_bp, cmp_ax_si, cmp_ax_di
	.word cmp_cx_ax, cmp_cx_cx, cmp_cx_dx, cmp_cx_bx, cmp_cx_sp, cmp_cx_bp, cmp_cx_si, cmp_cx_di
	.word cmp_dx_ax, cmp_dx_cx, cmp_dx_dx, cmp_dx_bx, cmp_dx_sp, cmp_dx_bp, cmp_dx_si, cmp_dx_di
	.word cmp_bx_ax, cmp_bx_cx, cmp_bx_dx, cmp_bx_bx, cmp_bx_sp, cmp_bx_bp, cmp_bx_si, cmp_bx_di
	.word cmp_sp_ax, cmp_sp_cx, cmp_sp_dx, cmp_sp_bx, cmp_sp_sp, cmp_sp_bp, cmp_sp_si, cmp_sp_di
	.word cmp_bp_ax, cmp_bp_cx, cmp_bp_dx, cmp_bp_bx, cmp_bp_sp, cmp_bp_bp, cmp_bp_si, cmp_bp_di
	.word cmp_si_ax, cmp_si_cx, cmp_si_dx, cmp_si_bx, cmp_si_sp, cmp_si_bp, cmp_si_si, cmp_si_di
	.word cmp_di_ax, cmp_di_cx, cmp_di_dx, cmp_di_bx, cmp_di_sp, cmp_di_bp, cmp_di_si, cmp_di_di

// These are called from "cpu_67.s":

	.global cmp_ax_siidx, cmp_ax_diidx, cmp_ax_bxidx
	.global cmp_cx_siidx, cmp_cx_diidx, cmp_cx_bxidx
	.global cmp_dx_siidx, cmp_dx_diidx, cmp_dx_bxidx
	.global cmp_bx_siidx, cmp_bx_diidx, cmp_bx_bxidx
	.global cmp_sp_siidx, cmp_sp_diidx, cmp_sp_bxidx
	.global cmp_bp_siidx, cmp_bp_diidx, cmp_bp_bxidx
	.global cmp_si_siidx, cmp_si_diidx, cmp_si_bxidx
	.global cmp_di_siidx, cmp_di_diidx, cmp_di_bxidx
	.global cmp_ax_sidisp8, cmp_ax_didisp8, cmp_ax_bpdisp8, cmp_ax_bxdisp8
	.global cmp_cx_sidisp8, cmp_cx_didisp8, cmp_cx_bpdisp8, cmp_cx_bxdisp8
	.global cmp_dx_sidisp8, cmp_dx_didisp8, cmp_dx_bpdisp8, cmp_dx_bxdisp8
	.global cmp_bx_sidisp8, cmp_bx_didisp8, cmp_bx_bpdisp8, cmp_bx_bxdisp8
	.global cmp_sp_sidisp8, cmp_sp_didisp8, cmp_sp_bpdisp8, cmp_sp_bxdisp8
	.global cmp_bp_sidisp8, cmp_bp_didisp8, cmp_bp_bpdisp8, cmp_bp_bxdisp8
	.global cmp_si_sidisp8, cmp_si_didisp8, cmp_si_bpdisp8, cmp_si_bxdisp8
	.global cmp_di_sidisp8, cmp_di_didisp8, cmp_di_bpdisp8, cmp_di_bxdisp8
	.global	cmp_r16_r0_bp_r4, cmp_r16_r0_bp_r5, cmp_r16_r0_bp_r6, cmp_r16_r0_bp_r7, cmp_r16_r0_bp_r8, cmp_r16_r0_bp_r9, cmp_r16_r0_bp_r10, cmp_r16_r0_bp_r11
	.global	cmp_r16_r0_r4, cmp_r16_r0_r5, cmp_r16_r0_r6, cmp_r16_r0_r7, cmp_r16_r0_r8, cmp_r16_r0_r9, cmp_r16_r0_r10, cmp_r16_r0_r11


.macro cmp_reg16_r0high reg
cmp_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
cmp_r16_r0_\reg:
	//-------
	// Indexing by the current effective segment.
	//-------
	mem_handler_jump_r0r3 .op_3b_RAM_\reg bad_EGA_opcode op_3b_MODEX_\reg
.op_3b_RAM_\reg:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r1, [r2, #1]			// Load high byte
	mov		r2, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	cmp		r2, r0, lsl #16
	b		complement_carry
.endm

	cmp_reg16_r0high r4
	cmp_reg16_r0high r5
	cmp_reg16_r0high r6
	cmp_reg16_r0high r7
	cmp_reg16_r0high r8
	cmp_reg16_r0high r9
	cmp_reg16_r0high r10
	cmp_reg16_r0high r11

	.ltorg

// --- [idx] ---

.macro cmp_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		cmp_r16_r0_\reg
.endm

cmp_ax_bxsi:
	cmp_reg16_bxidx r4 r10
cmp_cx_bxsi:
	cmp_reg16_bxidx r5 r10
cmp_dx_bxsi:
	cmp_reg16_bxidx r6 r10
cmp_bx_bxsi:
	cmp_reg16_bxidx r7 r10
cmp_bp_bxsi:
	cmp_reg16_bxidx r9 r10
cmp_sp_bxsi:
	cmp_reg16_bxidx r8 r10
cmp_si_bxsi:
	cmp_reg16_bxidx r10 r10
cmp_di_bxsi:
	cmp_reg16_bxidx r11 r10

cmp_ax_bxdi:
	cmp_reg16_bxidx r4 r11
cmp_cx_bxdi:
	cmp_reg16_bxidx r5 r11
cmp_dx_bxdi:
	cmp_reg16_bxidx r6 r11
cmp_bx_bxdi:
	cmp_reg16_bxidx r7 r11
cmp_sp_bxdi:
	cmp_reg16_bxidx r8 r11
cmp_bp_bxdi:
	cmp_reg16_bxidx r9 r11
cmp_si_bxdi:
	cmp_reg16_bxidx r10 r11
cmp_di_bxdi:
	cmp_reg16_bxidx r11 r11

.macro cmp_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		cmp_r16_r0_bp_\reg
.endm

cmp_ax_bpsi:
	cmp_reg16_bpidx r4 r10
cmp_cx_bpsi:
	cmp_reg16_bpidx r5 r10
cmp_dx_bpsi:
	cmp_reg16_bpidx r6 r10
cmp_bx_bpsi:
	cmp_reg16_bpidx r7 r10
cmp_sp_bpsi:
	cmp_reg16_bpidx r8 r10
cmp_bp_bpsi:
	cmp_reg16_bpidx r9 r10
cmp_si_bpsi:
	cmp_reg16_bpidx r10 r10
cmp_di_bpsi:
	cmp_reg16_bpidx r11 r10

cmp_ax_bpdi:
	cmp_reg16_bpidx r4 r11
cmp_cx_bpdi:
	cmp_reg16_bpidx r5 r11
cmp_dx_bpdi:
	cmp_reg16_bpidx r6 r11
cmp_bx_bpdi:
	cmp_reg16_bpidx r7 r11
cmp_sp_bpdi:
	cmp_reg16_bpidx r8 r11
cmp_bp_bpdi:
	cmp_reg16_bpidx r9 r11
cmp_si_bpdi:
	cmp_reg16_bpidx r10 r11
cmp_di_bpdi:
	cmp_reg16_bpidx r11 r11

.macro cmp_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		cmp_r16_r0_\reg
.endm

cmp_ax_siidx:
	cmp_reg16_idx r4 r10
cmp_cx_siidx:
	cmp_reg16_idx r5 r10
cmp_dx_siidx:
	cmp_reg16_idx r6 r10
cmp_bx_siidx:
	cmp_reg16_idx r7 r10
cmp_sp_siidx:
	cmp_reg16_idx r8 r10
cmp_bp_siidx:
	cmp_reg16_idx r9 r10
cmp_si_siidx:
	cmp_reg16_idx r10 r10
cmp_di_siidx:
	cmp_reg16_idx r11 r10

cmp_ax_diidx:
	cmp_reg16_idx r4 r11
cmp_cx_diidx:
	cmp_reg16_idx r5 r11
cmp_dx_diidx:
	cmp_reg16_idx r6 r11
cmp_bx_diidx:
	cmp_reg16_idx r7 r11
cmp_sp_diidx:
	cmp_reg16_idx r8 r11
cmp_bp_diidx:
	cmp_reg16_idx r9 r11
cmp_si_diidx:
	cmp_reg16_idx r10 r11
cmp_di_diidx:
	cmp_reg16_idx r11 r11

cmp_ax_bxidx:
	cmp_reg16_idx r4 r7
cmp_cx_bxidx:
	cmp_reg16_idx r5 r7
cmp_dx_bxidx:
	cmp_reg16_idx r6 r7
cmp_bx_bxidx:
	cmp_reg16_idx r7 r7
cmp_sp_bxidx:
	cmp_reg16_idx r8 r7
cmp_bp_bxidx:
	cmp_reg16_idx r9 r7
cmp_si_bxidx:
	cmp_reg16_idx r10 r7
cmp_di_bxidx:
	cmp_reg16_idx r11 r7

.macro cmp_reg16_disp16 reg
	r0_from_disp16
	b		cmp_r16_r0_\reg
.endm

cmp_ax_disp16:
	cmp_reg16_disp16 r4
cmp_cx_disp16:
	cmp_reg16_disp16 r5
cmp_dx_disp16:
	cmp_reg16_disp16 r6
cmp_bx_disp16:
	cmp_reg16_disp16 r7
cmp_sp_disp16:
	cmp_reg16_disp16 r8
cmp_bp_disp16:
	cmp_reg16_disp16 r9
cmp_si_disp16:
	cmp_reg16_disp16 r10
cmp_di_disp16:
	cmp_reg16_disp16 r11

// --- [idx+disp8] ---

.macro cmp_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		cmp_r16_r0_\reg
.endm

cmp_ax_bxsid8:
	cmp_reg16_bxidxdisp8 r4 r10
cmp_cx_bxsid8:
	cmp_reg16_bxidxdisp8 r5 r10
cmp_dx_bxsid8:
	cmp_reg16_bxidxdisp8 r6 r10
cmp_bx_bxsid8:
	cmp_reg16_bxidxdisp8 r7 r10
cmp_sp_bxsid8:
	cmp_reg16_bxidxdisp8 r8 r10
cmp_bp_bxsid8:
	cmp_reg16_bxidxdisp8 r9 r10
cmp_si_bxsid8:
	cmp_reg16_bxidxdisp8 r10 r10
cmp_di_bxsid8:
	cmp_reg16_bxidxdisp8 r11 r10

cmp_ax_bxdid8:
	cmp_reg16_bxidxdisp8 r4 r11
cmp_cx_bxdid8:
	cmp_reg16_bxidxdisp8 r5 r11
cmp_dx_bxdid8:
	cmp_reg16_bxidxdisp8 r6 r11
cmp_bx_bxdid8:
	cmp_reg16_bxidxdisp8 r7 r11
cmp_sp_bxdid8:
	cmp_reg16_bxidxdisp8 r8 r11
cmp_bp_bxdid8:
	cmp_reg16_bxidxdisp8 r9 r11
cmp_si_bxdid8:
	cmp_reg16_bxidxdisp8 r10 r11
cmp_di_bxdid8:
	cmp_reg16_bxidxdisp8 r11 r11

.macro cmp_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		cmp_r16_r0_bp_\reg
.endm

cmp_ax_bpsid8:
	cmp_reg16_bpidxdisp8 r4 r10
cmp_cx_bpsid8:
	cmp_reg16_bpidxdisp8 r5 r10
cmp_dx_bpsid8:
	cmp_reg16_bpidxdisp8 r6 r10
cmp_bx_bpsid8:
	cmp_reg16_bpidxdisp8 r7 r10
cmp_sp_bpsid8:
	cmp_reg16_bpidxdisp8 r8 r10
cmp_bp_bpsid8:
	cmp_reg16_bpidxdisp8 r9 r10
cmp_si_bpsid8:
	cmp_reg16_bpidxdisp8 r10 r10
cmp_di_bpsid8:
	cmp_reg16_bpidxdisp8 r11 r10

cmp_ax_bpdid8:
	cmp_reg16_bpidxdisp8 r4 r11
cmp_cx_bpdid8:
	cmp_reg16_bpidxdisp8 r5 r11
cmp_dx_bpdid8:
	cmp_reg16_bpidxdisp8 r6 r11
cmp_bx_bpdid8:
	cmp_reg16_bpidxdisp8 r7 r11
cmp_sp_bpdid8:
	cmp_reg16_bpidxdisp8 r8 r11
cmp_bp_bpdid8:
	cmp_reg16_bpidxdisp8 r9 r11
cmp_si_bpdid8:
	cmp_reg16_bpidxdisp8 r10 r11
cmp_di_bpdid8:
	cmp_reg16_bpidxdisp8 r11 r11

.macro cmp_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		cmp_r16_r0_\reg
.endm

cmp_ax_sidisp8:
	cmp_reg16_idxdisp8 r4 r10
cmp_cx_sidisp8:
	cmp_reg16_idxdisp8 r5 r10
cmp_dx_sidisp8:
	cmp_reg16_idxdisp8 r6 r10
cmp_bx_sidisp8:
	cmp_reg16_idxdisp8 r7 r10
cmp_sp_sidisp8:
	cmp_reg16_idxdisp8 r8 r10
cmp_bp_sidisp8:
	cmp_reg16_idxdisp8 r9 r10
cmp_si_sidisp8:
	cmp_reg16_idxdisp8 r10 r10
cmp_di_sidisp8:
	cmp_reg16_idxdisp8 r11 r10

cmp_ax_didisp8:
	cmp_reg16_idxdisp8 r4 r11
cmp_cx_didisp8:
	cmp_reg16_idxdisp8 r5 r11
cmp_dx_didisp8:
	cmp_reg16_idxdisp8 r6 r11
cmp_bx_didisp8:
	cmp_reg16_idxdisp8 r7 r11
cmp_sp_didisp8:
	cmp_reg16_idxdisp8 r8 r11
cmp_bp_didisp8:
	cmp_reg16_idxdisp8 r9 r11
cmp_si_didisp8:
	cmp_reg16_idxdisp8 r10 r11
cmp_di_didisp8:
	cmp_reg16_idxdisp8 r11 r11

cmp_ax_bxdisp8:
	cmp_reg16_idxdisp8 r4 r7
cmp_cx_bxdisp8:
	cmp_reg16_idxdisp8 r5 r7
cmp_dx_bxdisp8:
	cmp_reg16_idxdisp8 r6 r7
cmp_bx_bxdisp8:
	cmp_reg16_idxdisp8 r7 r7
cmp_sp_bxdisp8:
	cmp_reg16_idxdisp8 r8 r7
cmp_bp_bxdisp8:
	cmp_reg16_idxdisp8 r9 r7
cmp_si_bxdisp8:
	cmp_reg16_idxdisp8 r10 r7
cmp_di_bxdisp8:
	cmp_reg16_idxdisp8 r11 r7

.macro cmp_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		cmp_r16_r0_bp_\reg
.endm

cmp_ax_bpdisp8:
	cmp_reg16_bpdisp8 r4
cmp_cx_bpdisp8:
	cmp_reg16_bpdisp8 r5
cmp_dx_bpdisp8:
	cmp_reg16_bpdisp8 r6
cmp_bx_bpdisp8:
	cmp_reg16_bpdisp8 r7
cmp_sp_bpdisp8:
	cmp_reg16_bpdisp8 r8
cmp_bp_bpdisp8:
	cmp_reg16_bpdisp8 r9
cmp_si_bpdisp8:
	cmp_reg16_bpdisp8 r10
cmp_di_bpdisp8:
	cmp_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro cmp_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		cmp_r16_r0_\reg
.endm

cmp_ax_bxsid16:
	cmp_reg16_bxidxdisp16 r4 r10
cmp_cx_bxsid16:
	cmp_reg16_bxidxdisp16 r5 r10
cmp_dx_bxsid16:
	cmp_reg16_bxidxdisp16 r6 r10
cmp_bx_bxsid16:
	cmp_reg16_bxidxdisp16 r7 r10
cmp_sp_bxsid16:
	cmp_reg16_bxidxdisp16 r8 r10
cmp_bp_bxsid16:
	cmp_reg16_bxidxdisp16 r9 r10
cmp_si_bxsid16:
	cmp_reg16_bxidxdisp16 r10 r10
cmp_di_bxsid16:
	cmp_reg16_bxidxdisp16 r11 r10

cmp_ax_bxdid16:
	cmp_reg16_bxidxdisp16 r4 r11
cmp_cx_bxdid16:
	cmp_reg16_bxidxdisp16 r5 r11
cmp_dx_bxdid16:
	cmp_reg16_bxidxdisp16 r6 r11
cmp_bx_bxdid16:
	cmp_reg16_bxidxdisp16 r7 r11
cmp_sp_bxdid16:
	cmp_reg16_bxidxdisp16 r8 r11
cmp_bp_bxdid16:
	cmp_reg16_bxidxdisp16 r9 r11
cmp_si_bxdid16:
	cmp_reg16_bxidxdisp16 r10 r11
cmp_di_bxdid16:
	cmp_reg16_bxidxdisp16 r11 r11

.macro cmp_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		cmp_r16_r0_bp_\reg
.endm

cmp_ax_bpsid16:
	cmp_reg16_bpidxdisp16 r4 r10
cmp_cx_bpsid16:
	cmp_reg16_bpidxdisp16 r5 r10
cmp_dx_bpsid16:
	cmp_reg16_bpidxdisp16 r6 r10
cmp_bx_bpsid16:
	cmp_reg16_bpidxdisp16 r7 r10
cmp_sp_bpsid16:
	cmp_reg16_bpidxdisp16 r8 r10
cmp_bp_bpsid16:
	cmp_reg16_bpidxdisp16 r9 r10
cmp_si_bpsid16:
	cmp_reg16_bpidxdisp16 r10 r10
cmp_di_bpsid16:
	cmp_reg16_bpidxdisp16 r11 r10

cmp_ax_bpdid16:
	cmp_reg16_bpidxdisp16 r4 r11
cmp_cx_bpdid16:
	cmp_reg16_bpidxdisp16 r5 r11
cmp_dx_bpdid16:
	cmp_reg16_bpidxdisp16 r6 r11
cmp_bx_bpdid16:
	cmp_reg16_bpidxdisp16 r7 r11
cmp_sp_bpdid16:
	cmp_reg16_bpidxdisp16 r8 r11
cmp_bp_bpdid16:
	cmp_reg16_bpidxdisp16 r9 r11
cmp_si_bpdid16:
	cmp_reg16_bpidxdisp16 r10 r11
cmp_di_bpdid16:
	cmp_reg16_bpidxdisp16 r11 r11

.macro cmp_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		cmp_r16_r0_\reg
.endm

cmp_ax_sidisp16:
	cmp_reg16_idxdisp16 r4 r10
cmp_cx_sidisp16:
	cmp_reg16_idxdisp16 r5 r10
cmp_dx_sidisp16:
	cmp_reg16_idxdisp16 r6 r10
cmp_bx_sidisp16:
	cmp_reg16_idxdisp16 r7 r10
cmp_sp_sidisp16:
	cmp_reg16_idxdisp16 r8 r10
cmp_bp_sidisp16:
	cmp_reg16_idxdisp16 r9 r10
cmp_si_sidisp16:
	cmp_reg16_idxdisp16 r10 r10
cmp_di_sidisp16:
	cmp_reg16_idxdisp16 r11 r10

cmp_ax_didisp16:
	cmp_reg16_idxdisp16 r4 r11
cmp_cx_didisp16:
	cmp_reg16_idxdisp16 r5 r11
cmp_dx_didisp16:
	cmp_reg16_idxdisp16 r6 r11
cmp_bx_didisp16:
	cmp_reg16_idxdisp16 r7 r11
cmp_sp_didisp16:
	cmp_reg16_idxdisp16 r8 r11
cmp_bp_didisp16:
	cmp_reg16_idxdisp16 r9 r11
cmp_si_didisp16:
	cmp_reg16_idxdisp16 r10 r11
cmp_di_didisp16:
	cmp_reg16_idxdisp16 r11 r11

cmp_ax_bxdisp16:
	cmp_reg16_idxdisp16 r4 r7
cmp_cx_bxdisp16:
	cmp_reg16_idxdisp16 r5 r7
cmp_dx_bxdisp16:
	cmp_reg16_idxdisp16 r6 r7
cmp_bx_bxdisp16:
	cmp_reg16_idxdisp16 r7 r7
cmp_sp_bxdisp16:
	cmp_reg16_idxdisp16 r8 r7
cmp_bp_bxdisp16:
	cmp_reg16_idxdisp16 r9 r7
cmp_si_bxdisp16:
	cmp_reg16_idxdisp16 r10 r7
cmp_di_bxdisp16:
	cmp_reg16_idxdisp16 r11 r7

.macro cmp_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		cmp_r16_r0_bp_\reg
.endm

cmp_ax_bpdisp16:
	cmp_reg16_bpdisp16 r4
cmp_cx_bpdisp16:
	cmp_reg16_bpdisp16 r5
cmp_dx_bpdisp16:
	cmp_reg16_bpdisp16 r6
cmp_bx_bpdisp16:
	cmp_reg16_bpdisp16 r7
cmp_sp_bpdisp16:
	cmp_reg16_bpdisp16 r8
cmp_bp_bpdisp16:
	cmp_reg16_bpdisp16 r9
cmp_si_bpdisp16:
	cmp_reg16_bpdisp16 r10
cmp_di_bpdisp16:
	cmp_reg16_bpdisp16 r11


// --- registers ---
	
.macro cmp_reg16_reg16 rl rr
	mov		r0, \rl, lsl #16
	cmp		r0, \rr, lsl #16
	b		complement_carry
.endm
	
cmp_ax_ax:
	cmp_reg16_reg16		r4 r4
cmp_ax_cx:
	cmp_reg16_reg16		r4 r5
cmp_ax_dx:
	cmp_reg16_reg16		r4 r6
cmp_ax_bx:
	cmp_reg16_reg16		r4 r7
cmp_ax_sp:
	cmp_reg16_reg16		r4 r8
cmp_ax_bp:
	cmp_reg16_reg16		r4 r9
cmp_ax_si:
	cmp_reg16_reg16		r4 r10
cmp_ax_di:
	cmp_reg16_reg16		r4 r11
cmp_cx_ax:
	cmp_reg16_reg16		r5 r4
cmp_cx_cx:
	cmp_reg16_reg16		r5 r5
cmp_cx_dx:
	cmp_reg16_reg16		r5 r6
cmp_cx_bx:
	cmp_reg16_reg16		r5 r7
cmp_cx_sp:
	cmp_reg16_reg16		r5 r8
cmp_cx_bp:
	cmp_reg16_reg16		r5 r9
cmp_cx_si:
	cmp_reg16_reg16		r5 r10
cmp_cx_di:
	cmp_reg16_reg16		r5 r11
cmp_dx_ax:
	cmp_reg16_reg16		r6 r4
cmp_dx_cx:
	cmp_reg16_reg16		r6 r5
cmp_dx_dx:
	cmp_reg16_reg16		r6 r6
cmp_dx_bx:
	cmp_reg16_reg16		r6 r7
cmp_dx_sp:
	cmp_reg16_reg16		r6 r8
cmp_dx_bp:
	cmp_reg16_reg16		r6 r9
cmp_dx_si:
	cmp_reg16_reg16		r6 r10
cmp_dx_di:
	cmp_reg16_reg16		r6 r11
cmp_bx_ax:
	cmp_reg16_reg16		r7 r4
cmp_bx_cx:
	cmp_reg16_reg16		r7 r5
cmp_bx_dx:
	cmp_reg16_reg16		r7 r6
cmp_bx_bx:
	cmp_reg16_reg16		r7 r7
cmp_bx_sp:
	cmp_reg16_reg16		r7 r8
cmp_bx_bp:
	cmp_reg16_reg16		r7 r9
cmp_bx_si:
	cmp_reg16_reg16		r7 r10
cmp_bx_di:
	cmp_reg16_reg16		r7 r11
cmp_sp_ax:
	cmp_reg16_reg16		r8 r4
cmp_sp_cx:
	cmp_reg16_reg16		r8 r5
cmp_sp_dx:
	cmp_reg16_reg16		r8 r6
cmp_sp_bx:
	cmp_reg16_reg16		r8 r7
cmp_sp_sp:
	cmp_reg16_reg16		r8 r8
cmp_sp_bp:
	cmp_reg16_reg16		r8 r9
cmp_sp_si:
	cmp_reg16_reg16		r8 r10
cmp_sp_di:
	cmp_reg16_reg16		r8 r11
cmp_bp_ax:
	cmp_reg16_reg16		r9 r4
cmp_bp_cx:
	cmp_reg16_reg16		r9 r5
cmp_bp_dx:
	cmp_reg16_reg16		r9 r6
cmp_bp_bx:
	cmp_reg16_reg16		r9 r7
cmp_bp_sp:
	cmp_reg16_reg16		r9 r8
cmp_bp_bp:
	cmp_reg16_reg16		r9 r9
cmp_bp_si:
	cmp_reg16_reg16		r9 r10
cmp_bp_di:
	cmp_reg16_reg16		r9 r11
cmp_si_ax:
	cmp_reg16_reg16		r10 r4
cmp_si_cx:
	cmp_reg16_reg16		r10 r5
cmp_si_dx:
	cmp_reg16_reg16		r10 r6
cmp_si_bx:
	cmp_reg16_reg16		r10 r7
cmp_si_sp:
	cmp_reg16_reg16		r10 r8
cmp_si_bp:
	cmp_reg16_reg16		r10 r9
cmp_si_si:
	cmp_reg16_reg16		r10 r10
cmp_si_di:
	cmp_reg16_reg16		r10 r11
cmp_di_ax:
	cmp_reg16_reg16		r11 r4
cmp_di_cx:
	cmp_reg16_reg16		r11 r5
cmp_di_dx:
	cmp_reg16_reg16		r11 r6
cmp_di_bx:
	cmp_reg16_reg16		r11 r7
cmp_di_sp:
	cmp_reg16_reg16		r11 r8
cmp_di_bp:
	cmp_reg16_reg16		r11 r9
cmp_di_si:
	cmp_reg16_reg16		r11 r10
cmp_di_di:
	cmp_reg16_reg16		r11 r11

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

// ------------------- 3C = CMP AL,imm8 --------------------------------
op_3c:
	ldrb	r0,[r12],#1				// Load the immediate byte to r0, increment r12 by 1
	mov		r1, eax, lsl #24		// Shift the AL value to the topmost byte of r1
	cmp		r1, r0, lsl #24			// Shift the immediate byte also to the topmost byte, and then compare the values
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)

// ------------------- 3D = CMP AX,imm16 -------------------------------
op_3d:
	ldrb	r0,[r12],#1				// Load the immediate byte to r0, increment r12 by 1
	ldrb	r1,[r12],#1				// Load the immediate byte to r0, increment r12 by 1
	mov		r2, eax, lsl #16
	orr		r0, r1, lsl #8
	cmp		r2, r0, lsl #16			// Shift the immediate value also to the topmost halfword, and then compare the values
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)

// ------------------- 3F = AAS ----------------------------------------
//
// if((AL & 0xF) > 9 || AF == 1) {
//	AL = AL - 6;
//	AH = AH - 1;
//	AF = 1;
//	CF = 1;
// }
// else {
//	CF = 0;
//	AF = 0;
// }
// AL = AL & 0xF;
//
op_3f:
	ldr		r2, [sp, #SP_FLAGS]					// r2 = current x86 flags (for FLAG_AF)
	mov		r0, #0								// Clear all ARM flags
	//------
	// if ((reg_al & 0xf) > 9)
	//------
	and		r1, eax, #0x0F
	cmp		r1, #9
	bgt		1f									//	{
	//------
	// else if (get_AF())
	//------
2:	tst		r2, #FLAG_AF
	beq		4f									//	{
	and		r1, eax, #0xFF						//		SETFLAGBIT(OF,((reg_al>=0x80) && (reg_al<=0x85)));
	cmp		r1, #0x85
	bgt		1f
	cmp		r1, #0x80
	blt		1f
	orr		r0, #ARM_OVER
1:	ror		eax, #16
	sub		eax, #0x01000000
	sub		eax, #0x00060000					//		reg_ax -= 0x106;
	ror		eax, #16
	orr		r0, #ARM_CARRY						//		SETFLAGBIT(CF,true);
	orr		r2, #FLAG_AF						//		SETFLAGBIT(AF,true); }
	//------
	// SETFLAGBIT(ZF,(reg_al == 0));
	//------
4:	tst		eax, #0xFF
	orreq	r0, #ARM_ZERO
	//------
	// SETFLAGBIT(SF,(reg_al&0x80));
	//------
	tst		eax, #0x80
	orrne	r0, #ARM_NEG
	//------
	// SETFLAGBIT(PF,parity_lookup[reg_al]);
	//------
	//------
	// reg_al &= 0x0F;
	//------
	bic		eax, #0xF0
	str		r2, [sp, #SP_FLAGS]					// Save FLAG_AF
	b		restore_flags_from_r0
	
// =================== 40..47 = INC reg16 ==============================
// Opcodes 40..47 for AX, CX, DX, BX, SP, BP, SI, DI
// INC reg16 is like ADD reg16,1, except the Carry flag is not changed.
//
.macro inc_reg16 reg
	mrs		r0,cpsr					// r0 = Current flags
	mov		r1, \reg, lsl #16
	eor		\reg, r1, lsr #16
	adds	r1, #0x00010000			// Add 1 to the high halfword
	orr		\reg, r1, lsr #16
	mrs		r1,cpsr					// r1 = Flags after increment
	and		r0, #0x20000000			// r0 = Only the original Carry flag bit
	bic		r1, #0x20000000			// r1 = New flags with Carry cleared
	orr		r0, r1					// r0 = new flags + original Carry flag
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0
.endm

op_40:								// inc AX
	inc_reg16 r4
op_41:								// inc CX
	inc_reg16 r5
op_42:								// inc DX
	inc_reg16 r6
op_43:								// inc BX
	inc_reg16 r7
op_44:								// inc SP Note! This will break stack alignment unless it is followed by another INC SP!
	inc_reg16 r8
op_45:								// inc BP
	inc_reg16 r9
op_46:								// inc SI
	inc_reg16 r10
op_47:								// inc DI
	inc_reg16 r11

// =================== 48..4F = DEC reg16 ==============================
// Opcodes 48..4F for AX, CX, DX, BX, SP, BP, SI, DI
// DEC reg16 is like SUB reg16,1, except the Carry flag is not changed.
//
.macro dec_reg16 reg
	mrs		r0,cpsr					// r0 = Current flags
	mov		r1, \reg, lsl #16
	eor		\reg, r1, lsr #16
	subs	r1, #0x00010000			// Add 1 to the high halfword
	orr		\reg, r1, lsr #16
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Only the original Carry flag bit
	bic		r1, #0x20000000			// r1 = New flags with Carry cleared
	orr		r0, r1					// r0 = new flags
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0
.endm

op_48:								// DEC AX
	dec_reg16 r4
op_49:								// DEC CX
	dec_reg16 r5
op_4a:								// DEC DX
	dec_reg16 r6
op_4b:								// DEC BX
	dec_reg16 r7
	.global	op_4c
op_4c:								// DEC SP Note! This will break stack alignment unless it is followed by another DEC SP!
	dec_reg16 r8
op_4d:								// DEC BP
	dec_reg16 r9
op_4e:								// DEC SI
	dec_reg16 r10
op_4f:								// DEC DI
	dec_reg16 r11

// =================== 50..57 = PUSH reg16 ==============================
// Opcodes 50..57 for AX, CX, DX, BX, SP, BP, SI, DI

.macro push_reg16 reg
	mov		r1, \reg, lsr #8
	push_low_hi \reg r1 r2 r3
	b		loop
.endm

op_50:
	push_reg16 eax
op_51:
	push_reg16 ecx
op_52:
	push_reg16 edx
op_53:
	push_reg16 ebx
op_54:
	//-------
	// Windows 3.0 uses PUSH SP to determine if it is running on a 80186 processor.
	// If the value pushed is not the original value of the stack pointer, this is a 80186 processor.
	//-------
	mov		r0, esp
	mov		r1, r0, lsr #8
	push_low_hi r0 r1 r2 r3
	b		loop
op_55:
	push_reg16 ebp
op_56:
	push_reg16 esi
op_57:
	push_reg16 edi

// =================== 58..5F = POP reg16 ==============================
// Opcodes 58..5F for AX, CX, DX, BX, SP, BP, SI, DI

.macro pop_reg16 reg
	pop_reg_low_tmp r0 r1
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, \reg, lsl #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

op_58:
	pop_reg16 eax
op_59:
	pop_reg16 ecx
op_5a:
	pop_reg16 edx
op_5b:
	pop_reg16 ebx
op_5c:
	pop_reg16 esp
op_5d:
	pop_reg16 ebp
op_5e:
	pop_reg16 esi
op_5f:
	pop_reg16 edi

// ------------------- 60 = PUSHA ---------------------------------------
// Push AX, CX, DX, BX, orig SP, BP, SI, DI
//
// Note! This is a 80186+ opcode!
//
op_60:
	mov		r1, esp
	push_hword eax r0 r2
	push_hword ecx r0 r2
	push_hword edx r0 r2
	push_hword ebx r0 r2
	push_hword r1 r0 r2						// SP
	push_hword ebp r0 r2
	push_hword esi r0 r2
	push_hword edi r0 r2
	b		loop

// ------------------- 61 = POPA ---------------------------------------
// Pop DI, SI, BP, (nothing), BX, DX, CX, AX
//
// Note! This is a 80186+ opcode!
//
op_61:
	pop_reg_low_tmp r0 r1
	lsr		edi, #16
	orr		edi, r0, edi, lsl #16
	pop_reg_low_tmp r0 r1
	lsr		esi, #16
	orr		esi, r0, esi, lsl #16
	pop_reg_low_tmp r0 r1
	lsr		ebp, #16
	orr		ebp, r0, ebp, lsl #16
	add		r8, #2					// (nothing)
	pop_reg_low_tmp r0 r1
	lsr		ebx, #16
	orr		ebx, r0, ebx, lsl #16
	pop_reg_low_tmp r0 r1
	lsr		edx, #16
	orr		edx, r0, edx, lsl #16
	pop_reg_low_tmp r0 r1
	lsr		ecx, #16
	orr		ecx, r0, ecx, lsl #16
	pop_reg_low_tmp r0 r1
	lsr		eax, #16
	orr		eax, r0, eax, lsl #16
	b		loop

// ------------------- 68 = PUSH imm16 ---------------------------------
//
// Note! This is a 80186+ opcode!
//
op_68:
	ldrb	r0,[r12],#1				// Load the immediate byte to r0, increment r12 by 1
	ldrb	r1,[r12],#1				// Load the immediate byte to r0, increment r12 by 1
	push_low_hi r0 r1 r2 r3
	b		loop

	.ltorg

	.text
	.align 2

// ------------------- 66 = 32-bit override ----------------------------

	.global bad_386_opcode_back1
bad_386_opcode_back1:
	sub		r12,#1
	b		.unknown

	.ltorg
	
// ------------------- 69 = IMUL r16,r/m16,imm16 ------------------------
//
// Note! This is a 80186+ opcode!
// TODO! Handle overflow and carry flags! Both should be cleared when the result fits into target.
//
//
// 69048A00 		imul ax,[si],008A
// 69D20005		imul dx,dx,0500
//
op_69:
	modrm_jump_16
// 0 (idx only)
	.word imul_imm16_ax_bxsi, imul_imm16_ax_bxdi, imul_imm16_ax_bpsi, imul_imm16_ax_bpdi, imul_imm16_ax_siidx, imul_imm16_ax_diidx, imul_imm16_ax_disp16, imul_imm16_ax_bxidx
	.word imul_imm16_cx_bxsi, imul_imm16_cx_bxdi, imul_imm16_cx_bpsi, imul_imm16_cx_bpdi, imul_imm16_cx_siidx, imul_imm16_cx_diidx, imul_imm16_cx_disp16, imul_imm16_cx_bxidx
	.word imul_imm16_dx_bxsi, imul_imm16_dx_bxdi, imul_imm16_dx_bpsi, imul_imm16_dx_bpdi, imul_imm16_dx_siidx, imul_imm16_dx_diidx, imul_imm16_dx_disp16, imul_imm16_dx_bxidx
	.word imul_imm16_bx_bxsi, imul_imm16_bx_bxdi, imul_imm16_bx_bpsi, imul_imm16_bx_bpdi, imul_imm16_bx_siidx, imul_imm16_bx_diidx, imul_imm16_bx_disp16, imul_imm16_bx_bxidx
	.word imul_imm16_sp_bxsi, imul_imm16_sp_bxdi, imul_imm16_sp_bpsi, imul_imm16_sp_bpdi, imul_imm16_sp_siidx, imul_imm16_sp_diidx, imul_imm16_sp_disp16, imul_imm16_sp_bxidx
	.word imul_imm16_bp_bxsi, imul_imm16_bp_bxdi, imul_imm16_bp_bpsi, imul_imm16_bp_bpdi, imul_imm16_bp_siidx, imul_imm16_bp_diidx, imul_imm16_bp_disp16, imul_imm16_bp_bxidx
	.word imul_imm16_si_bxsi, imul_imm16_si_bxdi, imul_imm16_si_bpsi, imul_imm16_si_bpdi, imul_imm16_si_siidx, imul_imm16_si_diidx, imul_imm16_si_disp16, imul_imm16_si_bxidx
	.word imul_imm16_di_bxsi, imul_imm16_di_bxdi, imul_imm16_di_bpsi, imul_imm16_di_bpdi, imul_imm16_di_siidx, imul_imm16_di_diidx, imul_imm16_di_disp16, imul_imm16_di_bxidx
//0x40
	.word imul_imm16_ax_bxsidisp8, imul_imm16_ax_bxdidisp8, imul_imm16_ax_bpsid8, imul_imm16_ax_bpdid8, imul_imm16_ax_sidisp8, imul_imm16_ax_didisp8, imul_imm16_ax_bpdisp8, imul_imm16_ax_bxdisp8
	.word imul_imm16_cx_bxsidisp8, imul_imm16_cx_bxdidisp8, imul_imm16_cx_bpsid8, imul_imm16_cx_bpdid8, imul_imm16_cx_sidisp8, imul_imm16_cx_didisp8, imul_imm16_cx_bpdisp8, imul_imm16_cx_bxdisp8
	.word imul_imm16_dx_bxsidisp8, imul_imm16_dx_bxdidisp8, imul_imm16_dx_bpsid8, imul_imm16_dx_bpdid8, imul_imm16_dx_sidisp8, imul_imm16_dx_didisp8, imul_imm16_dx_bpdisp8, imul_imm16_dx_bxdisp8
	.word imul_imm16_bx_bxsidisp8, imul_imm16_bx_bxdidisp8, imul_imm16_bx_bpsid8, imul_imm16_bx_bpdid8, imul_imm16_bx_sidisp8, imul_imm16_bx_didisp8, imul_imm16_bx_bpdisp8, imul_imm16_bx_bxdisp8
	.word imul_imm16_sp_bxsidisp8, imul_imm16_sp_bxdidisp8, imul_imm16_sp_bpsid8, imul_imm16_sp_bpdid8, imul_imm16_sp_sidisp8, imul_imm16_sp_didisp8, imul_imm16_sp_bpdisp8, imul_imm16_sp_bxdisp8
	.word imul_imm16_bp_bxsidisp8, imul_imm16_bp_bxdidisp8, imul_imm16_bp_bpsid8, imul_imm16_bp_bpdid8, imul_imm16_bp_sidisp8, imul_imm16_bp_didisp8, imul_imm16_bp_bpdisp8, imul_imm16_bp_bxdisp8
	.word imul_imm16_si_bxsidisp8, imul_imm16_si_bxdidisp8, imul_imm16_si_bpsid8, imul_imm16_si_bpdid8, imul_imm16_si_sidisp8, imul_imm16_si_didisp8, imul_imm16_si_bpdisp8, imul_imm16_si_bxdisp8
	.word imul_imm16_di_bxsidisp8, imul_imm16_di_bxdidisp8, imul_imm16_di_bpsid8, imul_imm16_di_bpdid8, imul_imm16_di_sidisp8, imul_imm16_di_didisp8, imul_imm16_di_bpdisp8, imul_imm16_di_bxdisp8
//0x80 (+disp16)
	.word imul_imm16_ax_bxsidisp16, imul_imm16_ax_bxdidisp16, imul_imm16_ax_bpsid16, imul_imm16_ax_bpdid16, imul_imm16_ax_sidisp16, imul_imm16_ax_didisp16, imul_imm16_ax_bpdisp16, imul_imm16_ax_bxdisp16
	.word imul_imm16_cx_bxsidisp16, imul_imm16_cx_bxdidisp16, imul_imm16_cx_bpsid16, imul_imm16_cx_bpdid16, imul_imm16_cx_sidisp16, imul_imm16_cx_didisp16, imul_imm16_cx_bpdisp16, imul_imm16_cx_bxdisp16
	.word imul_imm16_dx_bxsidisp16, imul_imm16_dx_bxdidisp16, imul_imm16_dx_bpsid16, imul_imm16_dx_bpdid16, imul_imm16_dx_sidisp16, imul_imm16_dx_didisp16, imul_imm16_dx_bpdisp16, imul_imm16_dx_bxdisp16
	.word imul_imm16_bx_bxsidisp16, imul_imm16_bx_bxdidisp16, imul_imm16_bx_bpsid16, imul_imm16_bx_bpdid16, imul_imm16_bx_sidisp16, imul_imm16_bx_didisp16, imul_imm16_bx_bpdisp16, imul_imm16_bx_bxdisp16
	.word imul_imm16_sp_bxsidisp16, imul_imm16_sp_bxdidisp16, imul_imm16_sp_bpsid16, imul_imm16_sp_bpdid16, imul_imm16_sp_sidisp16, imul_imm16_sp_didisp16, imul_imm16_sp_bpdisp16, imul_imm16_sp_bxdisp16
	.word imul_imm16_bp_bxsidisp16, imul_imm16_bp_bxdidisp16, imul_imm16_bp_bpsid16, imul_imm16_bp_bpdid16, imul_imm16_bp_sidisp16, imul_imm16_bp_didisp16, imul_imm16_bp_bpdisp16, imul_imm16_bp_bxdisp16
	.word imul_imm16_si_bxsidisp16, imul_imm16_si_bxdidisp16, imul_imm16_si_bpsid16, imul_imm16_si_bpdid16, imul_imm16_si_sidisp16, imul_imm16_si_didisp16, imul_imm16_si_bpdisp16, imul_imm16_si_bxdisp16
	.word imul_imm16_di_bxsidisp16, imul_imm16_di_bxdidisp16, imul_imm16_di_bpsid16, imul_imm16_di_bpdid16, imul_imm16_di_sidisp16, imul_imm16_di_didisp16, imul_imm16_di_bpdisp16, imul_imm16_di_bxdisp16
//0xC0
	.word imul_ax_ax_imm16, imul_ax_cx_imm16, imul_ax_dx_imm16, imul_ax_bx_imm16, imul_ax_sp_imm16, imul_ax_bp_imm16, imul_ax_si_imm16, imul_ax_di_imm16
	.word imul_cx_ax_imm16, imul_cx_cx_imm16, imul_cx_dx_imm16, imul_cx_bx_imm16, imul_cx_sp_imm16, imul_cx_bp_imm16, imul_cx_si_imm16, imul_cx_di_imm16
	.word imul_dx_ax_imm16, imul_dx_cx_imm16, imul_dx_dx_imm16, imul_dx_bx_imm16, imul_dx_sp_imm16, imul_dx_bp_imm16, imul_dx_si_imm16, imul_dx_di_imm16
	.word imul_bx_ax_imm16, imul_bx_cx_imm16, imul_bx_dx_imm16, imul_bx_bx_imm16, imul_bx_sp_imm16, imul_bx_bp_imm16, imul_bx_si_imm16, imul_bx_di_imm16
	.word imul_sp_ax_imm16, imul_sp_cx_imm16, imul_sp_dx_imm16, imul_sp_bx_imm16, imul_sp_sp_imm16, imul_sp_bp_imm16, imul_sp_si_imm16, imul_sp_di_imm16
	.word imul_bp_ax_imm16, imul_bp_cx_imm16, imul_bp_dx_imm16, imul_bp_bx_imm16, imul_bp_sp_imm16, imul_bp_bp_imm16, imul_bp_si_imm16, imul_bp_di_imm16
	.word imul_si_ax_imm16, imul_si_cx_imm16, imul_si_dx_imm16, imul_si_bx_imm16, imul_si_sp_imm16, imul_si_bp_imm16, imul_si_si_imm16, imul_si_di_imm16
	.word imul_di_ax_imm16, imul_di_cx_imm16, imul_di_dx_imm16, imul_di_bx_imm16, imul_di_sp_imm16, imul_di_bp_imm16, imul_di_si_imm16, imul_di_di_imm16

// These are called from "cpu_67.s":

	.global imul_imm16_ax_siidx, imul_imm16_ax_diidx, imul_imm16_ax_bxidx
	.global imul_imm16_cx_siidx, imul_imm16_cx_diidx, imul_imm16_cx_bxidx
	.global imul_imm16_dx_siidx, imul_imm16_dx_diidx, imul_imm16_dx_bxidx
	.global imul_imm16_bx_siidx, imul_imm16_bx_diidx, imul_imm16_bx_bxidx
	.global imul_imm16_sp_siidx, imul_imm16_sp_diidx, imul_imm16_sp_bxidx
	.global imul_imm16_bp_siidx, imul_imm16_bp_diidx, imul_imm16_bp_bxidx
	.global imul_imm16_si_siidx, imul_imm16_si_diidx, imul_imm16_si_bxidx
	.global imul_imm16_di_siidx, imul_imm16_di_diidx, imul_imm16_di_bxidx
	.global imul_imm16_ax_sidisp8, imul_imm16_ax_didisp8, imul_imm16_ax_bpdisp8, imul_imm16_ax_bxdisp8
	.global imul_imm16_cx_sidisp8, imul_imm16_cx_didisp8, imul_imm16_cx_bpdisp8, imul_imm16_cx_bxdisp8
	.global imul_imm16_dx_sidisp8, imul_imm16_dx_didisp8, imul_imm16_dx_bpdisp8, imul_imm16_dx_bxdisp8
	.global imul_imm16_bx_sidisp8, imul_imm16_bx_didisp8, imul_imm16_bx_bpdisp8, imul_imm16_bx_bxdisp8
	.global imul_imm16_sp_sidisp8, imul_imm16_sp_didisp8, imul_imm16_sp_bpdisp8, imul_imm16_sp_bxdisp8
	.global imul_imm16_bp_sidisp8, imul_imm16_bp_didisp8, imul_imm16_bp_bpdisp8, imul_imm16_bp_bxdisp8
	.global imul_imm16_si_sidisp8, imul_imm16_si_didisp8, imul_imm16_si_bpdisp8, imul_imm16_si_bxdisp8
	.global imul_imm16_di_sidisp8, imul_imm16_di_didisp8, imul_imm16_di_bpdisp8, imul_imm16_di_bxdisp8

	.global imul_ax_ax_imm16, imul_ax_cx_imm16, imul_ax_dx_imm16, imul_ax_bx_imm16, imul_ax_sp_imm16, imul_ax_bp_imm16, imul_ax_si_imm16, imul_ax_di_imm16
	.global imul_cx_ax_imm16, imul_cx_cx_imm16, imul_cx_dx_imm16, imul_cx_bx_imm16, imul_cx_sp_imm16, imul_cx_bp_imm16, imul_cx_si_imm16, imul_cx_di_imm16
	.global imul_dx_ax_imm16, imul_dx_cx_imm16, imul_dx_dx_imm16, imul_dx_bx_imm16, imul_dx_sp_imm16, imul_dx_bp_imm16, imul_dx_si_imm16, imul_dx_di_imm16
	.global imul_bx_ax_imm16, imul_bx_cx_imm16, imul_bx_dx_imm16, imul_bx_bx_imm16, imul_bx_sp_imm16, imul_bx_bp_imm16, imul_bx_si_imm16, imul_bx_di_imm16
	.global imul_sp_ax_imm16, imul_sp_cx_imm16, imul_sp_dx_imm16, imul_sp_bx_imm16, imul_sp_sp_imm16, imul_sp_bp_imm16, imul_sp_si_imm16, imul_sp_di_imm16
	.global imul_bp_ax_imm16, imul_bp_cx_imm16, imul_bp_dx_imm16, imul_bp_bx_imm16, imul_bp_sp_imm16, imul_bp_bp_imm16, imul_bp_si_imm16, imul_bp_di_imm16
	.global imul_si_ax_imm16, imul_si_cx_imm16, imul_si_dx_imm16, imul_si_bx_imm16, imul_si_sp_imm16, imul_si_bp_imm16, imul_si_si_imm16, imul_si_di_imm16
	.global imul_di_ax_imm16, imul_di_cx_imm16, imul_di_dx_imm16, imul_di_bx_imm16, imul_di_sp_imm16, imul_di_bp_imm16, imul_di_si_imm16, imul_di_di_imm16

.macro imul_imm16_reg_r0 reg
	.global	imul_imm16_reg16_r0_bp_\reg
imul_imm16_reg16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	imul_imm16_reg16_r0_\reg
imul_imm16_reg16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_69_RAM_\reg bad_EGA_opcode_2 bad_MODEX_opcode_2
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_69_RAM_\reg:
	ldrb	r0,[r2] 					// Load byte to r0
	ldrsb	r1,[r2, #1]					// Get signed high byte
	ldrb	r2,[r12], #1
	ldrsb	r3,[r12], #1
	orr		r0, r1, lsl #8				// Now r0 = signed [disp16] value
	orr		r1, r2, r3, lsl #8			// Now r1 = signed imm16 value
	mul		r2, r0, r1
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r2, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r2, #0, #16
#endif
	b		loop	
.endm

	imul_imm16_reg_r0 r4
	imul_imm16_reg_r0 r5
	imul_imm16_reg_r0 r6
	imul_imm16_reg_r0 r7
	imul_imm16_reg_r0 r8
	imul_imm16_reg_r0 r9
	imul_imm16_reg_r0 r10
	imul_imm16_reg_r0 r11
	
// --- [idx] ---

.macro imul_imm16_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		imul_imm16_reg16_r0_\reg
.endm

imul_imm16_ax_bxsi:
	imul_imm16_reg16_bxidx r4 r10
imul_imm16_cx_bxsi:
	imul_imm16_reg16_bxidx r5 r10
imul_imm16_dx_bxsi:
	imul_imm16_reg16_bxidx r6 r10
imul_imm16_bx_bxsi:
	imul_imm16_reg16_bxidx r7 r10
imul_imm16_sp_bxsi:
	imul_imm16_reg16_bxidx r8 r10
imul_imm16_bp_bxsi:
	imul_imm16_reg16_bxidx r9 r10
imul_imm16_si_bxsi:
	imul_imm16_reg16_bxidx r10 r10
imul_imm16_di_bxsi:
	imul_imm16_reg16_bxidx r11 r10

imul_imm16_ax_bxdi:
	imul_imm16_reg16_bxidx r4 r11
imul_imm16_cx_bxdi:
	imul_imm16_reg16_bxidx r5 r11
imul_imm16_dx_bxdi:
	imul_imm16_reg16_bxidx r6 r11
imul_imm16_bx_bxdi:
	imul_imm16_reg16_bxidx r7 r11
imul_imm16_sp_bxdi:
	imul_imm16_reg16_bxidx r8 r11
imul_imm16_bp_bxdi:
	imul_imm16_reg16_bxidx r9 r11
imul_imm16_si_bxdi:
	imul_imm16_reg16_bxidx r10 r11
imul_imm16_di_bxdi:
	imul_imm16_reg16_bxidx r11 r11

.macro imul_imm16_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		imul_imm16_reg16_r0_bp_\reg
.endm

imul_imm16_ax_bpsi:
	imul_imm16_reg16_bpidx r4 r10
imul_imm16_cx_bpsi:
	imul_imm16_reg16_bpidx r5 r10
imul_imm16_dx_bpsi:
	imul_imm16_reg16_bpidx r6 r10
imul_imm16_bx_bpsi:
	imul_imm16_reg16_bpidx r7 r10
imul_imm16_sp_bpsi:
	imul_imm16_reg16_bpidx r8 r10
imul_imm16_bp_bpsi:
	imul_imm16_reg16_bpidx r9 r10
imul_imm16_si_bpsi:
	imul_imm16_reg16_bpidx r10 r10
imul_imm16_di_bpsi:
	imul_imm16_reg16_bpidx r11 r10

imul_imm16_ax_bpdi:
	imul_imm16_reg16_bpidx r4 r11
imul_imm16_cx_bpdi:
	imul_imm16_reg16_bpidx r5 r11
imul_imm16_dx_bpdi:
	imul_imm16_reg16_bpidx r6 r11
imul_imm16_bx_bpdi:
	imul_imm16_reg16_bpidx r7 r11
imul_imm16_sp_bpdi:
	imul_imm16_reg16_bpidx r8 r11
imul_imm16_bp_bpdi:
	imul_imm16_reg16_bpidx r9 r11
imul_imm16_si_bpdi:
	imul_imm16_reg16_bpidx r10 r11
imul_imm16_di_bpdi:
	imul_imm16_reg16_bpidx r11 r11

.macro imul_imm16_reg16_idx reg idx
	mov		r0, \idx
	b		imul_imm16_reg16_r0_\reg
.endm

imul_imm16_ax_siidx:
	imul_imm16_reg16_idx r4 r10
imul_imm16_cx_siidx:
	imul_imm16_reg16_idx r5 r10
imul_imm16_dx_siidx:
	imul_imm16_reg16_idx r6 r10
imul_imm16_bx_siidx:
	imul_imm16_reg16_idx r7 r10
imul_imm16_sp_siidx:
	imul_imm16_reg16_idx r8 r10
imul_imm16_bp_siidx:
	imul_imm16_reg16_idx r9 r10
imul_imm16_si_siidx:
	imul_imm16_reg16_idx r10 r10
imul_imm16_di_siidx:
	imul_imm16_reg16_idx r11 r10

imul_imm16_ax_diidx:
	imul_imm16_reg16_idx r4 r11
imul_imm16_cx_diidx:
	imul_imm16_reg16_idx r5 r11
imul_imm16_dx_diidx:
	imul_imm16_reg16_idx r6 r11
imul_imm16_bx_diidx:
	imul_imm16_reg16_idx r7 r11
imul_imm16_sp_diidx:
	imul_imm16_reg16_idx r8 r11
imul_imm16_bp_diidx:
	imul_imm16_reg16_idx r9 r11
imul_imm16_si_diidx:
	imul_imm16_reg16_idx r10 r11
imul_imm16_di_diidx:
	imul_imm16_reg16_idx r11 r11

imul_imm16_ax_bxidx:
	imul_imm16_reg16_idx r4 r7
imul_imm16_cx_bxidx:
	imul_imm16_reg16_idx r5 r7
imul_imm16_dx_bxidx:
	imul_imm16_reg16_idx r6 r7
imul_imm16_bx_bxidx:
	imul_imm16_reg16_idx r7 r7
imul_imm16_sp_bxidx:
	imul_imm16_reg16_idx r8 r7
imul_imm16_bp_bxidx:
	imul_imm16_reg16_idx r9 r7
imul_imm16_si_bxidx:
	imul_imm16_reg16_idx r10 r7
imul_imm16_di_bxidx:
	imul_imm16_reg16_idx r11 r7

.macro imul_imm16_reg16_disp16 reg
	r0_from_disp16
	b		imul_imm16_reg16_r0_\reg
.endm

imul_imm16_ax_disp16:
	imul_imm16_reg16_disp16 r4
imul_imm16_cx_disp16:
	imul_imm16_reg16_disp16 r5
imul_imm16_dx_disp16:
	imul_imm16_reg16_disp16 r6
imul_imm16_bx_disp16:
	imul_imm16_reg16_disp16 r7
imul_imm16_sp_disp16:
	imul_imm16_reg16_disp16 r8
imul_imm16_bp_disp16:
	imul_imm16_reg16_disp16 r9
imul_imm16_si_disp16:
	imul_imm16_reg16_disp16 r10
imul_imm16_di_disp16:
	imul_imm16_reg16_disp16 r11

// --- [idx+disp8] ---

.macro imul_imm16_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		imul_imm16_reg16_r0_\reg
.endm

imul_imm16_ax_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r4 r10
imul_imm16_cx_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r5 r10
imul_imm16_dx_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r6 r10
imul_imm16_bx_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r7 r10
imul_imm16_sp_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r8 r10
imul_imm16_bp_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r9 r10
imul_imm16_si_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r10 r10
imul_imm16_di_bxsidisp8:
	imul_imm16_reg16_bxidxdisp8 r11 r10

imul_imm16_ax_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r4 r11
imul_imm16_cx_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r5 r11
imul_imm16_dx_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r6 r11
imul_imm16_bx_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r7 r11
imul_imm16_sp_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r8 r11
imul_imm16_bp_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r9 r11
imul_imm16_si_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r10 r11
imul_imm16_di_bxdidisp8:
	imul_imm16_reg16_bxidxdisp8 r11 r11

.macro imul_imm16_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		imul_imm16_reg16_r0_bp_\reg
.endm

imul_imm16_ax_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r4 r10
imul_imm16_cx_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r5 r10
imul_imm16_dx_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r6 r10
imul_imm16_bx_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r7 r10
imul_imm16_sp_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r8 r10
imul_imm16_bp_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r9 r10
imul_imm16_si_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r10 r10
imul_imm16_di_bpsid8:
	imul_imm16_reg16_bpidxdisp8 r11 r10

imul_imm16_ax_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r4 r11
imul_imm16_cx_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r5 r11
imul_imm16_dx_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r6 r11
imul_imm16_bx_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r7 r11
imul_imm16_sp_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r8 r11
imul_imm16_bp_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r9 r11
imul_imm16_si_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r10 r11
imul_imm16_di_bpdid8:
	imul_imm16_reg16_bpidxdisp8 r11 r11

.macro imul_imm16_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		imul_imm16_reg16_r0_\reg
.endm

imul_imm16_ax_sidisp8:
	imul_imm16_reg16_idxdisp8 r4 r10
imul_imm16_cx_sidisp8:
	imul_imm16_reg16_idxdisp8 r5 r10
imul_imm16_dx_sidisp8:
	imul_imm16_reg16_idxdisp8 r6 r10
imul_imm16_bx_sidisp8:
	imul_imm16_reg16_idxdisp8 r7 r10
imul_imm16_sp_sidisp8:
	imul_imm16_reg16_idxdisp8 r8 r10
imul_imm16_bp_sidisp8:
	imul_imm16_reg16_idxdisp8 r9 r10
imul_imm16_si_sidisp8:
	imul_imm16_reg16_idxdisp8 r10 r10
imul_imm16_di_sidisp8:
	imul_imm16_reg16_idxdisp8 r11 r10

imul_imm16_ax_didisp8:
	imul_imm16_reg16_idxdisp8 r4 r11
imul_imm16_cx_didisp8:
	imul_imm16_reg16_idxdisp8 r5 r11
imul_imm16_dx_didisp8:
	imul_imm16_reg16_idxdisp8 r6 r11
imul_imm16_bx_didisp8:
	imul_imm16_reg16_idxdisp8 r7 r11
imul_imm16_sp_didisp8:
	imul_imm16_reg16_idxdisp8 r8 r11
imul_imm16_bp_didisp8:
	imul_imm16_reg16_idxdisp8 r9 r11
imul_imm16_si_didisp8:
	imul_imm16_reg16_idxdisp8 r10 r11
imul_imm16_di_didisp8:
	imul_imm16_reg16_idxdisp8 r11 r11

imul_imm16_ax_bxdisp8:
	imul_imm16_reg16_idxdisp8 r4 r7
imul_imm16_cx_bxdisp8:
	imul_imm16_reg16_idxdisp8 r5 r7
imul_imm16_dx_bxdisp8:
	imul_imm16_reg16_idxdisp8 r6 r7
imul_imm16_bx_bxdisp8:
	imul_imm16_reg16_idxdisp8 r7 r7
imul_imm16_sp_bxdisp8:
	imul_imm16_reg16_idxdisp8 r8 r7
imul_imm16_bp_bxdisp8:
	imul_imm16_reg16_idxdisp8 r9 r7
imul_imm16_si_bxdisp8:
	imul_imm16_reg16_idxdisp8 r10 r7
imul_imm16_di_bxdisp8:
	imul_imm16_reg16_idxdisp8 r11 r7

.macro imul_imm16_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		imul_imm16_reg16_r0_bp_\reg
.endm

imul_imm16_ax_bpdisp8:
	imul_imm16_reg16_bpdisp8 r4
imul_imm16_cx_bpdisp8:
	imul_imm16_reg16_bpdisp8 r5
imul_imm16_dx_bpdisp8:
	imul_imm16_reg16_bpdisp8 r6
imul_imm16_bx_bpdisp8:
	imul_imm16_reg16_bpdisp8 r7
imul_imm16_sp_bpdisp8:
	imul_imm16_reg16_bpdisp8 r8
imul_imm16_bp_bpdisp8:
	imul_imm16_reg16_bpdisp8 r9
imul_imm16_si_bpdisp8:
	imul_imm16_reg16_bpdisp8 r10
imul_imm16_di_bpdisp8:
	imul_imm16_reg16_bpdisp8 r11

// --- [idx+disp16] ---
//
.macro imul_imm16_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		imul_imm16_reg16_r0_\reg
.endm

imul_imm16_ax_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r4 r10
imul_imm16_cx_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r5 r10
imul_imm16_dx_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r6 r10
imul_imm16_bx_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r7 r10
imul_imm16_sp_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r8 r10
imul_imm16_bp_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r9 r10
imul_imm16_si_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r10 r10
imul_imm16_di_bxsidisp16:
	imul_imm16_reg16_bxidxdisp16 r11 r10

imul_imm16_ax_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r4 r11
imul_imm16_cx_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r5 r11
imul_imm16_dx_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r6 r11
imul_imm16_bx_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r7 r11
imul_imm16_sp_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r8 r11
imul_imm16_bp_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r9 r11
imul_imm16_si_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r10 r11
imul_imm16_di_bxdidisp16:
	imul_imm16_reg16_bxidxdisp16 r11 r11

.macro imul_imm16_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		imul_imm16_reg16_r0_bp_\reg
.endm

imul_imm16_ax_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r4 r10
imul_imm16_cx_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r5 r10
imul_imm16_dx_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r6 r10
imul_imm16_bx_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r7 r10
imul_imm16_sp_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r8 r10
imul_imm16_bp_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r9 r10
imul_imm16_si_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r10 r10
imul_imm16_di_bpsid16:
	imul_imm16_reg16_bpidxdisp16 r11 r10

imul_imm16_ax_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r4 r11
imul_imm16_cx_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r5 r11
imul_imm16_dx_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r6 r11
imul_imm16_bx_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r7 r11
imul_imm16_sp_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r8 r11
imul_imm16_bp_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r9 r11
imul_imm16_si_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r10 r11
imul_imm16_di_bpdid16:
	imul_imm16_reg16_bpidxdisp16 r11 r11

.macro imul_imm16_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		imul_imm16_reg16_r0_\reg
.endm

imul_imm16_ax_sidisp16:
	imul_imm16_reg16_idxdisp16 r4 r10
imul_imm16_cx_sidisp16:
	imul_imm16_reg16_idxdisp16 r5 r10
imul_imm16_dx_sidisp16:
	imul_imm16_reg16_idxdisp16 r6 r10
imul_imm16_bx_sidisp16:
	imul_imm16_reg16_idxdisp16 r7 r10
imul_imm16_sp_sidisp16:
	imul_imm16_reg16_idxdisp16 r8 r10
imul_imm16_bp_sidisp16:
	imul_imm16_reg16_idxdisp16 r9 r10
imul_imm16_si_sidisp16:
	imul_imm16_reg16_idxdisp16 r10 r10
imul_imm16_di_sidisp16:
	imul_imm16_reg16_idxdisp16 r11 r10

imul_imm16_ax_didisp16:
	imul_imm16_reg16_idxdisp16 r4 r11
imul_imm16_cx_didisp16:
	imul_imm16_reg16_idxdisp16 r5 r11
imul_imm16_dx_didisp16:
	imul_imm16_reg16_idxdisp16 r6 r11
imul_imm16_bx_didisp16:
	imul_imm16_reg16_idxdisp16 r7 r11
imul_imm16_sp_didisp16:
	imul_imm16_reg16_idxdisp16 r8 r11
imul_imm16_bp_didisp16:
	imul_imm16_reg16_idxdisp16 r9 r11
imul_imm16_si_didisp16:
	imul_imm16_reg16_idxdisp16 r10 r11
imul_imm16_di_didisp16:
	imul_imm16_reg16_idxdisp16 r11 r11

imul_imm16_ax_bxdisp16:
	imul_imm16_reg16_idxdisp16 r4 r7
imul_imm16_cx_bxdisp16:
	imul_imm16_reg16_idxdisp16 r5 r7
imul_imm16_dx_bxdisp16:
	imul_imm16_reg16_idxdisp16 r6 r7
imul_imm16_bx_bxdisp16:
	imul_imm16_reg16_idxdisp16 r7 r7
imul_imm16_sp_bxdisp16:
	imul_imm16_reg16_idxdisp16 r8 r7
imul_imm16_bp_bxdisp16:
	imul_imm16_reg16_idxdisp16 r9 r7
imul_imm16_si_bxdisp16:
	imul_imm16_reg16_idxdisp16 r10 r7
imul_imm16_di_bxdisp16:
	imul_imm16_reg16_idxdisp16 r11 r7

.macro imul_imm16_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		imul_imm16_reg16_r0_bp_\reg
.endm

imul_imm16_ax_bpdisp16:
	imul_imm16_reg16_bpdisp16 r4
imul_imm16_cx_bpdisp16:
	imul_imm16_reg16_bpdisp16 r5
imul_imm16_dx_bpdisp16:
	imul_imm16_reg16_bpdisp16 r6
imul_imm16_bx_bpdisp16:
	imul_imm16_reg16_bpdisp16 r7
imul_imm16_sp_bpdisp16:
	imul_imm16_reg16_bpdisp16 r8
imul_imm16_bp_bpdisp16:
	imul_imm16_reg16_bpdisp16 r9
imul_imm16_si_bpdisp16:
	imul_imm16_reg16_bpdisp16 r10
imul_imm16_di_bpdisp16:
	imul_imm16_reg16_bpdisp16 r11

// --- [registers] ---

.macro imul_reg1_reg2_imm16 reg1 reg2
	ldrb	r0,[r12], #1
	ldrsb	r1,[r12], #1
#if defined(RPi) || defined(Roku)
	lsl		r2, \reg2, #16
	asr		r2, #16						// Now r2 = signed reg2 value
#else
	sbfx	r2, \reg2, #0, #16
#endif
	orr		r0, r1, lsl #8				// Now r0 = signed imm16 value	
	mul		r1, r0, r2
#if defined(RPi) || defined(Roku)
	lsr		\reg1, #16
	orr		\reg1, r1, lsl #16
	ror		\reg1, #16
#else
	bfi		\reg1, r1, #0, #16
#endif
	b		loop	
.endm

imul_ax_ax_imm16:
	imul_reg1_reg2_imm16 r4 r4
imul_cx_ax_imm16:
	imul_reg1_reg2_imm16 r5 r4
imul_dx_ax_imm16:
	imul_reg1_reg2_imm16 r6 r4
imul_bx_ax_imm16:
	imul_reg1_reg2_imm16 r7 r4
imul_sp_ax_imm16:
	imul_reg1_reg2_imm16 r8 r4
imul_bp_ax_imm16:
	imul_reg1_reg2_imm16 r9 r4
imul_si_ax_imm16:
	imul_reg1_reg2_imm16 r10 r4
imul_di_ax_imm16:
	imul_reg1_reg2_imm16 r11 r4

imul_ax_cx_imm16:
	imul_reg1_reg2_imm16 r4 r5
imul_cx_cx_imm16:
	imul_reg1_reg2_imm16 r5 r5
imul_dx_cx_imm16:
	imul_reg1_reg2_imm16 r6 r5
imul_bx_cx_imm16:
	imul_reg1_reg2_imm16 r7 r5
imul_sp_cx_imm16:
	imul_reg1_reg2_imm16 r8 r5
imul_bp_cx_imm16:
	imul_reg1_reg2_imm16 r9 r5
imul_si_cx_imm16:
	imul_reg1_reg2_imm16 r10 r5
imul_di_cx_imm16:
	imul_reg1_reg2_imm16 r11 r5

imul_ax_dx_imm16:
	imul_reg1_reg2_imm16 r4 r6
imul_cx_dx_imm16:
	imul_reg1_reg2_imm16 r5 r6
imul_dx_dx_imm16:
	imul_reg1_reg2_imm16 r6 r6
imul_bx_dx_imm16:
	imul_reg1_reg2_imm16 r7 r6
imul_sp_dx_imm16:
	imul_reg1_reg2_imm16 r8 r6
imul_bp_dx_imm16:
	imul_reg1_reg2_imm16 r9 r6
imul_si_dx_imm16:
	imul_reg1_reg2_imm16 r10 r6
imul_di_dx_imm16:
	imul_reg1_reg2_imm16 r11 r6

imul_ax_bx_imm16:
	imul_reg1_reg2_imm16 r4 r7
imul_cx_bx_imm16:
	imul_reg1_reg2_imm16 r5 r7
imul_dx_bx_imm16:
	imul_reg1_reg2_imm16 r6 r7
imul_bx_bx_imm16:
	imul_reg1_reg2_imm16 r7 r7
imul_sp_bx_imm16:
	imul_reg1_reg2_imm16 r8 r7
imul_bp_bx_imm16:
	imul_reg1_reg2_imm16 r9 r7
imul_si_bx_imm16:
	imul_reg1_reg2_imm16 r10 r7
imul_di_bx_imm16:
	imul_reg1_reg2_imm16 r11 r7

imul_ax_sp_imm16:
	imul_reg1_reg2_imm16 r4 r8
imul_cx_sp_imm16:
	imul_reg1_reg2_imm16 r5 r8
imul_dx_sp_imm16:
	imul_reg1_reg2_imm16 r6 r8
imul_bx_sp_imm16:
	imul_reg1_reg2_imm16 r7 r8
imul_sp_sp_imm16:
	imul_reg1_reg2_imm16 r8 r8
imul_bp_sp_imm16:
	imul_reg1_reg2_imm16 r9 r8
imul_si_sp_imm16:
	imul_reg1_reg2_imm16 r10 r8
imul_di_sp_imm16:
	imul_reg1_reg2_imm16 r11 r8

imul_ax_bp_imm16:
	imul_reg1_reg2_imm16 r4 r9
imul_cx_bp_imm16:
	imul_reg1_reg2_imm16 r5 r9
imul_dx_bp_imm16:
	imul_reg1_reg2_imm16 r6 r9
imul_bx_bp_imm16:
	imul_reg1_reg2_imm16 r7 r9
imul_sp_bp_imm16:
	imul_reg1_reg2_imm16 r8 r9
imul_bp_bp_imm16:
	imul_reg1_reg2_imm16 r9 r9
imul_si_bp_imm16:
	imul_reg1_reg2_imm16 r10 r9
imul_di_bp_imm16:
	imul_reg1_reg2_imm16 r11 r9

imul_ax_si_imm16:
	imul_reg1_reg2_imm16 r4 r10
imul_cx_si_imm16:
	imul_reg1_reg2_imm16 r5 r10
imul_dx_si_imm16:
	imul_reg1_reg2_imm16 r6 r10
imul_bx_si_imm16:
	imul_reg1_reg2_imm16 r7 r10
imul_sp_si_imm16:
	imul_reg1_reg2_imm16 r8 r10
imul_bp_si_imm16:
	imul_reg1_reg2_imm16 r9 r10
imul_si_si_imm16:
	imul_reg1_reg2_imm16 r10 r10
imul_di_si_imm16:
	imul_reg1_reg2_imm16 r11 r10

imul_ax_di_imm16:
	imul_reg1_reg2_imm16 r4 r11
imul_cx_di_imm16:
	imul_reg1_reg2_imm16 r5 r11
imul_dx_di_imm16:
	imul_reg1_reg2_imm16 r6 r11
imul_bx_di_imm16:
	imul_reg1_reg2_imm16 r7 r11
imul_sp_di_imm16:
	imul_reg1_reg2_imm16 r8 r11
imul_bp_di_imm16:
	imul_reg1_reg2_imm16 r9 r11
imul_si_di_imm16:
	imul_reg1_reg2_imm16 r10 r11
imul_di_di_imm16:
	imul_reg1_reg2_imm16 r11 r11
	

// ------------------- 6A = PUSH imm8 ----------------------------------
//
// Note! This is a 80186+ opcode!
//
op_6a:
	ldrsb	r0,[r12],#1							// Load the sign-extended imm8 value to r0, increment r12 by 1
	mov		r1, r0, lsr #8
	push_low_hi r0 r1 r2 r3
	b		loop

// ------------------- 6B = IMUL r16,r/m16,imm8 ------------------------
// IMUL SI,BX,1D = 6BF31D => mod = 11, reg = 110 (SI), rm = 011 (BX)
// 6BBDE20015    imul di,[di+00E2],15
//
// Note! This is a 80186+ opcode!
// TODO! Handle overflow and carry flags!
//
//
op_6b:
	modrm_jump_16
// 0 (idx only)
	.word imul_imm8_ax_bxsi, imul_imm8_ax_bxdi, imul_imm8_ax_bpsi, imul_imm8_ax_bpdi, imul_imm8_ax_siidx, imul_imm8_ax_diidx, imul_imm8_ax_disp16, imul_imm8_ax_bxidx
	.word imul_imm8_cx_bxsi, imul_imm8_cx_bxdi, imul_imm8_cx_bpsi, imul_imm8_cx_bpdi, imul_imm8_cx_siidx, imul_imm8_cx_diidx, imul_imm8_cx_disp16, imul_imm8_cx_bxidx
	.word imul_imm8_dx_bxsi, imul_imm8_dx_bxdi, imul_imm8_dx_bpsi, imul_imm8_dx_bpdi, imul_imm8_dx_siidx, imul_imm8_dx_diidx, imul_imm8_dx_disp16, imul_imm8_dx_bxidx
	.word imul_imm8_bx_bxsi, imul_imm8_bx_bxdi, imul_imm8_bx_bpsi, imul_imm8_bx_bpdi, imul_imm8_bx_siidx, imul_imm8_bx_diidx, imul_imm8_bx_disp16, imul_imm8_bx_bxidx
	.word imul_imm8_sp_bxsi, imul_imm8_sp_bxdi, imul_imm8_sp_bpsi, imul_imm8_sp_bpdi, imul_imm8_sp_siidx, imul_imm8_sp_diidx, imul_imm8_sp_disp16, imul_imm8_sp_bxidx
	.word imul_imm8_bp_bxsi, imul_imm8_bp_bxdi, imul_imm8_bp_bpsi, imul_imm8_bp_bpdi, imul_imm8_bp_siidx, imul_imm8_bp_diidx, imul_imm8_bp_disp16, imul_imm8_bp_bxidx
	.word imul_imm8_si_bxsi, imul_imm8_si_bxdi, imul_imm8_si_bpsi, imul_imm8_si_bpdi, imul_imm8_si_siidx, imul_imm8_si_diidx, imul_imm8_si_disp16, imul_imm8_si_bxidx
	.word imul_imm8_di_bxsi, imul_imm8_di_bxdi, imul_imm8_di_bpsi, imul_imm8_di_bpdi, imul_imm8_di_siidx, imul_imm8_di_diidx, imul_imm8_di_disp16, imul_imm8_di_bxidx
//0x40
	.word imul_imm8_ax_bxsidisp8, imul_imm8_ax_bxdidisp8, imul_imm8_ax_bpsid8, imul_imm8_ax_bpdid8, imul_imm8_ax_sidisp8, imul_imm8_ax_didisp8, imul_imm8_ax_bpdisp8, imul_imm8_ax_bxdisp8
	.word imul_imm8_cx_bxsidisp8, imul_imm8_cx_bxdidisp8, imul_imm8_cx_bpsid8, imul_imm8_cx_bpdid8, imul_imm8_cx_sidisp8, imul_imm8_cx_didisp8, imul_imm8_cx_bpdisp8, imul_imm8_cx_bxdisp8
	.word imul_imm8_dx_bxsidisp8, imul_imm8_dx_bxdidisp8, imul_imm8_dx_bpsid8, imul_imm8_dx_bpdid8, imul_imm8_dx_sidisp8, imul_imm8_dx_didisp8, imul_imm8_dx_bpdisp8, imul_imm8_dx_bxdisp8
	.word imul_imm8_bx_bxsidisp8, imul_imm8_bx_bxdidisp8, imul_imm8_bx_bpsid8, imul_imm8_bx_bpdid8, imul_imm8_bx_sidisp8, imul_imm8_bx_didisp8, imul_imm8_bx_bpdisp8, imul_imm8_bx_bxdisp8
	.word imul_imm8_sp_bxsidisp8, imul_imm8_sp_bxdidisp8, imul_imm8_sp_bpsid8, imul_imm8_sp_bpdid8, imul_imm8_sp_sidisp8, imul_imm8_sp_didisp8, imul_imm8_sp_bpdisp8, imul_imm8_sp_bxdisp8
	.word imul_imm8_bp_bxsidisp8, imul_imm8_bp_bxdidisp8, imul_imm8_bp_bpsid8, imul_imm8_bp_bpdid8, imul_imm8_bp_sidisp8, imul_imm8_bp_didisp8, imul_imm8_bp_bpdisp8, imul_imm8_bp_bxdisp8
	.word imul_imm8_si_bxsidisp8, imul_imm8_si_bxdidisp8, imul_imm8_si_bpsid8, imul_imm8_si_bpdid8, imul_imm8_si_sidisp8, imul_imm8_si_didisp8, imul_imm8_si_bpdisp8, imul_imm8_si_bxdisp8
	.word imul_imm8_di_bxsidisp8, imul_imm8_di_bxdidisp8, imul_imm8_di_bpsid8, imul_imm8_di_bpdid8, imul_imm8_di_sidisp8, imul_imm8_di_didisp8, imul_imm8_di_bpdisp8, imul_imm8_di_bxdisp8
//0x80 (+disp16)
	.word imul_imm8_ax_bxsidisp16, imul_imm8_ax_bxdidisp16, imul_imm8_ax_bpsid16, imul_imm8_ax_bpdid16, imul_imm8_ax_sidisp16, imul_imm8_ax_didisp16, imul_imm8_ax_bpdisp16, imul_imm8_ax_bxdisp16
	.word imul_imm8_cx_bxsidisp16, imul_imm8_cx_bxdidisp16, imul_imm8_cx_bpsid16, imul_imm8_cx_bpdid16, imul_imm8_cx_sidisp16, imul_imm8_cx_didisp16, imul_imm8_cx_bpdisp16, imul_imm8_cx_bxdisp16
	.word imul_imm8_dx_bxsidisp16, imul_imm8_dx_bxdidisp16, imul_imm8_dx_bpsid16, imul_imm8_dx_bpdid16, imul_imm8_dx_sidisp16, imul_imm8_dx_didisp16, imul_imm8_dx_bpdisp16, imul_imm8_dx_bxdisp16
	.word imul_imm8_bx_bxsidisp16, imul_imm8_bx_bxdidisp16, imul_imm8_bx_bpsid16, imul_imm8_bx_bpdid16, imul_imm8_bx_sidisp16, imul_imm8_bx_didisp16, imul_imm8_bx_bpdisp16, imul_imm8_bx_bxdisp16
	.word imul_imm8_sp_bxsidisp16, imul_imm8_sp_bxdidisp16, imul_imm8_sp_bpsid16, imul_imm8_sp_bpdid16, imul_imm8_sp_sidisp16, imul_imm8_sp_didisp16, imul_imm8_sp_bpdisp16, imul_imm8_sp_bxdisp16
	.word imul_imm8_bp_bxsidisp16, imul_imm8_bp_bxdidisp16, imul_imm8_bp_bpsid16, imul_imm8_bp_bpdid16, imul_imm8_bp_sidisp16, imul_imm8_bp_didisp16, imul_imm8_bp_bpdisp16, imul_imm8_bp_bxdisp16
	.word imul_imm8_si_bxsidisp16, imul_imm8_si_bxdidisp16, imul_imm8_si_bpsid16, imul_imm8_si_bpdid16, imul_imm8_si_sidisp16, imul_imm8_si_didisp16, imul_imm8_si_bpdisp16, imul_imm8_si_bxdisp16
	.word imul_imm8_di_bxsidisp16, imul_imm8_di_bxdidisp16, imul_imm8_di_bpsid16, imul_imm8_di_bpdid16, imul_imm8_di_sidisp16, imul_imm8_di_didisp16, imul_imm8_di_bpdisp16, imul_imm8_di_bxdisp16
//0xC0
	.word imul_ax_ax_imm8, imul_ax_cx_imm8, imul_ax_dx_imm8, imul_ax_bx_imm8, imul_ax_sp_imm8, imul_ax_bp_imm8, imul_ax_si_imm8, imul_ax_di_imm8
	.word imul_cx_ax_imm8, imul_cx_cx_imm8, imul_cx_dx_imm8, imul_cx_bx_imm8, imul_cx_sp_imm8, imul_cx_bp_imm8, imul_cx_si_imm8, imul_cx_di_imm8
	.word imul_dx_ax_imm8, imul_dx_cx_imm8, imul_dx_dx_imm8, imul_dx_bx_imm8, imul_dx_sp_imm8, imul_dx_bp_imm8, imul_dx_si_imm8, imul_dx_di_imm8
	.word imul_bx_ax_imm8, imul_bx_cx_imm8, imul_bx_dx_imm8, imul_bx_bx_imm8, imul_bx_sp_imm8, imul_bx_bp_imm8, imul_bx_si_imm8, imul_bx_di_imm8
	.word imul_sp_ax_imm8, imul_sp_cx_imm8, imul_sp_dx_imm8, imul_sp_bx_imm8, imul_sp_sp_imm8, imul_sp_bp_imm8, imul_sp_si_imm8, imul_sp_di_imm8
	.word imul_bp_ax_imm8, imul_bp_cx_imm8, imul_bp_dx_imm8, imul_bp_bx_imm8, imul_bp_sp_imm8, imul_bp_bp_imm8, imul_bp_si_imm8, imul_bp_di_imm8
	.word imul_si_ax_imm8, imul_si_cx_imm8, imul_si_dx_imm8, imul_si_bx_imm8, imul_si_sp_imm8, imul_si_bp_imm8, imul_si_si_imm8, imul_si_di_imm8
	.word imul_di_ax_imm8, imul_di_cx_imm8, imul_di_dx_imm8, imul_di_bx_imm8, imul_di_sp_imm8, imul_di_bp_imm8, imul_di_si_imm8, imul_di_di_imm8

// These are called from "cpu_67.s":

	.global imul_imm8_ax_siidx, imul_imm8_ax_diidx, imul_imm8_ax_bxidx
	.global imul_imm8_cx_siidx, imul_imm8_cx_diidx, imul_imm8_cx_bxidx
	.global imul_imm8_dx_siidx, imul_imm8_dx_diidx, imul_imm8_dx_bxidx
	.global imul_imm8_bx_siidx, imul_imm8_bx_diidx, imul_imm8_bx_bxidx
	.global imul_imm8_sp_siidx, imul_imm8_sp_diidx, imul_imm8_sp_bxidx
	.global imul_imm8_bp_siidx, imul_imm8_bp_diidx, imul_imm8_bp_bxidx
	.global imul_imm8_si_siidx, imul_imm8_si_diidx, imul_imm8_si_bxidx
	.global imul_imm8_di_siidx, imul_imm8_di_diidx, imul_imm8_di_bxidx
	.global imul_imm8_ax_sidisp8, imul_imm8_ax_didisp8, imul_imm8_ax_bpdisp8, imul_imm8_ax_bxdisp8
	.global imul_imm8_cx_sidisp8, imul_imm8_cx_didisp8, imul_imm8_cx_bpdisp8, imul_imm8_cx_bxdisp8
	.global imul_imm8_dx_sidisp8, imul_imm8_dx_didisp8, imul_imm8_dx_bpdisp8, imul_imm8_dx_bxdisp8
	.global imul_imm8_bx_sidisp8, imul_imm8_bx_didisp8, imul_imm8_bx_bpdisp8, imul_imm8_bx_bxdisp8
	.global imul_imm8_sp_sidisp8, imul_imm8_sp_didisp8, imul_imm8_sp_bpdisp8, imul_imm8_sp_bxdisp8
	.global imul_imm8_bp_sidisp8, imul_imm8_bp_didisp8, imul_imm8_bp_bpdisp8, imul_imm8_bp_bxdisp8
	.global imul_imm8_si_sidisp8, imul_imm8_si_didisp8, imul_imm8_si_bpdisp8, imul_imm8_si_bxdisp8
	.global imul_imm8_di_sidisp8, imul_imm8_di_didisp8, imul_imm8_di_bpdisp8, imul_imm8_di_bxdisp8

	.global imul_ax_ax_imm8, imul_ax_cx_imm8, imul_ax_dx_imm8, imul_ax_bx_imm8, imul_ax_sp_imm8, imul_ax_bp_imm8, imul_ax_si_imm8, imul_ax_di_imm8
	.global imul_cx_ax_imm8, imul_cx_cx_imm8, imul_cx_dx_imm8, imul_cx_bx_imm8, imul_cx_sp_imm8, imul_cx_bp_imm8, imul_cx_si_imm8, imul_cx_di_imm8
	.global imul_dx_ax_imm8, imul_dx_cx_imm8, imul_dx_dx_imm8, imul_dx_bx_imm8, imul_dx_sp_imm8, imul_dx_bp_imm8, imul_dx_si_imm8, imul_dx_di_imm8
	.global imul_bx_ax_imm8, imul_bx_cx_imm8, imul_bx_dx_imm8, imul_bx_bx_imm8, imul_bx_sp_imm8, imul_bx_bp_imm8, imul_bx_si_imm8, imul_bx_di_imm8
	.global imul_sp_ax_imm8, imul_sp_cx_imm8, imul_sp_dx_imm8, imul_sp_bx_imm8, imul_sp_sp_imm8, imul_sp_bp_imm8, imul_sp_si_imm8, imul_sp_di_imm8
	.global imul_bp_ax_imm8, imul_bp_cx_imm8, imul_bp_dx_imm8, imul_bp_bx_imm8, imul_bp_sp_imm8, imul_bp_bp_imm8, imul_bp_si_imm8, imul_bp_di_imm8
	.global imul_si_ax_imm8, imul_si_cx_imm8, imul_si_dx_imm8, imul_si_bx_imm8, imul_si_sp_imm8, imul_si_bp_imm8, imul_si_si_imm8, imul_si_di_imm8
	.global imul_di_ax_imm8, imul_di_cx_imm8, imul_di_dx_imm8, imul_di_bx_imm8, imul_di_sp_imm8, imul_di_bp_imm8, imul_di_si_imm8, imul_di_di_imm8

.macro imul_imm8_reg_r0 reg
	.global	imul_imm8_reg16_r0_bp_\reg
imul_imm8_reg16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	imul_imm8_reg16_r0_\reg
imul_imm8_reg16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_6b_RAM_\reg bad_EGA_opcode_1 bad_MODEX_opcode_1
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_6b_RAM_\reg:
	ldrb	r0,[r2] 					// Load byte to r0
	ldrsb	r1,[r2, #1]					// Get signed high byte
	ldrsb	r2,[r12], #1				// r2 = signed imm8 value
	orr		r0, r1, lsl #8				// Now r0 = signed [disp16] value
	mul		r1, r0, r2
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r1, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r1, #0, #16
#endif
	b		loop	
.endm

	imul_imm8_reg_r0 r4
	imul_imm8_reg_r0 r5
	imul_imm8_reg_r0 r6
	imul_imm8_reg_r0 r7
	imul_imm8_reg_r0 r8
	imul_imm8_reg_r0 r9
	imul_imm8_reg_r0 r10
	imul_imm8_reg_r0 r11
	
// --- [idx] ---

.macro imul_imm8_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		imul_imm8_reg16_r0_\reg
.endm

imul_imm8_ax_bxsi:
	imul_imm8_reg16_bxidx r4 r10
imul_imm8_cx_bxsi:
	imul_imm8_reg16_bxidx r5 r10
imul_imm8_dx_bxsi:
	imul_imm8_reg16_bxidx r6 r10
imul_imm8_bx_bxsi:
	imul_imm8_reg16_bxidx r7 r10
imul_imm8_sp_bxsi:
	imul_imm8_reg16_bxidx r8 r10
imul_imm8_bp_bxsi:
	imul_imm8_reg16_bxidx r9 r10
imul_imm8_si_bxsi:
	imul_imm8_reg16_bxidx r10 r10
imul_imm8_di_bxsi:
	imul_imm8_reg16_bxidx r11 r10

imul_imm8_ax_bxdi:
	imul_imm8_reg16_bxidx r4 r11
imul_imm8_cx_bxdi:
	imul_imm8_reg16_bxidx r5 r11
imul_imm8_dx_bxdi:
	imul_imm8_reg16_bxidx r6 r11
imul_imm8_bx_bxdi:
	imul_imm8_reg16_bxidx r7 r11
imul_imm8_sp_bxdi:
	imul_imm8_reg16_bxidx r8 r11
imul_imm8_bp_bxdi:
	imul_imm8_reg16_bxidx r9 r11
imul_imm8_si_bxdi:
	imul_imm8_reg16_bxidx r10 r11
imul_imm8_di_bxdi:
	imul_imm8_reg16_bxidx r11 r11

.macro imul_imm8_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		imul_imm8_reg16_r0_bp_\reg
.endm

imul_imm8_ax_bpsi:
	imul_imm8_reg16_bpidx r4 r10
imul_imm8_cx_bpsi:
	imul_imm8_reg16_bpidx r5 r10
imul_imm8_dx_bpsi:
	imul_imm8_reg16_bpidx r6 r10
imul_imm8_bx_bpsi:
	imul_imm8_reg16_bpidx r7 r10
imul_imm8_sp_bpsi:
	imul_imm8_reg16_bpidx r8 r10
imul_imm8_bp_bpsi:
	imul_imm8_reg16_bpidx r9 r10
imul_imm8_si_bpsi:
	imul_imm8_reg16_bpidx r10 r10
imul_imm8_di_bpsi:
	imul_imm8_reg16_bpidx r11 r10

imul_imm8_ax_bpdi:
	imul_imm8_reg16_bpidx r4 r11
imul_imm8_cx_bpdi:
	imul_imm8_reg16_bpidx r5 r11
imul_imm8_dx_bpdi:
	imul_imm8_reg16_bpidx r6 r11
imul_imm8_bx_bpdi:
	imul_imm8_reg16_bpidx r7 r11
imul_imm8_sp_bpdi:
	imul_imm8_reg16_bpidx r8 r11
imul_imm8_bp_bpdi:
	imul_imm8_reg16_bpidx r9 r11
imul_imm8_si_bpdi:
	imul_imm8_reg16_bpidx r10 r11
imul_imm8_di_bpdi:
	imul_imm8_reg16_bpidx r11 r11

.macro imul_imm8_reg16_idx reg idx
	mov		r0, \idx
	b		imul_imm8_reg16_r0_\reg
.endm

imul_imm8_ax_siidx:
	imul_imm8_reg16_idx r4 r10
imul_imm8_cx_siidx:
	imul_imm8_reg16_idx r5 r10
imul_imm8_dx_siidx:
	imul_imm8_reg16_idx r6 r10
imul_imm8_bx_siidx:
	imul_imm8_reg16_idx r7 r10
imul_imm8_sp_siidx:
	imul_imm8_reg16_idx r8 r10
imul_imm8_bp_siidx:
	imul_imm8_reg16_idx r9 r10
imul_imm8_si_siidx:
	imul_imm8_reg16_idx r10 r10
imul_imm8_di_siidx:
	imul_imm8_reg16_idx r11 r10

imul_imm8_ax_diidx:
	imul_imm8_reg16_idx r4 r11
imul_imm8_cx_diidx:
	imul_imm8_reg16_idx r5 r11
imul_imm8_dx_diidx:
	imul_imm8_reg16_idx r6 r11
imul_imm8_bx_diidx:
	imul_imm8_reg16_idx r7 r11
imul_imm8_sp_diidx:
	imul_imm8_reg16_idx r8 r11
imul_imm8_bp_diidx:
	imul_imm8_reg16_idx r9 r11
imul_imm8_si_diidx:
	imul_imm8_reg16_idx r10 r11
imul_imm8_di_diidx:
	imul_imm8_reg16_idx r11 r11

imul_imm8_ax_bxidx:
	imul_imm8_reg16_idx r4 r7
imul_imm8_cx_bxidx:
	imul_imm8_reg16_idx r5 r7
imul_imm8_dx_bxidx:
	imul_imm8_reg16_idx r6 r7
imul_imm8_bx_bxidx:
	imul_imm8_reg16_idx r7 r7
imul_imm8_sp_bxidx:
	imul_imm8_reg16_idx r8 r7
imul_imm8_bp_bxidx:
	imul_imm8_reg16_idx r9 r7
imul_imm8_si_bxidx:
	imul_imm8_reg16_idx r10 r7
imul_imm8_di_bxidx:
	imul_imm8_reg16_idx r11 r7

.macro imul_imm8_reg16_disp16 reg
	r0_from_disp16
	b		imul_imm8_reg16_r0_\reg
.endm

imul_imm8_ax_disp16:
	imul_imm8_reg16_disp16 r4
imul_imm8_cx_disp16:
	imul_imm8_reg16_disp16 r5
imul_imm8_dx_disp16:
	imul_imm8_reg16_disp16 r6
imul_imm8_bx_disp16:
	imul_imm8_reg16_disp16 r7
imul_imm8_sp_disp16:
	imul_imm8_reg16_disp16 r8
imul_imm8_bp_disp16:
	imul_imm8_reg16_disp16 r9
imul_imm8_si_disp16:
	imul_imm8_reg16_disp16 r10
imul_imm8_di_disp16:
	imul_imm8_reg16_disp16 r11

// --- [idx+disp8] ---

.macro imul_imm8_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		imul_imm8_reg16_r0_\reg
.endm

imul_imm8_ax_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r4 r10
imul_imm8_cx_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r5 r10
imul_imm8_dx_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r6 r10
imul_imm8_bx_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r7 r10
imul_imm8_sp_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r8 r10
imul_imm8_bp_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r9 r10
imul_imm8_si_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r10 r10
imul_imm8_di_bxsidisp8:
	imul_imm8_reg16_bxidxdisp8 r11 r10

imul_imm8_ax_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r4 r11
imul_imm8_cx_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r5 r11
imul_imm8_dx_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r6 r11
imul_imm8_bx_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r7 r11
imul_imm8_sp_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r8 r11
imul_imm8_bp_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r9 r11
imul_imm8_si_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r10 r11
imul_imm8_di_bxdidisp8:
	imul_imm8_reg16_bxidxdisp8 r11 r11

.macro imul_imm8_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		imul_imm8_reg16_r0_bp_\reg
.endm

imul_imm8_ax_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r4 r10
imul_imm8_cx_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r5 r10
imul_imm8_dx_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r6 r10
imul_imm8_bx_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r7 r10
imul_imm8_sp_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r8 r10
imul_imm8_bp_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r9 r10
imul_imm8_si_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r10 r10
imul_imm8_di_bpsid8:
	imul_imm8_reg16_bpidxdisp8 r11 r10

imul_imm8_ax_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r4 r11
imul_imm8_cx_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r5 r11
imul_imm8_dx_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r6 r11
imul_imm8_bx_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r7 r11
imul_imm8_sp_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r8 r11
imul_imm8_bp_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r9 r11
imul_imm8_si_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r10 r11
imul_imm8_di_bpdid8:
	imul_imm8_reg16_bpidxdisp8 r11 r11

.macro imul_imm8_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		imul_imm8_reg16_r0_\reg
.endm

imul_imm8_ax_sidisp8:
	imul_imm8_reg16_idxdisp8 r4 r10
imul_imm8_cx_sidisp8:
	imul_imm8_reg16_idxdisp8 r5 r10
imul_imm8_dx_sidisp8:
	imul_imm8_reg16_idxdisp8 r6 r10
imul_imm8_bx_sidisp8:
	imul_imm8_reg16_idxdisp8 r7 r10
imul_imm8_sp_sidisp8:
	imul_imm8_reg16_idxdisp8 r8 r10
imul_imm8_bp_sidisp8:
	imul_imm8_reg16_idxdisp8 r9 r10
imul_imm8_si_sidisp8:
	imul_imm8_reg16_idxdisp8 r10 r10
imul_imm8_di_sidisp8:
	imul_imm8_reg16_idxdisp8 r11 r10

imul_imm8_ax_didisp8:
	imul_imm8_reg16_idxdisp8 r4 r11
imul_imm8_cx_didisp8:
	imul_imm8_reg16_idxdisp8 r5 r11
imul_imm8_dx_didisp8:
	imul_imm8_reg16_idxdisp8 r6 r11
imul_imm8_bx_didisp8:
	imul_imm8_reg16_idxdisp8 r7 r11
imul_imm8_sp_didisp8:
	imul_imm8_reg16_idxdisp8 r8 r11
imul_imm8_bp_didisp8:
	imul_imm8_reg16_idxdisp8 r9 r11
imul_imm8_si_didisp8:
	imul_imm8_reg16_idxdisp8 r10 r11
imul_imm8_di_didisp8:
	imul_imm8_reg16_idxdisp8 r11 r11

imul_imm8_ax_bxdisp8:
	imul_imm8_reg16_idxdisp8 r4 r7
imul_imm8_cx_bxdisp8:
	imul_imm8_reg16_idxdisp8 r5 r7
imul_imm8_dx_bxdisp8:
	imul_imm8_reg16_idxdisp8 r6 r7
imul_imm8_bx_bxdisp8:
	imul_imm8_reg16_idxdisp8 r7 r7
imul_imm8_sp_bxdisp8:
	imul_imm8_reg16_idxdisp8 r8 r7
imul_imm8_bp_bxdisp8:
	imul_imm8_reg16_idxdisp8 r9 r7
imul_imm8_si_bxdisp8:
	imul_imm8_reg16_idxdisp8 r10 r7
imul_imm8_di_bxdisp8:
	imul_imm8_reg16_idxdisp8 r11 r7

.macro imul_imm8_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		imul_imm8_reg16_r0_bp_\reg
.endm

imul_imm8_ax_bpdisp8:
	imul_imm8_reg16_bpdisp8 r4
imul_imm8_cx_bpdisp8:
	imul_imm8_reg16_bpdisp8 r5
imul_imm8_dx_bpdisp8:
	imul_imm8_reg16_bpdisp8 r6
imul_imm8_bx_bpdisp8:
	imul_imm8_reg16_bpdisp8 r7
imul_imm8_sp_bpdisp8:
	imul_imm8_reg16_bpdisp8 r8
imul_imm8_bp_bpdisp8:
	imul_imm8_reg16_bpdisp8 r9
imul_imm8_si_bpdisp8:
	imul_imm8_reg16_bpdisp8 r10
imul_imm8_di_bpdisp8:
	imul_imm8_reg16_bpdisp8 r11

// --- [idx+disp16] ---
//
.macro imul_imm8_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		imul_imm8_reg16_r0_\reg
.endm

imul_imm8_ax_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r4 r10
imul_imm8_cx_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r5 r10
imul_imm8_dx_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r6 r10
imul_imm8_bx_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r7 r10
imul_imm8_sp_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r8 r10
imul_imm8_bp_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r9 r10
imul_imm8_si_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r10 r10
imul_imm8_di_bxsidisp16:
	imul_imm8_reg16_bxidxdisp16 r11 r10

imul_imm8_ax_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r4 r11
imul_imm8_cx_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r5 r11
imul_imm8_dx_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r6 r11
imul_imm8_bx_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r7 r11
imul_imm8_sp_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r8 r11
imul_imm8_bp_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r9 r11
imul_imm8_si_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r10 r11
imul_imm8_di_bxdidisp16:
	imul_imm8_reg16_bxidxdisp16 r11 r11

.macro imul_imm8_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		imul_imm8_reg16_r0_bp_\reg
.endm

imul_imm8_ax_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r4 r10
imul_imm8_cx_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r5 r10
imul_imm8_dx_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r6 r10
imul_imm8_bx_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r7 r10
imul_imm8_sp_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r8 r10
imul_imm8_bp_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r9 r10
imul_imm8_si_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r10 r10
imul_imm8_di_bpsid16:
	imul_imm8_reg16_bpidxdisp16 r11 r10

imul_imm8_ax_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r4 r11
imul_imm8_cx_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r5 r11
imul_imm8_dx_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r6 r11
imul_imm8_bx_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r7 r11
imul_imm8_sp_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r8 r11
imul_imm8_bp_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r9 r11
imul_imm8_si_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r10 r11
imul_imm8_di_bpdid16:
	imul_imm8_reg16_bpidxdisp16 r11 r11

.macro imul_imm8_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		imul_imm8_reg16_r0_\reg
.endm

imul_imm8_ax_sidisp16:
	imul_imm8_reg16_idxdisp16 r4 r10
imul_imm8_cx_sidisp16:
	imul_imm8_reg16_idxdisp16 r5 r10
imul_imm8_dx_sidisp16:
	imul_imm8_reg16_idxdisp16 r6 r10
imul_imm8_bx_sidisp16:
	imul_imm8_reg16_idxdisp16 r7 r10
imul_imm8_sp_sidisp16:
	imul_imm8_reg16_idxdisp16 r8 r10
imul_imm8_bp_sidisp16:
	imul_imm8_reg16_idxdisp16 r9 r10
imul_imm8_si_sidisp16:
	imul_imm8_reg16_idxdisp16 r10 r10
imul_imm8_di_sidisp16:
	imul_imm8_reg16_idxdisp16 r11 r10

imul_imm8_ax_didisp16:
	imul_imm8_reg16_idxdisp16 r4 r11
imul_imm8_cx_didisp16:
	imul_imm8_reg16_idxdisp16 r5 r11
imul_imm8_dx_didisp16:
	imul_imm8_reg16_idxdisp16 r6 r11
imul_imm8_bx_didisp16:
	imul_imm8_reg16_idxdisp16 r7 r11
imul_imm8_sp_didisp16:
	imul_imm8_reg16_idxdisp16 r8 r11
imul_imm8_bp_didisp16:
	imul_imm8_reg16_idxdisp16 r9 r11
imul_imm8_si_didisp16:
	imul_imm8_reg16_idxdisp16 r10 r11
imul_imm8_di_didisp16:
	imul_imm8_reg16_idxdisp16 r11 r11

imul_imm8_ax_bxdisp16:
	imul_imm8_reg16_idxdisp16 r4 r7
imul_imm8_cx_bxdisp16:
	imul_imm8_reg16_idxdisp16 r5 r7
imul_imm8_dx_bxdisp16:
	imul_imm8_reg16_idxdisp16 r6 r7
imul_imm8_bx_bxdisp16:
	imul_imm8_reg16_idxdisp16 r7 r7
imul_imm8_sp_bxdisp16:
	imul_imm8_reg16_idxdisp16 r8 r7
imul_imm8_bp_bxdisp16:
	imul_imm8_reg16_idxdisp16 r9 r7
imul_imm8_si_bxdisp16:
	imul_imm8_reg16_idxdisp16 r10 r7
imul_imm8_di_bxdisp16:
	imul_imm8_reg16_idxdisp16 r11 r7

.macro imul_imm8_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		imul_imm8_reg16_r0_bp_\reg
.endm

imul_imm8_ax_bpdisp16:
	imul_imm8_reg16_bpdisp16 r4
imul_imm8_cx_bpdisp16:
	imul_imm8_reg16_bpdisp16 r5
imul_imm8_dx_bpdisp16:
	imul_imm8_reg16_bpdisp16 r6
imul_imm8_bx_bpdisp16:
	imul_imm8_reg16_bpdisp16 r7
imul_imm8_sp_bpdisp16:
	imul_imm8_reg16_bpdisp16 r8
imul_imm8_bp_bpdisp16:
	imul_imm8_reg16_bpdisp16 r9
imul_imm8_si_bpdisp16:
	imul_imm8_reg16_bpdisp16 r10
imul_imm8_di_bpdisp16:
	imul_imm8_reg16_bpdisp16 r11

// --- registers ---

.macro imul_reg1_reg2_imm8 reg1 reg2
	ldrsb	r0,[r12],#1				// Load the sign-extended imm8 value to r0, increment r12 by 1
#if defined(RPi) || defined(Roku)
	lsl		r1, \reg2, #16
	asr		r1, #16
#else
	sbfx	r1, \reg2, #0, #16
#endif
	mul		r2, r1, r0
#if defined(RPi) || defined(Roku)
	lsr		\reg1, #16
	orr		\reg1, r2, lsl #16
	ror		\reg1, #16
#else
	bfi		\reg1, r2, #0, #16
#endif
	b		loop	
.endm

imul_ax_ax_imm8:
	imul_reg1_reg2_imm8 r4 r4
imul_ax_cx_imm8:
	imul_reg1_reg2_imm8 r4 r5
imul_ax_dx_imm8:
	imul_reg1_reg2_imm8 r4 r6
imul_ax_bx_imm8:
	imul_reg1_reg2_imm8 r4 r7
imul_ax_sp_imm8:
	imul_reg1_reg2_imm8 r4 r8
imul_ax_bp_imm8:
	imul_reg1_reg2_imm8 r4 r9
imul_ax_si_imm8:
	imul_reg1_reg2_imm8 r4 r10
imul_ax_di_imm8:
	imul_reg1_reg2_imm8 r4 r11

imul_cx_ax_imm8:
	imul_reg1_reg2_imm8 r5 r4
imul_cx_cx_imm8:
	imul_reg1_reg2_imm8 r5 r5
imul_cx_dx_imm8:
	imul_reg1_reg2_imm8 r5 r6
imul_cx_bx_imm8:
	imul_reg1_reg2_imm8 r5 r7
imul_cx_sp_imm8:
	imul_reg1_reg2_imm8 r5 r8
imul_cx_bp_imm8:
	imul_reg1_reg2_imm8 r5 r9
imul_cx_si_imm8:
	imul_reg1_reg2_imm8 r5 r10
imul_cx_di_imm8:
	imul_reg1_reg2_imm8 r5 r11

imul_dx_ax_imm8:
	imul_reg1_reg2_imm8 r6 r4
imul_dx_cx_imm8:
	imul_reg1_reg2_imm8 r6 r5
imul_dx_dx_imm8:
	imul_reg1_reg2_imm8 r6 r6
imul_dx_bx_imm8:
	imul_reg1_reg2_imm8 r6 r7
imul_dx_sp_imm8:
	imul_reg1_reg2_imm8 r6 r8
imul_dx_bp_imm8:
	imul_reg1_reg2_imm8 r6 r9
imul_dx_si_imm8:
	imul_reg1_reg2_imm8 r6 r10
imul_dx_di_imm8:
	imul_reg1_reg2_imm8 r6 r11

imul_bx_ax_imm8:
	imul_reg1_reg2_imm8 r7 r4
imul_bx_cx_imm8:
	imul_reg1_reg2_imm8 r7 r5
imul_bx_dx_imm8:
	imul_reg1_reg2_imm8 r7 r6
imul_bx_bx_imm8:
	imul_reg1_reg2_imm8 r7 r7
imul_bx_sp_imm8:
	imul_reg1_reg2_imm8 r7 r8
imul_bx_bp_imm8:
	imul_reg1_reg2_imm8 r7 r9
imul_bx_si_imm8:
	imul_reg1_reg2_imm8 r7 r10
imul_bx_di_imm8:
	imul_reg1_reg2_imm8 r7 r11

imul_sp_ax_imm8:
	imul_reg1_reg2_imm8 r8 r4
imul_sp_cx_imm8:
	imul_reg1_reg2_imm8 r8 r5
imul_sp_dx_imm8:
	imul_reg1_reg2_imm8 r8 r6
imul_sp_bx_imm8:
	imul_reg1_reg2_imm8 r8 r7
imul_sp_sp_imm8:
	imul_reg1_reg2_imm8 r8 r8
imul_sp_bp_imm8:
	imul_reg1_reg2_imm8 r8 r9
imul_sp_si_imm8:
	imul_reg1_reg2_imm8 r8 r10
imul_sp_di_imm8:
	imul_reg1_reg2_imm8 r8 r11

imul_bp_ax_imm8:
	imul_reg1_reg2_imm8 r9 r4
imul_bp_cx_imm8:
	imul_reg1_reg2_imm8 r9 r5
imul_bp_dx_imm8:
	imul_reg1_reg2_imm8 r9 r6
imul_bp_bx_imm8:
	imul_reg1_reg2_imm8 r9 r7
imul_bp_sp_imm8:
	imul_reg1_reg2_imm8 r9 r8
imul_bp_bp_imm8:
	imul_reg1_reg2_imm8 r9 r9
imul_bp_si_imm8:
	imul_reg1_reg2_imm8 r9 r10
imul_bp_di_imm8:
	imul_reg1_reg2_imm8 r9 r11

imul_si_ax_imm8:
	imul_reg1_reg2_imm8 r10 r4
imul_si_cx_imm8:
	imul_reg1_reg2_imm8 r10 r5
imul_si_dx_imm8:
	imul_reg1_reg2_imm8 r10 r6
imul_si_bx_imm8:
	imul_reg1_reg2_imm8 r10 r7
imul_si_sp_imm8:
	imul_reg1_reg2_imm8 r10 r8
imul_si_bp_imm8:
	imul_reg1_reg2_imm8 r10 r9
imul_si_si_imm8:
	imul_reg1_reg2_imm8 r10 r10
imul_si_di_imm8:
	imul_reg1_reg2_imm8 r10 r11

imul_di_ax_imm8:
	imul_reg1_reg2_imm8 r11 r4
imul_di_cx_imm8:
	imul_reg1_reg2_imm8 r11 r5
imul_di_dx_imm8:
	imul_reg1_reg2_imm8 r11 r6
imul_di_bx_imm8:
	imul_reg1_reg2_imm8 r11 r7
imul_di_sp_imm8:
	imul_reg1_reg2_imm8 r11 r8
imul_di_bp_imm8:
	imul_reg1_reg2_imm8 r11 r9
imul_di_si_imm8:
	imul_reg1_reg2_imm8 r11 r10
imul_di_di_imm8:
	imul_reg1_reg2_imm8 r11 r11


// =================== 70..7F = Conditional Jumps ======================
//
.macro cond_jump cnd
	ldrsb	r0,[r12],#1				// Load sign-extended byte to r0, increment r12 by 1
	add\cnd	r12, r12, r0			// Adjust program counter by the jump amount, if the condition is true
	b		loop
.endm

op_70:								// JO cb
	cond_jump vs
op_71:								// JNO cb
	cond_jump vc
op_72:								// JC/JB/JNAE cb
	cond_jump cs
op_73:								// JNC/JNB/JAE cb
	cond_jump cc
op_74:								// JZ/JE cb (It is more likely that the jump is NOT taken)
	cond_jump eq
op_75:								// JNZ/JNE cb (It is more likely that the jump IS taken)
	cond_jump ne
op_76:								// JBE/JNA cb (C=1 or Z=1, x86 Carry has opposite sense to ARM Carry)
	ldrsb	r0,[r12],#1				// Load sign-extended byte to r0, increment r12 by 1
	addcs	r12, r12, r0			// Adjust program counter by the jump amount, if the condition is true
	bcs		loop
	addeq	r12, r12, r0			// Adjust program counter by the jump amount, if the condition is true
	b		loop
op_77:								// JA/JNBE cb (C=0 and Z=0, x86 Carry has opposite sense to ARM Carry)
	ldrsb	r0,[r12],#1				// Load sign-extended byte to r0, increment r12 by 1
	bcs		loop
	addne	r12, r12, r0			// Adjust program counter by the jump amount, if the condition is true
	b		loop
op_78:								// JS cb
	cond_jump mi
op_79:								// JNS cb
	cond_jump pl
op_7c:								// JL/JNGE cb
	cond_jump lt
op_7d:								// JNL/JGE cb
	cond_jump ge
op_7e:								// JLE/JNG cb
	cond_jump le
op_7f:								// JG/JNLE cb
	cond_jump gt

	.text
	.align 2

	//-------
	// JP/JPE cb
	// Special hack for "The Incredible Machine" and "Turbo Science"
	//	2004:6F5D 0BFF            or   di,di
	//	2004:6F5F 7A02            jpe  6F63 ($+2)
	// Special hack for "SOR_LOR"
	//	020B:3CB4 8B5E08          mov  bx,[bp+08]
	//	020B:3CB7 83FB08          cmp  bx,0008
	//	020B:3CBA 7506            jne  3CC2 ($+6)
	//	020B:3CBC 8B1EBA17        mov  bx,[17BA]
	//	020B:3CC0 7A04            jpe  3CC6 ($+4)
	// Special hack for "Wolfenstein 3D"
	//	1FD6:1CAC F646FC03		  test byte [bp-04],03
	//	1FD6:1CB0 7A02			  jpe  1CB4
	// Special hack for "CALGAMES"
	//	120C:5851 80E7B4          and  bh,B4
	//	120C:5854 7A02            jpe  5858 ($+2)
	// Special hack for "MM3"
	//	06C9:0013 1BC3            sbb  ax,bx
	//	06C9:0015 8CD3            mov  bx,ss
	//	06C9:0017 7A1E            jpe  0037 ($+1e)
	// Special hack for "MM3"
	//	06C9:001B 350281          xor  ax,8102
	//	06C9:001E 7A17            jpe  0037 ($+17)
	// Special hack for "STARGATE"
	//	02DE:18D6 0BC0			  or   ax,ax
	//	02DE:18D8 7A22			  jpe  18FC
	// Special hack for "STARGATE"
	//	02DE:16FF 833E4A0000	  cmp  word [004A],0000
	//	02DE:1704 7A11			  jpe  1717
	// Special hack for "Crime City"
	//	1D4A:0C16 7A00            jpe  0C18 ($+0)	
	// Special hack for "Bubble Ghost" (various similar code segments)
	//	02D9:3939 240C			  and  al,0C
	//	02D9:393B 7A33			  jpe  3970 ($+33)
	// Special hack for "F29 Retaliator" (several locations)
	//	02F0:5088 84E1            test cl,ah
	//	02F0:508A 7A0C            jpe  5098 ($+c)
	// Special hack for "Chess Genius 3"
	//	1B14:3812 0BF6            or   si,si
	//	1B14:3814 0F84C102        jz   00003AD9 ($+2c1)
	//	1B14:3818 7AD4            jpe  000037EE ($-2c)
	// Special hack for "Chess Genius 3"
	//	1B14:3B90 0BF6            or   si,si
	//	1B14:3B92 B00A            mov  al,0A
	//	1B14:3B94 7A0A            jpe  00003BA0 ($+a)
	// Special hack for "Chess Genius 3"
	//	1B14:AD4D F6C488          test ah,88
	//	1B14:AD50 740A            je   0000AD5C ($+a)
	//	1B14:AD52 B1C0            mov  cl,C0
	//	1B14:AD54 7A06            jpe  0000AD5C ($+6)
	// Special hack for "Chess Genius 3"
	//	1B14:B231 A860            test al,60
	//	1B14:B233 7A4B            jpe  0000B280 ($+4b)
	// Special hack for "Chess Genius 3"
	//	1B14:7CC5 A806            test al,06
	//	1B14:7CC7 7420            je   00007CE9 ($+20)
	//	1B14:7CC9 7A1E            jpe  00007CE9 ($+1e)
	// Special hack for "Chess Genius 3"
	//	1B14:4AAB 83C308          add  bx,0008
	//	1B14:4AAE 49              dec  cx
	//	1B14:4AAF 7AD3            jpe  00004A84 ($-2d)
	// Special hack for "Chess Genius 3"
	//	1B14:58C6 A809            test al,09
	//	1B14:58C8 B004            mov  al,04
	//	1B14:58CA 7A02            jpe  000058CE ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:0BB4 C684A1E101      mov  byte [si-1E5F],01
	//	1B14:0BB9 7AF3            jpe  00000BAE ($-d)
	// Special hack for "Chess Genius 3"
	//	1B14:6562 F6C4C0          test ah,C0
	//	1B14:6565 B220            mov  dl,20
	//	1B14:6567 740A            je   00006573 ($+a)
	//	1B14:6569 B22D            mov  dl,2D
	//	1B14:656B 7906            jns  00006573 ($+6)
	//	1B14:656D B22E            mov  dl,2E
	//	1B14:656F 7A02            jpe  00006573 ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:B276 80E411          and  ah,11
	//	1B14:B279 7A01            jpe  0000B27C ($+1)
	// Special hack for "Chess Genius 3"
	//	1B14:5387 F6C5C0          test ch,C0
	//	1B14:538A 7411            je   0000539D ($+11)
	//	1B14:538C B4A2            mov  ah,A2
	//	1B14:538E 7A06            jpe  00005396 ($+6)
	// Special hack for "Chess Genius 3"
	//	1B14:54C5 A8C0            test al,C0
	//	1B14:54C7 7411            je   000054DA ($+11)
	//	1B14:54C9 790B            jns  000054D6 ($+b)
	//	1B14:54CB 7A02            jpe  000054CF ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:43BD 240C            and  al,0C
	//	1B14:43BF 7A0C            jpe  000043CD ($+c)
	// Special hack for "Chess Genius 3"
	//	1B14:45C0 A828            test al,28
	//	1B14:45C2 7431            je   000045F5 ($+31)
	//	1B14:45C4 7A32            jpe  000045F8 ($+32)
	// Special hack for "Chess Genius 3"
	//	1B14:45D7 81E38080        and  bx,8080
	//	1B14:45DB 741E            je   000045FB ($+1e)
	//	1B14:45DD 888DF009        mov  [di+09F0],cl
	//	1B14:45E1 B015            mov  al,15
	//	1B14:45E3 7A0A            jpe  000045EF ($+a)
	// Special hack for "Chess Genius 3"
	//	1B14:481F 02E4            add  ah,ah
	//	1B14:4821 7522            jne  00004845 ($+22)
	//	1B14:4823 E8CEFF          call 000047F4 ($-32)
	//	1B14:4826 66C1CD10        ror  ebp,10
	//	1B14:482A 8B3E2827        mov  di,[2728]
	//	1B14:482E 8B85780A        mov  ax,[di+0A78]
	//	1B14:4832 8A957A0A        mov  dl,[di+0A7A]
	//	1B14:4836 A2FE01          mov  [01FE],al
	//	1B14:4839 E9FAF1          jmp  00003A36 ($-e06)
	//	1B14:483C 7838            js   00004876 ($+38)
	//	1B14:483E 7A20            jpe  00004860 ($+20)
	//	1B14:4840 689948          push 4899
	//	1B14:4843 EBAF            jmp  short 000047F4 ($-51)
	//	1B14:4845 73F5            jnc  0000483C ($-b)
	//	1B14:4847 7A14            jpe  0000485D ($+14)
	// Special hack for "Chess Genius 3"
	//	1B14:449D 83C510          add  bp,0010
	//	1B14:44A0 C3              ret
	//	1B14:44A1 7A1E            jpe  000044C1 ($+1e)
	//	...
	//	1B14:44E2 892E2E27		  mov  [272E],bp
	//	1B14:44E6 73B9			  jnc  000044A1
	//	...
	//	1B14:453D 02E4			  add  ah,ah
	//	1B14:453F 75A1			  jne  000044E2
	// Special hack for "Chess Genius 3"
	//	1B14:7DB6 F6			  test ch,A0	
	//	1B14:7DB9 8B			  mov  si,[2728]
	//	1B14:7DBD 0F			  js   00007F46
	//	...
	//	1B14:7F46 EB02            jmp  short 00007F4A ($+2)
	//	1B14:7F48 7AF2            jpe  00007F3C ($-e)
	// Special hack for "Chess Genius 3"
	//	1B14:41C9 A80C            test al,0C
	//	1B14:41CB 7ABF            jpe  0000418C ($-41)
	// Special hack for "Chess Genius 3"
	//	1B14:41CD A814            test al,14
	//	1B14:41CF 7495            je   00004166 ($-6b)
	//	1B14:41D1 7AB9            jpe  0000418C ($-47)
	// Special hack for "Chess Genius 3"
	//	1B14:44E2 892E2E27        mov  [272E],bp
	//	1B14:44E6 73B9            jnc  000044A1 ($-47)
	//	1B14:44E8 7AC6            jpe  000044B0 ($-3a)
	//	...
	//	1B14:453D 02E4			  add  ah,ah
	//	1B14:453F 75A1			  jne  000044E2
	// Special hack for "Chess Genius 3"
	//	1B14:A530 80E181          and  cl,81
	//	1B14:A533 7406            je   0000A53B ($+6)
	//	1B14:A535 7906            jns  0000A53D ($+6)
	//	1B14:A537 6657            push edi
	//	1B14:A539 7A02            jpe  0000A53D ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:A77F 0AD2            or   dl,dl
	//	1B14:A781 8B86AE01        mov  ax,[bp+01AE]
	//	1B14:A785 7A02            jpe  0000A789 ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:834F F6C47E          test ah,7E
	//	1B14:8352 7402            je   00008356 ($+2)
	//	1B14:8354 7AAC            jpe  00008302 ($-54)
	// Special hack for "Chess Genius 3"
	//	1B14:83BD F606000288      test byte [0200],88
	//	1B14:83C2 7AD2            jpe  00008396 ($-2e)
	// Special hack for "Chess Genius 3"
	//	1B14:B45B F6C381          test bl,81
	//	1B14:B45E 7402            je   0000B462 ($+2)
	//	1B14:B460 7A1A            jpe  0000B47C ($+1a)
	// Special hack for "Chess Genius 3"
	//	1B14:4C95 0BFF            or   di,di
	//	1B14:4C97 75DD            jne  00004C76 ($-23)
	//	1B14:4C99 E92BFE          jmp  00004AC7 ($-1d5)
	//	1B14:4C9C 7A33            jpe  00004CD1 ($+33)
	// Special hack for "Chess Genius 3"
	//	1B14:6247 0AE4            or   ah,ah
	//	1B14:6249 7404            je   0000624F ($+4)
	//	1B14:624B 7A01            jpe  0000624E ($+1)
	// Special hack for "Chess Genius 3"
	//	117D:8483 0AC7            or   al,bh
	//	117D:8485 7AF1            jpe  00008478 ($-f)
	// Special hack for "Chess Genius 3"
	//	15E2:6889 80E309        AND	BL,09                              
	//	15E2:688C 7A1C          JPE	68AA                               	
	// Special hack for "Chess Genius 3"
	//	15E2:BAF7 2411          AND	AL,11                              
	//	15E2:BAF9 B000          MOV	AL,00                              
	//	15E2:BAFB 7A01          JPE	BAFE
	// Special hack for "Super Frog"
	//	0158:00178D77 DFE0      fstsw ax
	//	0158:00178D79 9E        sahf
	//	0158:00178D7A 7AF8      jpe  00178D74 ($-8)
	// Special hack for YADRO "DDISP"
	//	13BD:1C7C 8A66FF          mov  ah,[bp+FF]
	//	13BD:1C7F 80CC01          or   ah,01
	//	13BD:1C82 9E              sahf
	//	13BD:1C83 7B1C            jpo  1CA1 ($+1c)
	//	13BD:1C85 CD3C            int  3C
	//	13BD:1C87 9B2E			  (data)
	//	13BD:1C89 7A1B            jpe  1CA6 ($+1b)
	// Special hack for Black Knight: Marine Strike Fighter
	//	0180:00289266 F7C610000000    test si,00000010
	//	0180:0028926C 7A06            jpe  00289274 ($+6)
	// Special hack for "Star Gunner"
	//	0008:00000E75 F6C106    test cl,06
	//	0008:00000E78 748E      je   00000E08 ($-72)
	//	0008:00000E7A 7A8C      jpe  00000E08 ($-74)
	//-------
op_7a:
	mrs		r0,cpsr					// r0 = Current flags
	ldrb	r1,[r12, #-3]
	cmp		r1, #0x00
	beq		7f						// Could be "STARGATE" or Black Knight: Marine Strike Fighter
	cmp		r1, #0x02
	beq		6f						// Could be "MM3" or "Chess Genius 3"
	cmp		r1, #0x08
	beq		15f						// Could be "Chess Genius 3"
	cmp		r1, #0x0A
	beq		28f						// Could be "Chess Genius 3"
	cmp		r1, #0x0B
	beq		1f						// Could be "The Incredible Machine" / "Turbo Science" / "STARGATE" / "Chess Genius 3"
	cmp		r1, #0x10
	beq		23f						// Could be "Chess Genius 3"
	cmp		r1, #0x24
	beq		8f						// Could be "Bubble Ghost" or "CG3"
	cmp		r1, #0x2B
	beq		27f						// Could be "Chess Genius 3"
	cmp		r1, #0x66
	beq		25f						// Could be "Chess Genius 3"
	cmp		r1, #0x73
	beq		21f						// Could be "Chess Genius 3"
	cmp		r1, #0x74
	beq		14f						// Could be "Chess Genius 3" or "Star Gunner"
	cmp		r1, #0x78
	beq		22f						// Could be "Chess Genius 3"
	cmp		r1, #0x79
	beq		20f						// Could be "Chess Genius 3"
	cmp		r1, #0x84
	beq		9f						// Could be "F29 Retaliator"
	cmp		r1, #0x8C
	beq		5f						// Could be "MM3"
	cmp		r1, #0x9B
	beq		31f						// Could be YADRO "DDISP"
	cmp		r1, #0xA8
	beq		13f						// Could be "Chess Genius 3"
	cmp		r1, #0xAE
	beq		26f						// Could be "Chess Genius 3"
	cmp		r1, #0xB0
	beq		11f						// Could be "Chess Genius 3"
	cmp		r1, #0xB1
	beq		12f						// Could be "Chess Genius 3"
	cmp		r1, #0xB2
	beq		17f						// Could be "Chess Genius 3"
	cmp		r1, #0xB4
	beq		19f						// Could be "Chess Genius 3"
	cmp		r1, #0xBA
	beq		2f						// Could be "SOR_LOR"
	cmp		r1, #0xC1
	beq		10f						// Could be "Chess Genius 3"
	cmp		r1, #0xE0
	beq		30f						// Could be "Super Frog"
	cmp		r1, #0xE1
	beq		16f						// Could be "Chess Genius 3"
	cmp		r1, #0xE3
	beq		29f						// Could be "Chess Genius 3"
	cmp		r1, #0xE4
	beq		18f						// Could be "Chess Genius 3"
	cmp		r1, #0xE7
	beq		4f						// Could be "CALGAMES"
	cmp		r1, #0xEB
	beq		24f						// Could be "Chess Genius 3"
	cmp		r1, #0xFC
	beq		3f						// Could be "Wolfenstein 3D"
	//-------
	// Check for a NOP
	//-------
	ldrb	r1, [r12]
	cmp		r1, #0
	addeq	r12, #1
	beq		restore_flags_from_r0	// Back to loop, restoring flags
	b		.unsjpe

	//-------
	//	2004:6F5D 0BFF            or   di,di
	//	2004:6F5F 7A02            jpe  6F63 ($+2)
	//
	//	02DE:18D6 0BC0			  or   ax,ax
	//	02DE:18D8 7A22			  jpe  18FC
	//
	//	15E2:7CF4 0BED          OR	BP,BP                              
	//	15E2:7CF6 7A04          JPE	7CFC                               	
	//-------
1:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xFF
	moveq	r1, edi					// Put the "or di,di" result to r1
	beq		.op_7a_r1
	cmp		r1, #0xC0
	moveq	r1, eax					// Put the "or ax,ax" result to r1
	beq		.op_7a_r1
	cmp		r1, #0xED
	moveq	r1, ebp					// Put the "or bp,bp" result to r1
	beq		.op_7a_r1
	b		.unsjpe
	//-------
	// Confirm it is "mov bx,[bp+08] & cmp bx,0008 & jne 3CC2 & mov bx,[17BA]"
	//-------
2:	ldrb	r1,[r12, #-5]
	cmp		r1, #0x8B
	bne		.unsjpe
	ldrb	r1,[r12, #-7]
	cmp		r1, #0x75
	bne		.unsjpe
	ldrb	r1,[r12, #-0x0D]
	cmp		r1, #0x8B
	bne		.unsjpe
	ldrb	r1,[r12, #-0x0C]
	cmp		r1, #0x5E
	bne		.unsjpe
	ldrb	r1,[r12, #-0x0B]
	cmp		r1, #0x08
	bne		.unsjpe
	ldrb	r1,[r12, #-0x0A]
	cmp		r1, #0x83
	bne		.unsjpe
	//-------
	// Put the "mov bx,[bp+08] & cmp bx,0008" result to r1
	//-------
	ldr		lr, [sp, #SP_PHYS_SS]
	mov		r1, ebp, lsl #16
	add		r1, #0x00080000			// r1 = (BP+08) << 16
	ldrb	r1,[lr, r1, lsr #16]	// "mov bx,[bp+08]"
	sub		r1, #8					// "cmp bx,0008"
	b		.op_7a_r1
	//-------
	// Wolfenstein 3D: Confirm it is "test byte [bp-04],03" = F6 46 FC 03
	//-------
3:	ldrb	r1,[r12, #-5]
	cmp		r1, #0xF6
	bne		.unsjpe
	ldrb	r1,[r12, #-4]
	cmp		r1, #0x46
	bne		.unsjpe
	ldrb	r1,[r12, #-2]
	cmp		r1, #0x03
	bne		.unsjpe
	//-------
	// Wolfenstein 3D: Put the "test byte [bp-04],03" result to r1
	//-------
	ldr		lr, [sp, #SP_PHYS_SS]
	mov		r1, ebp, lsl #16
	sub		r1, #0x00040000			// r1 = (BP-04)<<16
	ldrb	r1,[lr, r1, lsr #16]	// r1 = byte at [BP-04]
	and		r1, #3
	b		.op_7a_r1
	//-------
	// Confirm it is "and bh,B4" = 80 E7 B4
	//-------
4:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x80
	bne		.unsjpe
	ldrb	r1,[r12, #-2]
	cmp		r1, #0xB4
	bne		.unsjpe
	//-------
	// Put the "and bh,B4" result to r1
	//-------
	mov		r1, ebx, lsr #8
	and		r1, #0xB4
	b		.op_7a_r1
	//-------
	// Confirm it is "sbb ax,bx & mov bx,ss" = 1B C3 8C D3
	//-------
5:	ldrb	r1,[r12, #-5]
	cmp		r1, #0x1B
	bne		.unsjpe
	ldrb	r1,[r12, #-4]
	cmp		r1, #0xC3
	bne		.unsjpe
	ldrb	r1,[r12, #-2]
	cmp		r1, #0xD3
	bne		.unsjpe
	//-------
	// Put the "sbb ax,bx" result to r1
	//-------
	mov		r1, eax
	b		.op_7a_r1
	//-------
	// Micro Machines 3:
	//	06C9:001B 350281          xor  ax,8102
	//	06C9:001E 7A17            jpe  0037 ($+17)
	//
	// Chess Genius 3:
	//	1B14:83BD F606000288      test byte [0200],88
	//	1B14:83C2 7AD2            jpe  00008396 ($-2e)
	//-------
6:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x35
	beq		1f						// Make sure it is Micro Machines 3
	cmp		r1, #0x00
	beq		2f						// Make sure it is Chess Genius 3
	b		.unsjpe
	//-------
	// Make sure it is Micro Machines 3
	//-------
1:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x81
	bne		.unsjpe
	//-------
	// Put the "xor ax,8102" result to r1
	//-------
	mov		r1, eax
	b		.op_7a_r1
	//-------
	// Make sure it is Chess Genius 3
	//-------
2:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x88
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x06
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	//-------
	// Put the "test byte [0200],88" result to r1
	//-------
	mov		r1, r0					// Save flags to r1
	mov		r0, #0x0200				// r0 = [0200] address
	calc_linear_address_r2_from_r0r3	
	mov		r0, r1					// Restore flags from r1
	ldrb	r1, [r2]				// Get byte from [0200]
	and		r1, #0x88
	b		.op_7a_r1
	//-------
	// Special hack for "STARGATE"
	//	02DE:16FF 833E4A0000	  cmp  word [004A],0000
	//	02DE:1704 7A11			  jpe  1717
	// Special hack for Black Knight: Marine Strike Fighter
	//	0180:00289266 F7C610000000    test si,00000010
	//	0180:0028926C 7A06            jpe  00289274 ($+6)
	//-------
7:	ldrb	r1,[r12, #-6]
	cmp		r1, #0x83
	beq		1f						// Make sure it is STARGATE
	cmp		r1, #0xC6
	beq		2f						// Make sure it is Black Knight: Marine Strike Fighter
	b		.unsjpe
	//-------
	// Confirm it is "STARGATE"
	//-------
1:	ldrb	r1,[r12, #-5]
	cmpeq	r1, #0x3E
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x4A
	ldreqb	r1,[r12, #-2]
	cmpeq	r1, #0x00
	bne		.unsjpe
	//-------
	// Put the "cmp  word [004A],0000" result to r1
	//-------
	mov		r1, r0					// Save flags to r1
	mov		r0, #0x004A				// r0 = [004A] address
	mem_handler_jump_r0r3 .op_7a_7 bad_EGA_opcode bad_MODEX_opcode
.op_7a_7:
	mov		r0, r1					// Restore flags from r1
	ldrb	r1, [r2]				// Get byte from [004A]
	b		.op_7a_r1
	//-------
	// Confirm it is Black Knight: Marine Strike Fighter
	//-------
2:	ldrb	r1,[r12, #-7]
	cmpeq	r1, #0xF7
	ldrb	r1,[r12, #-5]
	cmpeq	r1, #0x10
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x00
	ldreqb	r1,[r12, #-2]
	cmpeq	r1, #0x00
	bne		.unsjpe
	//-------
	// Put the "test si,00000010" result to r1
	//-------
	and		r1, esi, #0x10
	b		.op_7a_r1
	//-------
	// Confirm it is "and  al,imm8" = 24 imm8
	// Anding AL with the reverse imm8 mask should result in zero.
	//-------
8:	ldrb	r1,[r12, #-2]
	bic		r1, eax, r1				// r1 = eax with the mask bits cleared
	ands	r1, #0xFF				// If any AL bits are on, this was not "and AL, imm8"!
	bne		.unsjpe
	//-------
	// Put the "and  al,imm8" result into r1
	//-------
	mov		r1, eax					// Put the "and al,imm8" result to r1
	b		.op_7a_r1
	//-------
	// Confirm it is "test cl,ah" = 84 E1
	//-------
9:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xE1
	bne		.unsjpe
	//-------
	// Put the "test cl,ah" result into r1
	//-------
	mov		r1, ecx					// r1 = CL
	and		r1, eax, lsr #8			// r1 = CL and AH
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:3812 0BF6            or   si,si
	//	1B14:3814 0F84C102        jz   00003AD9 ($+2c1)
	//	1B14:3818 7AD4            jpe  000037EE ($-2c)
	//-------
10:	ldrb	r1,[r12, #-6]
	cmp		r1, #0xF6
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x0B
	bne		.unsjpe
	//-------
	// Put the "or si,si" result into r1
	//-------
	mov		r1, esi
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:3B90 0BF6            or   si,si
	//	1B14:3B92 B00A            mov  al,0A
	//	1B14:3B94 7A0A            jpe  00003BA0 ($+a)
	//
	//	1B14:58C6 A809            test al,09
	//	1B14:58C8 B004            mov  al,04
	//	1B14:58CA 7A02            jpe  000058CE ($+2)
	//
	//	1B14:45D7 81E38080        and  bx,8080
	//	1B14:45DB 741E            je   000045FB ($+1e)
	//	1B14:45DD 888DF009        mov  [di+09F0],cl
	//	1B14:45E1 B015            mov  al,15
	//	1B14:45E3 7A0A            jpe  000045EF ($+a)
	//
	//	15E2:18E3 F6C4C0        TEST	AH,C0                              
	//	15E2:18E6 B020          MOV	AL,20                              
	//	15E2:18E8 740A          JZ	18F4                               
	//	15E2:18EA B02E          MOV	AL,2E                              
	//	15E2:18EC 7A06          JPE	18F4                               
	//
	//	15E2:BAF7 2411          AND	AL,11                              
	//	15E2:BAF9 B000          MOV	AL,00                              
	//	15E2:BAFB 7A01          JPE	BAFE
	//-------
11: ldrb	r1,[r12, #-5]
	cmp		r1, #0xA8
	beq		.op_7a_parity_byte
	cmp		r1, #0x24
	beq		.op_7a_parity_byte
	cmp		r1, #0x0B
	beq		1f
	cmp		r1, #0xF0
	beq		2f
	cmp		r1, #0x74
	beq		3f
	b		.unsjpe
1:	ldrb	r1,[r12, #-4]			// Is it "or si,si"?
	cmp		r1, #0xF6
	moveq	r1, esi					// Put the "or si,si" result into r1
	beq		.op_7a_r1
	b		.unsjpe
2:	ldrb	r1, [r12, #-10]			// Is it "and bx,8080"?
	cmp		r1, #0x80
	ldreqb	r1, [r12, #-11]
	cmpeq	r1, #0x80
	ldreqb	r1, [r12, #-12]
	cmpeq	r1, #0xE3
	ldreqb	r1, [r12, #-13]
	cmpeq	r1, #0x81
	bne		.unsjpe
	and		r1, ebx, #0x80			// Put the result into r1
	b		.op_7a_r1
3:	ldrb	r1, [r12, #-6]			// Is it "test ah,C0"?
	cmp		r1, #0x20
	ldreqb	r1, [r12, #-7]
	cmpeq	r1, #0xB0
	ldreqb	r1, [r12, #-8]
	cmpeq	r1, #0xC0
	ldreqb	r1, [r12, #-9]
	cmpeq	r1, #0xC4
	ldreqb	r1, [r12, #-10]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	mov		r1, eax, lsr #8			// Put the result into r1
	and		r1, #0xC0
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:AD4D F6C488          test ah,88
	//	1B14:AD50 740A            je   0000AD5C ($+a)
	//	1B14:AD52 B1C0            mov  cl,C0
	//	1B14:AD54 7A06            jpe  0000AD5C ($+6)
	//-------
12:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x0A
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x74
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0x88
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0xC4
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	//-------
	// Put the "test ah,88" result into r1
	//-------
	mov		r1, eax, lsr #8
	and		r1, #0x88
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:B231 A860            test al,60
	//	1B14:B233 7A4B            jpe  0000B280 ($+4b)
	//
	//	1B14:41C9 A80C            test al,0C
	//	1B14:41CB 7ABF            jpe  0000418C ($-41)
	//-------
13:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x60
	cmpne	r1, #0x0C
	beq		.op_7a_parity_byte
	b		.unsjpe
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:7CC5 A806            test al,06
	//	1B14:7CC7 7420            je   00007CE9 ($+20)
	//	1B14:7CC9 7A1E            jpe  00007CE9 ($+1e)
	//
	//	1B14:45C0 A828            test al,28
	//	1B14:45C2 7431            je   000045F5 ($+31)
	//	1B14:45C4 7A32            jpe  000045F8 ($+32)
	//
	//	1B14:41CD A814            test al,14
	//	1B14:41CF 7495            je   00004166 ($-6b)
	//	1B14:41D1 7AB9            jpe  0000418C ($-47)
	//
	//	1B14:834F F6C47E          test ah,7E
	//	1B14:8352 7402            je   00008356 ($+2)
	//	1B14:8354 7AAC            jpe  00008302 ($-54)
	//
	//	15E2:142D F6C430        TEST	AH,30                              
	//	15E2:1430 7402          JZ	1434                               
	//	15E2:1432 7A18          JPE	144C                               
	//
	//	1B14:B45B F6C381          test bl,81
	//	1B14:B45E 7402            je   0000B462 ($+2)
	//	1B14:B460 7A1A            jpe  0000B47C ($+1a)
	//
	//	1B14:6247 0AE4            or   ah,ah
	//	1B14:6249 7404            je   0000624F ($+4)
	//	1B14:624B 7A01            jpe  0000624E ($+1)
	//
	//	0008:00000E75 F6C106    test cl,06
	//	0008:00000E78 748E      je   00000E08 ($-72)
	//	0008:00000E7A 7A8C      jpe  00000E08 ($-74)
	//-------
14:	ldrb	r1,[r12, #-5]
	cmp		r1, #0xA8
	beq		.op_7a_parity_byte
	cmp		r1, #0xC4
	beq		1f
	cmp		r1, #0xC3
	beq		2f
	cmp		r1, #0x0A
	beq		3f
	cmp		r1, #0xC1
	beq		4f
	b		.unsjpe
1:	ldrb	r1, [r12, #-6]
	cmp		r1, #0xF6
	bne		.unsjpe
	//-------
	//	1B14:834F F6C47E          test ah,7E
	//	15E2:142D F6C430        TEST	AH,30                              
	// Put "test ah,imm8" result into r1
	//-------
	ldrb	r2, [r12, #-4]			// r2 = the imm8 value
	mov		r1, eax, lsr #8
	and		r1, r2
	b		.op_7a_r1
2:	ldrb	r1, [r12, #-4]
	cmp		r1, #0x81
	ldreqb	r1, [r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	//-------
	// Put "test bl,81" result into r1
	//-------
	and		r1, ebx, #0x81
	b		.op_7a_r1
3:	ldrb	r1, [r12, #-4]
	cmp		r1, #0xE4
	bne		.unsjpe
	//-------
	// Put "or ah,ah" result into r1
	//-------
	mov		r1, eax, lsr #8
	b		.op_7a_r1
	//-------
	//	0008:00000E75 F6C106    test cl,06
	//	0008:00000E78 748E      je   00000E08 ($-72)
	//	0008:00000E7A 7A8C      jpe  00000E08 ($-74)
	//-------
4:	ldrb	r1, [r12, #-4]
	cmp		r1, #0x06
	ldreqb	r1, [r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	//-------
	// Put "test cl,06" result into r1
	//-------
	and		r1, ecx, #0x06
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:4AAB 83C308          add  bx,0008
	//	1B14:4AAE 49              dec  cx
	//	1B14:4AAF 7AD3            jpe  00004A84 ($-2d)
	//-------
15:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x49
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xC3
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x83
	bne		.unsjpe
	//-------
	// Put the "dec cx" result into r1
	//-------
	mov		r1, ecx
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3" (jumps to this code after "or al,al")
	//	1B14:0BB4 C684A1E101      mov  byte [si-1E5F],01
	//	1B14:0BB9 7AF3            jpe  00000BAE ($-d)
	//-------
16:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x01
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xA1
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x84
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xC6
	bne		.unsjpe
	//-------
	// Put the "or al,al" result into r1
	//-------
	mov		r1, eax
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:6562 F6C4C0          test ah,C0
	//	1B14:6565 B220            mov  dl,20
	//	1B14:6567 740A            je   00006573 ($+a)
	//	1B14:6569 B22D            mov  dl,2D
	//	1B14:656B 7906            jns  00006573 ($+6)
	//	1B14:656D B22E            mov  dl,2E
	//	1B14:656F 7A02            jpe  00006573 ($+2)
	//-------
17:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x2E
	ldreqb	r1,[r12, #-12]
	cmpeq	r1, #0xC0
	ldreqb	r1,[r12, #-13]
	cmpeq	r1, #0xC4
	ldreqb	r1,[r12, #-14]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	//-------
	// Put the "test ah,C0" result into r1
	//-------
	mov		r1, eax, lsr #8
	and		r1, #0xC0
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:B276 80E411          and  ah,11
	//	1B14:B279 7A01            jpe  0000B27C ($+1)
	//-------
18:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x11
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x80
	bne		.unsjpe
	//-------
	// Put the "and ah,11" result into r1
	//-------
	mov		r1, eax, lsr #8
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:00005387 F6C5C0          test ch,C0
	//	1B14:0000538A 7411            je   0000539D ($+11)
	//	1B14:0000538C B4A2            mov  ah,A2
	//	1B14:0000538E 7A06            jpe  00005396 ($+6)
	//-------
19:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xA2
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xC0
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0xC5
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	//-------
	// Put the "test ch,C0" result into r1
	//-------
	mov		r1, ecx, lsr #8
	and		r1, #0xC0
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:54C5 A8C0            test al,C0
	//	1B14:54C7 7411            je   000054DA ($+11)
	//	1B14:54C9 790B            jns  000054D6 ($+b)
	//	1B14:54CB 7A02            jpe  000054CF ($+2)
	//-------
20:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x0B
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xC0
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0xA8
	bne		.unsjpe
	//-------
	// Put the "test al,C0" result into r1
	//-------
	and		r1, eax, #0xC0
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:481F 02E4            add  ah,ah
	//	1B14:4821 7522            jne  00004845 ($+22)
	//	1B14:4823 E8CEFF          call 000047F4 ($-32)
	//	1B14:4826 66C1CD10        ror  ebp,10
	//	1B14:482A 8B3E2827        mov  di,[2728]
	//	1B14:482E 8B85780A        mov  ax,[di+0A78]
	//	1B14:4832 8A957A0A        mov  dl,[di+0A7A]
	//	1B14:4836 A2FE01          mov  [01FE],al
	//	1B14:4839 E9FAF1          jmp  00003A36 ($-e06)
	//	1B14:483C 7838            js   00004876 ($+38)
	//	1B14:483E 7A20            jpe  00004860 ($+20)
	//	1B14:4840 689948          push 4899
	//	1B14:4843 EBAF            jmp  short 000047F4 ($-51)
	//	1B14:4845 73F5            jnc  0000483C ($-b)
	//	1B14:4847 7A14            jpe  0000485D ($+14)
	//
	//	1B14:44E2 892E2E27        mov  [272E],bp
	//	1B14:44E6 73B9            jnc  000044A1 ($-47)
	//	1B14:44E8 7AC6            jpe  000044B0 ($-3a)
	//	...
	//	1B14:453D 02E4			  add  ah,ah
	//	1B14:453F 75A1			  jne  000044E2
	//-------
21:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xF5
	beq		1f
	cmp		r1, #0xB9
	beq		2f
	b		.unsjpe
1:	ldrb	r1,[r12, #-4]
	cmp		r1, #0xAF
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0xEB
	ldreqb	r1,[r12, #-40]
	cmpeq	r1, #0xE4
	ldreqb	r1,[r12, #-41]
	cmpeq	r1, #0x02
	bne		.unsjpe
	//-------
	// Put the "add ah,ah" result into r1
	//-------
	mov		r1, eax, lsr #8
	b		.op_7a_r1
2:	ldrb	r1,[r12, #-6]
	cmp		r1, #0x2E
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x89
	ldreqb	r1,[r12, #(0x453D-0x44E9)]
	cmpeq	r1, #0x02
	ldreqb	r1,[r12, #(0x453E-0x44E9)]
	cmpeq	r1, #0xE4
	bne		.unsjpe
	//-------
	// Put the "add ah,ah" result into r1
	//-------
	mov		r1, eax, lsr #8
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:481F 02E4            add  ah,ah
	//	1B14:4821 7522            jne  00004845 ($+22)
	//	1B14:4823 E8CEFF          call 000047F4 ($-32)
	//	1B14:4826 66C1CD10        ror  ebp,10
	//	1B14:482A 8B3E2827        mov  di,[2728]
	//	1B14:482E 8B85780A        mov  ax,[di+0A78]
	//	1B14:4832 8A957A0A        mov  dl,[di+0A7A]
	//	1B14:4836 A2FE01          mov  [01FE],al
	//	1B14:4839 E9FAF1          jmp  00003A36 ($-e06)
	//	1B14:483C 7838            js   00004876 ($+38)
	//	1B14:483E 7A20            jpe  00004860 ($+20)
	//-------
22:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x38
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xF1
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0xFA
	ldreqb	r1,[r12, #-31]
	cmpeq	r1, #0xE4
	ldreqb	r1,[r12, #-32]
	cmpeq	r1, #0x02
	bne		.unsjpe
	//-------
	// Put the "add ah,ah" result into r1
	//-------
	mov		r1, eax, lsr #8
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:449D 83C510          add  bp,0010
	//	1B14:44A0 C3              ret
	//	1B14:44A1 7A1E            jpe  000044C1 ($+1e)
	//	...
	//	1B14:44E2 892E2E27		  mov  [272E],bp
	//	1B14:44E6 73B9			  jnc  000044A1
	//	...
	//	1B14:453D 02E4			  add  ah,ah
	//	1B14:453F 75A1			  jne  000044E2
	//-------
23:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xC3
	ldreqb	r1,[r12, #155]
	cmpeq	r1, #0x02
	ldreqb	r1,[r12, #156]
	cmpeq	r1, #0xE4
	ldreqb	r1,[r12, #157]
	cmpeq	r1, #0x75
	ldreqb	r1,[r12, #158]
	cmpeq	r1, #0xA1
	bne		.unsjpe
	//-------
	// Put the "add ah,ah" result into r1
	//-------
	mov		r1, eax, lsr #8
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:7DB6 F6??A0		  test ch,A0	
	//	1B14:7DB9 8B			  mov  si,[2728]
	//	1B14:7DBD 0F			  js   00007F46
	//	...
	//	1B14:7F46 EB02            jmp  short 00007F4A ($+2)
	//	1B14:7F48 7AF2            jpe  00007F3C ($-e)
	//-------
24:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x02
	ldreqb	r1,[r12, #-(0x7F49-0x7DBD)]
	cmpeq	r1, #0x0F
	ldreqb	r1,[r12, #-(0x7F49-0x7DB9)]
	cmpeq	r1, #0x8B
	ldreqb	r1,[r12, #-(0x7F49-0x7DB8)]
	cmpeq	r1, #0xA0
	ldreqb	r1,[r12, #-(0x7F49-0x7DB6)]
	cmpeq	r1, #0xF6
	bne		.unsjpe
	//-------
	// Put the "test ch,A0" result into r1
	//-------
	mov		r1, ecx, lsr #8
	and		r1, #0xA0
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:A530 80E181          and  cl,81
	//	1B14:A533 7406            je   0000A53B ($+6)
	//	1B14:A535 7906            jns  0000A53D ($+6)
	//	1B14:A537 6657            push edi
	//	1B14:A539 7A02            jpe  0000A53D ($+2)
	//-------
25:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x57
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x79
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x74
	ldreqb	r1,[r12, #-9]
	cmpeq	r1, #0xE1
	ldreqb	r1,[r12, #-10]
	cmpeq	r1, #0x80
	bne		.unsjpe
	//-------
	// Put the "and cl,81" result into r1
	//-------
	mov		r1, ecx
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:A77F 0AD2            or   dl,dl
	//	1B14:A781 8B86AE01        mov  ax,[bp+01AE]
	//	1B14:A785 7A02            jpe  0000A789 ($+2)
	//-------
26:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x01
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x86
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x8B
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xD2
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x0A
	bne		.unsjpe
	//-------
	// Put the "or dl,dl" result into r1
	//-------
	mov		r1, edx
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	1B14:4C95 0BFF            or   di,di
	//	1B14:4C97 75DD            jne  00004C76 ($-23)
	//	1B14:4C99 E92BFE          jmp  00004AC7 ($-1d5)
	//	1B14:4C9C 7A33            jpe  00004CD1 ($+33)
	//-------
27:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xFE
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xE9
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0xFF
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0x0B
	bne		.unsjpe
	//-------
	// Put the "or di,di" result into r1
	//-------
	mov		r1, edi
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	117D:8483 0AC7            or   al,bh
	//	117D:8485 7AF1            jpe  00008478 ($-f)
	//-------
28:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xC7
	bne		.unsjpe
	//-------
	// Put the "or al,bh" result into r1
	//-------
	mov		r1, eax
	b		.op_7a_r1
	//-------
	// Confirm it is "Chess Genius 3"
	//	15E2:6889 80E309        AND	BL,09                              
	//	15E2:688C 7A1C          JPE	68AA                       
	//        	
	//	15E2:6AE1 80E309        AND	BL,09                              
	//	15E2:6AE4 7AE8          JPE	6ACE                               	
	//-------
29:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x09
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x80
	bne		.unsjpe
	//-------
	// Put the "and bl,09" result into r1
	//-------
	mov		r1, ebx
	b		.op_7a_r1
	//-------
	// Confirm it is "Super Frog"
	//	0158:00178D77 DFE0      fstsw ax
	//	0158:00178D79 9E        sahf
	//	0158:00178D7A 7AF8      jpe  00178D74 ($-8)
	//-------
30:	ldrb	r1,[r12, #-2]
	cmp		r1, #0x9E
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xDF
	bne		.unsjpe
	//-------
	// Test the AH register FLAG_PF bit
	//-------
1:	tst		eax, #(FLAG_PF<<8)
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	addne	r12, r12, r1			// Adjust program counter by the jump amount, if the condition is true
	b		restore_flags_from_r0	// Back to loop, restoring flags
	//-------
	// Confirm it is YADRO "DDISP"
	//	13BD:1C7C 8A66FF          mov  ah,[bp+FF]
	//	13BD:1C7F 80CC01          or   ah,01
	//	13BD:1C82 9E              sahf
	//	13BD:1C83 7B1C            jpo  1CA1 ($+1c)
	//	13BD:1C85 CD3C            int  3C
	//	13BD:1C87 9B2E			  (data)
	//	13BD:1C89 7A1B            jpe  1CA6 ($+1b)
	//-------
31:	ldrb	r1, [r12, #-4]
	cmp		r1, #0x3C
	ldreqb	r1, [r12, #-5]
	cmpeq	r1, #0xCD
	bne		.unsjpe
	//-------
	// Get the parity flag from SP_FLAGS, as IRET has put it there.
	//-------
	ldrb	r1, [sp, #SP_FLAGS]
	tst		r1, #FLAG_PF			// Test the parity flag
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	addne	r12, r12, r1			// Adjust program counter by the jump amount, if the condition is true
	b		restore_flags_from_r0	// Back to loop, restoring flags
	//-------
	// We have the result in SP_PARITY_BYTE, use it.
	//-------
.op_7a_parity_byte:
	ldrb	r1, [sp, #SP_PARITY_BYTE]
	//-------
	// Calculate parity flag value from r1 register low byte.
	// Use special ARM hack by FluBBa ("http://www.ndsretro.com/armhacks.html"):
	// r1 is input/output byte. 1 = odd, 0 = even parity. Sign flag can also be used if actual value not needed.
	//-------
.op_7a_r1:
	and		r1, #0xFF
	eor 	r1,r1,r1,lsl#16
	eor 	r1,r1,r1,lsl#8
	eor 	r1,r1,r1,lsl#4
	eor 	r1,r1,r1,lsl#2
	eors 	r1,r1,r1,lsl#1
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	addpl	r12, r12, r1			// Adjust program counter by the jump amount, if the condition is true
	b		restore_flags_from_r0	// Back to loop, restoring flags
	//------
	// Tell "Unhandled JPE opcode" and exit the emulation.
	//------
	.global	.unsjpe
.unsjpe:
	ldr		r2, =BreakReason
	ldr		r1, =BRUnsJPE						// Tell "Unhandled JPE opcode"
	str		r1, [r2]
	b		.unknown


	//-------
	// JNP/JPO cb
	// Special hack for "Amazing Spiderman"
	// 	3EFE:0CC7 22C0            and  al,al
	// 	3EFE:0CC9 7B0B            jpo  0CD6 ($+b)
	// Special hack for "Tapper"
	//	1645:2F51 2598D5          and  ax,D598
	//	1645:2F54 7B01            jpo  2F57 ($+1)
	// Special hack for "TOUTRUN"
	// 	023F:1BC6 F6C4B4          test ah,B4
	//	023F:1BC9 7B02            jpo  1BCD ($+2)
	// Special hack for "GWBASIC"
	//	04D8:8C6F E85BF1          call 7DCD ($-ea5)		(Does "DEC AL" as the last operation before return)
	//	04D8:8C72 7B52            jpo  8CC6 ($+52)
	// Special hack for "BUBBOB"
	//	1AEC:1329 0BC0            or   ax,ax
	//	1AEC:132B 7B01            jpo  132E ($+1)
	// Special hack for "QB"
	//	2BEA:08A0 F6069C1A30      test byte [1A9C],30
	//	2BEA:08A5 741A            je   08C1 ($+1a)
	//	2BEA:08A7 7B18            jpo  08C1 ($+18)
	// Special hack for "Batman Returns"
	//	12F0:B607 A8C0            test al,C0
	//	12F0:B609 7837            js   B642 ($+37)
	//	12F0:B60B 7B1F            jpo  B62C ($+1f)
	// Special hack for "Batman Returns"
	//	12F0:B640 EBBE			  jmp  short B600 ($-42)
	//	12F0:B642 7B03            jpo  B647 ($+3)
	// Special hack for "F29 Retaliator"
	//	5741:0214 0AC0            or   al,al
	//	5741:0216 781C            js   0234 ($+1c)
	//	5741:0218 8ACF            mov  cl,bh
	//	5741:021A 7B10            jpo  022C ($+10)
	// Special hack for "F29 Retaliator"
	//	02F0:50C3 8BC7            mov  ax,di
	//	02F0:50C5 F6C403          test ah,03
	//	02F0:50C8 A1DB4F          mov  ax,[4FDB]
	//	02F0:50CB 7B2A            jpo  50F7 ($+2a)
	// Special hack for "F29 Retaliator"
	//	02F0:4FDF F606855060      test byte [5085],60
	//	02F0:4FE4 7B04            jpo  4FEA ($+4)
	// Special hack for "Super Solvers: Challenge of the Ancient Empires"
	//	02F0:D6BF A90300          test ax,0003
	//	02F0:D6C2 7408            je   D6CC ($+8)
	//	02F0:D6C4 7B06            jpo  D6CC ($+6)
	// Special hack for "Chess Genius 3"
	//	1AF0:3980 A818            test al,18
	//	1AF0:3982 7505            jne  00003989 ($+5)
	//	1AF0:3984 31BFB001        xor  [bx+01B0],di
	//	1AF0:3988 C3              ret
	//	1AF0:3989 7B0D            jpo  00003998 ($+d)
	// Special hack for "Chess Genius 3"
	//	1B14:3801 2458            and  al,58
	//	1B14:3803 8B2E1427        mov  bp,[2714]
	//	1B14:3807 7B1B            jpo  00003824 ($+1b)
	// Special hack for "Chess Genius 3"
	//	1B14:BA25 80E288          and  dl,88
	//	1B14:BA28 7B02            jpo  0000BA2C ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:B07A 2403            and  al,03
	//	1B14:B07C 7B09            jpo  0000B087 ($+9)
	// Special hack for "Chess Genius 3"
	//	1B14:B196 0AC9            or   cl,cl
	//	1B14:B198 7B02            jpo  0000B19C ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:B217 F6C318          test bl,18
	//	1B14:B21A 7405            je   0000B221 ($+5)
	//	1B14:B21C 7B03            jpo  0000B221 ($+3)
	// Special hack for "Chess Genius 3"
	//	1B14:4B3B F6C703          test bh,03
	//	1B14:4B3E 7B0B            jpo  00004B4B ($+b)
	// Special hack for "Chess Genius 3"
	//	1B14:4B5D 0BD2            or   dx,dx
	//	1B14:4B5F 7B1E            jpo  00004B7F ($+1e)
	// Special hack for "Chess Genius 3"
	//	1B14:6261 0AE4            or   ah,ah
	//	1B14:6263 7B04            jpo  00006269 ($+4)
	// Special hack for "Chess Genius 3"
	//	1B14:11B8 F6C4C0          test ah,C0
	//	1B14:11BB 790E            jns  000011CB ($+e)
	//	1B14:11BD 7B0E            jpo  000011CD ($+e)
	// Special hack for "Chess Genius 3"
	//	1B14:7E86 80E318          and  bl,18
	//	1B14:7E89 7B11            jpo  00007E9C ($+11)
	// Special hack for "Chess Genius 3"
	//	1B14:0F27 A90180          test ax,8001
	//	1B14:0F2A 79A1            jns  00000ECD ($-5f)
	//	1B14:0F2C 7B8D            jpo  00000EBB ($-73)
	// Special hack for "Chess Genius 3"
	//	1B14:631A A8C1            test al,C1
	//	1B14:631C 7404            je   00006322 ($+4)
	//	1B14:631E 7B02            jpo  00006322 ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:632B A850            test al,50
	//	1B14:632D 7424            je   00006353 ($+24)
	//	1B14:632F 7B0B            jpo  0000633C ($+b)
	// Special hack for "Chess Genius 3"
	//	1B14:43C3 84C9            test cl,cl
	//	1B14:43C5 7B02            jpo  000043C9 ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:3889 80E3C1		  and  bl,C1
	//	1B14:388C 89ADA801        mov  [di+01A8],bp
	//	1B14:3890 7B02            jpo  00003894 ($+2)
	// Special hack for "Chess Genius 3"
	//	1B14:4069 0ADB            or   bl,bl
	//	1B14:406B 7B12            jpo  0000407F ($+12)
	// Special hack for "Chess Genius 3"
	//	1B14:6CFF F6C203          test dl,03
	//	1B14:6D02 7408            je   00006D0C ($+8)
	//	1B14:6D04 BE36E2          mov  si,E236
	//	1B14:6D07 7B03            jpo  00006D0C ($+3)
	// Special hack for "Chess Genius 3"
	//	1B14:B2F6 A803            test al,03
	//	1B14:B2F8 742F            je   0000B329 ($+2f)
	//	1B14:B2FA B420            mov  ah,20
	//	1B14:B2FC 7B0E            jpo  0000B30C ($+e)
	// Special hack for "Chess Genius 3"
	//	1B14:0A65 F6C430          test ah,30
	//	1B14:0A68 740B            je   00000A75 ($+b)
	//	1B14:0A6A 7B09            jpo  00000A75 ($+9)
	// Special hack for "Chess Genius 3"
	//	1B14:0C4D F6C430          test ah,30
	//	1B14:0C50 8A4600          mov  al,[bp]
	//	1B14:0C53 7406            je   00000C5B ($+6)
	//	1B14:0C55 7B04            jpo  00000C5B ($+4)
	// Special hack for "Chess Genius 3"
	//	1B14:499F 80E503          and  ch,03
	//	1B14:49A2 7B98            jpo  0000493C ($-68)
	// Special hack for "Chess Genius 3"
	//	1B14:B675 F6C2C3          test dl,C3
	//	1B14:B678 7B05            jpo  0000B67F ($+5)
	// Special hack for "Chess Genius 3"
	//	1B14:B794 F6C488          test ah,88
	//	1B14:B797 7904            jns  0000B79D ($+4)
	//	1B14:B799 7B01            jpo  0000B79C ($+1)
	// Special hack for "Chess Genius 3"
	//	1B14:0B58 0AC0            or   al,al
	//	1B14:0B5A 7444            je   00000BA0 ($+44)
	//	1B14:0B5C 7856            js   00000BB4 ($+56)
	//	1B14:0B5E C684A1E101      mov  byte [si-1E5F],01
	//	1B14:0B63 7B49            jpo  00000BAE ($+49)
	// Special hack for "Chess Genius 3"
	//	1B14:8361 83F740          xor  di,0040
	//	1B14:8364 7B0E            jpo  00008374 ($+e)
	// Special hack for "Chess Genius 3"
	//	15E2:6F76 F6C1C0        TEST	CL,C0                              
	//	15E2:6F79 7B0A          JPO	6F85
	// Special hack for "Chess Genius 3"
	//	15E2:766F 0AC0          OR	AL,AL                              
	//	15E2:7671 7413          JZ	7686                               
	//	15E2:7673 7817          JS	768C                               
	//	15E2:7675 7B40          JPO	76B7
	// Special hack for "Chess Genius 3"
	//	15E2:8502 F6C541        TEST	CH,41                              
	//	15E2:8505 7409          JZ	8510                               
	//	15E2:8507 7B07          JPO	8510
	// Special hack for "Chess Genius 3"
	//	15E2:C1AA A803          TEST	AL,03                              
	//	15E2:C1AC BB3031        MOV	BX,3130                            
	//	15E2:C1AF 7429          JZ	C1DA                               
	//	15E2:C1B1 7B1E          JPO	C1D1
	// Special hack for "QBASIC"
	//	298C:0638 F6069A1630      test byte [169A],30
	//	298C:063D 741A            je   0659 ($+1a)
	//	298C:063F 7B18            jpo  0659 ($+18)
	// Special hack for "NHL '94"
	//	0691:32F8 80E403          and  ah,03
	//	0691:32FB 7B0B            jpo  3308 ($+b)
	// Special hack for YADRO "DDISP"
	//	13BD:1C7C 8A66FF          mov  ah,[bp+FF]
	//	13BD:1C7F 80CC01          or   ah,01
	//	13BD:1C82 9E              sahf
	//	13BD:1C83 7B1C            jpo  1CA1 ($+1c)
	// Special hack for "Stalingrad"
	//	0180:0020F923 DD7DFE      fstsw [ebp+FE]
	//	0180:0020F926 8A65FF	  mov  ah,[ebp+FF]
	//	0180:0020F929 80CC01      or   ah,01
	//   0180:0020F92C 9E		  sahf
	//   0180:0020F92D 7B18		  jpo  ($+18)
	// Special hack for "Star Gunner"
	//	0008:00000E64 F6C190      test cl,90
	//	0008:00000E67 749F        je   00000E08 ($-61)
	//	0008:00000E69 7B9D        jpo  00000E08 ($-63)
	//-------
op_7b:								
	mrs		r0,cpsr					// r0 = Current flags
	ldrb	r1,[r12, #-3]
	cmp		r1, #0x01
	beq		12f						// Could be "CG3" or "Stalingrad" ...
	cmp		r1, #0x0A
	beq		16f						// Could be "CG3"...
	cmp		r1, #0x0B
	beq		1f						// Could be "BUBBOB" or "CG3" ...
	cmp		r1, #0x14
	beq		13f						// Could be "CG3"...
	cmp		r1, #0x22
	beq		1f						// Could be "Amazing Spiderman"...
	cmp		r1, #0x24
	beq		15f						// Could be "CG3"...
	cmp		r1, #0x36
	beq		23f						// Could be "CG3"...
	cmp		r1, #0x50
	beq		11f						// Could be "F29RETAL"...
	cmp		r1, #0x5B
	beq		4f						// Could be "GWBASIC"...
	cmp		r1, #0x74
	beq		5f						// Could be "QB" or "AEPROG" or "CG3" or "Start Gunner"...
	cmp		r1, #0x78
	beq		6f						// Could be "BATMAN" or "CG3"...
	cmp		r1, #0x79
	beq		19f						// Could be "Chess Genius 3"...
	cmp		r1, #0x84
	beq		21f						// Could be "Chess Genius 3"...
	cmp		r1, #0x8A
	beq		8f						// Could be "F29RETAL"...
	cmp		r1, #0x98
	beq		2f						// Could be "Tapper"...
	cmp		r1, #0xA8
	beq		22f						// Could be "Chess Genius 3"...
	cmp		r1, #0xB4
	beq		24f						// Could be "Chess Genius 3"...
	cmp		r1, #0xC1
	beq		31f						// Could be "CG3"...
	cmp		r1, #0xC2
	beq		28f						// Could be "CG3"...
	cmp		r1, #0xC4
	beq		3f						// Could be "TOUTRUN"...
	cmp		r1, #0xC7
	beq		18f						// Could be "CG3"...
	cmp		r1, #0xDB
	beq		10f						// Could be "F29RETAL"...
	cmp		r1, #0xE1
	beq		29f						// Could be "CG3"...
	cmp		r1, #0xE2
	beq		14f						// Could be "CG3"...
	cmp		r1, #0xE3
	beq		20f						// Could be "CG3"...
	cmp		r1, #0xE4
	beq		32f						// Could be "NHL '94"...
	cmp		r1, #0xE5
	beq		27f						// Could be "CG3"...
	cmp		r1, #0xEB
	beq		7f						// Could be "BATMAN"...
	cmp		r1, #0xF7
	beq		30f						// Could be "CG3"...
	b		.unsjpo
	//-------
	//	15E2:4B5D 0BD2          OR	DX,DX
	//	15E2:4B5F 7B1E          JPO	4B7F
	//-------
1:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xC0				// Is it "and al,al" or "or ax,ax" ?
	moveq	r1, eax					// Put "and al,al" result into r1
	beq		op_7b_r1
	cmp		r1, #0xD2				// Is it "or dx,dx" ?
	moveq	r1, edx					// Put "or dx,dx" result into r1
	beq		op_7b_r1
	b		.unsjpo
	//-------
	// Make sure it is "and ax,D598" = 25 98 D5
	//-------
2:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x25
	bne		.unsjpo
	ldrb	r1,[r12, #-2]
	cmp		r1, #0xD5
	bne		.unsjpo
	//-------
	// Put "and ax,D598" result into r1
	//-------
	and		r1, eax, #0x98
	b		op_7b_r1
	//-------
	// Make sure it is "test ah,B4" = F6 C4 B4
	//-------
3:	ldrb	r1,[r12, #-4]
	cmp		r1, #0xF6
	bne		.unsjpo
	ldrb	r1,[r12, #-2]
	cmp		r1, #0xB4
	bne		.unsjpo
	//-------
	// Put "test ah,B4" result into r1
	//-------
	mov		r1, eax, lsr #8
	and		r1, #0xB4
	b		op_7b_r1
	//-------
	// Make sure it is "call $-ea5" = E8 5B F1
	//-------
4:	ldrb	r1,[r12, #-4]
	cmp		r1, #0xE8
	bne		.unsjpo
	ldrb	r1,[r12, #-2]
	cmp		r1, #0xF1
	bne		.unsjpo
	//-------
	// Put "dec al" result into r1
	//-------
	mov		r1, eax
	b		op_7b_r1
	//-------
	// Test whether it could be "QB", "AEPROG" or "CG3"
	//	2BEA:08A0 F6069C1A30      test byte [1A9C],30			QB (handled here)
	//	2BEA:08A5 741A            je   08C1 ($+1a)
	//	2BEA:08A7 7B18            jpo  08C1 ($+18)
	//
	//	02F0:D6BF A90300          test ax,0003					AEPROG (jump to 9f)
	//	02F0:D6C2 7408            je   D6CC ($+8)
	//	02F0:D6C4 7B06            jpo  D6CC ($+6)
	//
	//	1B14:B217 F6C318          test bl,18					CG3 (jump to 17f)
	//	1B14:B21A 7405            je   0000B221 ($+5)
	//	1B14:B21C 7B03            jpo  0000B221 ($+3)
	//
	//	1B14:631A A8C1            test al,C1					CG3 (jump to .op_7b_test_al_imm8)
	//	1B14:631C 7404            je   00006322 ($+4)
	//	1B14:631E 7B02            jpo  00006322 ($+2)
	//
	//	1B14:632B A850            test al,50					CG3 (jump to .op_7b_test_al_imm8)
	//	1B14:632D 7424            je   00006353 ($+24)
	//	1B14:632F 7B0B            jpo  0000633C ($+b)
	//
	//	1B14:0A65 F6C430          test ah,30
	//	1B14:0A68 740B            je   00000A75 ($+b)
	//	1B14:0A6A 7B09            jpo  00000A75 ($+9)
	//
	//	1B14:0C4D F6C430          test ah,30
	//	1B14:0C50 8A4600          mov  al,[bp]
	//	1B14:0C53 7406            je   00000C5B ($+6)
	//	1B14:0C55 7B04            jpo  00000C5B ($+4)
	//
	//	15E2:4CC4 A830          TEST	AL,30					CG3 (jump to .op_7b_test_al_imm8)
	//	15E2:4CC6 7408          JZ	4CD0
	//	15E2:4CC8 7B04          JPO	4CCE
	//
	//	15E2:54F6 F606D59D03    TEST	BYTE PTR [9DD5],03                 
	//	15E2:54FB 7420          JZ	551D                               
	//	15E2:54FD 7B1E          JPO	551D
	//
	//	15E2:8502 F6C541        TEST	CH,41                              
	//	15E2:8505 7409          JZ	8510                               
	//	15E2:8507 7B07          JPO	8510
	//
	//	15E2:C1AA A803          TEST	AL,03                              
	//	15E2:C1AC BB3031        MOV	BX,3130                            
	//	15E2:C1AF 7429          JZ	C1DA                               
	//	15E2:C1B1 7B1E          JPO	C1D1
	//
	//	298C:0638 F6069A1630    test byte [169A],30
	//	298C:063D 741A          je   00000659 ($+1a)
	//	298C:063F 7B18          jpo  00000659 ($+18)
	//
	//	0008:00000E64 F6C190    test cl,90
	//	0008:00000E67 749F      je   00000E08 ($-61)
	//	0008:00000E69 7B9D      jpo  00000E08 ($-63)
	//-------
5:	ldrb	r1,[r12, #-5]
	cmp		r1, #0x03
	beq		9f						// Could be "AEPROG", go test it
	cmp		r1, #0x16
	beq		1f						// Could be "QB", go test it
	cmp		r1, #0x1A
	beq		1f						// Could be "QB", go test it
	cmp		r1, #0x30
	beq		4f						// Could be "CG3", go test it
	cmp		r1, #0x46
	beq		26f						// Could be "CG3", go test it
	cmp		r1, #0x9D
	beq		2f						// Could be "CG3", go test it
	cmp		r1, #0xA8
	beq		.op_7b_test_al_imm8		// Seems to be "test al,imm8", go handle it
	cmp		r1, #0xC1
	beq		5f						// Could be "Star Gunner", go test it
	cmp		r1, #0xC3
	beq		17f						// Could be "CG3", go test it
	cmp		r1, #0xC4
	beq		25f						// Could be "CG3", go test it
	cmp		r1, #0xC5
	beq		3f						// Could be "CG3", go test it
	b		.unsjpo
	//-------
	// Make sure it is "QB":
	//	2BEA:08A0 F6069C1A30      test byte [1A9C],30
	//	2BEA:08A5 741A            je   08C1 ($+1a)
	//	2BEA:08A7 7B18            jpo  08C1 ($+18)
	//
	//	298C:0638 F6069A1630      test byte [169A],30
	//	298C:063D 741A            je   00000659 ($+1a)
	//	298C:063F 7B18            jpo  00000659 ($+18)
	//-------
1:	ldrb	r1,[r12, #-8]
	cmp		r1, #0xF6
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x06
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x30
	bne		.unsjpo
	//-------
	// Put the "test byte [1A9C],30" result to r1
	//-------
	mov		r1, r0					// Save flags to r1
	ldrb	r0,[r12, #-6]
	ldrb	r2,[r12, #-5]
	orr		r0, r2, lsl #8			// r0 = 1A9C / 169A
	ldr		r2, [sp, #SP_DS_BASE]	// r2 = logical DS segment
	calc_linear_address_r2_from_r0r3	
	mov		r0, r1					// Restore flags from r1
	ldrb	r1, [r2]				// Get byte from [1A9C]
	and		r1, #0x30
	b		op_7b_r1
	//-------
	// Make sure it is "CG3":
	//	15E2:54F6 F606D59D03    TEST	BYTE PTR [9DD5],03                 
	//	15E2:54FB 7420          JZ	551D                               
	//	15E2:54FD 7B1E          JPO	551D
	//-------
2:	ldrb	r1,[r12, #-8]
	cmp		r1, #0xF6
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x06
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xD5
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x03
	bne		.unsjpo
	//-------
	// Put the "test byte [9DD5],03" result to r1
	//-------
	mov		r1, r0					// Save flags to r1
	mov		r0, #0xD5
	orr		r0, #0x9D00
	calc_linear_address_r2_from_r0r3	
	mov		r0, r1					// Restore flags from r1
	ldrb	r1, [r2]				// Get byte from [9DD5]
	and		r1, #0x03
	b		op_7b_r1
	//-------
	// Make sure it is "CG3":
	//	15E2:8502 F6C541        TEST	CH,41                              
	//	15E2:8505 7409          JZ	8510                               
	//	15E2:8507 7B07          JPO	8510
	//-------
3:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x41
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpo
	//-------
	// Put the "test ch,41" result to r1
	//-------
	mov		r1, ecx, lsr #8
	and		r1, #0x41
	b		op_7b_r1
	//-------
	// Make sure it is "CG3":
	//	15E2:C1AA A803          TEST	AL,03                              
	//	15E2:C1AC BB3031        MOV	BX,3130                            
	//	15E2:C1AF 7429          JZ	C1DA                               
	//	15E2:C1B1 7B1E          JPO	C1D1
	//-------
4:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x31
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xBB
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x03
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0xA8
	bne		.unsjpo
	//-------
	// Put the "test al,03" result to r1
	//-------
	and		r1, eax, #0x03
	b		op_7b_r1
	//-------
	// Star Gunner:
	//	0008:00000E64 F6C190    test cl,90
	//	0008:00000E67 749F      je   00000E08 ($-61)
	//	0008:00000E69 7B9D      jpo  00000E08 ($-63)
	//-------
5:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x90
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpo
	//-------
	// Put the "test cl,90" result to r1
	//-------
	and		r1, ecx, #0x90
	b		op_7b_r1
	//-------
	// Batman:
	//	12F0:B607 A8C0            test al,C0
	//	12F0:B609 7837            js   B642 ($+37)
	//	12F0:B60B 7B1F            jpo  B62C ($+1f)
	// Chess Genius 3:
	//	15E2:766F 0AC0          OR	AL,AL                              
	//	15E2:7671 7413          JZ	7686                               
	//	15E2:7673 7817          JS	768C                               
	//	15E2:7675 7B40          JPO	76B7
	//-------
6:	ldrb	r1,[r12, #-5]
	cmp		r1, #0xA8
	beq		1f						// Could be BATMAN
	cmp		r1, #0x74
	beq		2f						// Could be Chess Genius 3
	b		.unsjpo
1:	ldrb	r1,[r12, #-4]
	cmp		r1, #0xC0
	ldreqb	r1,[r12, #-2]
	cmpeq	r1, #0x37
	bne		.unsjpo
	//-------
	// Put "test al,C0" result into r1
	//-------
	and		r1, eax, #0xC0
	b		op_7b_r1
2:	ldrb	r1,[r12, #-6]
	cmp		r1, #0xC0
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x0A
	bne		.unsjpo
	//-------
	// Put "or al,al" result into r1
	//-------
	mov		r1, eax
	b		op_7b_r1
	//-------
	// Make sure it is "Batman Returns", with the other jpo before this one.
	//	12F0:B607 A8C0            test al,C0
	//	12F0:B609 7837            js   B642 ($+37)
	//	12F0:B60B 7B1F            jpo  B62C ($+1f)
	//   ...
	//	12F0:B640 EBBE			  jmp  short B600 ($-42)
	//	12F0:B642 7B03            jpo  B647 ($+3)
	//-------
7:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xBE
	bne		.unsjpo
	ldrb	r1,[r12, #(0xB607-0xB643)]
	cmp		r1, #0xA8
	bne		.unsjpo
	ldrb	r1,[r12, #(0xB608-0xB643)]
	cmp		r1, #0xC0
	bne		.unsjpo
	//-------
	// Put "test al,C0" result into r1
	//-------
	and		r1, eax, #0xC0
	b		op_7b_r1
	//-------
	// Make sure it is "F29 Retaliator"
	//	5741:0214 0AC0            or   al,al
	//	5741:0216 781C            js   0234 ($+1c)
	//	5741:0218 8ACF            mov  cl,bh
	//	5741:021A 7B10            jpo  022C ($+10)
	//-------
8:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xCF
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x1C
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x78
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xC0
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x0A
	bne		.unsjpo
	//-------
	// Put "or al,al" result into r1
	//-------
	mov		r1, eax
	b		op_7b_r1
	//-------
	// Make sure it is "AEPROG":
	//	02F0:D6BF A90300          test ax,0003
	//	02F0:D6C2 7408            je   D6CC ($+8)
	//	02F0:D6C4 7B06            jpo  D6CC ($+6)
	//-------
9:	ldrb	r1,[r12, #-4]
	cmp		r1, #0x00
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xA9
	bne		.unsjpo
	//-------
	// Put "test ax,0003" result into r1
	//-------
	and		r1, eax, #3
	b		op_7b_r1
	//-------
	// Make sure it is "F29 Retaliator"
	//	02F0:50C3 8BC7            mov  ax,di
	//	02F0:50C5 F6C403          test ah,03
	//	02F0:50C8 A1DB4F          mov  ax,[4FDB]
	//	02F0:50CB 7B2A            jpo  50F7 ($+2a)
	//-------
10: ldrb	r1,[r12, #-2]
	cmp		r1, #0x4F
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xA1
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x03
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xC4
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0xF6
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0xC7
	ldreqb	r1,[r12, #-9]
	cmpeq	r1, #0x8B
	bne		.unsjpo	
	//-------
	// Put "mov  ax,di" and "test ah,03" result into r1
	//-------
	mov		r1, edi, lsr #8			// r1 = AH
	and		r1, #3
	b		op_7b_r1
	//-------
	// Make sure it is "F29 Retaliator"
	//	02F0:4FDF F606855060      test byte [5085],60
	//	02F0:4FE4 7B04            jpo  4FEA ($+4)
	//-------
11: ldrb	r1,[r12, #-2]
	cmp		r1, #0x60
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x85
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x06
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpo	
	//-------
	// Put the "test byte [5085],60" result to r1
	//-------
	mov		r1, r0					// Save flags to r1
	mov		r0, #0x85
	orr		r0, #0x5000
	mem_handler_jump_r0r3 .op_7b_11 bad_EGA_opcode bad_MODEX_opcode
.op_7b_11:
	mov		r0, r1					// Restore flags from r1
	ldrb	r1, [r2]
	and		r1, #0x60
	b		op_7b_r1

	//-------
	// Test whether this is "Chess Genius 3", YADRO "DDISP" or "Stalingrad"
	//-------
12:	ldrb	r1,[r12, #-2]
	cmp		r1, #0xC3
	beq		1f
	cmp		r1, #0x9E
	bne		.unsjpo			
	//-------
	// Make sure it is YADRO "DDISP"
	//	13BD:1C7C 8A66FF          mov  ah,[bp+FF]
	//	13BD:1C7F 80CC01          or   ah,01
	//	13BD:1C82 9E              sahf
	//	13BD:1C83 7B1C            jpo  1CA1 ($+1c)
	// or "Stalingrad"
	//	0180:0020F926 8A65FF	  mov  ah,[ebp+FF]
	//	0180:0020F929 80CC01      or   ah,01
	//   0180:0020F92C 9E		  sahf
	//   0180:0020F92D 7B18		  jpo  ($+18)
	//-------
	ldrb	r1, [r12, #-4]
	cmp		r1, #0xCC
	ldreqb	r1, [r12, #-5]
	cmpeq	r1, #0x80
	ldreqb	r1, [r12, #-6]
	cmpeq	r1, #0xFF
	ldreqb	r1, [r12, #-8]
	cmpeq	r1, #0x8A
	bne		.unsjpo
	//-------
	// Test the AH register FLAG_PF bit
	//-------
	tst		eax, #(FLAG_PF<<8)
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	addeq	r12, r12, r1			// Adjust program counter by the jump amount, if the condition is true
	b		restore_flags_from_r0	// Back to loop, restoring flags
	//-------
	// Make sure it is "Chess Genius 3"
	//	1AF0:3980 A818            test al,18
	//	1AF0:3982 7505            jne  00003989 ($+5)
	//	1AF0:3984 31BFB001        xor  [bx+01B0],di
	//	1AF0:3988 C3              ret
	//	1AF0:3989 7B0D            jpo  00003998 ($+d)
	//-------
1:	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x05
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0x75
	ldreqb	r1,[r12, #-9]
	cmpeq	r1, #0x18
	bne		.unsjpo	
	//-------
	// Put "test al,18" result into r1
	//-------
	and		r1, eax, #0x18
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:3801 2458            and  al,58
	//	1B14:3803 8B2E1427        mov  bp,[2714]
	//	1B14:3807 7B1B            jpo  00003824 ($+1b)
	//-------
13: ldrb	r1,[r12, #-6]
	cmp		r1, #0x58
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x24
	bne		.unsjpo	
	//-------
	// Put "and al,58" result into r1
	//-------
	and		r1, eax, #0x58
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:BA25 80E288          and  dl,88
	//	1B14:BA28 7B02            jpo  0000BA2C ($+2)
	//-------
14: ldrb	r1,[r12, #-2]
	cmp		r1, #0x88
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x80
	bne		.unsjpo	
	//-------
	// Put "and dl,88" result into r1
	//-------
	and		r1, edx, #0x88
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:B07A 2403            and  al,03
	//	1B14:B07C 7B09            jpo  0000B087 ($+9)
	//-------
15: ldrb	r1,[r12, #-2]
	cmp		r1, #0x03
	bne		.unsjpo	
	//-------
	// Put "and al,03" result into r1
	//-------
	and		r1, eax, #3
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:B196 0AC9            or   cl,cl
	//	1B14:B198 7B02            jpo  0000B19C ($+2)
	// Make sure it is "Chess Genius 3"
	//	1B14:6261 0AE4            or   ah,ah
	//	1B14:6263 7B04            jpo  00006269 ($+4)
	// Make sure it is "Chess Genius 3"
	//	1B14:4069 0ADB            or   bl,bl
	//	1B14:406B 7B12            jpo  0000407F ($+12)
	//-------
16: ldrb	r1,[r12, #-2]
	cmp		r1, #0xC9
	moveq	r1, ecx					// Put "or cl,cl" result into r1
	beq		op_7b_r1
	cmp		r1, #0xE4
	moveq	r1, eax, lsr #8			// Put "or ah,ah" result into r1
	beq		op_7b_r1
	cmp		r1, #0xDB
	moveq	r1, ebx					// Put "or bl,bl" result into r1
	beq		op_7b_r1
	b		.unsjpo	
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:B217 F6C318          test bl,18
	//	1B14:B21A 7405            je   0000B221 ($+5)
	//	1B14:B21C 7B03            jpo  0000B221 ($+3)
	//-------
17: ldrb	r1,[r12, #-4]
	cmp		r1, #0x18
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0xC3
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpo	
	//-------
	// Put "test bl,18" result into r1
	//-------
	and		r1, ebx, #0x18
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:4B3B F6C703          test bh,03
	//	1B14:4B3E 7B0B            jpo  00004B4B ($+b)
	//
	//	15E2:41F2 F6C703        TEST	BH,03                              
	//	15E2:41F5 7B95          JPO	418C                               - handled, 
	//-------
18: ldrb	r1,[r12, #-2]
	cmp		r1, #0x03
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xF6
	bne		.unsjpo	
	//-------
	// Put "test bh,03" result into r1
	//-------
	mov		r1, ebx, lsr #8
	and		r1, #3
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:11B8 F6C4C0          test ah,C0
	//	1B14:11BB 790E            jns  000011CB ($+e)
	//	1B14:11BD 7B0E            jpo  000011CD ($+e)
	//
	//	1B14:0F27 A90180          test ax,8001
	//	1B14:0F2A 79A1            jns  00000ECD ($-5f)
	//	1B14:0F2C 7B8D            jpo  00000EBB ($-73)
	//
	//	1B14:B794 F6C488          test ah,88
	//	1B14:B797 7904            jns  0000B79D ($+4)
	//	1B14:B799 7B01            jpo  0000B79C ($+1)
	//-------
19: ldrb	r1,[r12, #-6]
	cmp		r1, #0xF6
	bne		1f
	ldrb	r1,[r12, #-5]
	cmp		r1, #0xC4
	bne		.unsjpo
	//-------
	// Calculate "test ah,imm8" value
	//-------
	ldrb	r2, [r12, #-4]
	mov		r1, eax, lsr #8
	and		r1, r2
	b		op_7b_r1
	//-------
	// Make sure it is "test ax,8001"
	//-------
1:	cmp		r1, #0xA9
	bne		.unsjpo	
	ldrb	r1,[r12, #-5]
	cmp		r1, #0x01
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x80
	bne		.unsjpo	
	//-------
	// Put "test ax,8001" result into r1
	//-------
	and		r1, eax, #1
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:7E86 80E318          and  bl,18
	//	1B14:7E89 7B11            jpo  00007E9C ($+11)
	//-------
20: ldrb	r1,[r12, #-2]
	cmp		r1, #0x18
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x80
	bne		.unsjpo	
	//-------
	// Put "and bl,18" result into r1
	//-------
	and		r1, ebx, #0x18
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:43C3 84C9            test cl,cl
	//	1B14:43C5 7B02            jpo  000043C9 ($+2)
	//-------
21: ldrb	r1,[r12, #-2]
	cmp		r1, #0xC9
	bne		.unsjpo	
	//-------
	// Put "test cl,cl" result into r1
	//-------
	mov		r1, ecx
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:3889 80E3C1		  and  bl,C1
	//	1B14:388C 89ADA801        mov  [di+01A8],bp
	//	1B14:3890 7B02            jpo  00003894 ($+2)
	//-------
22: ldrb	r1,[r12, #-2]
	cmp		r1, #0x01
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xAD
	ldreqb	r1,[r12, #-5]
	cmpeq	r1, #0x89
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xC1
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0xE3
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0x80
	bne		.unsjpo	
	//-------
	// Put "and bl,C1" result into r1
	//-------
	and		r1, ebx, #0xC1
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:6CFF F6C203          test dl,03
	//	1B14:6D02 7408            je   00006D0C ($+8)
	//	1B14:6D04 BE36E2          mov  si,E236
	//	1B14:6D07 7B03            jpo  00006D0C ($+3)
	//-------
23: ldrb	r1,[r12, #-2]
	cmp		r1, #0xE2
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0x03
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0xC2
	ldreqb	r1,[r12, #-9]
	cmpeq	r1, #0xF6
	bne		.unsjpo
	//-------
	// Put "test dl,03" result into r1
	//-------
	and		r1, edx, #0x03
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:B2F6 A803            test al,03
	//	1B14:B2F8 742F            je   0000B329 ($+2f)
	//	1B14:B2FA B420            mov  ah,20
	//	1B14:B2FC 7B0E            jpo  0000B30C ($+e)
	//-------
24: ldrb	r1,[r12, #-5]
	cmp		r1, #0x74
	ldreqb	r1,[r12, #-7]
	cmpeq	r1, #0xA8
	beq		.op_7b_test_al_imm8
	b		.unsjpo
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:0A65 F6C430          test ah,30
	//	1B14:0A68 740B            je   00000A75 ($+b)
	//	1B14:0A6A 7B09            jpo  00000A75 ($+9)
	//-------
25: ldrb	r1,[r12, #-4]
	cmp		r1, #0x30
	ldreqb	r1,[r12, #-6]
	cmpeq	r1, #0xF6
	bne		.unsjpo
	//-------
	// Put "test ah,30" result into r1
	//-------
	mov		r1, eax, lsr #8
	and		r1, #0x30
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:0C4D F6C430          test ah,30
	//	1B14:0C50 8A4600          mov  al,[bp]
	//	1B14:0C53 7406            je   00000C5B ($+6)
	//	1B14:0C55 7B04            jpo  00000C5B ($+4)
	//-------
26: ldrb	r1,[r12, #-7]
	cmp		r1, #0x30
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0xC4
	ldreqb	r1,[r12, #-9]
	cmpeq	r1, #0xF6
	bne		.unsjpo
	//-------
	// Put "test ah,30" result into r1
	//-------
	mov		r1, eax, lsr #8
	and		r1, #0x30
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:499F 80E503          and  ch,03
	//	1B14:49A2 7B98            jpo  0000493C ($-68)
	//-------
27: ldrb	r1,[r12, #-2]
	cmp		r1, #0x03
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x80
	bne		.unsjpo
	//-------
	// Put "and ch,03" result into r1
	//-------
	mov		r1, ecx, lsr #8
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:B675 F6C2C3          test dl,C3
	//	1B14:B678 7B05            jpo  0000B67F ($+5)
	//-------
28: ldrb	r1,[r12, #-2]
	cmp		r1, #0xC3
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xF6
	bne		.unsjpo
	//-------
	// Put "test dl,C3" result into r1
	//-------
	and		r1, edx, #0xC3
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:0B58 0AC0            or   al,al
	//	1B14:0B5A 7444            je   00000BA0 ($+44)
	//	1B14:0B5C 7856            js   00000BB4 ($+56)
	//	1B14:0B5E C684A1E101      mov  byte [si-1E5F],01
	//	1B14:0B63 7B49            jpo  00000BAE ($+49)
	//-------
29: ldrb	r1,[r12, #-6]
	cmp		r1, #0xC6
	ldreqb	r1,[r12, #-8]
	cmpeq	r1, #0x78
	ldreqb	r1,[r12, #-10]
	cmpeq	r1, #0x74
	ldreqb	r1,[r12, #-11]
	cmpeq	r1, #0xC0
	ldreqb	r1,[r12, #-12]
	cmpeq	r1, #0x0A
	bne		.unsjpo
	//-------
	// Put "or al,al" result into r1
	//-------
	mov		r1, eax
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	1B14:8361 83F740          xor  di,0040
	//	1B14:8364 7B0E            jpo  00008374 ($+e)
	//-------
30: ldrb	r1,[r12, #-2]
	cmp		r1, #0x40
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x83
	bne		.unsjpo
	//-------
	// Put "xor di,0040" result into r1
	//-------
	mov		r1, edi
	b		op_7b_r1
	//-------
	// Make sure it is "Chess Genius 3"
	//	15E2:6F76 F6C1C0        TEST	CL,C0                              
	//	15E2:6F79 7B0A          JPO	6F85
	//-------
31: ldrb	r1,[r12, #-2]
	cmp		r1, #0xC0
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0xF6
	bne		.unsjpo
	//-------
	// Put "test cl,C0" result into r1
	//-------
	and		r1, ecx, #0xC0
	b		op_7b_r1
	//-------
	// Make sure it is "NHL '94"
	//	0691:000032F8 80E403          and  ah,03
	//	0691:000032FB 7B0B            jpo  00003308 ($+b)
	//-------
32: ldrb	r1,[r12, #-2]
	cmp		r1, #0x03
	ldreqb	r1,[r12, #-4]
	cmpeq	r1, #0x80
	bne		.unsjpo
	//-------
	// Put "and ah,03" result into r1
	//-------
	mov		r1, eax, lsr #8
	b		op_7b_r1
	//-------
	// Seems to be "test AL,imm8".
	// We have the result in SP_PARITY_BYTE, use it.
	//-------
.op_7b_test_al_imm8:
	ldrb	r1,[sp, #SP_PARITY_BYTE]
	//-------
	// Calculate parity flag value from r1 register low byte.
	// Use special ARM hack by FluBBa ("http://www.ndsretro.com/armhacks.html"):
	// r1 is input/output byte. 1 = odd, 0 = even parity. Sign flag can also be used if actual value not needed.
	//-------
op_7b_r1:
	and		r1, #0xFF
	eor 	r1,r1,r1,lsl#16
	eor 	r1,r1,r1,lsl#8
	eor 	r1,r1,r1,lsl#4
	eor 	r1,r1,r1,lsl#2
	eors 	r1,r1,r1,lsl#1
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	addmi	r12, r12, r1			// Adjust program counter by the jump amount, if the condition is true
	b		restore_flags_from_r0	// Back to loop, restoring flags
	//------
	// Tell "Unhandled JPO opcode" and exit the emulation.
	//------
	.global	.unsjpo
.unsjpo:
	ldr		r2, =BreakReason
	ldr		r1, =BRUnsJPO						// Tell "Unhandled JPO opcode"
	str		r1, [r2]
	b		.unknown
	
// ------------------- 80 = ??? r/m8,imm8 ------------------------------
//
// All modrm bytes supported!
//
//
	.global	op_80
op_80:
op_82:
	modrm_jump_16
// 0 (idx only)
.macro tmp oper
	.word \oper\()_bxsi_imm8, \oper\()_bxdi_imm8, \oper\()_bpsi_imm8, \oper\()_bpdi_imm8, \oper\()_siidx_imm8, \oper\()_diidx_imm8, \oper\()_disp16_imm8, \oper\()_bxidx_imm8
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
//0x40 (idx+disp8)
.macro tmp oper
	.word \oper\()_bxsid8_imm8, \oper\()_bxdid8_imm8, \oper\()_bpsid8_imm8, \oper\()_bpdid8_imm8, \oper\()_sidisp8_imm8, \oper\()_didisp8_imm8, \oper\()_bpdisp8_imm8, \oper\()_bxdisp8_imm8
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
//0x80 (idx+disp16)
.macro tmp oper
	.word \oper\()_bxsid16_imm8, \oper\()_bxdid16_imm8, \oper\()_bpsid16_imm8, \oper\()_bpdid16_imm8, \oper\()_sidisp16_imm8, \oper\()_didisp16_imm8, \oper\()_bpdisp16_imm8, \oper\()_bxdisp16_imm8
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
//0xc0 = mod = 11b => two register operands
// ADD r/m8,imm8
	.word add_al_imm8, add_cl_imm8, add_dl_imm8, add_bl_imm8, add_ah_imm8, add_ch_imm8, add_dh_imm8, add_bh_imm8
// OR r/m8,imm8
	.word or_al_imm8, or_cl_imm8, or_dl_imm8, or_bl_imm8, or_ah_imm8, or_ch_imm8, or_dh_imm8, or_bh_imm8
// ADC r/m8,imm8
	.word adc_al_imm8, adc_cl_imm8, adc_dl_imm8, adc_bl_imm8, adc_ah_imm8, adc_ch_imm8, adc_dh_imm8, adc_bh_imm8
// SBB r/m8,imm8
	.word sbb_al_imm8, sbb_cl_imm8, sbb_dl_imm8, sbb_bl_imm8, sbb_ah_imm8, sbb_ch_imm8, sbb_dh_imm8, sbb_bh_imm8
// AND r/m8,imm8
	.word and_al_imm8, and_cl_imm8, and_dl_imm8, and_bl_imm8, and_ah_imm8, and_ch_imm8, and_dh_imm8, and_bh_imm8
// SUB r/m8,imm8
	.word sub_al_imm8, sub_cl_imm8, sub_dl_imm8, sub_bl_imm8, sub_ah_imm8, sub_ch_imm8, sub_dh_imm8, sub_bh_imm8
// XOR r/m8,imm8
	.word xor_al_imm8, xor_cl_imm8, xor_dl_imm8, xor_bl_imm8, xor_ah_imm8, xor_ch_imm8, xor_dh_imm8, xor_bh_imm8
// CMP r/m8,imm8
	.word cmp_al_imm8, cmp_cl_imm8, cmp_dl_imm8, cmp_bl_imm8, cmp_ah_imm8, cmp_ch_imm8, cmp_dh_imm8, cmp_bh_imm8

	.ltorg

	.global add_al_imm8, add_cl_imm8, add_dl_imm8, add_bl_imm8, add_ah_imm8, add_ch_imm8, add_dh_imm8, add_bh_imm8
	.global or_al_imm8, or_cl_imm8, or_dl_imm8, or_bl_imm8, or_ah_imm8, or_ch_imm8, or_dh_imm8, or_bh_imm8
	.global adc_al_imm8, adc_cl_imm8, adc_dl_imm8, adc_bl_imm8, adc_ah_imm8, adc_ch_imm8, adc_dh_imm8, adc_bh_imm8
	.global sbb_al_imm8, sbb_cl_imm8, sbb_dl_imm8, sbb_bl_imm8, sbb_ah_imm8, sbb_ch_imm8, sbb_dh_imm8, sbb_bh_imm8
	.global and_al_imm8, and_cl_imm8, and_dl_imm8, and_bl_imm8, and_ah_imm8, and_ch_imm8, and_dh_imm8, and_bh_imm8
	.global sub_al_imm8, sub_cl_imm8, sub_dl_imm8, sub_bl_imm8, sub_ah_imm8, sub_ch_imm8, sub_dh_imm8, sub_bh_imm8
	.global xor_al_imm8, xor_cl_imm8, xor_dl_imm8, xor_bl_imm8, xor_ah_imm8, xor_ch_imm8, xor_dh_imm8, xor_bh_imm8
	.global cmp_al_imm8, cmp_cl_imm8, cmp_dl_imm8, cmp_bl_imm8, cmp_ah_imm8, cmp_ch_imm8, cmp_dh_imm8, cmp_bh_imm8

.macro op80common oper
	.global	\oper\()_t0_bp_imm8
\oper\()_t0_bp_imm8:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	\oper\()_t0_imm8
\oper\()_t0_imm8:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_80_RAM_\oper op_80_EGA_\oper op_80_MODEX_\oper
.endm

	//-------
	// Add: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op80common add
	.global	.op_80_RAM_add
.op_80_RAM_add:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	adds	r1, r0, lsl #24
	lsr		r1, #24					// Shift it to the lowest byte
	strb	r1, [r2]				// Save the changed byte
	b		loop

	//-------
	// Or: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op80common or
.op_80_RAM_or:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	orrs	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	lsr		r1, #24					// Shift it to the lowest byte
	strb	r1, [r2]				// Save the changed byte
	b		loop

	//-------
	// Adc: memory location in normal RAM.
	// On input:
	//	r1 = immediate byte << 24
	//	r2 = physical memory address
	//-------
	op80common adc
.op_80_RAM_adc:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	addcs	r1, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r1, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, r0, lsl #24		// Perform the actual addition, setting the resulting flags.
	lsr		r0, #24
	strb	r0, [r2]				// Save the result
	b		loop

	//-------
	// Sbb: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op80common sbb
.op_80_RAM_sbb:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	bcs		1f						// If input carry is set, we need to calculate the flags ourselves.
	rsbs	r0, r1, r0, lsl #24		// Perform the actual subtraction, setting the resulting flags.
	lsr		r0, #24					// Shift it to the lowest byte
	strb	r0,[r2]					// Save the changed byte
	b		complement_carry
	//-------
	// Input carry is set, so calculate the flags here.
	//-------
1:	sub		r3, r0, r1, lsr #24		// r2 = lf_var1d - lf_var2d
	sub		r3, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r3, r3, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	lsr		r3, #24
	strb	r3,[r2]					// Store byte to RAM
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0, r1, lsr #24
	eor		r3, r0
	and		r1, r3
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0

	//-------
	// And: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op80common and
.op_80_RAM_and:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	ands	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	lsr		r1, #24					// Shift it to the lowest byte
	strb	r1, [r2]				// Save the changed byte
	b		loop

	//-------
	// Sub: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op80common sub
.op_80_RAM_sub:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	rsbs	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	lsr		r1, #24					// Shift it to the lowest byte
	strb	r1,[r2]					// Save the changed byte
	b		complement_carry

	//-------
	// Xor: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op80common xor
.op_80_RAM_xor:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	eors	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	lsr		r1, #24					// Shift it to the lowest byte
	strb	r1, [r2]				// Save the changed byte
	b		loop

	//-------
	// Cmp: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op80common cmp
.op_80_RAM_cmp:
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	ldrb	r0, [r2] 							// Load byte to r0
	lsl		r1, #24								// imm8 byte to highest byte of r1
	rsbs	r1, r0, lsl #24			// Perform the operation using the highest bytes to get the correct flags
	b		complement_carry

.macro op80genall oper
\oper\()_bxsi_imm8:
	add		r0, ebx, esi
	b		\oper\()_t0_imm8
\oper\()_bxdi_imm8:
	add		r0, ebx, edi
	b		\oper\()_t0_imm8
\oper\()_bpsi_imm8:
	add		r0, ebp, esi
	b		\oper\()_t0_bp_imm8
\oper\()_bpdi_imm8:
	add		r0, ebp, edi
	b		\oper\()_t0_bp_imm8
	.global	\oper\()_siidx_imm8
\oper\()_siidx_imm8:
	mov		r0, esi
	b		\oper\()_t0_imm8
	.global	\oper\()_diidx_imm8
\oper\()_diidx_imm8:
	mov		r0, edi
	b		\oper\()_t0_imm8
\oper\()_disp16_imm8:
	r0_from_disp16
	b		\oper\()_t0_imm8
	.global	\oper\()_bxidx_imm8
\oper\()_bxidx_imm8:
	mov		r0, ebx
	b		\oper\()_t0_imm8
\oper\()_bxsid8_imm8:
	r0_from_bxidxdisp8 esi
	b		\oper\()_t0_imm8
\oper\()_bxdid8_imm8:
	r0_from_bxidxdisp8 edi
	b		\oper\()_t0_imm8
\oper\()_bpsid8_imm8:
	r0_from_bpidxdisp8 esi
	b		\oper\()_t0_bp_imm8
\oper\()_bpdid8_imm8:
	r0_from_bpidxdisp8 edi
	b		\oper\()_t0_bp_imm8
	.global	\oper\()_sidisp8_imm8
\oper\()_sidisp8_imm8:
	r0_from_idx_disp8 esi
	b		\oper\()_t0_imm8
	.global	\oper\()_didisp8_imm8
\oper\()_didisp8_imm8:
	r0_from_idx_disp8 edi
	b		\oper\()_t0_imm8
	.global	\oper\()_bpdisp8_imm8
\oper\()_bpdisp8_imm8:
	r0_from_idx_disp8 ebp
	b		\oper\()_t0_bp_imm8
	.global	\oper\()_bxdisp8_imm8
\oper\()_bxdisp8_imm8:
	r0_from_idx_disp8 ebx
	b		\oper\()_t0_imm8
\oper\()_bxsid16_imm8:
	r0_from_bxidxdisp16 esi
	b		\oper\()_t0_imm8
\oper\()_bxdid16_imm8:
	r0_from_bxidxdisp16 edi
	b		\oper\()_t0_imm8
\oper\()_bpsid16_imm8:
	r0_from_bpidxdisp16 esi
	b		\oper\()_t0_bp_imm8
\oper\()_bpdid16_imm8:
	r0_from_bpidxdisp16 edi
	b		\oper\()_t0_bp_imm8
\oper\()_sidisp16_imm8:
	r0_from_idx_disp16 esi
	b		\oper\()_t0_imm8
\oper\()_didisp16_imm8:
	r0_from_idx_disp16 edi
	b		\oper\()_t0_imm8
\oper\()_bpdisp16_imm8:
	r0_from_idx_disp16 ebp
	b		\oper\()_t0_bp_imm8
\oper\()_bxdisp16_imm8:
	r0_from_idx_disp16 ebx
	b		\oper\()_t0_imm8
.endm


// ----- ADD -----

op80genall add

.macro add_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	lsl		r1, #24								// imm8 byte to highest byte of r1
	adds	r1, \reg, lsl #24		// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the lowest byte of the register
	orr		\reg, r1, lsr #24		// Put the result to the lowest byte of the register
	b		loop
.endm
.macro add_reg8h_imm8 reg
	// ----- On input, r1 = imm8 byte value in high byte
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	and		r0, \reg, #0xFF00		// Put the reg8h value to the r0, clearing reg8l value
	lsl		r1, #24								// imm8 byte to highest byte of r1
	adds	r1, r0, lsl #16			// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the reg8h value of the register
	orr		\reg, r1, lsr #16		// Put the result to the highest byte of the register
	b		loop
.endm

add_al_imm8:
	add_reg8l_imm8 r4
add_cl_imm8:
	add_reg8l_imm8 r5
add_dl_imm8:
	add_reg8l_imm8 r6
add_bl_imm8:
	add_reg8l_imm8 r7
add_ah_imm8:
	add_reg8h_imm8 r4
add_ch_imm8:
	add_reg8h_imm8 r5
add_dh_imm8:
	add_reg8h_imm8 r6
add_bh_imm8:
	add_reg8h_imm8 r7

// ----- OR -----

op80genall or

.macro or_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #24								// imm8 byte to highest byte of r1
	mov		r0, \reg, lsl #24		// Shift the reg value to the topmost byte of r0
	orrs	r1, r0					// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the lowest byte of the register
	orr		\reg, r1, lsr #24		// Put the result to the lowest byte of the register
	b		loop
.endm

.macro or_reg8h_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #24								// imm8 byte to highest byte of r1
	and		r0, \reg, #0xFF00		// Put the reg8h value to the r0, clearing reg8l value
	orrs	r1, r0, lsl #16			// Perform the addition using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the reg8h value of the register
	orr		\reg, r1, lsr #16		// Put the result to the highest byte of the register
	b		loop
.endm

or_al_imm8:
	or_reg8l_imm8 r4
or_cl_imm8:
	or_reg8l_imm8 r5
or_dl_imm8:
	or_reg8l_imm8 r6
or_bl_imm8:
	or_reg8l_imm8 r7
or_ah_imm8:
	or_reg8h_imm8 r4
or_ch_imm8:
	or_reg8h_imm8 r5
or_dh_imm8:
	or_reg8h_imm8 r6
or_bh_imm8:
	or_reg8h_imm8 r7

// ----- ADC -----

op80genall adc

.macro adc_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	lsl		r1, #24								// imm8 byte to highest byte of r1
	addcs	r1, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r1, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r1, \reg, lsl #24		// Perform the actual addition, setting the resulting flags.
	bic		\reg, #0xFF				// Clear the lowest byte of the register
	orr		\reg, r1, lsr #24		// Put the result to the lowest byte of the register
	b		loop
.endm

.macro adc_reg8h_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	and		r0, \reg, #0xFF00		// Put the reg8h value to the r1, clearing reg8l value
	lsl		r1, #24								// imm8 byte to highest byte of r1
	addcs	r1, #0x01000000			// If input Carry is set, adjust the right operand so that ...
	subcs	r1, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r1, r0, lsl #16			// Perform the actual addition, setting the resulting flags.
	bic		\reg, #0xFF00			// Clear the reg8h value of the register
	orr		\reg, r1, lsr #16		// Put the result to the highest byte of the register
	b		loop
.endm

adc_al_imm8:
	adc_reg8l_imm8 r4
adc_cl_imm8:
	adc_reg8l_imm8 r5
adc_dl_imm8:
	adc_reg8l_imm8 r6
adc_bl_imm8:
	adc_reg8l_imm8 r7
adc_ah_imm8:
	adc_reg8h_imm8 r4
adc_ch_imm8:
	adc_reg8h_imm8 r5
adc_dh_imm8:
	adc_reg8h_imm8 r6
adc_bh_imm8:
	adc_reg8h_imm8 r7

// ----- SBB -----

op80genall sbb

.macro sbb_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	lsl		r1, #24								// imm8 byte to highest byte of r1
	bcs		1f
	rsbs	r0, r1, \reg, lsl #24	// Perform the actual subtraction, setting the resulting flags.
	bic		\reg, #0xFF				// Clear the lowest byte of the register
	orr		\reg, r0, lsr #24		// Put the result to the lowest byte of the register
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	and		r0, \reg, #0xFF	
	sub		r2, r0, r1, lsr #24		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r2, lsr #24		// Put the result to the lower byte of the high halfword of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0, r1, lsr #24
	eor		r2, r0, r2, lsr #24
	and		r1, r2
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

.macro sbb_reg8h_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	and		r0, \reg, #0xFF00		// Put the reg8h value to the r1, clearing reg8l value
	lsl		r1, #24								// imm8 byte to highest byte of r1
	bcs		1f
	rsbs	r0, r1, r0, lsl #16		// Perform the actual subtraction, setting the resulting flags.
	bic		\reg, #0xFF00			// Clear the reg8h value of the register
	orr		\reg, r0, lsr #16		// Put the result to the highest byte of the register
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	lsr		r1, #24
	rsb		r2, r1, r0, lsr #8		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #24			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	bic		\reg, #0xFF00			// Clear the current reg8l value
	orr		\reg, r2, lsr #16		// Put the result to the lower byte of the high halfword of the left register
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x80
	//-------
	eor		r1, r0, lsr #8
	eor		r2, r0, lsl #16
	and		r1, r2, lsr #24
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x80
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

sbb_al_imm8:
	sbb_reg8l_imm8 r4
sbb_cl_imm8:
	sbb_reg8l_imm8 r5
sbb_dl_imm8:
	sbb_reg8l_imm8 r6
sbb_bl_imm8:
	sbb_reg8l_imm8 r7
sbb_ah_imm8:
	sbb_reg8h_imm8 r4
sbb_ch_imm8:
	sbb_reg8h_imm8 r5
sbb_dh_imm8:
	sbb_reg8h_imm8 r6
sbb_bh_imm8:
	sbb_reg8h_imm8 r7

// ----- AND -----

op80genall and

.macro and_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #24								// imm8 byte to highest byte of r1
	mov		r0, \reg, lsl #24
	ands	r1, r0					// AND the values using the top byte, setting flags
	bic		\reg, #0xFF
	orr		\reg, r1, lsr #24
	b		loop
.endm

.macro and_reg8h_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #24								// imm8 byte to highest byte of r1
	mov		r0, \reg, lsl #16
	ands	r1, r0					// AND the values using the top byte, setting flags
	bic		\reg, #0xFF00
	orr		\reg, r1, lsr #16
	b		loop
.endm

and_al_imm8:
	and_reg8l_imm8 r4
and_cl_imm8:
	and_reg8l_imm8 r5
and_dl_imm8:
	and_reg8l_imm8 r6
and_bl_imm8:
	and_reg8l_imm8 r7

and_ah_imm8:
	and_reg8h_imm8 r4
and_ch_imm8:
	and_reg8h_imm8 r5
and_dh_imm8:
	and_reg8h_imm8 r6
and_bh_imm8:
	and_reg8h_imm8 r7

// ----- SUB -----

op80genall sub

.macro sub_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	lsl		r1, #24								// imm8 byte to highest byte of r1
	rsbs	r1, \reg, lsl #24		// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF				// Clear the lowest byte of the register
	orr		\reg, r1, lsr #24		// Put the result to the lowest byte of the register
	b		complement_carry
.endm
.macro sub_reg8h_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	and		r0, \reg, #0xFF00		// Put the reg8h value to the r0, clearing reg8l value
	lsl		r1, #24								// imm8 byte to highest byte of r1
	rsbs	r1, r0, lsl #16			// Perform the operation using the highest bytes to get the correct flags
	bic		\reg, #0xFF00			// Clear the reg8h value of the register
	orr		\reg, r1, lsr #16		// Put the result to the highest byte of the register
	b		complement_carry
.endm

sub_al_imm8:
	sub_reg8l_imm8 r4
sub_cl_imm8:
	sub_reg8l_imm8 r5
sub_dl_imm8:
	sub_reg8l_imm8 r6
sub_bl_imm8:
	sub_reg8l_imm8 r7
sub_ah_imm8:
	sub_reg8h_imm8 r4
sub_ch_imm8:
	sub_reg8h_imm8 r5
sub_dh_imm8:
	sub_reg8h_imm8 r6
sub_bh_imm8:
	sub_reg8h_imm8 r7

// ----- XOR -----

op80genall xor

.macro xor_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #24								// imm8 byte to highest byte of r1
	mov		r0, \reg, lsl #24
	eors	r1, r0					// XOR the values using the top byte, setting flags
	bic		\reg, #0xFF
	orr		\reg, r1, lsr #24
	b		loop
.endm

.macro xor_reg8h_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #24								// imm8 byte to highest byte of r1
	and		r0, \reg, #0xFF00		// Put reg8h to r1 and clear all but the topmost byte
	eors	r1, r0, lsl #16			// XOR the values using the top byte, setting flags
	bic		\reg, #0xFF00
	orr		\reg, r1, lsr #16
	b		loop
.endm

xor_al_imm8:
	xor_reg8l_imm8 r4
xor_cl_imm8:
	xor_reg8l_imm8 r5
xor_dl_imm8:
	xor_reg8l_imm8 r6
xor_bl_imm8:
	xor_reg8l_imm8 r7

xor_ah_imm8:
	xor_reg8h_imm8 r4
xor_ch_imm8:
	xor_reg8h_imm8 r5
xor_dh_imm8:
	xor_reg8h_imm8 r6
xor_bh_imm8:
	xor_reg8h_imm8 r7

// ----- CMP -----

op80genall cmp
	
.macro cmp_reg8l_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	lsl		r1, #24								// imm8 byte to highest byte of r1
	rsbs	r1, \reg, lsl #24		// Shift the register also to the topmost byte, and then compare the values
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm

.macro cmp_reg8h_imm8 reg
	ldrb	r1,[r12], #1						// Load the imm8 byte to r1
	and		r0, \reg, #0xFF00		// Put reg8h to r1 and clear out the low byte
	lsl		r1, #24								// imm8 byte to highest byte of r1
	rsbs	r1, r0, lsl #16			// Shift the immediate byte also to the topmost byte, and then compare the values
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm

cmp_al_imm8:
	cmp_reg8l_imm8 r4
cmp_cl_imm8:
	cmp_reg8l_imm8 r5
cmp_dl_imm8:
	cmp_reg8l_imm8 r6
cmp_bl_imm8:
	cmp_reg8l_imm8 r7
cmp_ah_imm8:
	cmp_reg8h_imm8 r4
cmp_ch_imm8:
	cmp_reg8h_imm8 r5
cmp_dh_imm8:
	cmp_reg8h_imm8 r6
cmp_bh_imm8:
	cmp_reg8h_imm8 r7

// ------------------- 81 = ??? r/m16,imm16 -------------------------------
// 
// All modrm bytes supported!
//
op_81:
	modrm_jump_16
// 0 (idx only)
.macro tmp oper
	.global	\oper\()_siidx_imm16, \oper\()_diidx_imm16, \oper\()_bxidx_imm16
	.word \oper\()_bxsi_imm16, \oper\()_bxdi_imm16, \oper\()_bpsi_imm16, \oper\()_bpdi_imm16, \oper\()_siidx_imm16, \oper\()_diidx_imm16, \oper\()_disp16_imm16, \oper\()_bxidx_imm16
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
// 0x40 (idx+disp8)
.macro tmp oper
	.global	\oper\()_sidisp8_imm16, \oper\()_didisp8_imm16, \oper\()_bpdisp8_imm16, \oper\()_bxdisp8_imm16
	.word \oper\()_bxsid8_imm16, \oper\()_bxdid8_imm16, \oper\()_bpsid8_imm16, \oper\()_bpdid8_imm16, \oper\()_sidisp8_imm16, \oper\()_didisp8_imm16, \oper\()_bpdisp8_imm16, \oper\()_bxdisp8_imm16
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
// 0x80 (idx+disp16)
.macro tmp oper
	.word \oper\()_bxsid16_imm16, \oper\()_bxdid16_imm16, \oper\()_bpsid16_imm16, \oper\()_bpdid16_imm16, \oper\()_sidisp16_imm16, \oper\()_didisp16_imm16, \oper\()_bpdisp16_imm16, \oper\()_bxdisp16_imm16
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
//0xc0 = mod = 11b => register operand
// ADD r/m16,imm16
	.word add_ax_imm16, add_cx_imm16, add_dx_imm16, add_bx_imm16, add_sp_imm16, add_bp_imm16, add_si_imm16, add_di_imm16
// OR r/m16,imm16
	.word or_ax_imm16, or_cx_imm16, or_dx_imm16, or_bx_imm16, or_sp_imm16, or_bp_imm16, or_si_imm16, or_di_imm16
// ADC r/m16,imm16
	.word adc_ax_imm16, adc_cx_imm16, adc_dx_imm16, adc_bx_imm16, adc_sp_imm16, adc_bp_imm16, adc_si_imm16, adc_di_imm16
// SBB r/m16,imm16
	.word sbb_ax_imm16, sbb_cx_imm16, sbb_dx_imm16, sbb_bx_imm16, sbb_sp_imm16, sbb_bp_imm16, sbb_si_imm16, sbb_di_imm16
// AND r/m16,imm16
	.word and_ax_imm16, and_cx_imm16, and_dx_imm16, and_bx_imm16, and_sp_imm16, and_bp_imm16, and_si_imm16, and_di_imm16
// SUB r/m16,imm16
	.word sub_ax_imm16, sub_cx_imm16, sub_dx_imm16, sub_bx_imm16, sub_sp_imm16, sub_bp_imm16, sub_si_imm16, sub_di_imm16
// XOR r/m16,imm16
	.word xor_ax_imm16, xor_cx_imm16, xor_dx_imm16, xor_bx_imm16, xor_sp_imm16, xor_bp_imm16, xor_si_imm16, xor_di_imm16
// CMP r/m16,imm16
	.word cmp_ax_imm16, cmp_cx_imm16, cmp_dx_imm16, cmp_bx_imm16, cmp_sp_imm16, cmp_bp_imm16, cmp_si_imm16, cmp_di_imm16

	.global add_ax_imm16, add_cx_imm16, add_dx_imm16, add_bx_imm16, add_sp_imm16, add_bp_imm16, add_si_imm16, add_di_imm16
	.global or_ax_imm16, or_cx_imm16, or_dx_imm16, or_bx_imm16, or_sp_imm16, or_bp_imm16, or_si_imm16, or_di_imm16
	.global adc_ax_imm16, adc_cx_imm16, adc_dx_imm16, adc_bx_imm16, adc_sp_imm16, adc_bp_imm16, adc_si_imm16, adc_di_imm16
	.global sbb_ax_imm16, sbb_cx_imm16, sbb_dx_imm16, sbb_bx_imm16, sbb_sp_imm16, sbb_bp_imm16, sbb_si_imm16, sbb_di_imm16
	.global and_ax_imm16, and_cx_imm16, and_dx_imm16, and_bx_imm16, and_sp_imm16, and_bp_imm16, and_si_imm16, and_di_imm16
	.global sub_ax_imm16, sub_cx_imm16, sub_dx_imm16, sub_bx_imm16, sub_sp_imm16, sub_bp_imm16, sub_si_imm16, sub_di_imm16
	.global xor_ax_imm16, xor_cx_imm16, xor_dx_imm16, xor_bx_imm16, xor_sp_imm16, xor_bp_imm16, xor_si_imm16, xor_di_imm16
	.global cmp_ax_imm16, cmp_cx_imm16, cmp_dx_imm16, cmp_bx_imm16, cmp_sp_imm16, cmp_bp_imm16, cmp_si_imm16, cmp_di_imm16

.macro op81common oper
	.global	\oper\()_r0_bp_imm16
\oper\()_r0_bp_imm16:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	\oper\()_r0_imm16
\oper\()_r0_imm16:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_81_RAM_\oper op_81_EGA_\oper bad_MODEX_opcode
.endm

	//-------
	// Add: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common add
.op_81_RAM_add:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	orr		r0, r1, lsl #8			// r0 low halfword = value from RAM
	ldrb	r1, [r12, #1]			// r1 = high byte of imm16 value
	orr		r0, r1, lsl #24			// Save it to r0 highest byte
	ldrb	r1, [r12],#2			// r1 = low byte of imm16 value
	orr		r1, r0, lsr #16			// r1 = imm16 value in low halfword
	lsl		r0, #16					// r0 = RAM value in high halfword
	//-------
	// Perform the actual operation
	//-------
	adds	r0, r1, lsl #16			// ADD the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

	//-------
	// Or: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common or
.op_81_RAM_or:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	orr		r0, r1, lsl #8			// r0 low halfword = value from RAM
	ldrb	r1, [r12, #1]			// r1 = high byte of imm16 value
	orr		r0, r1, lsl #24			// Save it to r0 highest byte
	ldrb	r1, [r12],#2			// r1 = low byte of imm16 value
	orr		r1, r0, lsr #16			// r1 = imm16 value in low halfword
	lsl		r0, #16					// r0 = RAM value in high halfword
	//-------
	// Perform the actual operation
	//-------
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #16					// Shift it to the high halfword
	orrs	r0, r1					// OR the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

	//-------
	// Adc: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common adc
.op_81_RAM_adc:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	ldrb	r3, [r12], #1
	orr		r0, r1, lsl #8			// r0 low halfword = value from RAM
	ldrb	r1, [r12], #1			// r1 = high byte of imm16 value
	lsl		r3, #16
	orr		r1, r3, r1, lsl #24		// r1 = imm16 value in high 16bits
	//-------
	// Perform the actual operation
	//-------
	addcs	r1, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r1, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, r0, lsl #16		// Perform the actual addition, setting the resulting flags.
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		loop

	//-------
	// Sbb: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common sbb
.op_81_RAM_sbb:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	ldrb	r3, [r12], #1			// r3 = low byte of imm16 value
	orr		r0, r1, lsl #8			// r0 low halfword = value from RAM
	ldrb	r1, [r12], #1			// r1 = high byte of imm16 value
	bcs		1f
	//-------
	// Perform the actual operation
	//-------
	lsl		r3, #16
	orr		r1, r3, r1, lsl #24		// r1 = imm16 value in high 16 bits
	rsbs	r0, r1, r0, lsl #16		// Perform the actual subtraction, setting the resulting flags.
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		complement_carry
	//-------
	// Input carry set, calculate the flags separately
	//-------
1:	orr		r1, r3, r1, lsl #8		// r1 = imm16 value
	sub		r3, r0, r1				// r3 = lf_var1d - lf_var2d
	sub		r3, #1					// r3 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r3, r3, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	lsr		r3, #16
	strb	r3,[r2]					// Store byte to RAM
	ror		r3, #8
	strb	r3,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0
	eor		r3, r0, r3, ror #24
	and		r1, r3
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0


	//-------
	// And: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common and
.op_81_RAM_and:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	orr		r0, r1, lsl #8			// r0 low halfword = value from RAM
	ldrb	r1, [r12, #1]			// r1 = high byte of imm16 value
	orr		r0, r1, lsl #24			// Save it to r0 highest byte
	ldrb	r1, [r12],#2			// r1 = low byte of imm16 value
	orr		r1, r0, lsr #16			// r1 = imm16 value in low halfword
	lsl		r0, #16					// r0 = RAM value in high halfword
	//-------
	// Perform the actual operation
	//-------
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #16					// Shift it to the high halfword
	ands	r0, r1					// AND the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

	//-------
	// Sub: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common sub
.op_81_RAM_sub:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	orr		r0, r1, lsl #8			// r0 low halfword = value from RAM
	ldrb	r1, [r12, #1]			// r1 = high byte of imm16 value
	orr		r0, r1, lsl #24			// Save it to r0 highest byte
	ldrb	r1, [r12],#2			// r1 = low byte of imm16 value
	orr		r1, r0, lsr #16			// r1 = imm16 value in low halfword
	lsl		r0, #16					// r0 = RAM value in high halfword
	//-------
	// Perform the actual operation
	//-------
	subs	r0, r1, lsl #16			// SUB the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		complement_carry

	//-------
	// Xor: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common xor
.op_81_RAM_xor:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	orr		r0, r1, lsl #8			// r0 low halfword = value from RAM
	ldrb	r1, [r12, #1]			// r1 = high byte of imm16 value
	orr		r0, r1, lsl #24			// Save it to r0 highest byte
	ldrb	r1, [r12],#2			// r1 = low byte of imm16 value
	orr		r1, r0, lsr #16			// r1 = imm16 value in low halfword
	lsl		r0, #16					// r0 = RAM value in high halfword
	//-------
	// Perform the actual operation
	//-------
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #16					// Shift it to the high halfword
	eors	r0, r1					// XOR the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

	//-------
	// Cmp: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op81common cmp
.op_81_RAM_cmp:
	//-------
	// Load the values from RAM and imm16
	//-------
	ldrb	r0, [r2]
	ldrb	r1, [r2, #1]
	lsl		r0, #16					// r0 = RAM value in high halfword
	orr		r0, r1, lsl #24			// r0 high halfword = value from RAM
	ldrb	r1, [r12], #1
	ldrb	r2, [r12], #1
	lsl		r1, #16
	orr		r1, r2, lsl #24			// r1 high halfword = imm16 value
	//-------
	// Perform the actual operation
	//-------
	cmp		r0, r1					// CMP the values, setting flags
	b		complement_carry

	.ltorg

.macro op81genall oper

// --- [idx] ---

\oper\()_bxsi_imm16:
	add		r0, r7, r10
	b		\oper\()_r0_imm16
\oper\()_bxdi_imm16:
	add		r0, r7, r11
	b		\oper\()_r0_imm16
\oper\()_bpsi_imm16:
	add		r0, r9, r10
	b		\oper\()_r0_bp_imm16
\oper\()_bpdi_imm16:
	add		r0, r9, r11
	b		\oper\()_r0_bp_imm16
\oper\()_siidx_imm16:
	mov		r0, r10
	b		\oper\()_r0_imm16
\oper\()_diidx_imm16:
	mov		r0, r11
	b		\oper\()_r0_imm16
\oper\()_disp16_imm16:
	r0_from_disp16
	b		\oper\()_r0_imm16
\oper\()_bxidx_imm16:
	mov		r0, r7
	b		\oper\()_r0_imm16

// --- [idx+disp8] ---

\oper\()_bxsid8_imm16:
	r0_from_bxidxdisp8 r10
	b		\oper\()_r0_imm16
\oper\()_bxdid8_imm16:
	r0_from_bxidxdisp8 r11
	b		\oper\()_r0_imm16
\oper\()_bpsid8_imm16:
	r0_from_bpidxdisp8 r10
	b		\oper\()_r0_bp_imm16
\oper\()_bpdid8_imm16:
	r0_from_bpidxdisp8 r11
	b		\oper\()_r0_bp_imm16
\oper\()_sidisp8_imm16:
	r0_from_idx_disp8 r10
	b		\oper\()_r0_imm16
\oper\()_didisp8_imm16:
	r0_from_idx_disp8 r11
	b		\oper\()_r0_imm16
\oper\()_bpdisp8_imm16:
	r0_from_idx_disp8 r9
	b		\oper\()_r0_bp_imm16
\oper\()_bxdisp8_imm16:
	r0_from_idx_disp8 r7
	b		\oper\()_r0_imm16

// --- [idx+disp16] ---

\oper\()_bxsid16_imm16:
	r0_from_bxidxdisp16 r10
	b		\oper\()_r0_imm16
\oper\()_bxdid16_imm16:
	r0_from_bxidxdisp16 r11
	b		\oper\()_r0_imm16
\oper\()_bpsid16_imm16:
	r0_from_bpidxdisp16 r10
	b		\oper\()_r0_bp_imm16
\oper\()_bpdid16_imm16:
	r0_from_bpidxdisp16 r11
	b		\oper\()_r0_bp_imm16
\oper\()_sidisp16_imm16:
	r0_from_idx_disp16 r10
	b		\oper\()_r0_imm16
\oper\()_didisp16_imm16:
	r0_from_idx_disp16 r11
	b		\oper\()_r0_imm16
\oper\()_bpdisp16_imm16:
	r0_from_idx_disp16 r9
	b		\oper\()_r0_bp_imm16
\oper\()_bxdisp16_imm16:
	r0_from_idx_disp16 r7
	b		\oper\()_r0_imm16
	
.endm

// ----- ADD -----

op81genall add

.macro add_reg16_imm16 reg
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	adds	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

add_ax_imm16:
	add_reg16_imm16 r4
add_cx_imm16:
	add_reg16_imm16 r5
add_dx_imm16:
	add_reg16_imm16 r6
add_bx_imm16:
	add_reg16_imm16 r7
add_sp_imm16:
	add_reg16_imm16 r8
add_bp_imm16:
	add_reg16_imm16 r9
add_si_imm16:
	add_reg16_imm16 r10
add_di_imm16:
	add_reg16_imm16 r11

// ----- OR -----

op81genall or

.macro or_reg16_imm16 reg
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C or O)
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	orrs	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

or_ax_imm16:
	or_reg16_imm16 r4
or_cx_imm16:
	or_reg16_imm16 r5
or_dx_imm16:
	or_reg16_imm16 r6
or_bx_imm16:
	or_reg16_imm16 r7
or_sp_imm16:
	or_reg16_imm16 r8
or_bp_imm16:
	or_reg16_imm16 r9
or_si_imm16:
	or_reg16_imm16 r10
or_di_imm16:
	or_reg16_imm16 r11

// ----- ADC -----

op81genall adc

.macro adc_reg16_imm16 reg
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r2, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	eor		\reg, r2, lsr #16
	addcs	r2, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r2, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r2, r0, lsl #16		// Perform the actual addition, setting the resulting flags.
	orr		\reg, r0, lsr #16
	b		loop
.endm

adc_ax_imm16:
	adc_reg16_imm16 r4
adc_cx_imm16:
	adc_reg16_imm16 r5
adc_dx_imm16:
	adc_reg16_imm16 r6
adc_bx_imm16:
	adc_reg16_imm16 r7
adc_sp_imm16:
	adc_reg16_imm16 r8
adc_bp_imm16:
	adc_reg16_imm16 r9
adc_si_imm16:
	adc_reg16_imm16 r10
adc_di_imm16:
	adc_reg16_imm16 r11

// ----- SBB -----

op81genall sbb

.macro sbb_reg16_imm16 reg
	ldrb	r1,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r2,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r0, \reg, lsl #16
	orr		r1, r2, lsl #8			// r0 = low byte | (high byte << 8)
	eor		\reg, r0, lsr #16
	bcs		1f
	subs	r0, r1, lsl #16			// Perform the actual subtraction, setting the resulting flags.
	orr		\reg, r0, lsr #16
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	rsb		r2, r1, r0, lsr #16		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	orr		\reg, r2, lsr #16
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0, lsr #16
	eor		r2, r0
	and		r1, r2, lsr #16
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

sbb_ax_imm16:
	sbb_reg16_imm16 r4
sbb_cx_imm16:
	sbb_reg16_imm16 r5
sbb_dx_imm16:
	sbb_reg16_imm16 r6
sbb_bx_imm16:
	sbb_reg16_imm16 r7
sbb_sp_imm16:
	sbb_reg16_imm16 r8
sbb_bp_imm16:
	sbb_reg16_imm16 r9
sbb_si_imm16:
	sbb_reg16_imm16 r10
sbb_di_imm16:
	sbb_reg16_imm16 r11

// ----- AND -----

op81genall and

.macro and_reg16_imm16 reg
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	ands	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

and_ax_imm16:
	and_reg16_imm16 r4
and_cx_imm16:
	and_reg16_imm16 r5
and_dx_imm16:
	and_reg16_imm16 r6
and_bx_imm16:
	and_reg16_imm16 r7
and_sp_imm16:
	and_reg16_imm16 r8
and_bp_imm16:
	and_reg16_imm16 r9
and_si_imm16:
	and_reg16_imm16 r10
and_di_imm16:
	and_reg16_imm16 r11

// ----- SUB -----

op81genall sub

.macro sub_reg16_imm16 reg
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	subs	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm

sub_ax_imm16:
	sub_reg16_imm16 r4
sub_cx_imm16:
	sub_reg16_imm16 r5
sub_dx_imm16:
	sub_reg16_imm16 r6
sub_bx_imm16:
	sub_reg16_imm16 r7
sub_sp_imm16:
	sub_reg16_imm16 r8
sub_bp_imm16:
	sub_reg16_imm16 r9
sub_si_imm16:
	sub_reg16_imm16 r10
sub_di_imm16:
	sub_reg16_imm16 r11

// ----- XOR -----

op81genall xor

.macro xor_reg16_imm16 reg
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	eors	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

xor_ax_imm16:
	xor_reg16_imm16 r4
xor_cx_imm16:
	xor_reg16_imm16 r5
xor_dx_imm16:
	xor_reg16_imm16 r6
xor_bx_imm16:
	xor_reg16_imm16 r7
xor_sp_imm16:
	xor_reg16_imm16 r8
xor_bp_imm16:
	xor_reg16_imm16 r9
xor_si_imm16:
	xor_reg16_imm16 r10
xor_di_imm16:
	xor_reg16_imm16 r11

// ----- CMP -----

op81genall cmp

.macro cmp_reg16_imm16 reg
	ldrb	r0,[r12],#1				// Load low byte to r1, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r2, \reg, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	cmp		r2, r0, lsl #16			// Perform the operation using the high 16 bits
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm

cmp_ax_imm16:
	cmp_reg16_imm16 r4
cmp_cx_imm16:
	cmp_reg16_imm16 r5
cmp_dx_imm16:
	cmp_reg16_imm16 r6
cmp_bx_imm16:
	cmp_reg16_imm16 r7
cmp_sp_imm16:
	cmp_reg16_imm16 r8
cmp_bp_imm16:
	cmp_reg16_imm16 r9
cmp_si_imm16:
	cmp_reg16_imm16 r10
cmp_di_imm16:
	cmp_reg16_imm16 r11

	
// ------------------- 83 = ??? r/m16,+imm8 ----------------------------
// 
// All modrm bytes supported!
//
//
	.global	op_83
op_83:
	ldrb	r1,[r12],#1				// Load the second opcode byte to r1, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	ldr		pc,[pc, r1, lsl #2]		// Jump to the handler
	.word	0						// Dummy word to align the table to PC+8
// 0 (idx only)
.macro tmp oper
	.global	\oper\()_siidx_simm8, \oper\()_diidx_simm8, \oper\()_disp16_simm8, \oper\()_bxidx_simm8
	.word \oper\()_bxsi_simm8, \oper\()_bxdi_simm8, \oper\()_bpsi_simm8, \oper\()_bpdi_simm8, \oper\()_siidx_simm8, \oper\()_diidx_simm8, \oper\()_disp16_simm8, \oper\()_bxidx_simm8
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
// 0x40 (idx+disp8)
.macro tmp oper
	.global \oper\()_sidisp8_simm8, \oper\()_didisp8_simm8, \oper\()_bpdisp8_simm8, \oper\()_bxdisp8_simm8
	.word \oper\()_bxsid8_simm8, \oper\()_bxdid8_simm8, \oper\()_bpsid8_simm8, \oper\()_bpdid8_simm8, \oper\()_sidisp8_simm8, \oper\()_didisp8_simm8, \oper\()_bpdisp8_simm8, \oper\()_bxdisp8_simm8
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
// 0x80 (idx+disp16)
.macro tmp oper
	.word \oper\()_bxsid16_simm8, \oper\()_bxdid16_simm8, \oper\()_bpsid16_simm8, \oper\()_bpdid16_simm8, \oper\()_sidisp16_simm8, \oper\()_didisp16_simm8, \oper\()_bpdisp16_simm8, \oper\()_bxdisp16_simm8
.endm
tmp add
tmp or
tmp adc
tmp sbb
tmp and
tmp sub
tmp xor
tmp cmp
.purgem tmp	
//0xc0 = mod = 11b => two register operands
// ADD r/m16,+imm8
	.word add_ax_simm8, add_cx_simm8, add_dx_simm8, add_bx_simm8, add_sp_simm8, add_bp_simm8, add_si_simm8, add_di_simm8
// OR r/m16,+imm8
	.word or_ax_simm8, or_cx_simm8, or_dx_simm8, or_bx_simm8, or_sp_simm8, or_bp_simm8, or_si_simm8, or_di_simm8
// ADC r/m16,+imm8
	.word adc_ax_simm8, adc_cx_simm8, adc_dx_simm8, adc_bx_simm8, adc_sp_simm8, adc_bp_simm8, adc_si_simm8, adc_di_simm8
// SBB r/m16,+imm8
	.word sbb_ax_simm8, sbb_cx_simm8, sbb_dx_simm8, sbb_bx_simm8, sbb_sp_simm8, sbb_bp_simm8, sbb_si_simm8, sbb_di_simm8
// AND r/m16,+imm8
	.word and_ax_simm8, and_cx_simm8, and_dx_simm8, and_bx_simm8, and_sp_simm8, and_bp_simm8, and_si_simm8, and_di_simm8
// SUB r/m16,+imm8
	.word sub_ax_simm8, sub_cx_simm8, sub_dx_simm8, sub_bx_simm8, sub_sp_simm8, sub_bp_simm8, sub_si_simm8, sub_di_simm8
// XOR r/m16,+imm8
	.word xor_ax_simm8, xor_cx_simm8, xor_dx_simm8, xor_bx_simm8, xor_sp_simm8, xor_bp_simm8, xor_si_simm8, xor_di_simm8
// CMP r/m16 (reg),+imm8
	.word cmp_ax_simm8, cmp_cx_simm8, cmp_dx_simm8, cmp_bx_simm8, cmp_sp_simm8, cmp_bp_simm8, cmp_si_simm8, cmp_di_simm8

	.global add_ax_simm8, add_cx_simm8, add_dx_simm8, add_bx_simm8, add_sp_simm8, add_bp_simm8, add_si_simm8, add_di_simm8
	.global or_ax_simm8, or_cx_simm8, or_dx_simm8, or_bx_simm8, or_sp_simm8, or_bp_simm8, or_si_simm8, or_di_simm8
	.global adc_ax_simm8, adc_cx_simm8, adc_dx_simm8, adc_bx_simm8, adc_sp_simm8, adc_bp_simm8, adc_si_simm8, adc_di_simm8
	.global sbb_ax_simm8, sbb_cx_simm8, sbb_dx_simm8, sbb_bx_simm8, sbb_sp_simm8, sbb_bp_simm8, sbb_si_simm8, sbb_di_simm8
	.global and_ax_simm8, and_cx_simm8, and_dx_simm8, and_bx_simm8, and_sp_simm8, and_bp_simm8, and_si_simm8, and_di_simm8
	.global sub_ax_simm8, sub_cx_simm8, sub_dx_simm8, sub_bx_simm8, sub_sp_simm8, sub_bp_simm8, sub_si_simm8, sub_di_simm8
	.global xor_ax_simm8, xor_cx_simm8, xor_dx_simm8, xor_bx_simm8, xor_sp_simm8, xor_bp_simm8, xor_si_simm8, xor_di_simm8
	.global cmp_ax_simm8, cmp_cx_simm8, cmp_dx_simm8, cmp_bx_simm8, cmp_sp_simm8, cmp_bp_simm8, cmp_si_simm8, cmp_di_simm8

.macro op83common oper
	.global	\oper\()_r0_bp_simm8
\oper\()_r0_bp_simm8:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	\oper\()_r0_simm8
\oper\()_r0_simm8:
	//-------
	// Indexing by the current effective segment.
	//-------
	mem_handler_jump_r0r3 .op_83_RAM_\oper op_83_EGA_\oper bad_MODEX_opcode_1
	//-------
	// The actual RAM handler must immediately follow this macro!
	//-------
.endm

	//-------
	// Add: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common add
.op_83_RAM_add:
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	lsl		r0, #16
	orr		r0, r1, lsl #24
	//-------
	// Next load the simm8 value into r1.
	//-------
	ldrsb	r1,[r12],#1
	//-------
	// Perform the actual operation
	//-------
	adds	r0, r1, lsl #16			// ADD the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

	//-------
	// Or: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common or
.op_83_RAM_or:
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	lsl		r0, #16
	orr		r0, r1, lsl #24
	//-------
	// Next load the simm8 value into r1.
	//-------
	ldrsb	r1,[r12],#1
	//-------
	// Perform the actual operation
	//-------
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #16					// Shift it to the high halfword
	orrs	r0, r1					// OR the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

	//-------
	// Adc: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common adc
.op_83_RAM_adc:
	ldrb	r0, [r2] 				// Load byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	lsl		r0, #16
	orr		r0, r1, lsl #24
	//-------
	// Next load the simm8 value into r1.
	//-------
	ldrsb	r1,[r12],#1
	//-------
	// Perform the actual operation
	//-------
	addcs	r0, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r0, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, lsl #16			// Perform the actual addition, setting the resulting flags.
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		loop

	//-------
	// Sbb: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common sbb
.op_83_RAM_sbb:
	ldrsb	r1, [r12],#1			// r1 = simm8 value
	ldrb	r0, [r2] 				// Load byte to r0
	ldrb	r3, [r2, #1]			// Load high byte to r1
	lsl		r1, #16
	orr		r0, r3, lsl #8
	bcs		1f
	//-------
	// Perform the actual operation
	//-------
	rsbs	r0, r1, r0, lsl #16		// Perform the actual subtraction, setting the resulting flags.
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]					// Store low byte to [physical segment + disp16]
	lsr		r0, #8
	strb	r0,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	b		complement_carry
	//-------
	// Input carry set, calculate the flags separately
	//-------
1:	sub		r3, r0, r1, lsr #16		// r3 = lf_var1d - lf_var2d
	sub		r3, #1					// r3 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r3, r3, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	lsr		r3, #16
	strb	r3,[r2]					// Store byte to RAM
	ror		r3, #8
	strb	r3,[r2, #1]				// Store high byte to [physical segment + disp16 + 1]
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0, r1, lsr #16
	eor		r3, r0, r3, ror #24
	and		r1, r3
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0

	//-------
	// And: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common and
.op_83_RAM_and:
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	lsl		r0, #16
	orr		r0, r1, lsl #24
	//-------
	// Next load the simm8 value into r1.
	//-------
	ldrsb	r1,[r12],#1
	//-------
	// Perform the actual operation
	//-------
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #16					// Shift it to the high halfword
	ands	r0, r1					// AND the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

	//-------
	// Sub: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common sub
.op_83_RAM_sub:
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	lsl		r0, #16
	orr		r0, r1, lsl #24
	//-------
	// Next load the simm8 value into r1.
	//-------
	ldrsb	r1,[r12],#1
	//-------
	// Perform the actual operation
	//-------
	subs	r0, r1, lsl #16			// SUB the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		complement_carry

	//-------
	// Xor: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common xor
.op_83_RAM_xor:
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	lsl		r0, #16
	orr		r0, r1, lsl #24
	//-------
	// Next load the simm8 value into r1.
	//-------
	ldrsb	r1,[r12],#1
	//-------
	// Perform the actual operation
	//-------
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r1, #16					// Shift it to the high halfword
	eors	r0, r1					// XOR the values, setting flags
	//-------
	// Save the result into [r2]
	//-------
	lsr		r0, #16
	strb	r0,[r2]
	lsr		r0, #8
	strb	r0,[r2, #1]
	b		loop

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	//-------
	// Cmp: memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
	op83common cmp
.op_83_RAM_cmp:
	ldrb	r0, [r2] 				// Load low byte to r0
	ldrb	r1, [r2, #1]			// Load high byte to r1
	lsl		r0, #16
	orr		r0, r1, lsl #24
	//-------
	// Next load the simm8 value into r1.
	//-------
	ldrsb	r1,[r12],#1
	//-------
	// Perform the actual operation
	//-------
	cmp		r0, r1, lsl #16			// CMP the values, setting flags
	b		complement_carry

	.text
	.align 2

	.ltorg
	
.macro op83genall oper

// --- [idx] ---

\oper\()_bxsi_simm8:
	add		r0, r7, r10
	b		\oper\()_r0_simm8
\oper\()_bxdi_simm8:
	add		r0, r7, r11
	b		\oper\()_r0_simm8
\oper\()_bpsi_simm8:
	add		r0, r9, r10
	b		\oper\()_r0_bp_simm8
\oper\()_bpdi_simm8:
	add		r0, r9, r11
	b		\oper\()_r0_bp_simm8
\oper\()_siidx_simm8:
	mov		r0, r10
	b		\oper\()_r0_simm8
\oper\()_diidx_simm8:
	mov		r0, r11
	b		\oper\()_r0_simm8
\oper\()_disp16_simm8:
	r0_from_disp16
	b		\oper\()_r0_simm8
\oper\()_bxidx_simm8:
	mov		r0, r7
	b		\oper\()_r0_simm8

// --- [idx+disp8] ---

\oper\()_bxsid8_simm8:
	r0_from_bxidxdisp8 r10
	b		\oper\()_r0_simm8
\oper\()_bxdid8_simm8:
	r0_from_bxidxdisp8 r11
	b		\oper\()_r0_simm8
\oper\()_bpsid8_simm8:
	r0_from_bpidxdisp8 r10
	b		\oper\()_r0_bp_simm8
\oper\()_bpdid8_simm8:
	r0_from_bpidxdisp8 r11
	b		\oper\()_r0_bp_simm8
\oper\()_sidisp8_simm8:
	r0_from_idx_disp8 r10
	b		\oper\()_r0_simm8
\oper\()_didisp8_simm8:
	r0_from_idx_disp8 r11
	b		\oper\()_r0_simm8
\oper\()_bpdisp8_simm8:
	r0_from_idx_disp8 r9
	b		\oper\()_r0_bp_simm8
\oper\()_bxdisp8_simm8:
	r0_from_idx_disp8 r7
	b		\oper\()_r0_simm8

// --- [idx+disp16] ---

\oper\()_bxsid16_simm8:
	r0_from_bxidxdisp16 r10
	b		\oper\()_r0_simm8
\oper\()_bxdid16_simm8:
	r0_from_bxidxdisp16 r11
	b		\oper\()_r0_simm8
\oper\()_bpsid16_simm8:
	r0_from_bpidxdisp16 r10
	b		\oper\()_r0_bp_simm8
\oper\()_bpdid16_simm8:
	r0_from_bpidxdisp16 r11
	b		\oper\()_r0_bp_simm8
\oper\()_sidisp16_simm8:
	r0_from_idx_disp16 r10
	b		\oper\()_r0_simm8
\oper\()_didisp16_simm8:
	r0_from_idx_disp16 r11
	b		\oper\()_r0_simm8
\oper\()_bpdisp16_simm8:
	r0_from_idx_disp16 r9
	b		\oper\()_r0_bp_simm8
\oper\()_bxdisp16_simm8:
	r0_from_idx_disp16 r7
	b		\oper\()_r0_simm8
	
.endm

// ----- ADD -----

op83genall add
	
.macro add_reg16_simm8 reg
	ldrsb	r0,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	adds	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

add_ax_simm8:
	add_reg16_simm8 r4
add_cx_simm8:
	add_reg16_simm8 r5
add_dx_simm8:
	add_reg16_simm8 r6
add_bx_simm8:
	add_reg16_simm8 r7
add_sp_simm8:
	add_reg16_simm8 r8
add_bp_simm8:
	add_reg16_simm8 r9
add_si_simm8:
	add_reg16_simm8 r10
add_di_simm8:
	add_reg16_simm8 r11

// ----- OR ------

op83genall or

.macro or_reg16_simm8 reg
	ldrsb	r0,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r2, \reg, lsl #16
	lsl		r0, #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	orrs	r0, r2, r0				// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

or_ax_simm8:
	or_reg16_simm8 r4
or_cx_simm8:
	or_reg16_simm8 r5
or_dx_simm8:
	or_reg16_simm8 r6
or_bx_simm8:
	or_reg16_simm8 r7
or_sp_simm8:
	or_reg16_simm8 r8
or_bp_simm8:
	or_reg16_simm8 r9
or_si_simm8:
	or_reg16_simm8 r10
or_di_simm8:
	or_reg16_simm8 r11

// ----- ADC -----

op83genall adc

.macro adc_reg16_simm8 reg
	ldrsb	r0,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	mov		r1, \reg, lsl #16
	eor		\reg, r1, lsr #16
	addcs	r1, #0x00010000			// If input Carry is set, adjust the right operand so that ...
	subcs	r1, #0x00000001			// ... we can use the ARM ADC opcode for the actual operation.
	adcs	r0, r1, r0, lsl #16		// Perform the actual addition, setting the resulting flags.
	orr		\reg, r0, lsr #16
	b		loop
.endm

adc_ax_simm8:
	adc_reg16_simm8 r4
adc_cx_simm8:
	adc_reg16_simm8 r5
adc_dx_simm8:
	adc_reg16_simm8 r6
adc_bx_simm8:
	adc_reg16_simm8 r7
adc_sp_simm8:
	adc_reg16_simm8 r8
adc_bp_simm8:
	adc_reg16_simm8 r9
adc_si_simm8:
	adc_reg16_simm8 r10
adc_di_simm8:
	adc_reg16_simm8 r11

// ----- SBB -----

op83genall sbb

.macro sbb_reg16_simm8 reg
	ldrsb	r1,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	mov		r0, \reg, lsl #16
	eor		\reg, r0, lsr #16
	bcs		1f
	subs	r0, r1, lsl #16			// Perform the actual subtraction, setting the resulting flags.
	orr		\reg, r0, lsr #16
	b		complement_carry
	//-------
	// Input carry is set, so calculate flags separately.
	//-------
1:	lsl		r1, #16					// Make r1 be a 16-bit value
	lsr		r1, #16
	rsb		r2, r1, r0, lsr #16		// r2 = lf_var1d - lf_var2d
	sub		r2, #1					// r2 = lf_var1d - lf_var2d - Carry
	//-------
	// Calculate Carry, Zero and Sign flags
	//-------
	movs	r2, r2, lsl #16			// Determine Carry, Zero and Sign flags
	//-------
	// Save the result
	//-------
	orr		\reg, r2, lsr #16
	//-------
	// Calculate Overflow flag: ((lf_var1d ^ lf_var2d) & (lf_var1d ^ lf_resd)) & 0x8000
	//-------
	eor		r1, r0, lsr #16
	eor		r2, r0
	and		r1, r2, lsr #16
	mrs		r0,cpsr					// Get Carry, Sign and Zero flags to r0
	tst		r1, #0x8000
	orrne	r0, #ARM_OVER
	biceq	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

sbb_ax_simm8:
	sbb_reg16_simm8 r4
sbb_cx_simm8:
	sbb_reg16_simm8 r5
sbb_dx_simm8:
	sbb_reg16_simm8 r6
sbb_bx_simm8:
	sbb_reg16_simm8 r7
sbb_sp_simm8:
	sbb_reg16_simm8 r8
sbb_bp_simm8:
	sbb_reg16_simm8 r9
sbb_si_simm8:
	sbb_reg16_simm8 r10
sbb_di_simm8:
	sbb_reg16_simm8 r11

// ----- AND -----

op83genall and
	
.macro and_reg16_simm8 reg
	ldrsb	r0,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r2, \reg, lsl #16
	lsl		r0, #16					// We can not do the shift using a shifter in 'ands' as it affects the Carry flag
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	ands	r0, r2					// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

and_ax_simm8:
	and_reg16_simm8 r4
and_cx_simm8:
	and_reg16_simm8 r5
and_dx_simm8:
	and_reg16_simm8 r6
and_bx_simm8:
	and_reg16_simm8 r7
and_sp_simm8:
	and_reg16_simm8 r8
and_bp_simm8:
	and_reg16_simm8 r9
and_si_simm8:
	and_reg16_simm8 r10
and_di_simm8:
	and_reg16_simm8 r11

// ----- SUB -----

op83genall sub

.macro sub_reg16_simm8 reg
	ldrsb	r0,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	subs	r0, r2, r0, lsl #16		// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		complement_carry
.endm

sub_ax_simm8:
	sub_reg16_simm8 r4
sub_cx_simm8:
	sub_reg16_simm8 r5
sub_dx_simm8:
	sub_reg16_simm8 r6
sub_bx_simm8:
	sub_reg16_simm8 r7
sub_sp_simm8:
	sub_reg16_simm8 r8
sub_bp_simm8:
	sub_reg16_simm8 r9
sub_si_simm8:
	sub_reg16_simm8 r10
sub_di_simm8:
	sub_reg16_simm8 r11

// ----- XOR -----

op83genall xor

.macro xor_reg16_simm8 reg
	ldrsb	r0,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r2, \reg, lsl #16
	lsl		r0, #16					// We can not do the shift using a shifter in 'ands' as it affects the Carry flag
	eor		\reg, r2, lsr #16		// Clear the 16-bit register value
	eors	r0, r2					// Perform the operation using the high 16 bits
	orr		\reg, r0, lsr #16		// Put the result to the 16-bit register
	b		loop
.endm

xor_ax_simm8:
	xor_reg16_simm8 r4
xor_cx_simm8:
	xor_reg16_simm8 r5
xor_dx_simm8:
	xor_reg16_simm8 r6
xor_bx_simm8:
	xor_reg16_simm8 r7
xor_sp_simm8:
	xor_reg16_simm8 r8
xor_bp_simm8:
	xor_reg16_simm8 r9
xor_si_simm8:
	xor_reg16_simm8 r10
xor_di_simm8:
	xor_reg16_simm8 r11

// ----- CMP -----

	op83genall cmp

.macro cmp_reg16_simm8 reg
	ldrsb	r0,[r12],#1				// Load the simm8 byte to r0, increment r12 by 1
	mov		r2, \reg, lsl #16
	cmp		r2, r0, lsl #16			// Compare the values
	b		complement_carry		// Jump back to loop, reversing the Carry flag (ARM -> x86 convention)
.endm

cmp_ax_simm8:
	cmp_reg16_simm8 r4
cmp_cx_simm8:
	cmp_reg16_simm8 r5
cmp_dx_simm8:
	cmp_reg16_simm8 r6
cmp_bx_simm8:
	cmp_reg16_simm8 r7
cmp_sp_simm8:
	cmp_reg16_simm8 r8
cmp_bp_simm8:
	cmp_reg16_simm8 r9
cmp_si_simm8:
	cmp_reg16_simm8 r10
cmp_di_simm8:
	cmp_reg16_simm8 r11

	.text
	.align 2

// ------------------- 84 = TEST r8,r/m8 -------------------------------
//
// All modrm bytes supported!
//
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual tst operation, so C and O work like in x86.
//
	.global	op_84
op_84:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word test_bxsi_al, test_bxdi_al, test_bpsi_al, test_bpdi_al, test_siidx_al, test_diidx_al, test_disp16_al, test_bxidx_al
	.word test_bxsi_cl, test_bxdi_cl, test_bpsi_cl, test_bpdi_cl, test_siidx_cl, test_diidx_cl, test_disp16_cl, test_bxidx_cl
	.word test_bxsi_dl, test_bxdi_dl, test_bpsi_dl, test_bpdi_dl, test_siidx_dl, test_diidx_dl, test_disp16_dl, test_bxidx_dl
	.word test_bxsi_bl, test_bxdi_bl, test_bpsi_bl, test_bpdi_bl, test_siidx_bl, test_diidx_bl, test_disp16_bl, test_bxidx_bl
	.word test_bxsi_ah, test_bxdi_ah, test_bpsi_ah, test_bpdi_ah, test_siidx_ah, test_diidx_ah, test_disp16_ah, test_bxidx_ah
	.word test_bxsi_ch, test_bxdi_ch, test_bpsi_ch, test_bpdi_ch, test_siidx_ch, test_diidx_ch, test_disp16_ch, test_bxidx_ch
	.word test_bxsi_dh, test_bxdi_dh, test_bpsi_dh, test_bpdi_dh, test_siidx_dh, test_diidx_dh, test_disp16_dh, test_bxidx_dh
	.word test_bxsi_bh, test_bxdi_bh, test_bpsi_bh, test_bpdi_bh, test_siidx_bh, test_diidx_bh, test_disp16_bh, test_bxidx_bh
//0x40
	.word test_bxsid8_al, test_bxdid8_al, test_bpsid8_al, test_bpdid8_al, test_sidisp8_al, test_didisp8_al, test_bpdisp8_al, test_bxdisp8_al
	.word test_bxsid8_cl, test_bxdid8_cl, test_bpsid8_cl, test_bpdid8_cl, test_sidisp8_cl, test_didisp8_cl, test_bpdisp8_cl, test_bxdisp8_cl
	.word test_bxsid8_dl, test_bxdid8_dl, test_bpsid8_dl, test_bpdid8_dl, test_sidisp8_dl, test_didisp8_dl, test_bpdisp8_dl, test_bxdisp8_dl
	.word test_bxsid8_bl, test_bxdid8_bl, test_bpsid8_bl, test_bpdid8_bl, test_sidisp8_bl, test_didisp8_bl, test_bpdisp8_bl, test_bxdisp8_bl
	.word test_bxsid8_ah, test_bxdid8_ah, test_bpsid8_ah, test_bpdid8_ah, test_sidisp8_ah, test_didisp8_ah, test_bpdisp8_ah, test_bxdisp8_ah
	.word test_bxsid8_ch, test_bxdid8_ch, test_bpsid8_ch, test_bpdid8_ch, test_sidisp8_ch, test_didisp8_ch, test_bpdisp8_ch, test_bxdisp8_ch
	.word test_bxsid8_dh, test_bxdid8_dh, test_bpsid8_dh, test_bpdid8_dh, test_sidisp8_dh, test_didisp8_dh, test_bpdisp8_dh, test_bxdisp8_dh
	.word test_bxsid8_bh, test_bxdid8_bh, test_bpsid8_bh, test_bpdid8_bh, test_sidisp8_bh, test_didisp8_bh, test_bpdisp8_bh, test_bxdisp8_bh
//0x80
	.word test_bxsid16_al, test_bxdid16_al, test_bpsid16_al, test_bpdid16_al, test_sidisp16_al, test_didisp16_al, test_bpdisp16_al, test_bxdisp16_al
	.word test_bxsid16_cl, test_bxdid16_cl, test_bpsid16_cl, test_bpdid16_cl, test_sidisp16_cl, test_didisp16_cl, test_bpdisp16_cl, test_bxdisp16_cl
	.word test_bxsid16_dl, test_bxdid16_dl, test_bpsid16_dl, test_bpdid16_dl, test_sidisp16_dl, test_didisp16_dl, test_bpdisp16_dl, test_bxdisp16_dl
	.word test_bxsid16_bl, test_bxdid16_bl, test_bpsid16_bl, test_bpdid16_bl, test_sidisp16_bl, test_didisp16_bl, test_bpdisp16_bl, test_bxdisp16_bl
	.word test_bxsid16_ah, test_bxdid16_ah, test_bpsid16_ah, test_bpdid16_ah, test_sidisp16_ah, test_didisp16_ah, test_bpdisp16_ah, test_bxdisp16_ah
	.word test_bxsid16_ch, test_bxdid16_ch, test_bpsid16_ch, test_bpdid16_ch, test_sidisp16_ch, test_didisp16_ch, test_bpdisp16_ch, test_bxdisp16_ch
	.word test_bxsid16_dh, test_bxdid16_dh, test_bpsid16_dh, test_bpdid16_dh, test_sidisp16_dh, test_didisp16_dh, test_bpdisp16_dh, test_bxdisp16_dh
	.word test_bxsid16_bh, test_bxdid16_bh, test_bpsid16_bh, test_bpdid16_bh, test_sidisp16_bh, test_didisp16_bh, test_bpdisp16_bh, test_bxdisp16_bh
//0xc0 = mod = 11b => two register operands
	.word test_al_al, test_al_cl, test_al_dl, test_al_bl, test_al_ah, test_al_ch, test_al_dh, test_al_bh
	.word test_al_cl, test_cl_cl, test_cl_dl, test_cl_bl, test_cl_ah, test_cl_ch, test_cl_dh, test_cl_bh
	.word test_al_dl, test_cl_dl, test_dl_dl, test_dl_bl, test_dl_ah, test_dl_ch, test_dl_dh, test_dl_bh
	.word test_al_bl, test_cl_bl, test_dl_bl, test_bl_bl, test_bl_ah, test_bl_ch, test_bl_dh, test_bl_bh
	.word test_al_ah, test_cl_ah, test_dl_ah, test_bl_ah, test_ah_ah, test_ah_ch, test_ah_dh, test_ah_bh
	.word test_al_ch, test_cl_ch, test_dl_ch, test_bl_ch, test_ah_ch, test_ch_ch, test_ch_dh, test_ch_bh
	.word test_al_dh, test_cl_dh, test_dl_dh, test_bl_dh, test_ah_dh, test_ch_dh, test_dh_dh, test_dh_bh
	.word test_al_bh, test_cl_bh, test_dl_bh, test_bl_bh, test_ah_bh, test_ch_bh, test_dh_bh, test_bh_bh

// These are called from "cpu_386.s":

	.global	test_siidx_al, test_siidx_cl, test_siidx_dl, test_siidx_bl, test_siidx_ah, test_siidx_ch, test_siidx_dh, test_siidx_bh
	.global	test_diidx_al, test_diidx_cl, test_diidx_dl, test_diidx_bl, test_diidx_ah, test_diidx_ch, test_diidx_dh, test_diidx_bh
	.global	test_bxidx_al, test_bxidx_cl, test_bxidx_dl, test_bxidx_bl, test_bxidx_ah, test_bxidx_ch, test_bxidx_dh, test_bxidx_bh
	.global	test_sidisp8_al, test_sidisp8_cl, test_sidisp8_dl, test_sidisp8_bl, test_sidisp8_ah, test_sidisp8_ch, test_sidisp8_dh, test_sidisp8_bh
	.global	test_didisp8_al, test_didisp8_cl, test_didisp8_dl, test_didisp8_bl, test_didisp8_ah, test_didisp8_ch, test_didisp8_dh, test_didisp8_bh
	.global	test_bpdisp8_al, test_bpdisp8_cl, test_bpdisp8_dl, test_bpdisp8_bl, test_bpdisp8_ah, test_bpdisp8_ch, test_bpdisp8_dh, test_bpdisp8_bh
	.global	test_bxdisp8_al, test_bxdisp8_cl, test_bxdisp8_dl, test_bxdisp8_bl, test_bxdisp8_ah, test_bxdisp8_ch, test_bxdisp8_dh, test_bxdisp8_bh

.macro test_r0_reg8l reg
	.global	test_r0_r8l_bp_\reg
test_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	test_r0_r8l_\reg
test_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_84_RAM_l_\reg op_84_EGA_l_\reg op_84_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_84_RAM_l_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	mov		r1, \reg, lsl #24
	tst		r1, r0, lsl #24
	b		loop
.endm
.macro test_r0_reg8h reg
	.global	test_r0_r8h_bp_\reg
test_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	test_r0_r8h_\reg
test_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_84_RAM_h_\reg op_84_EGA_h_\reg op_84_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_84_RAM_h_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	and		r1, \reg, #0xFF00
	lsl		r0, #24
	tst		r0, r1, lsl #16
	b		loop
.endm

	test_r0_reg8l r4
	test_r0_reg8l r5
	test_r0_reg8l r6
	test_r0_reg8l r7
	test_r0_reg8h r4
	test_r0_reg8h r5
	test_r0_reg8h r6
	test_r0_reg8h r7

	.ltorg

// --- [idx] ---

.macro test_bxidx_reg8l idx reg
	add		r0, r7, \idx
	b		test_r0_r8l_\reg
.endm
.macro test_bxidx_reg8h idx reg
	add		r0, r7, \idx
	b		test_r0_r8h_\reg
.endm

test_bxsi_al:
	test_bxidx_reg8l r10 r4
test_bxsi_cl:
	test_bxidx_reg8l r10 r5
test_bxsi_dl:
	test_bxidx_reg8l r10 r6
test_bxsi_bl:
	test_bxidx_reg8l r10 r7
test_bxsi_ah:
	test_bxidx_reg8h r10 r4
test_bxsi_ch:
	test_bxidx_reg8h r10 r5
test_bxsi_dh:
	test_bxidx_reg8h r10 r6
test_bxsi_bh:
	test_bxidx_reg8h r10 r7

test_bxdi_al:
	test_bxidx_reg8l r11 r4
test_bxdi_cl:
	test_bxidx_reg8l r11 r5
test_bxdi_dl:
	test_bxidx_reg8l r11 r6
test_bxdi_bl:
	test_bxidx_reg8l r11 r7
test_bxdi_ah:
	test_bxidx_reg8h r11 r4
test_bxdi_ch:
	test_bxidx_reg8h r11 r5
test_bxdi_dh:
	test_bxidx_reg8h r11 r6
test_bxdi_bh:
	test_bxidx_reg8h r11 r7

.macro test_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		test_r0_r8l_bp_\reg
.endm
.macro test_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		test_r0_r8h_bp_\reg
.endm

test_bpsi_al:
	test_bpidx_reg8l r10 r4
test_bpsi_cl:
	test_bpidx_reg8l r10 r5
test_bpsi_dl:
	test_bpidx_reg8l r10 r6
test_bpsi_bl:
	test_bpidx_reg8l r10 r7
test_bpsi_ah:
	test_bpidx_reg8h r10 r4
test_bpsi_ch:
	test_bpidx_reg8h r10 r5
test_bpsi_dh:
	test_bpidx_reg8h r10 r6
test_bpsi_bh:
	test_bpidx_reg8h r10 r7

test_bpdi_al:
	test_bpidx_reg8l r11 r4
test_bpdi_cl:
	test_bpidx_reg8l r11 r5
test_bpdi_dl:
	test_bpidx_reg8l r11 r6
test_bpdi_bl:
	test_bpidx_reg8l r11 r7
test_bpdi_ah:
	test_bpidx_reg8h r11 r4
test_bpdi_ch:
	test_bpidx_reg8h r11 r5
test_bpdi_dh:
	test_bpidx_reg8h r11 r6
test_bpdi_bh:
	test_bpidx_reg8h r11 r7

.macro test_idx_reg8l idx reg
	mov		r0, \idx				// r0high = idx register value
	b		test_r0_r8l_\reg
.endm
.macro test_idx_reg8h idx reg
	mov		r0, \idx				// r0high = idx register value
	b		test_r0_r8h_\reg
.endm

test_siidx_al:
	test_idx_reg8l r10 r4
test_siidx_cl:
	test_idx_reg8l r10 r5
test_siidx_dl:
	test_idx_reg8l r10 r6
test_siidx_bl:
	test_idx_reg8l r10 r7
test_siidx_ah:
	test_idx_reg8h r10 r4
test_siidx_ch:
	test_idx_reg8h r10 r5
test_siidx_dh:
	test_idx_reg8h r10 r6
test_siidx_bh:
	test_idx_reg8h r10 r7

test_diidx_al:
	test_idx_reg8l r11 r4
test_diidx_cl:
	test_idx_reg8l r11 r5
test_diidx_dl:
	test_idx_reg8l r11 r6
test_diidx_bl:
	test_idx_reg8l r11 r7
test_diidx_ah:
	test_idx_reg8h r11 r4
test_diidx_ch:
	test_idx_reg8h r11 r5
test_diidx_dh:
	test_idx_reg8h r11 r6
test_diidx_bh:
	test_idx_reg8h r11 r7

test_bxidx_al:
	test_idx_reg8l r7 r4
test_bxidx_cl:
	test_idx_reg8l r7 r5
test_bxidx_dl:
	test_idx_reg8l r7 r6
test_bxidx_bl:
	test_idx_reg8l r7 r7
test_bxidx_ah:
	test_idx_reg8h r7 r4
test_bxidx_ch:
	test_idx_reg8h r7 r5
test_bxidx_dh:
	test_idx_reg8h r7 r6
test_bxidx_bh:
	test_idx_reg8h r7 r7
	
.macro test_disp16_reg8l reg
	r0_from_disp16
	b		test_r0_r8l_\reg
.endm

.macro test_disp16_reg8h reg
	r0_from_disp16
	b		test_r0_r8h_\reg
.endm

test_disp16_al:
	test_disp16_reg8l r4
test_disp16_cl:
	test_disp16_reg8l r5
test_disp16_dl:
	test_disp16_reg8l r6
test_disp16_bl:
	test_disp16_reg8l r7
test_disp16_ah:
	test_disp16_reg8h r4
test_disp16_ch:
	test_disp16_reg8h r5
test_disp16_dh:
	test_disp16_reg8h r6
test_disp16_bh:
	test_disp16_reg8h r7

// --- [idx+disp8] ---

.macro test_bxidxd8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		test_r0_r8l_\reg
.endm
.macro test_bxidxd8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		test_r0_r8h_\reg
.endm

test_bxsid8_al:
	test_bxidxd8_reg8l r10 r4
test_bxsid8_cl:
	test_bxidxd8_reg8l r10 r5
test_bxsid8_dl:
	test_bxidxd8_reg8l r10 r6
test_bxsid8_bl:
	test_bxidxd8_reg8l r10 r7
test_bxsid8_ah:
	test_bxidxd8_reg8h r10 r4
test_bxsid8_ch:
	test_bxidxd8_reg8h r10 r5
test_bxsid8_dh:
	test_bxidxd8_reg8h r10 r6
test_bxsid8_bh:
	test_bxidxd8_reg8h r10 r7

test_bxdid8_al:
	test_bxidxd8_reg8l r11 r4
test_bxdid8_cl:
	test_bxidxd8_reg8l r11 r5
test_bxdid8_dl:
	test_bxidxd8_reg8l r11 r6
test_bxdid8_bl:
	test_bxidxd8_reg8l r11 r7
test_bxdid8_ah:
	test_bxidxd8_reg8h r11 r4
test_bxdid8_ch:
	test_bxidxd8_reg8h r11 r5
test_bxdid8_dh:
	test_bxidxd8_reg8h r11 r6
test_bxdid8_bh:
	test_bxidxd8_reg8h r11 r7

.macro test_bpidxd8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		test_r0_r8l_bp_\reg
.endm
.macro test_bpidxd8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		test_r0_r8h_bp_\reg
.endm

test_bpsid8_al:
	test_bpidxd8_reg8l r10 r4
test_bpsid8_cl:
	test_bpidxd8_reg8l r10 r5
test_bpsid8_dl:
	test_bpidxd8_reg8l r10 r6
test_bpsid8_bl:
	test_bpidxd8_reg8l r10 r7
test_bpsid8_ah:
	test_bpidxd8_reg8h r10 r4
test_bpsid8_ch:
	test_bpidxd8_reg8h r10 r5
test_bpsid8_dh:
	test_bpidxd8_reg8h r10 r6
test_bpsid8_bh:
	test_bpidxd8_reg8h r10 r7

test_bpdid8_al:
	test_bpidxd8_reg8l r11 r4
test_bpdid8_cl:
	test_bpidxd8_reg8l r11 r5
test_bpdid8_dl:
	test_bpidxd8_reg8l r11 r6
test_bpdid8_bl:
	test_bpidxd8_reg8l r11 r7
test_bpdid8_ah:
	test_bpidxd8_reg8h r11 r4
test_bpdid8_ch:
	test_bpidxd8_reg8h r11 r5
test_bpdid8_dh:
	test_bpidxd8_reg8h r11 r6
test_bpdid8_bh:
	test_bpidxd8_reg8h r11 r7

.macro test_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		test_r0_r8l_\reg
.endm
.macro test_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		test_r0_r8h_\reg
.endm

test_sidisp8_al:
	test_idxdisp8_reg8l r10 r4
test_sidisp8_cl:
	test_idxdisp8_reg8l r10 r5
test_sidisp8_dl:
	test_idxdisp8_reg8l r10 r6
test_sidisp8_bl:
	test_idxdisp8_reg8l r10 r7
test_sidisp8_ah:
	test_idxdisp8_reg8h r10 r4
test_sidisp8_ch:
	test_idxdisp8_reg8h r10 r5
test_sidisp8_dh:
	test_idxdisp8_reg8h r10 r6
test_sidisp8_bh:
	test_idxdisp8_reg8h r10 r7

test_didisp8_al:
	test_idxdisp8_reg8l r11 r4
test_didisp8_cl:
	test_idxdisp8_reg8l r11 r5
test_didisp8_dl:
	test_idxdisp8_reg8l r11 r6
test_didisp8_bl:
	test_idxdisp8_reg8l r11 r7
test_didisp8_ah:
	test_idxdisp8_reg8h r11 r4
test_didisp8_ch:
	test_idxdisp8_reg8h r11 r5
test_didisp8_dh:
	test_idxdisp8_reg8h r11 r6
test_didisp8_bh:
	test_idxdisp8_reg8h r11 r7

test_bxdisp8_al:
	test_idxdisp8_reg8l r7 r4
test_bxdisp8_cl:
	test_idxdisp8_reg8l r7 r5
test_bxdisp8_dl:
	test_idxdisp8_reg8l r7 r6
test_bxdisp8_bl:
	test_idxdisp8_reg8l r7 r7
test_bxdisp8_ah:
	test_idxdisp8_reg8h r7 r4
test_bxdisp8_ch:
	test_idxdisp8_reg8h r7 r5
test_bxdisp8_dh:
	test_idxdisp8_reg8h r7 r6
test_bxdisp8_bh:
	test_idxdisp8_reg8h r7 r7

.macro test_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		test_r0_r8l_bp_\reg
.endm
.macro test_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		test_r0_r8h_bp_\reg
.endm

test_bpdisp8_al:
	test_bpdisp8_reg8l r4
test_bpdisp8_cl:
	test_bpdisp8_reg8l r5
test_bpdisp8_dl:
	test_bpdisp8_reg8l r6
test_bpdisp8_bl:
	test_bpdisp8_reg8l r7
test_bpdisp8_ah:
	test_bpdisp8_reg8h r4
test_bpdisp8_ch:
	test_bpdisp8_reg8h r5
test_bpdisp8_dh:
	test_bpdisp8_reg8h r6
test_bpdisp8_bh:
	test_bpdisp8_reg8h r7

// --- [idx+disp16] ---

.macro test_bxidxdisp16_reg8l idx reg
	r0_from_bxidxdisp16 \idx
	b		test_r0_r8l_\reg
.endm
.macro test_bxidxdisp16_reg8h idx reg
	r0_from_bxidxdisp16 \idx
	b		test_r0_r8h_\reg
.endm

test_bxsid16_al:
	test_bxidxdisp16_reg8l r10 r4
test_bxsid16_cl:
	test_bxidxdisp16_reg8l r10 r5
test_bxsid16_dl:
	test_bxidxdisp16_reg8l r10 r6
test_bxsid16_bl:
	test_bxidxdisp16_reg8l r10 r7
test_bxsid16_ah:
	test_bxidxdisp16_reg8h r10 r4
test_bxsid16_ch:
	test_bxidxdisp16_reg8h r10 r5
test_bxsid16_dh:
	test_bxidxdisp16_reg8h r10 r6
test_bxsid16_bh:
	test_bxidxdisp16_reg8h r10 r7

test_bxdid16_al:
	test_bxidxdisp16_reg8l r11 r4
test_bxdid16_cl:
	test_bxidxdisp16_reg8l r11 r5
test_bxdid16_dl:
	test_bxidxdisp16_reg8l r11 r6
test_bxdid16_bl:
	test_bxidxdisp16_reg8l r11 r7
test_bxdid16_ah:
	test_bxidxdisp16_reg8h r11 r4
test_bxdid16_ch:
	test_bxidxdisp16_reg8h r11 r5
test_bxdid16_dh:
	test_bxidxdisp16_reg8h r11 r6
test_bxdid16_bh:
	test_bxidxdisp16_reg8h r11 r7

.macro test_bpidxd16_reg8l idx reg
	r0_from_bpidxdisp16 \idx
	b		test_r0_r8l_bp_\reg
.endm
.macro test_bpidxd16_reg8h idx reg
	r0_from_bpidxdisp16 \idx
	b		test_r0_r8h_bp_\reg
.endm

test_bpsid16_al:
	test_bpidxd16_reg8l r10 r4
test_bpsid16_cl:
	test_bpidxd16_reg8l r10 r5
test_bpsid16_dl:
	test_bpidxd16_reg8l r10 r6
test_bpsid16_bl:
	test_bpidxd16_reg8l r10 r7
test_bpsid16_ah:
	test_bpidxd16_reg8h r10 r4
test_bpsid16_ch:
	test_bpidxd16_reg8h r10 r5
test_bpsid16_dh:
	test_bpidxd16_reg8h r10 r6
test_bpsid16_bh:
	test_bpidxd16_reg8h r10 r7

test_bpdid16_al:
	test_bpidxd16_reg8l r11 r4
test_bpdid16_cl:
	test_bpidxd16_reg8l r11 r5
test_bpdid16_dl:
	test_bpidxd16_reg8l r11 r6
test_bpdid16_bl:
	test_bpidxd16_reg8l r11 r7
test_bpdid16_ah:
	test_bpidxd16_reg8h r11 r4
test_bpdid16_ch:
	test_bpidxd16_reg8h r11 r5
test_bpdid16_dh:
	test_bpidxd16_reg8h r11 r6
test_bpdid16_bh:
	test_bpidxd16_reg8h r11 r7

.macro test_idxdisp16_reg8l idx reg
	r0_from_idx_disp16 \idx
	b		test_r0_r8l_\reg
.endm
.macro test_idxdisp16_reg8h idx reg
	r0_from_idx_disp16 \idx
	b		test_r0_r8h_\reg
.endm

test_sidisp16_al:
	test_idxdisp16_reg8l r10 r4
test_sidisp16_cl:
	test_idxdisp16_reg8l r10 r5
test_sidisp16_dl:
	test_idxdisp16_reg8l r10 r6
test_sidisp16_bl:
	test_idxdisp16_reg8l r10 r7
test_sidisp16_ah:
	test_idxdisp16_reg8h r10 r4
test_sidisp16_ch:
	test_idxdisp16_reg8h r10 r5
test_sidisp16_dh:
	test_idxdisp16_reg8h r10 r6
test_sidisp16_bh:
	test_idxdisp16_reg8h r10 r7

test_didisp16_al:
	test_idxdisp16_reg8l r11 r4
test_didisp16_cl:
	test_idxdisp16_reg8l r11 r5
test_didisp16_dl:
	test_idxdisp16_reg8l r11 r6
test_didisp16_bl:
	test_idxdisp16_reg8l r11 r7
test_didisp16_ah:
	test_idxdisp16_reg8h r11 r4
test_didisp16_ch:
	test_idxdisp16_reg8h r11 r5
test_didisp16_dh:
	test_idxdisp16_reg8h r11 r6
test_didisp16_bh:
	test_idxdisp16_reg8h r11 r7

test_bxdisp16_al:
	test_idxdisp16_reg8l r7 r4
test_bxdisp16_cl:
	test_idxdisp16_reg8l r7 r5
test_bxdisp16_dl:
	test_idxdisp16_reg8l r7 r6
test_bxdisp16_bl:
	test_idxdisp16_reg8l r7 r7
test_bxdisp16_ah:
	test_idxdisp16_reg8h r7 r4
test_bxdisp16_ch:
	test_idxdisp16_reg8h r7 r5
test_bxdisp16_dh:
	test_idxdisp16_reg8h r7 r6
test_bxdisp16_bh:
	test_idxdisp16_reg8h r7 r7

.macro test_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		test_r0_r8l_bp_\reg
.endm
.macro test_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		test_r0_r8h_bp_\reg
.endm

test_bpdisp16_al:
	test_bpdisp16_reg8l r4
test_bpdisp16_cl:
	test_bpdisp16_reg8l r5
test_bpdisp16_dl:
	test_bpdisp16_reg8l r6
test_bpdisp16_bl:
	test_bpdisp16_reg8l r7
test_bpdisp16_ah:
	test_bpdisp16_reg8h r4
test_bpdisp16_ch:
	test_bpdisp16_reg8h r5
test_bpdisp16_dh:
	test_bpdisp16_reg8h r6
test_bpdisp16_bh:
	test_bpdisp16_reg8h r7


// --- registers ---

.macro test_reg8l_reg8l rl rr
	mov		r0, \rl, lsl #24
	mov		r1, \rr, lsl #24
	tst		r0, r1
	b		loop
.endm
.macro test_reg8l_reg8h rl rr
	mov		r0, \rl, lsl #24
	and		r1, \rr, #0xFF00
	tst		r0, r1, lsl #16
	b		loop
.endm
.macro test_reg8h_reg8h rl rr
	and		r0, \rl, #0xFF00
	and		r1, \rr, #0xFF00
	lsl		r0, #16
	tst		r0, r1, lsl #16
	b		loop
.endm

	.global test_al_al 
	.global test_cl_al 
	.global test_dl_al 
	.global test_bl_al 
	.global test_ah_al 
	.global test_ch_al 
	.global test_dh_al 
	.global test_bh_al
	.global test_al_cl 
	.global test_cl_cl 
	.global test_dl_cl 
	.global test_bl_cl 
	.global test_ah_cl 
	.global test_ch_cl 
	.global test_dh_cl 
	.global test_bh_cl
	.global test_al_dl 
	.global test_cl_dl 
	.global test_dl_dl 
	.global test_bl_dl 
	.global test_ah_dl 
	.global test_ch_dl 
	.global test_dh_dl 
	.global test_bh_dl
	.global test_al_bl 
	.global test_cl_bl 
	.global test_dl_bl 
	.global test_bl_bl 
	.global test_ah_bl 
	.global test_ch_bl 
	.global test_dh_bl 
	.global test_bh_bl
	.global test_al_ah 
	.global test_cl_ah 
	.global test_dl_ah 
	.global test_bl_ah 
	.global test_ah_ah 
	.global test_ch_ah 
	.global test_dh_ah 
	.global test_bh_ah
	.global test_al_ch 
	.global test_cl_ch 
	.global test_dl_ch 
	.global test_bl_ch 
	.global test_ah_ch 
	.global test_ch_ch 
	.global test_dh_ch 
	.global test_bh_ch
	.global test_al_dh 
	.global test_cl_dh 
	.global test_dl_dh 
	.global test_bl_dh 
	.global test_ah_dh 
	.global test_ch_dh 
	.global test_dh_dh 
	.global test_bh_dh
	.global test_al_bh 
	.global test_cl_bh 
	.global test_dl_bh 
	.global test_bl_bh 
	.global test_ah_bh 
	.global test_ch_bh 
	.global test_dh_bh 
	.global test_bh_bh

test_al_al:
	test_reg8l_reg8l eax eax
test_al_cl:
test_cl_al:
	test_reg8l_reg8l eax ecx
test_al_dl:
test_dl_al:
	test_reg8l_reg8l eax edx
test_al_bl:
test_bl_al:
	test_reg8l_reg8l eax ebx
test_al_ah:
test_ah_al:
	test_reg8l_reg8h eax eax
test_al_ch:
test_ch_al:
	test_reg8l_reg8h eax ecx
test_al_dh:
test_dh_al:
	test_reg8l_reg8h eax edx
test_al_bh:
test_bh_al:
	test_reg8l_reg8h eax ebx

test_cl_cl:
	test_reg8l_reg8l ecx ecx
test_cl_dl:
test_dl_cl:
	test_reg8l_reg8l ecx edx
test_cl_bl:
test_bl_cl:
	test_reg8l_reg8l ecx ebx
test_cl_ah:
test_ah_cl:
	test_reg8l_reg8h ecx eax
test_cl_ch:
test_ch_cl:
	test_reg8l_reg8h ecx ecx
test_cl_dh:
test_dh_cl:
	test_reg8l_reg8h ecx edx
test_cl_bh:
test_bh_cl:
	test_reg8l_reg8h ecx ebx

test_dl_dl:
	test_reg8l_reg8l edx edx
test_dl_bl:
test_bl_dl:
	test_reg8l_reg8l edx ebx
test_dl_ah:
test_ah_dl:
	test_reg8l_reg8h edx eax
test_dl_ch:
test_ch_dl:
	test_reg8l_reg8h edx ecx
test_dl_dh:
test_dh_dl:
	test_reg8l_reg8h edx edx
test_dl_bh:
test_bh_dl:
	test_reg8l_reg8h edx ebx

test_bl_bl:
	test_reg8l_reg8l ebx ebx
test_bl_ah:
test_ah_bl:
	test_reg8l_reg8h ebx eax
test_bl_ch:
test_ch_bl:
	test_reg8l_reg8h ebx ecx
test_bl_dh:
test_dh_bl:
	test_reg8l_reg8h ebx edx
test_bl_bh:
test_bh_bl:
	test_reg8l_reg8h ebx ebx

test_ah_ah:
	test_reg8h_reg8h eax eax
test_ah_ch:
test_ch_ah:
	test_reg8h_reg8h eax ecx
test_ah_dh:
test_dh_ah:
	test_reg8h_reg8h eax edx
test_ah_bh:
test_bh_ah:
	test_reg8h_reg8h eax ebx

test_ch_ch:
	test_reg8h_reg8h ecx ecx
test_ch_dh:
test_dh_ch:
	test_reg8h_reg8h ecx edx
test_ch_bh:
test_bh_ch:
	test_reg8h_reg8h ecx ebx

test_dh_dh:
	test_reg8h_reg8h edx edx
test_dh_bh:
test_bh_dh:
	test_reg8h_reg8h edx ebx

test_bh_bh:
	test_reg8h_reg8h ebx ebx
	
// ------------------- 85 = TEST r16,r/m16 -----------------------------
//
// All modrm variations supported!
//
//
// x86 clears C and O flags, while ARM leaves O untouched and C gets the shifter output.
// We clear all the flags before the actual tst operation, so C and O work like in x86.
//
op_85:
	msr		cpsr_f,#0							// Clear all flags (especially C and O)
	modrm_jump_16
// 0
	.word test_bxsi_ax, test_bxdi_ax, test_bpsi_ax, test_bpdi_ax, test_siidx_ax, test_diidx_ax, test_disp16_ax, test_bxidx_ax
	.word test_bxsi_cx, test_bxdi_cx, test_bpsi_cx, test_bpdi_cx, test_siidx_cx, test_diidx_cx, test_disp16_cx, test_bxidx_cx
	.word test_bxsi_dx, test_bxdi_dx, test_bpsi_dx, test_bpdi_dx, test_siidx_dx, test_diidx_dx, test_disp16_dx, test_bxidx_dx
	.word test_bxsi_bx, test_bxdi_bx, test_bpsi_bx, test_bpdi_bx, test_siidx_bx, test_diidx_bx, test_disp16_bx, test_bxidx_bx
	.word test_bxsi_sp, test_bxdi_sp, test_bpsi_sp, test_bpdi_sp, test_siidx_sp, test_diidx_sp, test_disp16_sp, test_bxidx_sp
	.word test_bxsi_bp, test_bxdi_bp, test_bpsi_bp, test_bpdi_bp, test_siidx_bp, test_diidx_bp, test_disp16_bp, test_bxidx_bp
	.word test_bxsi_si, test_bxdi_si, test_bpsi_si, test_bpdi_si, test_siidx_si, test_diidx_si, test_disp16_si, test_bxidx_si
	.word test_bxsi_di, test_bxdi_di, test_bpsi_di, test_bpdi_di, test_siidx_di, test_diidx_di, test_disp16_di, test_bxidx_di
//0x40
	.word test_bxsid8_ax, test_bxdid8_ax, test_bpsid8_ax, test_bpdid8_ax, test_sidisp8_ax, test_didisp8_ax, test_bpdisp8_ax, test_bxdisp8_ax
	.word test_bxsid8_cx, test_bxdid8_cx, test_bpsid8_cx, test_bpdid8_cx, test_sidisp8_cx, test_didisp8_cx, test_bpdisp8_cx, test_bxdisp8_cx
	.word test_bxsid8_dx, test_bxdid8_dx, test_bpsid8_dx, test_bpdid8_dx, test_sidisp8_dx, test_didisp8_dx, test_bpdisp8_dx, test_bxdisp8_dx
	.word test_bxsid8_bx, test_bxdid8_bx, test_bpsid8_bx, test_bpdid8_bx, test_sidisp8_bx, test_didisp8_bx, test_bpdisp8_bx, test_bxdisp8_bx
	.word test_bxsid8_sp, test_bxdid8_sp, test_bpsid8_sp, test_bpdid8_sp, test_sidisp8_sp, test_didisp8_sp, test_bpdisp8_sp, test_bxdisp8_sp
	.word test_bxsid8_bp, test_bxdid8_bp, test_bpsid8_bp, test_bpdid8_bp, test_sidisp8_bp, test_didisp8_bp, test_bpdisp8_bp, test_bxdisp8_bp
	.word test_bxsid8_si, test_bxdid8_si, test_bpsid8_si, test_bpdid8_si, test_sidisp8_si, test_didisp8_si, test_bpdisp8_si, test_bxdisp8_si
	.word test_bxsid8_di, test_bxdid8_di, test_bpsid8_di, test_bpdid8_di, test_sidisp8_di, test_didisp8_di, test_bpdisp8_di, test_bxdisp8_di
//0x80
	.word test_bxsid16_ax, test_bxdid16_ax, test_bpsid16_ax, test_bpdid16_ax, test_sidisp16_ax, test_didisp16_ax, test_bpdisp16_ax, test_bxdisp16_ax
	.word test_bxsid16_cx, test_bxdid16_cx, test_bpsid16_cx, test_bpdid16_cx, test_sidisp16_cx, test_didisp16_cx, test_bpdisp16_cx, test_bxdisp16_cx
	.word test_bxsid16_dx, test_bxdid16_dx, test_bpsid16_dx, test_bpdid16_dx, test_sidisp16_dx, test_didisp16_dx, test_bpdisp16_dx, test_bxdisp16_dx
	.word test_bxsid16_bx, test_bxdid16_bx, test_bpsid16_bx, test_bpdid16_bx, test_sidisp16_bx, test_didisp16_bx, test_bpdisp16_bx, test_bxdisp16_bx
	.word test_bxsid16_sp, test_bxdid16_sp, test_bpsid16_sp, test_bpdid16_sp, test_sidisp16_sp, test_didisp16_sp, test_bpdisp16_sp, test_bxdisp16_sp
	.word test_bxsid16_bp, test_bxdid16_bp, test_bpsid16_bp, test_bpdid16_bp, test_sidisp16_bp, test_didisp16_bp, test_bpdisp16_bp, test_bxdisp16_bp
	.word test_bxsid16_si, test_bxdid16_si, test_bpsid16_si, test_bpdid16_si, test_sidisp16_si, test_didisp16_si, test_bpdisp16_si, test_bxdisp16_si
	.word test_bxsid16_di, test_bxdid16_di, test_bpsid16_di, test_bpdid16_di, test_sidisp16_di, test_didisp16_di, test_bpdisp16_di, test_bxdisp16_di
//0xc0 = mod = 11b => two register operands
	.word test_ax_ax, test_ax_cx, test_ax_dx, test_ax_bx, test_ax_sp, test_ax_bp, test_ax_si, test_ax_di
	.word test_ax_cx, test_cx_cx, test_cx_dx, test_cx_bx, test_cx_sp, test_cx_bp, test_cx_si, test_cx_di
	.word test_ax_dx, test_cx_dx, test_dx_dx, test_dx_bx, test_dx_sp, test_dx_bp, test_dx_si, test_dx_di
	.word test_ax_bx, test_cx_bx, test_dx_bx, test_bx_bx, test_bx_sp, test_bx_bp, test_bx_si, test_bx_di
	.word test_ax_sp, test_cx_sp, test_dx_sp, test_bx_sp, test_sp_sp, test_bp_sp, test_si_sp, test_di_sp
	.word test_ax_bp, test_cx_bp, test_dx_bp, test_bx_bp, test_bp_sp, test_bp_bp, test_bp_si, test_bp_di
	.word test_ax_si, test_cx_si, test_dx_si, test_bx_si, test_si_sp, test_bp_si, test_si_si, test_si_di
	.word test_ax_di, test_cx_di, test_dx_di, test_bx_di, test_di_sp, test_bp_di, test_si_di, test_di_di

// These are called from "cpu_67.s":

	.global test_siidx_ax, test_diidx_ax, test_bxidx_ax
	.global test_siidx_cx, test_diidx_cx, test_bxidx_cx
	.global test_siidx_dx, test_diidx_dx, test_bxidx_dx
	.global test_siidx_bx, test_diidx_bx, test_bxidx_bx
	.global test_siidx_sp, test_diidx_sp, test_bxidx_sp
	.global test_siidx_bp, test_diidx_bp, test_bxidx_bp
	.global test_siidx_si, test_diidx_si, test_bxidx_si
	.global test_siidx_di, test_diidx_di, test_bxidx_di
	.global test_sidisp8_ax, test_didisp8_ax, test_bpdisp8_ax, test_bxdisp8_ax
	.global test_sidisp8_cx, test_didisp8_cx, test_bpdisp8_cx, test_bxdisp8_cx
	.global test_sidisp8_dx, test_didisp8_dx, test_bpdisp8_dx, test_bxdisp8_dx
	.global test_sidisp8_bx, test_didisp8_bx, test_bpdisp8_bx, test_bxdisp8_bx
	.global test_sidisp8_sp, test_didisp8_sp, test_bpdisp8_sp, test_bxdisp8_sp
	.global test_sidisp8_bp, test_didisp8_bp, test_bpdisp8_bp, test_bxdisp8_bp
	.global test_sidisp8_si, test_didisp8_si, test_bpdisp8_si, test_bxdisp8_si
	.global test_sidisp8_di, test_didisp8_di, test_bpdisp8_di, test_bxdisp8_di
	.global test_ax_ax, test_cx_ax, test_dx_ax, test_bx_ax, test_sp_ax, test_bp_ax, test_si_ax, test_di_ax
	.global test_ax_cx, test_cx_cx, test_dx_cx, test_bx_cx, test_sp_cx, test_bp_cx, test_si_cx, test_di_cx
	.global test_ax_dx, test_cx_dx, test_dx_dx, test_bx_dx, test_sp_dx, test_bp_dx, test_si_dx, test_di_dx
	.global test_ax_bx, test_cx_bx, test_dx_bx, test_bx_bx, test_sp_bx, test_bp_bx, test_si_bx, test_di_bx
	.global test_ax_sp, test_cx_sp, test_dx_sp, test_bx_sp, test_sp_sp, test_bp_sp, test_si_sp, test_di_sp
	.global test_ax_bp, test_cx_bp, test_dx_bp, test_bx_bp, test_sp_bp, test_bp_bp, test_si_bp, test_di_bp
	.global test_ax_si, test_cx_si, test_dx_si, test_bx_si, test_sp_si, test_bp_si, test_si_si, test_di_si
	.global test_ax_di, test_cx_di, test_dx_di, test_bx_di, test_sp_di, test_bp_di, test_si_di, test_di_di

.macro test_r0_reg16 reg
	.global	test_r0_r16_bp_\reg
test_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	test_r0_r16_\reg
test_r0_r16_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_85_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_85_RAM_\reg:
	ldrb	r0, [r2] 				// Load byte to r0
	ldrb	r1, [r2, #1]
	mov		r2, \reg, lsl #16
	orr		r0, r1, lsl #8
	tst		r2, r0, lsl #16
	b		loop
.endm

	test_r0_reg16 r4
	test_r0_reg16 r5
	test_r0_reg16 r6
	test_r0_reg16 r7
	test_r0_reg16 r8
	test_r0_reg16 r9
	test_r0_reg16 r10
	test_r0_reg16 r11

	.ltorg

// --- [idx] ----

.macro test_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		test_r0_r16_\reg
.endm

test_bxsi_ax:
	test_bxidx_reg16 r10 r4
test_bxsi_cx:
	test_bxidx_reg16 r10 r5
test_bxsi_dx:
	test_bxidx_reg16 r10 r6
test_bxsi_bx:
	test_bxidx_reg16 r10 r7
test_bxsi_sp:
	test_bxidx_reg16 r10 r8
test_bxsi_bp:
	test_bxidx_reg16 r10 r9
test_bxsi_si:
	test_bxidx_reg16 r10 r10
test_bxsi_di:
	test_bxidx_reg16 r10 r11

test_bxdi_ax:
	test_bxidx_reg16 r11 r4
test_bxdi_cx:
	test_bxidx_reg16 r11 r5
test_bxdi_dx:
	test_bxidx_reg16 r11 r6
test_bxdi_bx:
	test_bxidx_reg16 r11 r7
test_bxdi_sp:
	test_bxidx_reg16 r11 r8
test_bxdi_bp:
	test_bxidx_reg16 r11 r9
test_bxdi_si:
	test_bxidx_reg16 r11 r10
test_bxdi_di:
	test_bxidx_reg16 r11 r11

.macro test_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		test_r0_r16_bp_\reg
.endm

test_bpsi_ax:
	test_bpidx_reg16 r10 r4
test_bpsi_cx:
	test_bpidx_reg16 r10 r5
test_bpsi_dx:
	test_bpidx_reg16 r10 r6
test_bpsi_bx:
	test_bpidx_reg16 r10 r7
test_bpsi_sp:
	test_bpidx_reg16 r10 r8
test_bpsi_bp:
	test_bpidx_reg16 r10 r9
test_bpsi_si:
	test_bpidx_reg16 r10 r10
test_bpsi_di:
	test_bpidx_reg16 r10 r11

test_bpdi_ax:
	test_bpidx_reg16 r11 r4
test_bpdi_cx:
	test_bpidx_reg16 r11 r5
test_bpdi_dx:
	test_bpidx_reg16 r11 r6
test_bpdi_bx:
	test_bpidx_reg16 r11 r7
test_bpdi_sp:
	test_bpidx_reg16 r11 r8
test_bpdi_bp:
	test_bpidx_reg16 r11 r9
test_bpdi_si:
	test_bpidx_reg16 r11 r10
test_bpdi_di:
	test_bpidx_reg16 r11 r11

.macro test_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		test_r0_r16_\reg
.endm

test_siidx_ax:
	test_idx_reg16 r10 r4
test_siidx_cx:
	test_idx_reg16 r10 r5
test_siidx_dx:
	test_idx_reg16 r10 r6
test_siidx_bx:
	test_idx_reg16 r10 r7
test_siidx_sp:
	test_idx_reg16 r10 r8
test_siidx_bp:
	test_idx_reg16 r10 r9
test_siidx_si:
	test_idx_reg16 r10 r10
test_siidx_di:
	test_idx_reg16 r10 r11

test_diidx_ax:
	test_idx_reg16 r11 r4
test_diidx_cx:
	test_idx_reg16 r11 r5
test_diidx_dx:
	test_idx_reg16 r11 r6
test_diidx_bx:
	test_idx_reg16 r11 r7
test_diidx_sp:
	test_idx_reg16 r11 r8
test_diidx_bp:
	test_idx_reg16 r11 r9
test_diidx_si:
	test_idx_reg16 r11 r10
test_diidx_di:
	test_idx_reg16 r11 r11

test_bxidx_ax:
	test_idx_reg16 r7 r4
test_bxidx_cx:
	test_idx_reg16 r7 r5
test_bxidx_dx:
	test_idx_reg16 r7 r6
test_bxidx_bx:
	test_idx_reg16 r7 r7
test_bxidx_sp:
	test_idx_reg16 r7 r8
test_bxidx_bp:
	test_idx_reg16 r7 r9
test_bxidx_si:
	test_idx_reg16 r7 r10
test_bxidx_di:
	test_idx_reg16 r7 r11
	
.macro test_disp16_reg16 reg
	r0_from_disp16
	b		test_r0_r16_\reg
.endm

test_disp16_ax:
	test_disp16_reg16 r4
test_disp16_cx:
	test_disp16_reg16 r5
test_disp16_dx:
	test_disp16_reg16 r6
test_disp16_bx:
	test_disp16_reg16 r7
test_disp16_sp:
	test_disp16_reg16 r8
test_disp16_bp:
	test_disp16_reg16 r9
test_disp16_si:
	test_disp16_reg16 r10
test_disp16_di:
	test_disp16_reg16 r11

// --- [idx+disp8] ----

.macro test_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		test_r0_r16_\reg
.endm

test_bxsid8_ax:
	test_bxidxd8_reg16 r10 r4
test_bxsid8_cx:
	test_bxidxd8_reg16 r10 r5
test_bxsid8_dx:
	test_bxidxd8_reg16 r10 r6
test_bxsid8_bx:
	test_bxidxd8_reg16 r10 r7
test_bxsid8_sp:
	test_bxidxd8_reg16 r10 r8
test_bxsid8_bp:
	test_bxidxd8_reg16 r10 r9
test_bxsid8_si:
	test_bxidxd8_reg16 r10 r10
test_bxsid8_di:
	test_bxidxd8_reg16 r10 r11

test_bxdid8_ax:
	test_bxidxd8_reg16 r11 r4
test_bxdid8_cx:
	test_bxidxd8_reg16 r11 r5
test_bxdid8_dx:
	test_bxidxd8_reg16 r11 r6
test_bxdid8_bx:
	test_bxidxd8_reg16 r11 r7
test_bxdid8_sp:
	test_bxidxd8_reg16 r11 r8
test_bxdid8_bp:
	test_bxidxd8_reg16 r11 r9
test_bxdid8_si:
	test_bxidxd8_reg16 r11 r10
test_bxdid8_di:
	test_bxidxd8_reg16 r11 r11

.macro test_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		test_r0_r16_bp_\reg
.endm

test_bpsid8_ax:
	test_bpidxd8_reg16 r10 r4
test_bpsid8_cx:
	test_bpidxd8_reg16 r10 r5
test_bpsid8_dx:
	test_bpidxd8_reg16 r10 r6
test_bpsid8_bx:
	test_bpidxd8_reg16 r10 r7
test_bpsid8_sp:
	test_bpidxd8_reg16 r10 r8
test_bpsid8_bp:
	test_bpidxd8_reg16 r10 r9
test_bpsid8_si:
	test_bpidxd8_reg16 r10 r10
test_bpsid8_di:
	test_bpidxd8_reg16 r10 r11

test_bpdid8_ax:
	test_bpidxd8_reg16 r11 r4
test_bpdid8_cx:
	test_bpidxd8_reg16 r11 r5
test_bpdid8_dx:
	test_bpidxd8_reg16 r11 r6
test_bpdid8_bx:
	test_bpidxd8_reg16 r11 r7
test_bpdid8_sp:
	test_bpidxd8_reg16 r11 r8
test_bpdid8_bp:
	test_bpidxd8_reg16 r11 r9
test_bpdid8_si:
	test_bpidxd8_reg16 r11 r10
test_bpdid8_di:
	test_bpidxd8_reg16 r11 r11

.macro test_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		test_r0_r16_\reg
.endm

test_sidisp8_ax:
	test_idxdisp8_reg16 r10 r4
test_sidisp8_cx:
	test_idxdisp8_reg16 r10 r5
test_sidisp8_dx:
	test_idxdisp8_reg16 r10 r6
test_sidisp8_bx:
	test_idxdisp8_reg16 r10 r7
test_sidisp8_sp:
	test_idxdisp8_reg16 r10 r8
test_sidisp8_bp:
	test_idxdisp8_reg16 r10 r9
test_sidisp8_si:
	test_idxdisp8_reg16 r10 r10
test_sidisp8_di:
	test_idxdisp8_reg16 r10 r11

test_didisp8_ax:
	test_idxdisp8_reg16 r11 r4
test_didisp8_cx:
	test_idxdisp8_reg16 r11 r5
test_didisp8_dx:
	test_idxdisp8_reg16 r11 r6
test_didisp8_bx:
	test_idxdisp8_reg16 r11 r7
test_didisp8_sp:
	test_idxdisp8_reg16 r11 r8
test_didisp8_bp:
	test_idxdisp8_reg16 r11 r9
test_didisp8_si:
	test_idxdisp8_reg16 r11 r10
test_didisp8_di:
	test_idxdisp8_reg16 r11 r11

test_bxdisp8_ax:
	test_idxdisp8_reg16 r7 r4
test_bxdisp8_cx:
	test_idxdisp8_reg16 r7 r5
test_bxdisp8_dx:
	test_idxdisp8_reg16 r7 r6
test_bxdisp8_bx:
	test_idxdisp8_reg16 r7 r7
test_bxdisp8_sp:
	test_idxdisp8_reg16 r7 r8
test_bxdisp8_bp:
	test_idxdisp8_reg16 r7 r9
test_bxdisp8_si:
	test_idxdisp8_reg16 r7 r10
test_bxdisp8_di:
	test_idxdisp8_reg16 r7 r11
	
.macro test_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		test_r0_r16_bp_\reg
.endm
	
test_bpdisp8_ax:
	test_bpdisp8_reg16 r4
test_bpdisp8_cx:
	test_bpdisp8_reg16 r5
test_bpdisp8_dx:
	test_bpdisp8_reg16 r6
test_bpdisp8_bx:
	test_bpdisp8_reg16 r7
test_bpdisp8_sp:
	test_bpdisp8_reg16 r8
test_bpdisp8_bp:
	test_bpdisp8_reg16 r9
test_bpdisp8_si:
	test_bpdisp8_reg16 r10
test_bpdisp8_di:
	test_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro test_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		test_r0_r16_\reg
.endm

test_bxsid16_ax:
	test_bxidxd16_reg16 r10 r4
test_bxsid16_cx:
	test_bxidxd16_reg16 r10 r5
test_bxsid16_dx:
	test_bxidxd16_reg16 r10 r6
test_bxsid16_bx:
	test_bxidxd16_reg16 r10 r7
test_bxsid16_sp:
	test_bxidxd16_reg16 r10 r8
test_bxsid16_bp:
	test_bxidxd16_reg16 r10 r9
test_bxsid16_si:
	test_bxidxd16_reg16 r10 r10
test_bxsid16_di:
	test_bxidxd16_reg16 r10 r11

test_bxdid16_ax:
	test_bxidxd16_reg16 r11 r4
test_bxdid16_cx:
	test_bxidxd16_reg16 r11 r5
test_bxdid16_dx:
	test_bxidxd16_reg16 r11 r6
test_bxdid16_bx:
	test_bxidxd16_reg16 r11 r7
test_bxdid16_sp:
	test_bxidxd16_reg16 r11 r8
test_bxdid16_bp:
	test_bxidxd16_reg16 r11 r9
test_bxdid16_si:
	test_bxidxd16_reg16 r11 r10
test_bxdid16_di:
	test_bxidxd16_reg16 r11 r11

.macro test_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		test_r0_r16_bp_\reg
.endm

test_bpsid16_ax:
	test_bpidxd16_reg16 r10 r4
test_bpsid16_cx:
	test_bpidxd16_reg16 r10 r5
test_bpsid16_dx:
	test_bpidxd16_reg16 r10 r6
test_bpsid16_bx:
	test_bpidxd16_reg16 r10 r7
test_bpsid16_sp:
	test_bpidxd16_reg16 r10 r8
test_bpsid16_bp:
	test_bpidxd16_reg16 r10 r9
test_bpsid16_si:
	test_bpidxd16_reg16 r10 r10
test_bpsid16_di:
	test_bpidxd16_reg16 r10 r11

test_bpdid16_ax:
	test_bpidxd16_reg16 r11 r4
test_bpdid16_cx:
	test_bpidxd16_reg16 r11 r5
test_bpdid16_dx:
	test_bpidxd16_reg16 r11 r6
test_bpdid16_bx:
	test_bpidxd16_reg16 r11 r7
test_bpdid16_sp:
	test_bpidxd16_reg16 r11 r8
test_bpdid16_bp:
	test_bpidxd16_reg16 r11 r9
test_bpdid16_si:
	test_bpidxd16_reg16 r11 r10
test_bpdid16_di:
	test_bpidxd16_reg16 r11 r11

.macro test_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		test_r0_r16_\reg
.endm

test_sidisp16_ax:
	test_idxdisp16_reg16 r10 r4
test_sidisp16_cx:
	test_idxdisp16_reg16 r10 r5
test_sidisp16_dx:
	test_idxdisp16_reg16 r10 r6
test_sidisp16_bx:
	test_idxdisp16_reg16 r10 r7
test_sidisp16_sp:
	test_idxdisp16_reg16 r10 r8
test_sidisp16_bp:
	test_idxdisp16_reg16 r10 r9
test_sidisp16_si:
	test_idxdisp16_reg16 r10 r10
test_sidisp16_di:
	test_idxdisp16_reg16 r10 r11

test_didisp16_ax:
	test_idxdisp16_reg16 r11 r4
test_didisp16_cx:
	test_idxdisp16_reg16 r11 r5
test_didisp16_dx:
	test_idxdisp16_reg16 r11 r6
test_didisp16_bx:
	test_idxdisp16_reg16 r11 r7
test_didisp16_sp:
	test_idxdisp16_reg16 r11 r8
test_didisp16_bp:
	test_idxdisp16_reg16 r11 r9
test_didisp16_si:
	test_idxdisp16_reg16 r11 r10
test_didisp16_di:
	test_idxdisp16_reg16 r11 r11

test_bxdisp16_ax:
	test_idxdisp16_reg16 r7 r4
test_bxdisp16_cx:
	test_idxdisp16_reg16 r7 r5
test_bxdisp16_dx:
	test_idxdisp16_reg16 r7 r6
test_bxdisp16_bx:
	test_idxdisp16_reg16 r7 r7
test_bxdisp16_sp:
	test_idxdisp16_reg16 r7 r8
test_bxdisp16_bp:
	test_idxdisp16_reg16 r7 r9
test_bxdisp16_si:
	test_idxdisp16_reg16 r7 r10
test_bxdisp16_di:
	test_idxdisp16_reg16 r7 r11

.macro test_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		test_r0_r16_bp_\reg
.endm

test_bpdisp16_ax:
	test_bpdisp16_reg16 r4
test_bpdisp16_cx:
	test_bpdisp16_reg16 r5
test_bpdisp16_dx:
	test_bpdisp16_reg16 r6
test_bpdisp16_bx:
	test_bpdisp16_reg16 r7
test_bpdisp16_sp:
	test_bpdisp16_reg16 r8
test_bpdisp16_bp:
	test_bpdisp16_reg16 r9
test_bpdisp16_si:
	test_bpdisp16_reg16 r10
test_bpdisp16_di:
	test_bpdisp16_reg16 r11

// --- registers ---

.macro test_reg16_reg16 rl rr
	mov		r0, \rl, lsl #16
	mov		r1, \rr, lsl #16
	tst		r0, r1
	b		loop
.endm
	
test_ax_ax:
	test_reg16_reg16 eax eax
test_cx_ax:
test_ax_cx:
	test_reg16_reg16 eax ecx
test_dx_ax:
test_ax_dx:
	test_reg16_reg16 eax edx
test_bx_ax:
test_ax_bx:
	test_reg16_reg16 eax ebx
test_sp_ax:
test_ax_sp:
	test_reg16_reg16 eax esp
test_bp_ax:
test_ax_bp:
	test_reg16_reg16 eax ebp
test_si_ax:
test_ax_si:
	test_reg16_reg16 eax esi
test_di_ax:
test_ax_di:
	test_reg16_reg16 eax edi
test_cx_cx:
	test_reg16_reg16 ecx ecx
test_dx_cx:
test_cx_dx:
	test_reg16_reg16 ecx edx
test_bx_cx:
test_cx_bx:
	test_reg16_reg16 ecx ebx
test_sp_cx:
test_cx_sp:
	test_reg16_reg16 ecx esp
test_bp_cx:
test_cx_bp:
	test_reg16_reg16 ecx ebp
test_si_cx:
test_cx_si:
	test_reg16_reg16 ecx esi
test_di_cx:
test_cx_di:
	test_reg16_reg16 ecx edi
test_dx_dx:
	test_reg16_reg16 edx edx
test_bx_dx:
test_dx_bx:
	test_reg16_reg16 edx ebx
test_sp_dx:
test_dx_sp:
	test_reg16_reg16 edx esp
test_bp_dx:
test_dx_bp:
	test_reg16_reg16 edx ebp
test_si_dx:
test_dx_si:
	test_reg16_reg16 edx esi
test_di_dx:
test_dx_di:
	test_reg16_reg16 edx edi
test_bx_bx:
	test_reg16_reg16 ebx ebx
test_sp_bx:
test_bx_sp:
	test_reg16_reg16 ebx esp
test_bp_bx:
test_bx_bp:
	test_reg16_reg16 ebx ebp
test_si_bx:
test_bx_si:
	test_reg16_reg16 ebx esi
test_di_bx:
test_bx_di:
	test_reg16_reg16 ebx edi
test_sp_sp:
	test_reg16_reg16 esp esp
test_sp_bp:
test_bp_sp:
	test_reg16_reg16 ebp esp
test_bp_bp:
	test_reg16_reg16 ebp ebp
test_si_bp:
test_bp_si:
	test_reg16_reg16 ebp esi
test_di_bp:
test_bp_di:
	test_reg16_reg16 ebp edi
test_sp_si:
test_si_sp:
	test_reg16_reg16 esi esp
test_si_si:
	test_reg16_reg16 esi esi
test_di_si:
test_si_di:
	test_reg16_reg16 esi edi
test_sp_di:
test_di_sp:
	test_reg16_reg16 edi esp
test_di_di:
	test_reg16_reg16 edi edi

// ------------------- 86 = XCHG r/m8,r8 -----------------------------
//
// All modrm bytes supported!
//
//
	.global	op_86
op_86:
	modrm_jump_16
// 0
	.word xchg_bxsi_al, xchg_bxdi_al, xchg_bpsi_al, xchg_bpdi_al, xchg_siidx_al, xchg_diidx_al, xchg_disp16_al, xchg_bxidx_al
	.word xchg_bxsi_cl, xchg_bxdi_cl, xchg_bpsi_cl, xchg_bpdi_cl, xchg_siidx_cl, xchg_diidx_cl, xchg_disp16_cl, xchg_bxidx_cl
	.word xchg_bxsi_dl, xchg_bxdi_dl, xchg_bpsi_dl, xchg_bpdi_dl, xchg_siidx_dl, xchg_diidx_dl, xchg_disp16_dl, xchg_bxidx_dl
	.word xchg_bxsi_bl, xchg_bxdi_bl, xchg_bpsi_bl, xchg_bpdi_bl, xchg_siidx_bl, xchg_diidx_bl, xchg_disp16_bl, xchg_bxidx_bl
	.word xchg_bxsi_ah, xchg_bxdi_ah, xchg_bpsi_ah, xchg_bpdi_ah, xchg_siidx_ah, xchg_diidx_ah, xchg_disp16_ah, xchg_bxidx_ah
	.word xchg_bxsi_ch, xchg_bxdi_ch, xchg_bpsi_ch, xchg_bpdi_ch, xchg_siidx_ch, xchg_diidx_ch, xchg_disp16_ch, xchg_bxidx_ch
	.word xchg_bxsi_dh, xchg_bxdi_dh, xchg_bpsi_dh, xchg_bpdi_dh, xchg_siidx_dh, xchg_diidx_dh, xchg_disp16_dh, xchg_bxidx_dh
	.word xchg_bxsi_bh, xchg_bxdi_bh, xchg_bpsi_bh, xchg_bpdi_bh, xchg_siidx_bh, xchg_diidx_bh, xchg_disp16_bh, xchg_bxidx_bh
//0x40
	.word xchg_bxsid8_al, xchg_bxdid8_al, xchg_bpsid8_al, xchg_bpdid8_al, xchg_sidisp8_al, xchg_didisp8_al, xchg_bpdisp8_al, xchg_bxdisp8_al
	.word xchg_bxsid8_cl, xchg_bxdid8_cl, xchg_bpsid8_cl, xchg_bpdid8_cl, xchg_sidisp8_cl, xchg_didisp8_cl, xchg_bpdisp8_cl, xchg_bxdisp8_cl
	.word xchg_bxsid8_dl, xchg_bxdid8_dl, xchg_bpsid8_dl, xchg_bpdid8_dl, xchg_sidisp8_dl, xchg_didisp8_dl, xchg_bpdisp8_dl, xchg_bxdisp8_dl
	.word xchg_bxsid8_bl, xchg_bxdid8_bl, xchg_bpsid8_bl, xchg_bpdid8_bl, xchg_sidisp8_bl, xchg_didisp8_bl, xchg_bpdisp8_bl, xchg_bxdisp8_bl
	.word xchg_bxsid8_ah, xchg_bxdid8_ah, xchg_bpsid8_ah, xchg_bpdid8_ah, xchg_sidisp8_ah, xchg_didisp8_ah, xchg_bpdisp8_ah, xchg_bxdisp8_ah
	.word xchg_bxsid8_ch, xchg_bxdid8_ch, xchg_bpsid8_ch, xchg_bpdid8_ch, xchg_sidisp8_ch, xchg_didisp8_ch, xchg_bpdisp8_ch, xchg_bxdisp8_ch
	.word xchg_bxsid8_dh, xchg_bxdid8_dh, xchg_bpsid8_dh, xchg_bpdid8_dh, xchg_sidisp8_dh, xchg_didisp8_dh, xchg_bpdisp8_dh, xchg_bxdisp8_dh
	.word xchg_bxsid8_bh, xchg_bxdid8_bh, xchg_bpsid8_bh, xchg_bpdid8_bh, xchg_sidisp8_bh, xchg_didisp8_bh, xchg_bpdisp8_bh, xchg_bxdisp8_bh
//0x80
	.word xchg_bxsid16_al, xchg_bxdid16_al, xchg_bpsid16_al, xchg_bpdid16_al, xchg_sidisp16_al, xchg_didisp16_al, xchg_bpdisp16_al, xchg_bxdisp16_al
	.word xchg_bxsid16_cl, xchg_bxdid16_cl, xchg_bpsid16_cl, xchg_bpdid16_cl, xchg_sidisp16_cl, xchg_didisp16_cl, xchg_bpdisp16_cl, xchg_bxdisp16_cl
	.word xchg_bxsid16_dl, xchg_bxdid16_dl, xchg_bpsid16_dl, xchg_bpdid16_dl, xchg_sidisp16_dl, xchg_didisp16_dl, xchg_bpdisp16_dl, xchg_bxdisp16_dl
	.word xchg_bxsid16_bl, xchg_bxdid16_bl, xchg_bpsid16_bl, xchg_bpdid16_bl, xchg_sidisp16_bl, xchg_didisp16_bl, xchg_bpdisp16_bl, xchg_bxdisp16_bl
	.word xchg_bxsid16_ah, xchg_bxdid16_ah, xchg_bpsid16_ah, xchg_bpdid16_ah, xchg_sidisp16_ah, xchg_didisp16_ah, xchg_bpdisp16_ah, xchg_bxdisp16_ah
	.word xchg_bxsid16_ch, xchg_bxdid16_ch, xchg_bpsid16_ch, xchg_bpdid16_ch, xchg_sidisp16_ch, xchg_didisp16_ch, xchg_bpdisp16_ch, xchg_bxdisp16_ch
	.word xchg_bxsid16_dh, xchg_bxdid16_dh, xchg_bpsid16_dh, xchg_bpdid16_dh, xchg_sidisp16_dh, xchg_didisp16_dh, xchg_bpdisp16_dh, xchg_bxdisp16_dh
	.word xchg_bxsid16_bh, xchg_bxdid16_bh, xchg_bpsid16_bh, xchg_bpdid16_bh, xchg_sidisp16_bh, xchg_didisp16_bh, xchg_bpdisp16_bh, xchg_bxdisp16_bh
//0xc0 = mod = 11b => two register operands. We can skip operations like XCHG AL,AL
	.word loop, xchg_al_cl, xchg_al_dl, xchg_al_bl, xchg_al_ah, xchg_al_ch, xchg_al_dh, xchg_al_bh
	.word xchg_al_cl, loop, xchg_cl_dl, xchg_cl_bl, xchg_cl_ah, xchg_cl_ch, xchg_cl_dh, xchg_cl_bh
	.word xchg_al_dl, xchg_cl_dl, loop, xchg_dl_bl, xchg_dl_ah, xchg_dl_ch, xchg_dl_dh, xchg_dl_bh
	.word xchg_al_bl, xchg_cl_bl, xchg_dl_bl, loop, xchg_bl_ah, xchg_bl_ch, xchg_bl_dh, xchg_bl_bh
	.word xchg_al_ah, xchg_cl_ah, xchg_dl_ah, xchg_bl_ah, loop, xchg_ah_ch, xchg_ah_dh, xchg_ah_bh
	.word xchg_al_ch, xchg_cl_ch, xchg_dl_ch, xchg_bl_ch, xchg_ah_ch, loop, xchg_ch_dh, xchg_ch_bh
	.word xchg_al_dh, xchg_cl_dh, xchg_dl_dh, xchg_bl_dh, xchg_ah_dh, xchg_ch_dh, loop, xchg_dh_bh
	.word xchg_al_bh, xchg_cl_bh, xchg_dl_bh, xchg_bl_bh, xchg_ah_bh, xchg_ch_bh, xchg_dh_bh, loop

// These are called from "cpu_386.s":

	.global	xchg_siidx_al, xchg_siidx_cl, xchg_siidx_dl, xchg_siidx_bl, xchg_siidx_ah, xchg_siidx_ch, xchg_siidx_dh, xchg_siidx_bh
	.global	xchg_diidx_al, xchg_diidx_cl, xchg_diidx_dl, xchg_diidx_bl, xchg_diidx_ah, xchg_diidx_ch, xchg_diidx_dh, xchg_diidx_bh
	.global	xchg_bxidx_al, xchg_bxidx_cl, xchg_bxidx_dl, xchg_bxidx_bl, xchg_bxidx_ah, xchg_bxidx_ch, xchg_bxidx_dh, xchg_bxidx_bh
	.global	xchg_sidisp8_al, xchg_sidisp8_cl, xchg_sidisp8_dl, xchg_sidisp8_bl, xchg_sidisp8_ah, xchg_sidisp8_ch, xchg_sidisp8_dh, xchg_sidisp8_bh
	.global	xchg_didisp8_al, xchg_didisp8_cl, xchg_didisp8_dl, xchg_didisp8_bl, xchg_didisp8_ah, xchg_didisp8_ch, xchg_didisp8_dh, xchg_didisp8_bh
	.global	xchg_bpdisp8_al, xchg_bpdisp8_cl, xchg_bpdisp8_dl, xchg_bpdisp8_bl, xchg_bpdisp8_ah, xchg_bpdisp8_ch, xchg_bpdisp8_dh, xchg_bpdisp8_bh
	.global	xchg_bxdisp8_al, xchg_bxdisp8_cl, xchg_bxdisp8_dl, xchg_bxdisp8_bl, xchg_bxdisp8_ah, xchg_bxdisp8_ch, xchg_bxdisp8_dh, xchg_bxdisp8_bh

	.global xchg_cl_al 
	.global xchg_dl_al 
	.global xchg_bl_al 
	.global xchg_ah_al 
	.global xchg_ch_al 
	.global xchg_dh_al 
	.global xchg_bh_al
	.global xchg_al_cl 
	.global xchg_dl_cl 
	.global xchg_bl_cl 
	.global xchg_ah_cl 
	.global xchg_ch_cl 
	.global xchg_dh_cl 
	.global xchg_bh_cl
	.global xchg_al_dl 
	.global xchg_cl_dl 
	.global xchg_bl_dl 
	.global xchg_ah_dl 
	.global xchg_ch_dl 
	.global xchg_dh_dl 
	.global xchg_bh_dl
	.global xchg_al_bl 
	.global xchg_cl_bl 
	.global xchg_dl_bl 
	.global xchg_ah_bl 
	.global xchg_ch_bl 
	.global xchg_dh_bl 
	.global xchg_bh_bl
	.global xchg_al_ah 
	.global xchg_cl_ah 
	.global xchg_dl_ah 
	.global xchg_bl_ah 
	.global xchg_ch_ah 
	.global xchg_dh_ah 
	.global xchg_bh_ah
	.global xchg_al_ch 
	.global xchg_cl_ch 
	.global xchg_dl_ch 
	.global xchg_bl_ch 
	.global xchg_ah_ch 
	.global xchg_dh_ch 
	.global xchg_bh_ch
	.global xchg_al_dh 
	.global xchg_cl_dh 
	.global xchg_dl_dh 
	.global xchg_bl_dh 
	.global xchg_ah_dh 
	.global xchg_ch_dh 
	.global xchg_bh_dh
	.global xchg_al_bh 
	.global xchg_cl_bh 
	.global xchg_dl_bh 
	.global xchg_bl_bh 
	.global xchg_ah_bh 
	.global xchg_ch_bh 
	.global xchg_dh_bh 

.macro xchg_r0_r8l_reg reg
	.global	xchg_r0_r8l_bp_\reg
xchg_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	xchg_r0_r8l_\reg
xchg_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_86_RAM_l_\reg op_86_EGA_l_\reg op_86_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_86_RAM_l_\reg:
	ldrb	r0, [r2]
	strb	\reg, [r2]
#if defined(RPi) || defined(Roku)
	bic		\reg, #0xFF
	orr		\reg, r0
#else
	bfi		\reg, r0, #0, #8
#endif
	b		loop
.endm
.macro xchg_r0_r8h_reg reg
	.global	xchg_r0_r8h_bp_\reg
xchg_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	xchg_r0_r8h_\reg
xchg_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_86_RAM_h_\reg op_86_EGA_h_\reg op_86_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_86_RAM_h_\reg:
	mov		r1, \reg, lsr #8
	ldrb	r0, [r2]
#if defined(RPi) || defined(Roku)
	bic		\reg, #0xFF00
	strb	r1, [r2]
	orr		\reg, r0, lsl #8
#else
	strb	r1, [r2]
	bfi		\reg, r0, #8, #8
#endif
	b		loop
.endm

	xchg_r0_r8l_reg r4
	xchg_r0_r8l_reg r5
	xchg_r0_r8l_reg r6
	xchg_r0_r8l_reg r7
	xchg_r0_r8h_reg r4
	xchg_r0_r8h_reg r5
	xchg_r0_r8h_reg r6
	xchg_r0_r8h_reg r7

	.ltorg

// --- [idx] ---
//
.macro xchg_bxsi_reg8l reg
	add		r0, r7, r10
	b		xchg_r0_r8l_\reg
.endm
.macro xchg_bxsi_reg8h reg
	add		r0, r7, r10
	b		xchg_r0_r8h_\reg
.endm

xchg_bxsi_al:
	xchg_bxsi_reg8l r4
xchg_bxsi_cl:
	xchg_bxsi_reg8l r5
xchg_bxsi_dl:
	xchg_bxsi_reg8l r6
xchg_bxsi_bl:
	xchg_bxsi_reg8l r7
xchg_bxsi_ah:
	xchg_bxsi_reg8h r4
xchg_bxsi_ch:
	xchg_bxsi_reg8h r5
xchg_bxsi_dh:
	xchg_bxsi_reg8h r6
xchg_bxsi_bh:
	xchg_bxsi_reg8h r7

.macro xchg_bxdi_reg8l reg
	add		r0, r7, r11
	b		xchg_r0_r8l_\reg
.endm
.macro xchg_bxdi_reg8h reg
	add		r0, r7, r11
	b		xchg_r0_r8h_\reg
.endm

xchg_bxdi_al:
	xchg_bxdi_reg8l r4
xchg_bxdi_cl:
	xchg_bxdi_reg8l r5
xchg_bxdi_dl:
	xchg_bxdi_reg8l r6
xchg_bxdi_bl:
	xchg_bxdi_reg8l r7
xchg_bxdi_ah:
	xchg_bxdi_reg8h r4
xchg_bxdi_ch:
	xchg_bxdi_reg8h r5
xchg_bxdi_dh:
	xchg_bxdi_reg8h r6
xchg_bxdi_bh:
	xchg_bxdi_reg8h r7

.macro xchg_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		xchg_r0_r8l_bp_\reg
.endm
.macro xchg_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		xchg_r0_r8h_bp_\reg
.endm

xchg_bpsi_al:
	xchg_bpidx_reg8l r10 r4
xchg_bpsi_cl:
	xchg_bpidx_reg8l r10 r5
xchg_bpsi_dl:
	xchg_bpidx_reg8l r10 r6
xchg_bpsi_bl:
	xchg_bpidx_reg8l r10 r7
xchg_bpsi_ah:
	xchg_bpidx_reg8h r10 r4
xchg_bpsi_ch:
	xchg_bpidx_reg8h r10 r5
xchg_bpsi_dh:
	xchg_bpidx_reg8h r10 r6
xchg_bpsi_bh:
	xchg_bpidx_reg8h r10 r7

xchg_bpdi_al:
	xchg_bpidx_reg8l r11 r4
xchg_bpdi_cl:
	xchg_bpidx_reg8l r11 r5
xchg_bpdi_dl:
	xchg_bpidx_reg8l r11 r6
xchg_bpdi_bl:
	xchg_bpidx_reg8l r11 r7
xchg_bpdi_ah:
	xchg_bpidx_reg8h r11 r4
xchg_bpdi_ch:
	xchg_bpidx_reg8h r11 r5
xchg_bpdi_dh:
	xchg_bpidx_reg8h r11 r6
xchg_bpdi_bh:
	xchg_bpidx_reg8h r11 r7

.macro xchg_idx_reg8l idx reg
	mov		r0, \idx
	b		xchg_r0_r8l_\reg
.endm
.macro xchg_idx_reg8h idx reg
	mov		r0, \idx
	b		xchg_r0_r8h_\reg
.endm

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

xchg_siidx_al:
	xchg_idx_reg8l r10 r4
xchg_siidx_cl:
	xchg_idx_reg8l r10 r5
xchg_siidx_dl:
	xchg_idx_reg8l r10 r6
xchg_siidx_bl:
	xchg_idx_reg8l r10 r7

xchg_siidx_ah:
	xchg_idx_reg8h r10 r4
xchg_siidx_ch:
	xchg_idx_reg8h r10 r5
xchg_siidx_dh:
	xchg_idx_reg8h r10 r6
xchg_siidx_bh:
	xchg_idx_reg8h r10 r7

xchg_diidx_al:
	xchg_idx_reg8l r11 r4
xchg_diidx_cl:
	xchg_idx_reg8l r11 r5
xchg_diidx_dl:
	xchg_idx_reg8l r11 r6
xchg_diidx_bl:
	xchg_idx_reg8l r11 r7

xchg_diidx_ah:
	xchg_idx_reg8h r11 r4
xchg_diidx_ch:
	xchg_idx_reg8h r11 r5
xchg_diidx_dh:
	xchg_idx_reg8h r11 r6
xchg_diidx_bh:
	xchg_idx_reg8h r11 r7
	
xchg_bxidx_al:
	xchg_idx_reg8l r7 r4
xchg_bxidx_cl:
	xchg_idx_reg8l r7 r5
xchg_bxidx_dl:
	xchg_idx_reg8l r7 r6
xchg_bxidx_bl:
	xchg_idx_reg8l r7 r7

xchg_bxidx_ah:
	xchg_idx_reg8h r7 r4
xchg_bxidx_ch:
	xchg_idx_reg8h r7 r5
xchg_bxidx_dh:
	xchg_idx_reg8h r7 r6
xchg_bxidx_bh:
	xchg_idx_reg8h r7 r7

	.text
	.align	2

.macro xchg_disp16_reg8l reg
	r0_from_disp16
	b		xchg_r0_r8l_\reg
.endm

.macro xchg_disp16_reg8h reg
	r0_from_disp16
	b		xchg_r0_r8h_\reg
.endm

xchg_disp16_al:
	xchg_disp16_reg8l r4
xchg_disp16_cl:
	xchg_disp16_reg8l r5
xchg_disp16_dl:
	xchg_disp16_reg8l r6
xchg_disp16_bl:
	xchg_disp16_reg8l r7
xchg_disp16_ah:
	xchg_disp16_reg8h r4
xchg_disp16_ch:
	xchg_disp16_reg8h r5
xchg_disp16_dh:
	xchg_disp16_reg8h r6
xchg_disp16_bh:
	xchg_disp16_reg8h r7

// --- [idx + disp8] ---

.macro xchg_bxidxdisp8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		xchg_r0_r8l_\reg
.endm
.macro xchg_bxidxdisp8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		xchg_r0_r8h_\reg
.endm

xchg_bxsid8_al:
	xchg_bxidxdisp8_reg8l r10 r4
xchg_bxsid8_cl:
	xchg_bxidxdisp8_reg8l r10 r5
xchg_bxsid8_dl:
	xchg_bxidxdisp8_reg8l r10 r6
xchg_bxsid8_bl:
	xchg_bxidxdisp8_reg8l r10 r7
xchg_bxsid8_ah:
	xchg_bxidxdisp8_reg8h r10 r4
xchg_bxsid8_ch:
	xchg_bxidxdisp8_reg8h r10 r5
xchg_bxsid8_dh:
	xchg_bxidxdisp8_reg8h r10 r6
xchg_bxsid8_bh:
	xchg_bxidxdisp8_reg8h r10 r7

xchg_bxdid8_al:
	xchg_bxidxdisp8_reg8l r11 r4
xchg_bxdid8_cl:
	xchg_bxidxdisp8_reg8l r11 r5
xchg_bxdid8_dl:
	xchg_bxidxdisp8_reg8l r11 r6
xchg_bxdid8_bl:
	xchg_bxidxdisp8_reg8l r11 r7
xchg_bxdid8_ah:
	xchg_bxidxdisp8_reg8h r11 r4
xchg_bxdid8_ch:
	xchg_bxidxdisp8_reg8h r11 r5
xchg_bxdid8_dh:
	xchg_bxidxdisp8_reg8h r11 r6
xchg_bxdid8_bh:
	xchg_bxidxdisp8_reg8h r11 r7

.macro xchg_bpidxdisp8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		xchg_r0_r8l_bp_\reg
.endm
.macro xchg_bpidxdisp8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		xchg_r0_r8h_bp_\reg
.endm

xchg_bpsid8_al:
	xchg_bpidxdisp8_reg8l r10 r4
xchg_bpsid8_cl:
	xchg_bpidxdisp8_reg8l r10 r5
xchg_bpsid8_dl:
	xchg_bpidxdisp8_reg8l r10 r6
xchg_bpsid8_bl:
	xchg_bpidxdisp8_reg8l r10 r7
xchg_bpsid8_ah:
	xchg_bpidxdisp8_reg8h r10 r4
xchg_bpsid8_ch:
	xchg_bpidxdisp8_reg8h r10 r5
xchg_bpsid8_dh:
	xchg_bpidxdisp8_reg8h r10 r6
xchg_bpsid8_bh:
	xchg_bpidxdisp8_reg8h r10 r7

xchg_bpdid8_al:
	xchg_bpidxdisp8_reg8l r11 r4
xchg_bpdid8_cl:
	xchg_bpidxdisp8_reg8l r11 r5
xchg_bpdid8_dl:
	xchg_bpidxdisp8_reg8l r11 r6
xchg_bpdid8_bl:
	xchg_bpidxdisp8_reg8l r11 r7
xchg_bpdid8_ah:
	xchg_bpidxdisp8_reg8h r11 r4
xchg_bpdid8_ch:
	xchg_bpidxdisp8_reg8h r11 r5
xchg_bpdid8_dh:
	xchg_bpidxdisp8_reg8h r11 r6
xchg_bpdid8_bh:
	xchg_bpidxdisp8_reg8h r11 r7

.macro xchg_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		xchg_r0_r8l_\reg
.endm
.macro xchg_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		xchg_r0_r8h_\reg
.endm

xchg_sidisp8_al:
	xchg_idxdisp8_reg8l r10 r4
xchg_sidisp8_cl:
	xchg_idxdisp8_reg8l r10 r5
xchg_sidisp8_dl:
	xchg_idxdisp8_reg8l r10 r6
xchg_sidisp8_bl:
	xchg_idxdisp8_reg8l r10 r7

xchg_sidisp8_ah:
	xchg_idxdisp8_reg8h r10 r4
xchg_sidisp8_ch:
	xchg_idxdisp8_reg8h r10 r5
xchg_sidisp8_dh:
	xchg_idxdisp8_reg8h r10 r6
xchg_sidisp8_bh:
	xchg_idxdisp8_reg8h r10 r7

xchg_didisp8_al:
	xchg_idxdisp8_reg8l r11 r4
xchg_didisp8_cl:
	xchg_idxdisp8_reg8l r11 r5
xchg_didisp8_dl:
	xchg_idxdisp8_reg8l r11 r6
xchg_didisp8_bl:
	xchg_idxdisp8_reg8l r11 r7

xchg_didisp8_ah:
	xchg_idxdisp8_reg8h r11 r4
xchg_didisp8_ch:
	xchg_idxdisp8_reg8h r11 r5
xchg_didisp8_dh:
	xchg_idxdisp8_reg8h r11 r6
xchg_didisp8_bh:
	xchg_idxdisp8_reg8h r11 r7

xchg_bxdisp8_al:
	xchg_idxdisp8_reg8l r7 r4
xchg_bxdisp8_cl:
	xchg_idxdisp8_reg8l r7 r5
xchg_bxdisp8_dl:
	xchg_idxdisp8_reg8l r7 r6
xchg_bxdisp8_bl:
	xchg_idxdisp8_reg8l r7 r7

xchg_bxdisp8_ah:
	xchg_idxdisp8_reg8h r7 r4
xchg_bxdisp8_ch:
	xchg_idxdisp8_reg8h r7 r5
xchg_bxdisp8_dh:
	xchg_idxdisp8_reg8h r7 r6
xchg_bxdisp8_bh:
	xchg_idxdisp8_reg8h r7 r7

.macro xchg_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		xchg_r0_r8l_bp_\reg
.endm
.macro xchg_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		xchg_r0_r8h_bp_\reg
.endm

xchg_bpdisp8_al:
	xchg_bpdisp8_reg8l r4
xchg_bpdisp8_cl:
	xchg_bpdisp8_reg8l r5
xchg_bpdisp8_dl:
	xchg_bpdisp8_reg8l r6
xchg_bpdisp8_bl:
	xchg_bpdisp8_reg8l r7

xchg_bpdisp8_ah:
	xchg_bpdisp8_reg8h r4
xchg_bpdisp8_ch:
	xchg_bpdisp8_reg8h r5
xchg_bpdisp8_dh:
	xchg_bpdisp8_reg8h r6
xchg_bpdisp8_bh:
	xchg_bpdisp8_reg8h r7

// --- idx + disp16 ---

.macro xchg_bxidxdisp16_reg8l reg idx
	r0_from_bxidxdisp16 \idx
	b		xchg_r0_r8l_\reg
.endm
.macro xchg_bxidxdisp16_reg8h reg idx
	r0_from_bxidxdisp16 \idx
	b		xchg_r0_r8h_\reg
.endm

xchg_bxsid16_al:
	xchg_bxidxdisp16_reg8l r4 r10
xchg_bxsid16_cl:
	xchg_bxidxdisp16_reg8l r5 r10
xchg_bxsid16_dl:
	xchg_bxidxdisp16_reg8l r6 r10
xchg_bxsid16_bl:
	xchg_bxidxdisp16_reg8l r7 r10
xchg_bxsid16_ah:
	xchg_bxidxdisp16_reg8h r4 r10
xchg_bxsid16_ch:
	xchg_bxidxdisp16_reg8h r5 r10
xchg_bxsid16_dh:
	xchg_bxidxdisp16_reg8h r6 r10
xchg_bxsid16_bh:
	xchg_bxidxdisp16_reg8h r7 r10

xchg_bxdid16_al:
	xchg_bxidxdisp16_reg8l r4 r11
xchg_bxdid16_cl:
	xchg_bxidxdisp16_reg8l r5 r11
xchg_bxdid16_dl:
	xchg_bxidxdisp16_reg8l r6 r11
xchg_bxdid16_bl:
	xchg_bxidxdisp16_reg8l r7 r11
xchg_bxdid16_ah:
	xchg_bxidxdisp16_reg8h r4 r11
xchg_bxdid16_ch:
	xchg_bxidxdisp16_reg8h r5 r11
xchg_bxdid16_dh:
	xchg_bxidxdisp16_reg8h r6 r11
xchg_bxdid16_bh:
	xchg_bxidxdisp16_reg8h r7 r11

.macro xchg_bpidxdisp16_reg8l reg idx
	r0_from_bpidxdisp16 \idx
	b		xchg_r0_r8l_bp_\reg
.endm
.macro xchg_bpidxdisp16_reg8h reg idx
	r0_from_bpidxdisp16 \idx
	b		xchg_r0_r8h_bp_\reg
.endm

xchg_bpsid16_al:
	xchg_bpidxdisp16_reg8l r4 r10
xchg_bpsid16_cl:
	xchg_bpidxdisp16_reg8l r5 r10
xchg_bpsid16_dl:
	xchg_bpidxdisp16_reg8l r6 r10
xchg_bpsid16_bl:
	xchg_bpidxdisp16_reg8l r7 r10
xchg_bpsid16_ah:
	xchg_bpidxdisp16_reg8h r4 r10
xchg_bpsid16_ch:
	xchg_bpidxdisp16_reg8h r5 r10
xchg_bpsid16_dh:
	xchg_bpidxdisp16_reg8h r6 r10
xchg_bpsid16_bh:
	xchg_bpidxdisp16_reg8h r7 r10

xchg_bpdid16_al:
	xchg_bpidxdisp16_reg8l r4 r11
xchg_bpdid16_cl:
	xchg_bpidxdisp16_reg8l r5 r11
xchg_bpdid16_dl:
	xchg_bpidxdisp16_reg8l r6 r11
xchg_bpdid16_bl:
	xchg_bpidxdisp16_reg8l r7 r11
xchg_bpdid16_ah:
	xchg_bpidxdisp16_reg8h r4 r11
xchg_bpdid16_ch:
	xchg_bpidxdisp16_reg8h r5 r11
xchg_bpdid16_dh:
	xchg_bpidxdisp16_reg8h r6 r11
xchg_bpdid16_bh:
	xchg_bpidxdisp16_reg8h r7 r11

.macro xchg_idx_disp16_reg8l reg idx
	r0_from_idx_disp16 \idx
	b		xchg_r0_r8l_\reg
.endm

.macro xchg_idx_disp16_reg8h reg idx
	r0_from_idx_disp16 \idx
	b		xchg_r0_r8h_\reg
.endm

xchg_sidisp16_al:
	xchg_idx_disp16_reg8l r4 r10
xchg_sidisp16_cl:
	xchg_idx_disp16_reg8l r5 r10
xchg_sidisp16_dl:
	xchg_idx_disp16_reg8l r6 r10
xchg_sidisp16_bl:
	xchg_idx_disp16_reg8l r7 r10
xchg_sidisp16_ah:
	xchg_idx_disp16_reg8h r4 r10
xchg_sidisp16_ch:
	xchg_idx_disp16_reg8h r5 r10
xchg_sidisp16_dh:
	xchg_idx_disp16_reg8h r6 r10
xchg_sidisp16_bh:
	xchg_idx_disp16_reg8h r7 r10

xchg_didisp16_al:
	xchg_idx_disp16_reg8l r4 r11
xchg_didisp16_cl:
	xchg_idx_disp16_reg8l r5 r11
xchg_didisp16_dl:
	xchg_idx_disp16_reg8l r6 r11
xchg_didisp16_bl:
	xchg_idx_disp16_reg8l r7 r11
xchg_didisp16_ah:
	xchg_idx_disp16_reg8h r4 r11
xchg_didisp16_ch:
	xchg_idx_disp16_reg8h r5 r11
xchg_didisp16_dh:
	xchg_idx_disp16_reg8h r6 r11
xchg_didisp16_bh:
	xchg_idx_disp16_reg8h r7 r11

xchg_bxdisp16_al:
	xchg_idx_disp16_reg8l r4 r7
xchg_bxdisp16_cl:
	xchg_idx_disp16_reg8l r5 r7
xchg_bxdisp16_dl:
	xchg_idx_disp16_reg8l r6 r7
xchg_bxdisp16_bl:
	xchg_idx_disp16_reg8l r7 r7
xchg_bxdisp16_ah:
	xchg_idx_disp16_reg8h r4 r7
xchg_bxdisp16_ch:
	xchg_idx_disp16_reg8h r5 r7
xchg_bxdisp16_dh:
	xchg_idx_disp16_reg8h r6 r7
xchg_bxdisp16_bh:
	xchg_idx_disp16_reg8h r7 r7

.macro xchg_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		xchg_r0_r8l_bp_\reg
.endm

.macro xchg_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		xchg_r0_r8h_bp_\reg
.endm

xchg_bpdisp16_al:
	xchg_bpdisp16_reg8l r4
xchg_bpdisp16_cl:
	xchg_bpdisp16_reg8l r5
xchg_bpdisp16_dl:
	xchg_bpdisp16_reg8l r6
xchg_bpdisp16_bl:
	xchg_bpdisp16_reg8l r7
xchg_bpdisp16_ah:
	xchg_bpdisp16_reg8h r4
xchg_bpdisp16_ch:
	xchg_bpdisp16_reg8h r5
xchg_bpdisp16_dh:
	xchg_bpdisp16_reg8h r6
xchg_bpdisp16_bh:
	xchg_bpdisp16_reg8h r7

// --- registers ---

.macro xchg_reg8l_reg8l reg1 reg2
#if defined(RPi) || defined(Roku)
	and		r0, \reg1, #0xFF
	and		r1, \reg2, #0xFF
	bic		\reg1, #0xFF
	bic		\reg2, #0xFF
	orr		\reg1, r1				// Old reg2 low byte to reg1 low byte
	orr		\reg2, r0				// Old reg1 low byte to reg2 low byte
#else
	ubfx	r0, \reg1, #0, #8
	bfi		\reg1, \reg2, #0, #8
	bfi		\reg2, r0, #0, #8
#endif
	b		loop
.endm

.macro xchg_reg8l_reg8h reg1 reg2
#if defined(RPi) || defined(Roku)
	and		r0, \reg1, #0xFF
	and		r1, \reg2, #0xFF00
	bic		\reg1, #0xFF
	bic		\reg2, #0xFF00
	orr		\reg1, r1, lsr #8		// Old regh hi byte to regl low byte
	orr		\reg2, r0, lsl #8		// Old regl low byte to regh hi byte
#else
	ubfx	r0, \reg2, #8, #8
	bfi		\reg2, \reg1, #8, #8
	bfi		\reg1, r0, #0, #8
#endif
	b		loop
.endm

.macro xchg_reg8h_reg8h reg1 reg2
#if defined(RPi) || defined(Roku)
	and		r0, \reg1, #0xFF00
	and		r1, \reg2, #0xFF00
	bic		\reg1, #0xFF00
	bic		\reg2, #0xFF00
	orr		\reg1, r1				// Old reg2 hi byte to reg1 hi byte
	orr		\reg2, r0				// Old reg1 hi byte to reg2 hi byte
#else
	ubfx	r0, \reg1, #8, #8
	ubfx	r1, \reg2, #8, #8
	bfi		\reg1, r1, #8, #8
	bfi		\reg2, r0, #8, #8
#endif
	b		loop
.endm

xchg_al_cl:
xchg_cl_al:
	xchg_reg8l_reg8l r4 r5
xchg_al_dl:
xchg_dl_al:
	xchg_reg8l_reg8l r4 r6
xchg_al_bl:
xchg_bl_al:
	xchg_reg8l_reg8l r4 r7
xchg_al_ah:
xchg_ah_al:
	xchg_reg8l_reg8h r4 r4
xchg_al_ch:
xchg_ch_al:
	xchg_reg8l_reg8h r4 r5
xchg_al_dh:
xchg_dh_al:
	xchg_reg8l_reg8h r4 r6
xchg_al_bh:
xchg_bh_al:
	xchg_reg8l_reg8h r4 r7

xchg_cl_dl:
xchg_dl_cl:
	xchg_reg8l_reg8l r5 r6
xchg_cl_bl:
xchg_bl_cl:
	xchg_reg8l_reg8l r5 r7
xchg_cl_ah:
xchg_ah_cl:
	xchg_reg8l_reg8h r5 r4
xchg_cl_ch:
xchg_ch_cl:
	xchg_reg8l_reg8h r5 r5
xchg_cl_dh:
xchg_dh_cl:
	xchg_reg8l_reg8h r5 r6
xchg_cl_bh:
xchg_bh_cl:
	xchg_reg8l_reg8h r5 r7

xchg_dl_bl:
xchg_bl_dl:
	xchg_reg8l_reg8l r6 r7
xchg_dl_ah:
xchg_ah_dl:
	xchg_reg8l_reg8h r6 r4
xchg_dl_ch:
xchg_ch_dl:
	xchg_reg8l_reg8h r6 r5
xchg_dl_dh:
xchg_dh_dl:
	xchg_reg8l_reg8h r6 r6
xchg_dl_bh:
xchg_bh_dl:
	xchg_reg8l_reg8h r6 r7

xchg_bl_ah:
xchg_ah_bl:
	xchg_reg8l_reg8h r7 r4
xchg_bl_ch:
xchg_ch_bl:
	xchg_reg8l_reg8h r7 r5
xchg_bl_dh:
xchg_dh_bl:
	xchg_reg8l_reg8h r7 r6
xchg_bl_bh:
xchg_bh_bl:
	xchg_reg8l_reg8h r7 r7

xchg_ah_ch:
xchg_ch_ah:
	xchg_reg8h_reg8h r4 r5
xchg_ah_dh:
xchg_dh_ah:
	xchg_reg8h_reg8h r4 r6
xchg_ah_bh:
xchg_bh_ah:
	xchg_reg8h_reg8h r4 r7

xchg_ch_dh:
xchg_dh_ch:
	xchg_reg8h_reg8h r5 r6
xchg_ch_bh:
xchg_bh_ch:
	xchg_reg8h_reg8h r5 r7

xchg_dh_bh:
xchg_bh_dh:
	xchg_reg8h_reg8h r6 r7

// ------------------- 87 = XCHG r16,r/m16 -----------------------------
//
// All modrm bytes supported!
//
op_87:
	modrm_jump_16
// 0
	.word xchg_bxsi_ax, xchg_bxdi_ax, xchg_bpsi_ax, xchg_bpdi_ax, xchg_siidx_ax, xchg_diidx_ax, xchg_disp16_ax, xchg_bxidx_ax
	.word xchg_bxsi_cx, xchg_bxdi_cx, xchg_bpsi_cx, xchg_bpdi_cx, xchg_siidx_cx, xchg_diidx_cx, xchg_disp16_cx, xchg_bxidx_cx
	.word xchg_bxsi_dx, xchg_bxdi_dx, xchg_bpsi_dx, xchg_bpdi_dx, xchg_siidx_dx, xchg_diidx_dx, xchg_disp16_dx, xchg_bxidx_dx
	.word xchg_bxsi_bx, xchg_bxdi_bx, xchg_bpsi_bx, xchg_bpdi_bx, xchg_siidx_bx, xchg_diidx_bx, xchg_disp16_bx, xchg_bxidx_bx
	.word xchg_bxsi_sp, xchg_bxdi_sp, xchg_bpsi_sp, xchg_bpdi_sp, xchg_siidx_sp, xchg_diidx_sp, xchg_disp16_sp, xchg_bxidx_sp
	.word xchg_bxsi_bp, xchg_bxdi_bp, xchg_bpsi_bp, xchg_bpdi_bp, xchg_siidx_bp, xchg_diidx_bp, xchg_disp16_bp, xchg_bxidx_bp
	.word xchg_bxsi_si, xchg_bxdi_si, xchg_bpsi_si, xchg_bpdi_si, xchg_siidx_si, xchg_diidx_si, xchg_disp16_si, xchg_bxidx_si
	.word xchg_bxsi_di, xchg_bxdi_di, xchg_bpsi_di, xchg_bpdi_di, xchg_siidx_di, xchg_diidx_di, xchg_disp16_di, xchg_bxidx_di
// 0x40
	.word xchg_bxsid8_ax, xchg_bxdid8_ax, xchg_bpsid8_ax, xchg_bpdid8_ax, xchg_sidisp8_ax, xchg_didisp8_ax, xchg_bpdisp8_ax, xchg_bxdisp8_ax
	.word xchg_bxsid8_cx, xchg_bxdid8_cx, xchg_bpsid8_cx, xchg_bpdid8_cx, xchg_sidisp8_cx, xchg_didisp8_cx, xchg_bpdisp8_cx, xchg_bxdisp8_cx
	.word xchg_bxsid8_dx, xchg_bxdid8_dx, xchg_bpsid8_dx, xchg_bpdid8_dx, xchg_sidisp8_dx, xchg_didisp8_dx, xchg_bpdisp8_dx, xchg_bxdisp8_dx
	.word xchg_bxsid8_bx, xchg_bxdid8_bx, xchg_bpsid8_bx, xchg_bpdid8_bx, xchg_sidisp8_bx, xchg_didisp8_bx, xchg_bpdisp8_bx, xchg_bxdisp8_bx
	.word xchg_bxsid8_sp, xchg_bxdid8_sp, xchg_bpsid8_sp, xchg_bpdid8_sp, xchg_sidisp8_sp, xchg_didisp8_sp, xchg_bpdisp8_sp, xchg_bxdisp8_sp
	.word xchg_bxsid8_bp, xchg_bxdid8_bp, xchg_bpsid8_bp, xchg_bpdid8_bp, xchg_sidisp8_bp, xchg_didisp8_bp, xchg_bpdisp8_bp, xchg_bxdisp8_bp
	.word xchg_bxsid8_si, xchg_bxdid8_si, xchg_bpsid8_si, xchg_bpdid8_si, xchg_sidisp8_si, xchg_didisp8_si, xchg_bpdisp8_si, xchg_bxdisp8_si
	.word xchg_bxsid8_di, xchg_bxdid8_di, xchg_bpsid8_di, xchg_bpdid8_di, xchg_sidisp8_di, xchg_didisp8_di, xchg_bpdisp8_di, xchg_bxdisp8_di
// 0x80
	.word xchg_bxsid16_ax, xchg_bxdid16_ax, xchg_bpsid16_ax, xchg_bpdid16_ax, xchg_sidisp16_ax, xchg_didisp16_ax, xchg_bpdisp16_ax, xchg_bxdisp16_ax
	.word xchg_bxsid16_cx, xchg_bxdid16_cx, xchg_bpsid16_cx, xchg_bpdid16_cx, xchg_sidisp16_cx, xchg_didisp16_cx, xchg_bpdisp16_cx, xchg_bxdisp16_cx
	.word xchg_bxsid16_dx, xchg_bxdid16_dx, xchg_bpsid16_dx, xchg_bpdid16_dx, xchg_sidisp16_dx, xchg_didisp16_dx, xchg_bpdisp16_dx, xchg_bxdisp16_dx
	.word xchg_bxsid16_bx, xchg_bxdid16_bx, xchg_bpsid16_bx, xchg_bpdid16_bx, xchg_sidisp16_bx, xchg_didisp16_bx, xchg_bpdisp16_bx, xchg_bxdisp16_bx
	.word xchg_bxsid16_sp, xchg_bxdid16_sp, xchg_bpsid16_sp, xchg_bpdid16_sp, xchg_sidisp16_sp, xchg_didisp16_sp, xchg_bpdisp16_sp, xchg_bxdisp16_sp
	.word xchg_bxsid16_bp, xchg_bxdid16_bp, xchg_bpsid16_bp, xchg_bpdid16_bp, xchg_sidisp16_bp, xchg_didisp16_bp, xchg_bpdisp16_bp, xchg_bxdisp16_bp
	.word xchg_bxsid16_si, xchg_bxdid16_si, xchg_bpsid16_si, xchg_bpdid16_si, xchg_sidisp16_si, xchg_didisp16_si, xchg_bpdisp16_si, xchg_bxdisp16_si
	.word xchg_bxsid16_di, xchg_bxdid16_di, xchg_bpsid16_di, xchg_bpdid16_di, xchg_sidisp16_di, xchg_didisp16_di, xchg_bpdisp16_di, xchg_bxdisp16_di
//0xc0 = mod = 11b => two register operands. We can skip operations like XCHG AX,AX
	.word loop, xchg_ax_cx, xchg_ax_dx, xchg_ax_bx, xchg_ax_sp, xchg_ax_bp, xchg_ax_si, xchg_ax_di
	.word xchg_ax_cx, loop, xchg_cx_dx, xchg_cx_bx, xchg_cx_sp, xchg_cx_bp, xchg_cx_si, xchg_cx_di
	.word xchg_ax_dx, xchg_cx_dx, loop, xchg_dx_bx, xchg_dx_sp, xchg_dx_bp, xchg_dx_si, xchg_dx_di
	.word xchg_ax_bx, xchg_cx_bx, xchg_dx_bx, loop, xchg_bx_sp, xchg_bx_bp, xchg_bx_si, xchg_bx_di
	.word xchg_ax_sp, xchg_cx_sp, xchg_dx_sp, xchg_bx_sp, loop, xchg_sp_bp, xchg_sp_si, xchg_sp_di
	.word xchg_ax_bp, xchg_cx_bp, xchg_dx_bp, xchg_bx_bp, xchg_sp_bp, loop, xchg_bp_si, xchg_bp_di
	.word xchg_ax_si, xchg_cx_si, xchg_dx_si, xchg_bx_si, xchg_sp_si, xchg_bp_si, loop, xchg_si_di
	.word xchg_ax_di, xchg_cx_di, xchg_dx_di, xchg_bx_di, xchg_sp_di, xchg_bp_di, xchg_si_di, loop

// These are called from "cpu_67.s":

	.global xchg_siidx_ax, xchg_diidx_ax, xchg_bxidx_ax
	.global xchg_siidx_cx, xchg_diidx_cx, xchg_bxidx_cx
	.global xchg_siidx_dx, xchg_diidx_dx, xchg_bxidx_dx
	.global xchg_siidx_bx, xchg_diidx_bx, xchg_bxidx_bx
	.global xchg_siidx_sp, xchg_diidx_sp, xchg_bxidx_sp
	.global xchg_siidx_bp, xchg_diidx_bp, xchg_bxidx_bp
	.global xchg_siidx_si, xchg_diidx_si, xchg_bxidx_si
	.global xchg_siidx_di, xchg_diidx_di, xchg_bxidx_di
	.global xchg_sidisp8_ax, xchg_didisp8_ax, xchg_bpdisp8_ax, xchg_bxdisp8_ax
	.global xchg_sidisp8_cx, xchg_didisp8_cx, xchg_bpdisp8_cx, xchg_bxdisp8_cx
	.global xchg_sidisp8_dx, xchg_didisp8_dx, xchg_bpdisp8_dx, xchg_bxdisp8_dx
	.global xchg_sidisp8_bx, xchg_didisp8_bx, xchg_bpdisp8_bx, xchg_bxdisp8_bx
	.global xchg_sidisp8_sp, xchg_didisp8_sp, xchg_bpdisp8_sp, xchg_bxdisp8_sp
	.global xchg_sidisp8_bp, xchg_didisp8_bp, xchg_bpdisp8_bp, xchg_bxdisp8_bp
	.global xchg_sidisp8_si, xchg_didisp8_si, xchg_bpdisp8_si, xchg_bxdisp8_si
	.global xchg_sidisp8_di, xchg_didisp8_di, xchg_bpdisp8_di, xchg_bxdisp8_di
	.global xchg_ax_ax, xchg_cx_ax, xchg_dx_ax, xchg_bx_ax, xchg_sp_ax, xchg_bp_ax, xchg_si_ax, xchg_di_ax
	.global xchg_ax_cx, xchg_cx_cx, xchg_dx_cx, xchg_bx_cx, xchg_sp_cx, xchg_bp_cx, xchg_si_cx, xchg_di_cx
	.global xchg_ax_dx, xchg_cx_dx, xchg_dx_dx, xchg_bx_dx, xchg_sp_dx, xchg_bp_dx, xchg_si_dx, xchg_di_dx
	.global xchg_ax_bx, xchg_cx_bx, xchg_dx_bx, xchg_bx_bx, xchg_sp_bx, xchg_bp_bx, xchg_si_bx, xchg_di_bx
	.global xchg_ax_sp, xchg_cx_sp, xchg_dx_sp, xchg_bx_sp, xchg_sp_sp, xchg_bp_sp, xchg_si_sp, xchg_di_sp
	.global xchg_ax_bp, xchg_cx_bp, xchg_dx_bp, xchg_bx_bp, xchg_sp_bp, xchg_bp_bp, xchg_si_bp, xchg_di_bp
	.global xchg_ax_si, xchg_cx_si, xchg_dx_si, xchg_bx_si, xchg_sp_si, xchg_bp_si, xchg_si_si, xchg_di_si
	.global xchg_ax_di, xchg_cx_di, xchg_dx_di, xchg_bx_di, xchg_sp_di, xchg_bp_di, xchg_si_di, xchg_di_di
	.global	xchg_r0_r16_bp_r4, xchg_r0_r16_bp_r5, xchg_r0_r16_bp_r6, xchg_r0_r16_bp_r7, xchg_r0_r16_bp_r8, xchg_r0_r16_bp_r9, xchg_r0_r16_bp_r10, xchg_r0_r16_bp_r11, xchg_r0_r16_bp_r4
	.global	xchg_r0_r16_r4, xchg_r0_r16_r5, xchg_r0_r16_r6, xchg_r0_r16_r7, xchg_r0_r16_r8, xchg_r0_r16_r9, xchg_r0_r16_r10, xchg_r0_r16_r11, xchg_r0_r16_r4

.macro xchg_reg16_r0high reg
xchg_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
xchg_r0_r16_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_87_RAM_\reg op_87_EGA_\reg bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_87_RAM_\reg:
	ldrb	r0, [r2]
	strb	\reg, [r2]
	lsr		\reg, #8
	ldrb	r1, [r2, #1]
	strb	\reg, [r2, #1]
	lsr		\reg, #8							// Clear low 16 bits of register	
	orr		\reg, r0, \reg, lsl #16				// Set new lowest byte to register
	orr		\reg, r1, lsl #8					// Set new second byte to register
	b		loop
.endm

	xchg_reg16_r0high r4
	xchg_reg16_r0high r5
	xchg_reg16_r0high r6
	xchg_reg16_r0high r7
	xchg_reg16_r0high r8
	xchg_reg16_r0high r9
	xchg_reg16_r0high r10
	xchg_reg16_r0high r11

	.ltorg

// --- [idx] ----

.macro xchg_bxidx_reg16 idx reg
	add		r0, r7, \idx
	b		xchg_r0_r16_\reg
.endm

xchg_bxsi_ax:
	xchg_bxidx_reg16 r10 r4
xchg_bxsi_cx:
	xchg_bxidx_reg16 r10 r5
xchg_bxsi_dx:
	xchg_bxidx_reg16 r10 r6
xchg_bxsi_bx:
	xchg_bxidx_reg16 r10 r7
xchg_bxsi_sp:
	xchg_bxidx_reg16 r10 r8
xchg_bxsi_bp:
	xchg_bxidx_reg16 r10 r9
xchg_bxsi_si:
	xchg_bxidx_reg16 r10 r10
xchg_bxsi_di:
	xchg_bxidx_reg16 r10 r11

xchg_bxdi_ax:
	xchg_bxidx_reg16 r11 r4
xchg_bxdi_cx:
	xchg_bxidx_reg16 r11 r5
xchg_bxdi_dx:
	xchg_bxidx_reg16 r11 r6
xchg_bxdi_bx:
	xchg_bxidx_reg16 r11 r7
xchg_bxdi_sp:
	xchg_bxidx_reg16 r11 r8
xchg_bxdi_bp:
	xchg_bxidx_reg16 r11 r9
xchg_bxdi_si:
	xchg_bxidx_reg16 r11 r10
xchg_bxdi_di:
	xchg_bxidx_reg16 r11 r11

.macro xchg_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		xchg_r0_r16_bp_\reg
.endm

xchg_bpsi_ax:
	xchg_bpidx_reg16 r10 r4
xchg_bpsi_cx:
	xchg_bpidx_reg16 r10 r5
xchg_bpsi_dx:
	xchg_bpidx_reg16 r10 r6
xchg_bpsi_bx:
	xchg_bpidx_reg16 r10 r7
xchg_bpsi_sp:
	xchg_bpidx_reg16 r10 r8
xchg_bpsi_bp:
	xchg_bpidx_reg16 r10 r9
xchg_bpsi_si:
	xchg_bpidx_reg16 r10 r10
xchg_bpsi_di:
	xchg_bpidx_reg16 r10 r11

xchg_bpdi_ax:
	xchg_bpidx_reg16 r11 r4
xchg_bpdi_cx:
	xchg_bpidx_reg16 r11 r5
xchg_bpdi_dx:
	xchg_bpidx_reg16 r11 r6
xchg_bpdi_bx:
	xchg_bpidx_reg16 r11 r7
xchg_bpdi_sp:
	xchg_bpidx_reg16 r11 r8
xchg_bpdi_bp:
	xchg_bpidx_reg16 r11 r9
xchg_bpdi_si:
	xchg_bpidx_reg16 r11 r10
xchg_bpdi_di:
	xchg_bpidx_reg16 r11 r11

.macro xchg_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		xchg_r0_r16_\reg
.endm

xchg_siidx_ax:
	xchg_idx_reg16 r10 r4
xchg_siidx_cx:
	xchg_idx_reg16 r10 r5
xchg_siidx_dx:
	xchg_idx_reg16 r10 r6
xchg_siidx_bx:
	xchg_idx_reg16 r10 r7
xchg_siidx_sp:
	xchg_idx_reg16 r10 r8
xchg_siidx_bp:
	xchg_idx_reg16 r10 r9
xchg_siidx_si:
	xchg_idx_reg16 r10 r10
xchg_siidx_di:
	xchg_idx_reg16 r10 r11

xchg_diidx_ax:
	xchg_idx_reg16 r11 r4
xchg_diidx_cx:
	xchg_idx_reg16 r11 r5
xchg_diidx_dx:
	xchg_idx_reg16 r11 r6
xchg_diidx_bx:
	xchg_idx_reg16 r11 r7
xchg_diidx_sp:
	xchg_idx_reg16 r11 r8
xchg_diidx_bp:
	xchg_idx_reg16 r11 r9
xchg_diidx_si:
	xchg_idx_reg16 r11 r10
xchg_diidx_di:
	xchg_idx_reg16 r11 r11

xchg_bxidx_ax:
	xchg_idx_reg16 r7 r4
xchg_bxidx_cx:
	xchg_idx_reg16 r7 r5
xchg_bxidx_dx:
	xchg_idx_reg16 r7 r6
xchg_bxidx_bx:
	xchg_idx_reg16 r7 r7
xchg_bxidx_sp:
	xchg_idx_reg16 r7 r8
xchg_bxidx_bp:
	xchg_idx_reg16 r7 r9
xchg_bxidx_si:
	xchg_idx_reg16 r7 r10
xchg_bxidx_di:
	xchg_idx_reg16 r7 r11
	
.macro xchg_disp16_reg16 reg
	r0_from_disp16
	b		xchg_r0_r16_\reg
.endm

xchg_disp16_ax:
	xchg_disp16_reg16 r4
xchg_disp16_cx:
	xchg_disp16_reg16 r5
xchg_disp16_dx:
	xchg_disp16_reg16 r6
xchg_disp16_bx:
	xchg_disp16_reg16 r7
xchg_disp16_sp:
	xchg_disp16_reg16 r8
xchg_disp16_bp:
	xchg_disp16_reg16 r9
xchg_disp16_si:
	xchg_disp16_reg16 r10
xchg_disp16_di:
	xchg_disp16_reg16 r11

// --- [idx+disp8] ----

.macro xchg_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		xchg_r0_r16_\reg
.endm

xchg_bxsid8_ax:
	xchg_bxidxd8_reg16 r10 r4
xchg_bxsid8_cx:
	xchg_bxidxd8_reg16 r10 r5
xchg_bxsid8_dx:
	xchg_bxidxd8_reg16 r10 r6
xchg_bxsid8_bx:
	xchg_bxidxd8_reg16 r10 r7
xchg_bxsid8_sp:
	xchg_bxidxd8_reg16 r10 r8
xchg_bxsid8_bp:
	xchg_bxidxd8_reg16 r10 r9
xchg_bxsid8_si:
	xchg_bxidxd8_reg16 r10 r10
xchg_bxsid8_di:
	xchg_bxidxd8_reg16 r10 r11

xchg_bxdid8_ax:
	xchg_bxidxd8_reg16 r11 r4
xchg_bxdid8_cx:
	xchg_bxidxd8_reg16 r11 r5
xchg_bxdid8_dx:
	xchg_bxidxd8_reg16 r11 r6
xchg_bxdid8_bx:
	xchg_bxidxd8_reg16 r11 r7
xchg_bxdid8_sp:
	xchg_bxidxd8_reg16 r11 r8
xchg_bxdid8_bp:
	xchg_bxidxd8_reg16 r11 r9
xchg_bxdid8_si:
	xchg_bxidxd8_reg16 r11 r10
xchg_bxdid8_di:
	xchg_bxidxd8_reg16 r11 r11

.macro xchg_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		xchg_r0_r16_bp_\reg
.endm

xchg_bpsid8_ax:
	xchg_bpidxd8_reg16 r10 r4
xchg_bpsid8_cx:
	xchg_bpidxd8_reg16 r10 r5
xchg_bpsid8_dx:
	xchg_bpidxd8_reg16 r10 r6
xchg_bpsid8_bx:
	xchg_bpidxd8_reg16 r10 r7
xchg_bpsid8_sp:
	xchg_bpidxd8_reg16 r10 r8
xchg_bpsid8_bp:
	xchg_bpidxd8_reg16 r10 r9
xchg_bpsid8_si:
	xchg_bpidxd8_reg16 r10 r10
xchg_bpsid8_di:
	xchg_bpidxd8_reg16 r10 r11

xchg_bpdid8_ax:
	xchg_bpidxd8_reg16 r11 r4
xchg_bpdid8_cx:
	xchg_bpidxd8_reg16 r11 r5
xchg_bpdid8_dx:
	xchg_bpidxd8_reg16 r11 r6
xchg_bpdid8_bx:
	xchg_bpidxd8_reg16 r11 r7
xchg_bpdid8_sp:
	xchg_bpidxd8_reg16 r11 r8
xchg_bpdid8_bp:
	xchg_bpidxd8_reg16 r11 r9
xchg_bpdid8_si:
	xchg_bpidxd8_reg16 r11 r10
xchg_bpdid8_di:
	xchg_bpidxd8_reg16 r11 r11

.macro xchg_idxdisp8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		xchg_r0_r16_\reg
.endm

xchg_sidisp8_ax:
	xchg_idxdisp8_reg16 r10 r4
xchg_sidisp8_cx:
	xchg_idxdisp8_reg16 r10 r5
xchg_sidisp8_dx:
	xchg_idxdisp8_reg16 r10 r6
xchg_sidisp8_bx:
	xchg_idxdisp8_reg16 r10 r7
xchg_sidisp8_sp:
	xchg_idxdisp8_reg16 r10 r8
xchg_sidisp8_bp:
	xchg_idxdisp8_reg16 r10 r9
xchg_sidisp8_si:
	xchg_idxdisp8_reg16 r10 r10
xchg_sidisp8_di:
	xchg_idxdisp8_reg16 r10 r11

xchg_didisp8_ax:
	xchg_idxdisp8_reg16 r11 r4
xchg_didisp8_cx:
	xchg_idxdisp8_reg16 r11 r5
xchg_didisp8_dx:
	xchg_idxdisp8_reg16 r11 r6
xchg_didisp8_bx:
	xchg_idxdisp8_reg16 r11 r7
xchg_didisp8_sp:
	xchg_idxdisp8_reg16 r11 r8
xchg_didisp8_bp:
	xchg_idxdisp8_reg16 r11 r9
xchg_didisp8_si:
	xchg_idxdisp8_reg16 r11 r10
xchg_didisp8_di:
	xchg_idxdisp8_reg16 r11 r11

xchg_bxdisp8_ax:
	xchg_idxdisp8_reg16 r7 r4
xchg_bxdisp8_cx:
	xchg_idxdisp8_reg16 r7 r5
xchg_bxdisp8_dx:
	xchg_idxdisp8_reg16 r7 r6
xchg_bxdisp8_bx:
	xchg_idxdisp8_reg16 r7 r7
xchg_bxdisp8_sp:
	xchg_idxdisp8_reg16 r7 r8
xchg_bxdisp8_bp:
	xchg_idxdisp8_reg16 r7 r9
xchg_bxdisp8_si:
	xchg_idxdisp8_reg16 r7 r10
xchg_bxdisp8_di:
	xchg_idxdisp8_reg16 r7 r11
	
.macro xchg_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		xchg_r0_r16_bp_\reg
.endm
	
xchg_bpdisp8_ax:
	xchg_bpdisp8_reg16 r4
xchg_bpdisp8_cx:
	xchg_bpdisp8_reg16 r5
xchg_bpdisp8_dx:
	xchg_bpdisp8_reg16 r6
xchg_bpdisp8_bx:
	xchg_bpdisp8_reg16 r7
xchg_bpdisp8_sp:
	xchg_bpdisp8_reg16 r8
xchg_bpdisp8_bp:
	xchg_bpdisp8_reg16 r9
xchg_bpdisp8_si:
	xchg_bpdisp8_reg16 r10
xchg_bpdisp8_di:
	xchg_bpdisp8_reg16 r11

// --- [idx+disp16] ---

.macro xchg_bxidxd16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		xchg_r0_r16_\reg
.endm

xchg_bxsid16_ax:
	xchg_bxidxd16_reg16 r10 r4
xchg_bxsid16_cx:
	xchg_bxidxd16_reg16 r10 r5
xchg_bxsid16_dx:
	xchg_bxidxd16_reg16 r10 r6
xchg_bxsid16_bx:
	xchg_bxidxd16_reg16 r10 r7
xchg_bxsid16_sp:
	xchg_bxidxd16_reg16 r10 r8
xchg_bxsid16_bp:
	xchg_bxidxd16_reg16 r10 r9
xchg_bxsid16_si:
	xchg_bxidxd16_reg16 r10 r10
xchg_bxsid16_di:
	xchg_bxidxd16_reg16 r10 r11

xchg_bxdid16_ax:
	xchg_bxidxd16_reg16 r11 r4
xchg_bxdid16_cx:
	xchg_bxidxd16_reg16 r11 r5
xchg_bxdid16_dx:
	xchg_bxidxd16_reg16 r11 r6
xchg_bxdid16_bx:
	xchg_bxidxd16_reg16 r11 r7
xchg_bxdid16_sp:
	xchg_bxidxd16_reg16 r11 r8
xchg_bxdid16_bp:
	xchg_bxidxd16_reg16 r11 r9
xchg_bxdid16_si:
	xchg_bxidxd16_reg16 r11 r10
xchg_bxdid16_di:
	xchg_bxidxd16_reg16 r11 r11

.macro xchg_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		xchg_r0_r16_bp_\reg
.endm

xchg_bpsid16_ax:
	xchg_bpidxd16_reg16 r10 r4
xchg_bpsid16_cx:
	xchg_bpidxd16_reg16 r10 r5
xchg_bpsid16_dx:
	xchg_bpidxd16_reg16 r10 r6
xchg_bpsid16_bx:
	xchg_bpidxd16_reg16 r10 r7
xchg_bpsid16_sp:
	xchg_bpidxd16_reg16 r10 r8
xchg_bpsid16_bp:
	xchg_bpidxd16_reg16 r10 r9
xchg_bpsid16_si:
	xchg_bpidxd16_reg16 r10 r10
xchg_bpsid16_di:
	xchg_bpidxd16_reg16 r10 r11

xchg_bpdid16_ax:
	xchg_bpidxd16_reg16 r11 r4
xchg_bpdid16_cx:
	xchg_bpidxd16_reg16 r11 r5
xchg_bpdid16_dx:
	xchg_bpidxd16_reg16 r11 r6
xchg_bpdid16_bx:
	xchg_bpidxd16_reg16 r11 r7
xchg_bpdid16_sp:
	xchg_bpidxd16_reg16 r11 r8
xchg_bpdid16_bp:
	xchg_bpidxd16_reg16 r11 r9
xchg_bpdid16_si:
	xchg_bpidxd16_reg16 r11 r10
xchg_bpdid16_di:
	xchg_bpidxd16_reg16 r11 r11

.macro xchg_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		xchg_r0_r16_\reg
.endm

xchg_sidisp16_ax:
	xchg_idxdisp16_reg16 r10 r4
xchg_sidisp16_cx:
	xchg_idxdisp16_reg16 r10 r5
xchg_sidisp16_dx:
	xchg_idxdisp16_reg16 r10 r6
xchg_sidisp16_bx:
	xchg_idxdisp16_reg16 r10 r7
xchg_sidisp16_sp:
	xchg_idxdisp16_reg16 r10 r8
xchg_sidisp16_bp:
	xchg_idxdisp16_reg16 r10 r9
xchg_sidisp16_si:
	xchg_idxdisp16_reg16 r10 r10
xchg_sidisp16_di:
	xchg_idxdisp16_reg16 r10 r11

xchg_didisp16_ax:
	xchg_idxdisp16_reg16 r11 r4
xchg_didisp16_cx:
	xchg_idxdisp16_reg16 r11 r5
xchg_didisp16_dx:
	xchg_idxdisp16_reg16 r11 r6
xchg_didisp16_bx:
	xchg_idxdisp16_reg16 r11 r7
xchg_didisp16_sp:
	xchg_idxdisp16_reg16 r11 r8
xchg_didisp16_bp:
	xchg_idxdisp16_reg16 r11 r9
xchg_didisp16_si:
	xchg_idxdisp16_reg16 r11 r10
xchg_didisp16_di:
	xchg_idxdisp16_reg16 r11 r11

xchg_bxdisp16_ax:
	xchg_idxdisp16_reg16 r7 r4
xchg_bxdisp16_cx:
	xchg_idxdisp16_reg16 r7 r5
xchg_bxdisp16_dx:
	xchg_idxdisp16_reg16 r7 r6
xchg_bxdisp16_bx:
	xchg_idxdisp16_reg16 r7 r7
xchg_bxdisp16_sp:
	xchg_idxdisp16_reg16 r7 r8
xchg_bxdisp16_bp:
	xchg_idxdisp16_reg16 r7 r9
xchg_bxdisp16_si:
	xchg_idxdisp16_reg16 r7 r10
xchg_bxdisp16_di:
	xchg_idxdisp16_reg16 r7 r11

.macro xchg_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		xchg_r0_r16_bp_\reg
.endm

xchg_bpdisp16_ax:
	xchg_bpdisp16_reg16 r4
xchg_bpdisp16_cx:
	xchg_bpdisp16_reg16 r5
xchg_bpdisp16_dx:
	xchg_bpdisp16_reg16 r6
xchg_bpdisp16_bx:
	xchg_bpdisp16_reg16 r7
xchg_bpdisp16_sp:
	xchg_bpdisp16_reg16 r8
xchg_bpdisp16_bp:
	xchg_bpdisp16_reg16 r9
xchg_bpdisp16_si:
	xchg_bpdisp16_reg16 r10
xchg_bpdisp16_di:
	xchg_bpdisp16_reg16 r11


// --- registers ---
	
.macro xchg_reg16_reg16 rl rr
#if defined(RPi) || defined(Roku)
	mov		r0, \rl, lsl #16
	mov		r1, \rr, lsl #16
	orr		\rl, r1, \rl, lsr #16
	orr		\rr, r0, \rr, lsr #16
	ror		\rl, #16
	ror		\rr, #16
#else
	ubfx	r0, \rl, #0, #16
	bfi		\rl, \rr, #0, #16
	bfi		\rr, r0, #0, #16
#endif
	b		loop
.endm
	
xchg_ax_cx:
xchg_cx_ax:
	xchg_reg16_reg16 eax ecx
xchg_dx_ax:
xchg_ax_dx:
	xchg_reg16_reg16 eax edx
xchg_bx_ax:
xchg_ax_bx:
	xchg_reg16_reg16 eax ebx
xchg_sp_ax:
xchg_ax_sp:
	xchg_reg16_reg16 eax esp
xchg_bp_ax:
xchg_ax_bp:
	xchg_reg16_reg16 eax ebp
xchg_si_ax:
xchg_ax_si:
	xchg_reg16_reg16 eax esi
xchg_di_ax:
xchg_ax_di:
	xchg_reg16_reg16 eax edi
xchg_dx_cx:
xchg_cx_dx:
	xchg_reg16_reg16 ecx edx
xchg_bx_cx:
xchg_cx_bx:
	xchg_reg16_reg16 ecx ebx
xchg_sp_cx:
xchg_cx_sp:
	xchg_reg16_reg16 ecx esp
xchg_bp_cx:
xchg_cx_bp:
	xchg_reg16_reg16 ecx ebp
xchg_si_cx:
xchg_cx_si:
	xchg_reg16_reg16 ecx esi
xchg_di_cx:
xchg_cx_di:
	xchg_reg16_reg16 ecx edi
xchg_bx_dx:
xchg_dx_bx:
	xchg_reg16_reg16 edx ebx
xchg_sp_dx:
xchg_dx_sp:
	xchg_reg16_reg16 edx esp
xchg_bp_dx:
xchg_dx_bp:
	xchg_reg16_reg16 edx ebp
xchg_si_dx:
xchg_dx_si:
	xchg_reg16_reg16 edx esi
xchg_di_dx:
xchg_dx_di:
	xchg_reg16_reg16 edx edi
xchg_sp_bx:
xchg_bx_sp:
	xchg_reg16_reg16 ebx esp
xchg_bp_bx:
xchg_bx_bp:
	xchg_reg16_reg16 ebx ebp
xchg_si_bx:
xchg_bx_si:
	xchg_reg16_reg16 ebx esi
xchg_di_bx:
xchg_bx_di:
	xchg_reg16_reg16 ebx edi
xchg_bp_sp:
xchg_sp_bp:
	xchg_reg16_reg16 ebp esp
xchg_si_bp:
xchg_bp_si:
	xchg_reg16_reg16 ebp esi
xchg_di_bp:
xchg_bp_di:
	xchg_reg16_reg16 ebp edi
xchg_si_sp:
xchg_sp_si:
	xchg_reg16_reg16 esi esp
xchg_di_si:
xchg_si_di:
	xchg_reg16_reg16 esi edi
xchg_di_sp:
xchg_sp_di:
	xchg_reg16_reg16 edi esp


// ------------------- 88 = MOV r/m8,r8 -------------------------------
//
// All modrm bytes supported!
//
//
	.global	op_88
op_88:
	modrm_jump_16
// 0
	.word mov_bxsi_al, mov_bxdi_al, mov_bpsi_al, mov_bpdi_al, mov_siidx_al, mov_diidx_al, mov_disp16_al, mov_bxidx_al
	.word mov_bxsi_cl, mov_bxdi_cl, mov_bpsi_cl, mov_bpdi_cl, mov_siidx_cl, mov_diidx_cl, mov_disp16_cl, mov_bxidx_cl
	.word mov_bxsi_dl, mov_bxdi_dl, mov_bpsi_dl, mov_bpdi_dl, mov_siidx_dl, mov_diidx_dl, mov_disp16_dl, mov_bxidx_dl
	.word mov_bxsi_bl, mov_bxdi_bl, mov_bpsi_bl, mov_bpdi_bl, mov_siidx_bl, mov_diidx_bl, mov_disp16_bl, mov_bxidx_bl
	.word mov_bxsi_ah, mov_bxdi_ah, mov_bpsi_ah, mov_bpdi_ah, mov_siidx_ah, mov_diidx_ah, mov_disp16_ah, mov_bxidx_ah
	.word mov_bxsi_ch, mov_bxdi_ch, mov_bpsi_ch, mov_bpdi_ch, mov_siidx_ch, mov_diidx_ch, mov_disp16_ch, mov_bxidx_ch
	.word mov_bxsi_dh, mov_bxdi_dh, mov_bpsi_dh, mov_bpdi_dh, mov_siidx_dh, mov_diidx_dh, mov_disp16_dh, mov_bxidx_dh
	.word mov_bxsi_bh, mov_bxdi_bh, mov_bpsi_bh, mov_bpdi_bh, mov_siidx_bh, mov_diidx_bh, mov_disp16_bh, mov_bxidx_bh
//0x40
	.word mov_bxsidisp8_al, mov_bxdidisp8_al, mov_bpsidisp8_al, mov_bpdidisp8_al, mov_sidisp8_al, mov_didisp8_al, mov_bpdisp8_al, mov_bxdisp8_al
	.word mov_bxsidisp8_cl, mov_bxdidisp8_cl, mov_bpsidisp8_cl, mov_bpdidisp8_cl, mov_sidisp8_cl, mov_didisp8_cl, mov_bpdisp8_cl, mov_bxdisp8_cl
	.word mov_bxsidisp8_dl, mov_bxdidisp8_dl, mov_bpsidisp8_dl, mov_bpdidisp8_dl, mov_sidisp8_dl, mov_didisp8_dl, mov_bpdisp8_dl, mov_bxdisp8_dl
	.word mov_bxsidisp8_bl, mov_bxdidisp8_bl, mov_bpsidisp8_bl, mov_bpdidisp8_bl, mov_sidisp8_bl, mov_didisp8_bl, mov_bpdisp8_bl, mov_bxdisp8_bl
	.word mov_bxsidisp8_ah, mov_bxdidisp8_ah, mov_bpsidisp8_ah, mov_bpdidisp8_ah, mov_sidisp8_ah, mov_didisp8_ah, mov_bpdisp8_ah, mov_bxdisp8_ah
	.word mov_bxsidisp8_ch, mov_bxdidisp8_ch, mov_bpsidisp8_ch, mov_bpdidisp8_ch, mov_sidisp8_ch, mov_didisp8_ch, mov_bpdisp8_ch, mov_bxdisp8_ch
	.word mov_bxsidisp8_dh, mov_bxdidisp8_dh, mov_bpsidisp8_dh, mov_bpdidisp8_dh, mov_sidisp8_dh, mov_didisp8_dh, mov_bpdisp8_dh, mov_bxdisp8_dh
	.word mov_bxsidisp8_bh, mov_bxdidisp8_bh, mov_bpsidisp8_bh, mov_bpdidisp8_bh, mov_sidisp8_bh, mov_didisp8_bh, mov_bpdisp8_bh, mov_bxdisp8_bh
//0x80 = mod = 10b => [idx+disp16]
	.word mov_bxsidisp16_al, mov_bxdidisp16_al, mov_bpsidisp16_al, mov_bpdidisp16_al, mov_sidisp16_al, mov_didisp16_al, mov_bpdisp16_al, mov_bxdisp16_al
	.word mov_bxsidisp16_cl, mov_bxdidisp16_cl, mov_bpsidisp16_cl, mov_bpdidisp16_cl, mov_sidisp16_cl, mov_didisp16_cl, mov_bpdisp16_cl, mov_bxdisp16_cl
	.word mov_bxsidisp16_dl, mov_bxdidisp16_dl, mov_bpsidisp16_dl, mov_bpdidisp16_dl, mov_sidisp16_dl, mov_didisp16_dl, mov_bpdisp16_dl, mov_bxdisp16_dl
	.word mov_bxsidisp16_bl, mov_bxdidisp16_bl, mov_bpsidisp16_bl, mov_bpdidisp16_bl, mov_sidisp16_bl, mov_didisp16_bl, mov_bpdisp16_bl, mov_bxdisp16_bl
	.word mov_bxsidisp16_ah, mov_bxdidisp16_ah, mov_bpsidisp16_ah, mov_bpdidisp16_ah, mov_sidisp16_ah, mov_didisp16_ah, mov_bpdisp16_ah, mov_bxdisp16_ah
	.word mov_bxsidisp16_ch, mov_bxdidisp16_ch, mov_bpsidisp16_ch, mov_bpdidisp16_ch, mov_sidisp16_ch, mov_didisp16_ch, mov_bpdisp16_ch, mov_bxdisp16_ch
	.word mov_bxsidisp16_dh, mov_bxdidisp16_dh, mov_bpsidisp16_dh, mov_bpdidisp16_dh, mov_sidisp16_dh, mov_didisp16_dh, mov_bpdisp16_dh, mov_bxdisp16_dh
	.word mov_bxsidisp16_bh, mov_bxdidisp16_bh, mov_bpsidisp16_bh, mov_bpdidisp16_bh, mov_sidisp16_bh, mov_didisp16_bh, mov_bpdisp16_bh, mov_bxdisp16_bh
//0xc0 = mod = 11b => two register operands
	.word loop, mov_cl_al, mov_dl_al, mov_bl_al, mov_ah_al, mov_ch_al, mov_dh_al, mov_bh_al
	.word mov_al_cl, loop, mov_dl_cl, mov_bl_cl, mov_ah_cl, mov_ch_cl, mov_dh_cl, mov_bh_cl
	.word mov_al_dl, mov_cl_dl, loop, mov_bl_dl, mov_ah_dl, mov_ch_dl, mov_dh_dl, mov_bh_dl
	.word mov_al_bl, mov_cl_bl, mov_dl_bl, loop, mov_ah_bl, mov_ch_bl, mov_dh_bl, mov_bh_bl
	.word mov_al_ah, mov_cl_ah, mov_dl_ah, mov_bl_ah, loop, mov_ch_ah, mov_dh_ah, mov_bh_ah
	.word mov_al_ch, mov_cl_ch, mov_dl_ch, mov_bl_ch, mov_ah_ch, loop, mov_dh_ch, mov_bh_ch
	.word mov_al_dh, mov_cl_dh, mov_dl_dh, mov_bl_dh, mov_ah_dh, mov_ch_dh, loop, mov_bh_dh
	.word mov_al_bh, mov_cl_bh, mov_dl_bh, mov_bl_bh, mov_ah_bh, mov_ch_bh, mov_dh_bh, loop

	.global	mov_siidx_al, mov_siidx_cl, mov_siidx_dl, mov_siidx_bl, mov_siidx_ah, mov_siidx_ch, mov_siidx_dh, mov_siidx_bh
	.global	mov_diidx_al, mov_diidx_cl, mov_diidx_dl, mov_diidx_bl, mov_diidx_ah, mov_diidx_ch, mov_diidx_dh, mov_diidx_bh
	.global	mov_bxidx_al, mov_bxidx_cl, mov_bxidx_dl, mov_bxidx_bl, mov_bxidx_ah, mov_bxidx_ch, mov_bxidx_dh, mov_bxidx_bh
	.global	mov_sidisp8_al, mov_sidisp8_cl, mov_sidisp8_dl, mov_sidisp8_bl, mov_sidisp8_ah, mov_sidisp8_ch, mov_sidisp8_dh, mov_sidisp8_bh
	.global	mov_didisp8_al, mov_didisp8_cl, mov_didisp8_dl, mov_didisp8_bl, mov_didisp8_ah, mov_didisp8_ch, mov_didisp8_dh, mov_didisp8_bh
	.global	mov_bpdisp8_al, mov_bpdisp8_cl, mov_bpdisp8_dl, mov_bpdisp8_bl, mov_bpdisp8_ah, mov_bpdisp8_ch, mov_bpdisp8_dh, mov_bpdisp8_bh
	.global	mov_bxdisp8_al, mov_bxdisp8_cl, mov_bxdisp8_dl, mov_bxdisp8_bl, mov_bxdisp8_ah, mov_bxdisp8_ch, mov_bxdisp8_dh, mov_bxdisp8_bh
	.global mov_cl_al, mov_dl_al, mov_bl_al, mov_ah_al, mov_ch_al, mov_dh_al, mov_bh_al
	.global mov_al_cl, mov_dl_cl, mov_bl_cl, mov_ah_cl, mov_ch_cl, mov_dh_cl, mov_bh_cl
	.global mov_al_dl, mov_cl_dl, mov_bl_dl, mov_ah_dl, mov_ch_dl, mov_dh_dl, mov_bh_dl
	.global mov_al_bl, mov_cl_bl, mov_dl_bl, mov_ah_bl, mov_ch_bl, mov_dh_bl, mov_bh_bl
	.global mov_al_ah, mov_cl_ah, mov_dl_ah, mov_bl_ah, mov_ch_ah, mov_dh_ah, mov_bh_ah
	.global mov_al_ch, mov_cl_ch, mov_dl_ch, mov_bl_ch, mov_ah_ch, mov_dh_ch, mov_bh_ch
	.global mov_al_dh, mov_cl_dh, mov_dl_dh, mov_bl_dh, mov_ah_dh, mov_ch_dh, mov_bh_dh
	.global mov_al_bh, mov_cl_bh, mov_dl_bh, mov_bl_bh, mov_ah_bh, mov_ch_bh, mov_dh_bh


.macro mov_r0_r8l_reg reg
	.global	mov_r0_r8l_bp_\reg
mov_r0_r8l_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_r8l_\reg
mov_r0_r8l_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_88_RAM_l_\reg op_88_EGA_l_\reg op_88_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_88_RAM_l_\reg:
	strb	\reg,[r2]							// Store the value to [physical segment + (unsigned)(idx)]
	b		loop
.endm
.macro mov_r0_r8h_reg reg
	.global	mov_r0_r8h_bp_\reg
mov_r0_r8h_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_r8h_\reg
mov_r0_r8h_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_88_RAM_h_\reg op_88_EGA_h_\reg op_88_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_88_RAM_h_\reg:
	mov		r1, \reg, lsr #8		// Put high byte of register to low byte of r1
	strb	r1,[r2]					// Store the value to [physical segment + (unsigned)(idx)]
	b		loop
.endm

	mov_r0_r8l_reg r4
	mov_r0_r8l_reg r5
	mov_r0_r8l_reg r6
	mov_r0_r8l_reg r7
	mov_r0_r8h_reg r4
	mov_r0_r8h_reg r5
	mov_r0_r8h_reg r6
	mov_r0_r8h_reg r7

	.ltorg

// --- [idx] ---
//
.macro mov_bxsi_reg8l reg
	add		r0, r7, r10
	b		mov_r0_r8l_\reg
.endm
.macro mov_bxsi_reg8h reg
	add		r0, r7, r10
	b		mov_r0_r8h_\reg
.endm

mov_bxsi_al:
	mov_bxsi_reg8l r4
mov_bxsi_cl:
	mov_bxsi_reg8l r5
mov_bxsi_dl:
	mov_bxsi_reg8l r6
mov_bxsi_bl:
	mov_bxsi_reg8l r7
mov_bxsi_ah:
	mov_bxsi_reg8h r4
mov_bxsi_ch:
	mov_bxsi_reg8h r5
mov_bxsi_dh:
	mov_bxsi_reg8h r6
mov_bxsi_bh:
	mov_bxsi_reg8h r7

.macro mov_bxdi_reg8l reg
	add		r0, r7, r11
	b		mov_r0_r8l_\reg
.endm
.macro mov_bxdi_reg8h reg
	add		r0, r7, r11
	b		mov_r0_r8h_\reg
.endm

mov_bxdi_al:
	mov_bxdi_reg8l r4
mov_bxdi_cl:
	mov_bxdi_reg8l r5
mov_bxdi_dl:
	mov_bxdi_reg8l r6
mov_bxdi_bl:
	mov_bxdi_reg8l r7
mov_bxdi_ah:
	mov_bxdi_reg8h r4
mov_bxdi_ch:
	mov_bxdi_reg8h r5
mov_bxdi_dh:
	mov_bxdi_reg8h r6
mov_bxdi_bh:
	mov_bxdi_reg8h r7

.macro mov_bpidx_reg8l idx reg
	add		r0, r9, \idx
	b		mov_r0_r8l_bp_\reg
.endm
.macro mov_bpidx_reg8h idx reg
	add		r0, r9, \idx
	b		mov_r0_r8h_bp_\reg
.endm

mov_bpsi_al:
	mov_bpidx_reg8l r10 r4
mov_bpsi_cl:
	mov_bpidx_reg8l r10 r5
mov_bpsi_dl:
	mov_bpidx_reg8l r10 r6
mov_bpsi_bl:
	mov_bpidx_reg8l r10 r7
mov_bpsi_ah:
	mov_bpidx_reg8h r10 r4
mov_bpsi_ch:
	mov_bpidx_reg8h r10 r5
mov_bpsi_dh:
	mov_bpidx_reg8h r10 r6
mov_bpsi_bh:
	mov_bpidx_reg8h r10 r7

mov_bpdi_al:
	mov_bpidx_reg8l r11 r4
mov_bpdi_cl:
	mov_bpidx_reg8l r11 r5
mov_bpdi_dl:
	mov_bpidx_reg8l r11 r6
mov_bpdi_bl:
	mov_bpidx_reg8l r11 r7
mov_bpdi_ah:
	mov_bpidx_reg8h r11 r4
mov_bpdi_ch:
	mov_bpidx_reg8h r11 r5
mov_bpdi_dh:
	mov_bpidx_reg8h r11 r6
mov_bpdi_bh:
	mov_bpidx_reg8h r11 r7

.macro mov_idx_reg8l idx reg
	mov		r0, \idx
	b		mov_r0_r8l_\reg
.endm
.macro mov_idx_reg8h idx reg
	mov		r0, \idx
	b		mov_r0_r8h_\reg
.endm

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

mov_siidx_al:
	mov_idx_reg8l r10 r4
mov_siidx_cl:
	mov_idx_reg8l r10 r5
mov_siidx_dl:
	mov_idx_reg8l r10 r6
mov_siidx_bl:
	mov_idx_reg8l r10 r7

mov_siidx_ah:
	mov_idx_reg8h r10 r4
mov_siidx_ch:
	mov_idx_reg8h r10 r5
mov_siidx_dh:
	mov_idx_reg8h r10 r6
mov_siidx_bh:
	mov_idx_reg8h r10 r7

mov_diidx_al:
	mov_idx_reg8l r11 r4
mov_diidx_cl:
	mov_idx_reg8l r11 r5
mov_diidx_dl:
	mov_idx_reg8l r11 r6
mov_diidx_bl:
	mov_idx_reg8l r11 r7

mov_diidx_ah:
	mov_idx_reg8h r11 r4
mov_diidx_ch:
	mov_idx_reg8h r11 r5
mov_diidx_dh:
	mov_idx_reg8h r11 r6
mov_diidx_bh:
	mov_idx_reg8h r11 r7
	
mov_bxidx_al:
	mov_idx_reg8l r7 r4
mov_bxidx_cl:
	mov_idx_reg8l r7 r5
mov_bxidx_dl:
	mov_idx_reg8l r7 r6
mov_bxidx_bl:
	mov_idx_reg8l r7 r7

mov_bxidx_ah:
	mov_idx_reg8h r7 r4
mov_bxidx_ch:
	mov_idx_reg8h r7 r5
mov_bxidx_dh:
	mov_idx_reg8h r7 r6
mov_bxidx_bh:
	mov_idx_reg8h r7 r7

.macro mov_disp16_reg8l reg
	r0_from_disp16
	b		mov_r0_r8l_\reg
.endm

.macro mov_disp16_reg8h reg
	r0_from_disp16
	b		mov_r0_r8h_\reg
.endm

	.global	op_a2
op_a2:									// "mov [1234],al" == A2 34 12 == 88 06 34 12
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
mov_disp16_al:
	r0_from_disp16
	mem_handler_jump_r0r3 .op_88_RAM_l_r4 op_88_EGA_l_r4 op_88_MODEX_l_r4
mov_disp16_cl:
	mov_disp16_reg8l r5
mov_disp16_dl:
	mov_disp16_reg8l r6
mov_disp16_bl:
	mov_disp16_reg8l r7
mov_disp16_ah:
	mov_disp16_reg8h r4
mov_disp16_ch:
	mov_disp16_reg8h r5
mov_disp16_dh:
	mov_disp16_reg8h r6
mov_disp16_bh:
	mov_disp16_reg8h r7

	.text
	.align	2

// --- [idx + disp8] ---

.macro mov_bxidxdisp8_reg8l idx reg
	r0_from_bxidxdisp8 \idx
	b		mov_r0_r8l_\reg
.endm
.macro mov_bxidxdisp8_reg8h idx reg
	r0_from_bxidxdisp8 \idx
	b		mov_r0_r8h_\reg
.endm

mov_bxsidisp8_al:
	mov_bxidxdisp8_reg8l r10 r4
mov_bxsidisp8_cl:
	mov_bxidxdisp8_reg8l r10 r5
mov_bxsidisp8_dl:
	mov_bxidxdisp8_reg8l r10 r6
mov_bxsidisp8_bl:
	mov_bxidxdisp8_reg8l r10 r7
mov_bxsidisp8_ah:
	mov_bxidxdisp8_reg8h r10 r4
mov_bxsidisp8_ch:
	mov_bxidxdisp8_reg8h r10 r5
mov_bxsidisp8_dh:
	mov_bxidxdisp8_reg8h r10 r6
mov_bxsidisp8_bh:
	mov_bxidxdisp8_reg8h r10 r7

mov_bxdidisp8_al:
	mov_bxidxdisp8_reg8l r11 r4
mov_bxdidisp8_cl:
	mov_bxidxdisp8_reg8l r11 r5
mov_bxdidisp8_dl:
	mov_bxidxdisp8_reg8l r11 r6
mov_bxdidisp8_bl:
	mov_bxidxdisp8_reg8l r11 r7
mov_bxdidisp8_ah:
	mov_bxidxdisp8_reg8h r11 r4
mov_bxdidisp8_ch:
	mov_bxidxdisp8_reg8h r11 r5
mov_bxdidisp8_dh:
	mov_bxidxdisp8_reg8h r11 r6
mov_bxdidisp8_bh:
	mov_bxidxdisp8_reg8h r11 r7

.macro mov_bpidxdisp8_reg8l idx reg
	r0_from_bpidxdisp8 \idx
	b		mov_r0_r8l_bp_\reg
.endm
.macro mov_bpidxdisp8_reg8h idx reg
	r0_from_bpidxdisp8 \idx
	b		mov_r0_r8h_bp_\reg
.endm

mov_bpsidisp8_al:
	mov_bpidxdisp8_reg8l r10 r4
mov_bpsidisp8_cl:
	mov_bpidxdisp8_reg8l r10 r5
mov_bpsidisp8_dl:
	mov_bpidxdisp8_reg8l r10 r6
mov_bpsidisp8_bl:
	mov_bpidxdisp8_reg8l r10 r7

mov_bpsidisp8_ah:
	mov_bpidxdisp8_reg8h r10 r4
mov_bpsidisp8_ch:
	mov_bpidxdisp8_reg8h r10 r5
mov_bpsidisp8_dh:
	mov_bpidxdisp8_reg8h r10 r6
mov_bpsidisp8_bh:
	mov_bpidxdisp8_reg8h r10 r7

mov_bpdidisp8_al:
	mov_bpidxdisp8_reg8l r11 r4
mov_bpdidisp8_cl:
	mov_bpidxdisp8_reg8l r11 r5
mov_bpdidisp8_dl:
	mov_bpidxdisp8_reg8l r11 r6
mov_bpdidisp8_bl:
	mov_bpidxdisp8_reg8l r11 r7

mov_bpdidisp8_ah:
	mov_bpidxdisp8_reg8h r11 r4
mov_bpdidisp8_ch:
	mov_bpidxdisp8_reg8h r11 r5
mov_bpdidisp8_dh:
	mov_bpidxdisp8_reg8h r11 r6
mov_bpdidisp8_bh:
	mov_bpidxdisp8_reg8h r11 r7

.macro mov_idxdisp8_reg8l idx reg
	r0_from_idx_disp8 \idx
	b		mov_r0_r8l_\reg
.endm
.macro mov_idxdisp8_reg8h idx reg
	r0_from_idx_disp8 \idx
	b		mov_r0_r8h_\reg
.endm

mov_sidisp8_al:
	mov_idxdisp8_reg8l r10 r4
mov_sidisp8_cl:
	mov_idxdisp8_reg8l r10 r5
mov_sidisp8_dl:
	mov_idxdisp8_reg8l r10 r6
mov_sidisp8_bl:
	mov_idxdisp8_reg8l r10 r7

mov_sidisp8_ah:
	mov_idxdisp8_reg8h r10 r4
mov_sidisp8_ch:
	mov_idxdisp8_reg8h r10 r5
mov_sidisp8_dh:
	mov_idxdisp8_reg8h r10 r6
mov_sidisp8_bh:
	mov_idxdisp8_reg8h r10 r7

mov_didisp8_al:
	mov_idxdisp8_reg8l r11 r4
mov_didisp8_cl:
	mov_idxdisp8_reg8l r11 r5
mov_didisp8_dl:
	mov_idxdisp8_reg8l r11 r6
mov_didisp8_bl:
	mov_idxdisp8_reg8l r11 r7

mov_didisp8_ah:
	mov_idxdisp8_reg8h r11 r4
mov_didisp8_ch:
	mov_idxdisp8_reg8h r11 r5
mov_didisp8_dh:
	mov_idxdisp8_reg8h r11 r6
mov_didisp8_bh:
	mov_idxdisp8_reg8h r11 r7

mov_bxdisp8_al:
	mov_idxdisp8_reg8l r7 r4
mov_bxdisp8_cl:
	mov_idxdisp8_reg8l r7 r5
mov_bxdisp8_dl:
	mov_idxdisp8_reg8l r7 r6
mov_bxdisp8_bl:
	mov_idxdisp8_reg8l r7 r7

mov_bxdisp8_ah:
	mov_idxdisp8_reg8h r7 r4
mov_bxdisp8_ch:
	mov_idxdisp8_reg8h r7 r5
mov_bxdisp8_dh:
	mov_idxdisp8_reg8h r7 r6
mov_bxdisp8_bh:
	mov_idxdisp8_reg8h r7 r7

.macro mov_bpdisp8_reg8l reg
	r0_from_idx_disp8 r9
	b		mov_r0_r8l_bp_\reg
.endm
.macro mov_bpdisp8_reg8h reg
	r0_from_idx_disp8 r9
	b		mov_r0_r8h_bp_\reg
.endm

mov_bpdisp8_al:
	mov_bpdisp8_reg8l r4
mov_bpdisp8_cl:
	mov_bpdisp8_reg8l r5
mov_bpdisp8_dl:
	mov_bpdisp8_reg8l r6
mov_bpdisp8_bl:
	mov_bpdisp8_reg8l r7

mov_bpdisp8_ah:
	mov_bpdisp8_reg8h r4
mov_bpdisp8_ch:
	mov_bpdisp8_reg8h r5
mov_bpdisp8_dh:
	mov_bpdisp8_reg8h r6
mov_bpdisp8_bh:
	mov_bpdisp8_reg8h r7

// --- idx + disp16 ---

.macro mov_bxidxdisp16_reg8l reg idx
	r0_from_bxidxdisp16 \idx
	b		mov_r0_r8l_\reg
.endm
.macro mov_bxidxdisp16_reg8h reg idx
	r0_from_bxidxdisp16 \idx
	b		mov_r0_r8h_\reg
.endm

mov_bxsidisp16_al:
	mov_bxidxdisp16_reg8l r4 r10
mov_bxsidisp16_cl:
	mov_bxidxdisp16_reg8l r5 r10
mov_bxsidisp16_dl:
	mov_bxidxdisp16_reg8l r6 r10
mov_bxsidisp16_bl:
	mov_bxidxdisp16_reg8l r7 r10
mov_bxsidisp16_ah:
	mov_bxidxdisp16_reg8h r4 r10
mov_bxsidisp16_ch:
	mov_bxidxdisp16_reg8h r5 r10
mov_bxsidisp16_dh:
	mov_bxidxdisp16_reg8h r6 r10
mov_bxsidisp16_bh:
	mov_bxidxdisp16_reg8h r7 r10

mov_bxdidisp16_al:
	mov_bxidxdisp16_reg8l r4 r11
mov_bxdidisp16_cl:
	mov_bxidxdisp16_reg8l r5 r11
mov_bxdidisp16_dl:
	mov_bxidxdisp16_reg8l r6 r11
mov_bxdidisp16_bl:
	mov_bxidxdisp16_reg8l r7 r11
mov_bxdidisp16_ah:
	mov_bxidxdisp16_reg8h r4 r11
mov_bxdidisp16_ch:
	mov_bxidxdisp16_reg8h r5 r11
mov_bxdidisp16_dh:
	mov_bxidxdisp16_reg8h r6 r11
mov_bxdidisp16_bh:
	mov_bxidxdisp16_reg8h r7 r11

.macro mov_bpidxdisp16_reg8l reg idx
	r0_from_bpidxdisp16 \idx
	b		mov_r0_r8l_bp_\reg
.endm
.macro mov_bpidxdisp16_reg8h reg idx
	r0_from_bpidxdisp16 \idx
	b		mov_r0_r8h_bp_\reg
.endm

mov_bpsidisp16_al:
	mov_bpidxdisp16_reg8l r4 r10
mov_bpsidisp16_cl:
	mov_bpidxdisp16_reg8l r5 r10
mov_bpsidisp16_dl:
	mov_bpidxdisp16_reg8l r6 r10
mov_bpsidisp16_bl:
	mov_bpidxdisp16_reg8l r7 r10
mov_bpsidisp16_ah:
	mov_bpidxdisp16_reg8h r4 r10
mov_bpsidisp16_ch:
	mov_bpidxdisp16_reg8h r5 r10
mov_bpsidisp16_dh:
	mov_bpidxdisp16_reg8h r6 r10
mov_bpsidisp16_bh:
	mov_bpidxdisp16_reg8h r7 r10

mov_bpdidisp16_al:
	mov_bpidxdisp16_reg8l r4 r11
mov_bpdidisp16_cl:
	mov_bpidxdisp16_reg8l r5 r11
mov_bpdidisp16_dl:
	mov_bpidxdisp16_reg8l r6 r11
mov_bpdidisp16_bl:
	mov_bpidxdisp16_reg8l r7 r11
mov_bpdidisp16_ah:
	mov_bpidxdisp16_reg8h r4 r11
mov_bpdidisp16_ch:
	mov_bpidxdisp16_reg8h r5 r11
mov_bpdidisp16_dh:
	mov_bpidxdisp16_reg8h r6 r11
mov_bpdidisp16_bh:
	mov_bpidxdisp16_reg8h r7 r11

.macro mov_idx_disp16_reg8l reg idx
	r0_from_idx_disp16 \idx
	b		mov_r0_r8l_\reg
.endm

.macro mov_idx_disp16_reg8h reg idx
	r0_from_idx_disp16 \idx
	b		mov_r0_r8h_\reg
.endm

mov_sidisp16_al:
	mov_idx_disp16_reg8l r4 r10
mov_sidisp16_cl:
	mov_idx_disp16_reg8l r5 r10
mov_sidisp16_dl:
	mov_idx_disp16_reg8l r6 r10
mov_sidisp16_bl:
	mov_idx_disp16_reg8l r7 r10
mov_sidisp16_ah:
	mov_idx_disp16_reg8h r4 r10
mov_sidisp16_ch:
	mov_idx_disp16_reg8h r5 r10
mov_sidisp16_dh:
	mov_idx_disp16_reg8h r6 r10
mov_sidisp16_bh:
	mov_idx_disp16_reg8h r7 r10

mov_didisp16_al:
	mov_idx_disp16_reg8l r4 r11
mov_didisp16_cl:
	mov_idx_disp16_reg8l r5 r11
mov_didisp16_dl:
	mov_idx_disp16_reg8l r6 r11
mov_didisp16_bl:
	mov_idx_disp16_reg8l r7 r11
mov_didisp16_ah:
	mov_idx_disp16_reg8h r4 r11
mov_didisp16_ch:
	mov_idx_disp16_reg8h r5 r11
mov_didisp16_dh:
	mov_idx_disp16_reg8h r6 r11
mov_didisp16_bh:
	mov_idx_disp16_reg8h r7 r11

mov_bxdisp16_al:
	mov_idx_disp16_reg8l r4 r7
mov_bxdisp16_cl:
	mov_idx_disp16_reg8l r5 r7
mov_bxdisp16_dl:
	mov_idx_disp16_reg8l r6 r7
mov_bxdisp16_bl:
	mov_idx_disp16_reg8l r7 r7
mov_bxdisp16_ah:
	mov_idx_disp16_reg8h r4 r7
mov_bxdisp16_ch:
	mov_idx_disp16_reg8h r5 r7
mov_bxdisp16_dh:
	mov_idx_disp16_reg8h r6 r7
mov_bxdisp16_bh:
	mov_idx_disp16_reg8h r7 r7

.macro mov_bpdisp16_reg8l reg
	r0_from_idx_disp16 r9
	b		mov_r0_r8l_bp_\reg
.endm

.macro mov_bpdisp16_reg8h reg
	r0_from_idx_disp16 r9
	b		mov_r0_r8h_bp_\reg
.endm

mov_bpdisp16_al:
	mov_bpdisp16_reg8l r4
mov_bpdisp16_cl:
	mov_bpdisp16_reg8l r5
mov_bpdisp16_dl:
	mov_bpdisp16_reg8l r6
mov_bpdisp16_bl:
	mov_bpdisp16_reg8l r7
mov_bpdisp16_ah:
	mov_bpdisp16_reg8h r4
mov_bpdisp16_ch:
	mov_bpdisp16_reg8h r5
mov_bpdisp16_dh:
	mov_bpdisp16_reg8h r6
mov_bpdisp16_bh:
	mov_bpdisp16_reg8h r7

// ------------------- 89 = MOV r/m16,r16 ------------------------------
// 
// All modrm variations supported!
//
//
	.global	op_89
op_89:
	modrm_jump_16
// 0
	.word mov_bxsi_ax, mov_bxdi_ax, mov_bpsi_ax, mov_bpdi_ax, mov_siidx_ax, mov_diidx_ax, mov_disp16_ax, mov_bxidx_ax
	.word mov_bxsi_cx, mov_bxdi_cx, mov_bpsi_cx, mov_bpdi_cx, mov_siidx_cx, mov_diidx_cx, mov_disp16_cx, mov_bxidx_cx
	.word mov_bxsi_dx, mov_bxdi_dx, mov_bpsi_dx, mov_bpdi_dx, mov_siidx_dx, mov_diidx_dx, mov_disp16_dx, mov_bxidx_dx
	.word mov_bxsi_bx, mov_bxdi_bx, mov_bpsi_bx, mov_bpdi_bx, mov_siidx_bx, mov_diidx_bx, mov_disp16_bx, mov_bxidx_bx
	.word mov_bxsi_sp, mov_bxdi_sp, mov_bpsi_sp, mov_bpdi_sp, mov_siidx_sp, mov_diidx_sp, mov_disp16_sp, mov_bxidx_sp
	.word mov_bxsi_bp, mov_bxdi_bp, mov_bpsi_bp, mov_bpdi_bp, mov_siidx_bp, mov_diidx_bp, mov_disp16_bp, mov_bxidx_bp
	.word mov_bxsi_si, mov_bxdi_si, mov_bpsi_si, mov_bpdi_si, mov_siidx_si, mov_diidx_si, mov_disp16_si, mov_bxidx_si
	.word mov_bxsi_di, mov_bxdi_di, mov_bpsi_di, mov_bpdi_di, mov_siidx_di, mov_diidx_di, mov_disp16_di, mov_bxidx_di
//0x40 (+disp8)
	.word mov_bxsid8_ax, mov_bxdid8_ax, mov_bpsid8_ax, mov_bpdid8_ax, mov_sidisp8_ax, mov_didisp8_ax, mov_bpdisp8_ax, mov_bxdisp8_ax
	.word mov_bxsid8_cx, mov_bxdid8_cx, mov_bpsid8_cx, mov_bpdid8_cx, mov_sidisp8_cx, mov_didisp8_cx, mov_bpdisp8_cx, mov_bxdisp8_cx
	.word mov_bxsid8_dx, mov_bxdid8_dx, mov_bpsid8_dx, mov_bpdid8_dx, mov_sidisp8_dx, mov_didisp8_dx, mov_bpdisp8_dx, mov_bxdisp8_dx
	.word mov_bxsid8_bx, mov_bxdid8_bx, mov_bpsid8_bx, mov_bpdid8_bx, mov_sidisp8_bx, mov_didisp8_bx, mov_bpdisp8_bx, mov_bxdisp8_bx
	.word mov_bxsid8_sp, mov_bxdid8_sp, mov_bpsid8_sp, mov_bpdid8_sp, mov_sidisp8_sp, mov_didisp8_sp, mov_bpdisp8_sp, mov_bxdisp8_sp
	.word mov_bxsid8_bp, mov_bxdid8_bp, mov_bpsid8_bp, mov_bpdid8_bp, mov_sidisp8_bp, mov_didisp8_bp, mov_bpdisp8_bp, mov_bxdisp8_bp
	.word mov_bxsid8_si, mov_bxdid8_si, mov_bpsid8_si, mov_bpdid8_si, mov_sidisp8_si, mov_didisp8_si, mov_bpdisp8_si, mov_bxdisp8_si
	.word mov_bxsid8_di, mov_bxdid8_di, mov_bpsid8_di, mov_bpdid8_di, mov_sidisp8_di, mov_didisp8_di, mov_bpdisp8_di, mov_bxdisp8_di
//0x80
	.word mov_bxsid16_ax, mov_bxdid16_ax, mov_bpsid16_ax, mov_bpdid16_ax, mov_sidisp16_ax, mov_didisp16_ax, mov_bpdisp16_ax, mov_bxdisp16_ax
	.word mov_bxsid16_cx, mov_bxdid16_cx, mov_bpsid16_cx, mov_bpdid16_cx, mov_sidisp16_cx, mov_didisp16_cx, mov_bpdisp16_cx, mov_bxdisp16_cx
	.word mov_bxsid16_dx, mov_bxdid16_dx, mov_bpsid16_dx, mov_bpdid16_dx, mov_sidisp16_dx, mov_didisp16_dx, mov_bpdisp16_dx, mov_bxdisp16_dx
	.word mov_bxsid16_bx, mov_bxdid16_bx, mov_bpsid16_bx, mov_bpdid16_bx, mov_sidisp16_bx, mov_didisp16_bx, mov_bpdisp16_bx, mov_bxdisp16_bx
	.word mov_bxsid16_sp, mov_bxdid16_sp, mov_bpsid16_sp, mov_bpdid16_sp, mov_sidisp16_sp, mov_didisp16_sp, mov_bpdisp16_sp, mov_bxdisp16_sp
	.word mov_bxsid16_bp, mov_bxdid16_bp, mov_bpsid16_bp, mov_bpdid16_bp, mov_sidisp16_bp, mov_didisp16_bp, mov_bpdisp16_bp, mov_bxdisp16_bp
	.word mov_bxsid16_si, mov_bxdid16_si, mov_bpsid16_si, mov_bpdid16_si, mov_sidisp16_si, mov_didisp16_si, mov_bpdisp16_si, mov_bxdisp16_si
	.word mov_bxsid16_di, mov_bxdid16_di, mov_bpsid16_di, mov_bpdid16_di, mov_sidisp16_di, mov_didisp16_di, mov_bpdisp16_di, mov_bxdisp16_di
//0xc0 = mod = 11b => two register operands
	.word loop, mov_cx_ax, mov_dx_ax, mov_bx_ax, mov_sp_ax, mov_bp_ax, mov_si_ax, mov_di_ax
	.word mov_ax_cx, loop, mov_dx_cx, mov_bx_cx, mov_sp_cx, mov_bp_cx, mov_si_cx, mov_di_cx
	.word mov_ax_dx, mov_cx_dx, loop, mov_bx_dx, mov_sp_dx, mov_bp_dx, mov_si_dx, mov_di_dx
	.word mov_ax_bx, mov_cx_bx, mov_dx_bx, loop, mov_sp_bx, mov_bp_bx, mov_si_bx, mov_di_bx
	.word mov_ax_sp, mov_cx_sp, mov_dx_sp, mov_bx_sp, loop, mov_bp_sp, mov_si_sp, mov_di_sp
	.word mov_ax_bp, mov_cx_bp, mov_dx_bp, mov_bx_bp, mov_sp_bp, loop, mov_si_bp, mov_di_bp
	.word mov_ax_si, mov_cx_si, mov_dx_si, mov_bx_si, mov_sp_si, mov_bp_si, loop, mov_di_si
	.word mov_ax_di, mov_cx_di, mov_dx_di, mov_bx_di, mov_sp_di, mov_bp_di, mov_si_di, loop

// These are called from "cpu_67.s":

	.global mov_siidx_ax, mov_diidx_ax, mov_bxidx_ax
	.global mov_siidx_cx, mov_diidx_cx, mov_bxidx_cx
	.global mov_siidx_dx, mov_diidx_dx, mov_bxidx_dx
	.global mov_siidx_bx, mov_diidx_bx, mov_bxidx_bx
	.global mov_siidx_sp, mov_diidx_sp, mov_bxidx_sp
	.global mov_siidx_bp, mov_diidx_bp, mov_bxidx_bp
	.global mov_siidx_si, mov_diidx_si, mov_bxidx_si
	.global mov_siidx_di, mov_diidx_di, mov_bxidx_di
	.global mov_sidisp8_ax, mov_didisp8_ax, mov_bpdisp8_ax, mov_bxdisp8_ax
	.global mov_sidisp8_cx, mov_didisp8_cx, mov_bpdisp8_cx, mov_bxdisp8_cx
	.global mov_sidisp8_dx, mov_didisp8_dx, mov_bpdisp8_dx, mov_bxdisp8_dx
	.global mov_sidisp8_bx, mov_didisp8_bx, mov_bpdisp8_bx, mov_bxdisp8_bx
	.global mov_sidisp8_sp, mov_didisp8_sp, mov_bpdisp8_sp, mov_bxdisp8_sp
	.global mov_sidisp8_bp, mov_didisp8_bp, mov_bpdisp8_bp, mov_bxdisp8_bp
	.global mov_sidisp8_si, mov_didisp8_si, mov_bpdisp8_si, mov_bxdisp8_si
	.global mov_sidisp8_di, mov_didisp8_di, mov_bpdisp8_di, mov_bxdisp8_di
	.global mov_ax_ax, mov_cx_ax, mov_dx_ax, mov_bx_ax, mov_sp_ax, mov_bp_ax, mov_si_ax, mov_di_ax
	.global mov_ax_cx, mov_cx_cx, mov_dx_cx, mov_bx_cx, mov_sp_cx, mov_bp_cx, mov_si_cx, mov_di_cx
	.global mov_ax_dx, mov_cx_dx, mov_dx_dx, mov_bx_dx, mov_sp_dx, mov_bp_dx, mov_si_dx, mov_di_dx
	.global mov_ax_bx, mov_cx_bx, mov_dx_bx, mov_bx_bx, mov_sp_bx, mov_bp_bx, mov_si_bx, mov_di_bx
	.global mov_ax_sp, mov_cx_sp, mov_dx_sp, mov_bx_sp, mov_sp_sp, mov_bp_sp, mov_si_sp, mov_di_sp
	.global mov_ax_bp, mov_cx_bp, mov_dx_bp, mov_bx_bp, mov_sp_bp, mov_bp_bp, mov_si_bp, mov_di_bp
	.global mov_ax_si, mov_cx_si, mov_dx_si, mov_bx_si, mov_sp_si, mov_bp_si, mov_si_si, mov_di_si
	.global mov_ax_di, mov_cx_di, mov_dx_di, mov_bx_di, mov_sp_di, mov_bp_di, mov_si_di, mov_di_di
	.global	mov_r0_r16_bp_r4, mov_r0_r16_bp_r5, mov_r0_r16_bp_r6, mov_r0_r16_bp_r7, mov_r0_r16_bp_r8, mov_r0_r16_bp_r9, mov_r0_r16_bp_r10, mov_r0_r16_bp_r11, mov_r0_r16_bp_r4
	.global	mov_r0_r16_r4, mov_r0_r16_r5, mov_r0_r16_r6, mov_r0_r16_r7, mov_r0_r16_r8, mov_r0_r16_r9, mov_r0_r16_r10, mov_r0_r16_r11, mov_r0_r16_r4

.macro mov_r0_reg16 reg
mov_r0_r16_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
mov_r0_r16_\reg:
	mem_handler_jump_r0r3 1f op_89_EGA_\reg op_89_MODEX_\reg
1:	strb	\reg, [r2]
	mov		r1, \reg, lsr #8
	strb	r1, [r2, #1]
	b		loop
.endm

	mov_r0_reg16 r4
	mov_r0_reg16 r5
	mov_r0_reg16 r6
	mov_r0_reg16 r7
	mov_r0_reg16 r8
	mov_r0_reg16 r9
	mov_r0_reg16 r10
	mov_r0_reg16 r11
	
// --- MOV [idx],reg16 ---
//

.macro mov_bxidx_reg16 idx reg
	add		r0, r7, \idx			// r0 = BX+idx
	b		mov_r0_r16_\reg
.endm

mov_bxsi_ax:
	mov_bxidx_reg16 r10 r4
mov_bxsi_cx:
	mov_bxidx_reg16 r10 r5
mov_bxsi_dx:
	mov_bxidx_reg16 r10 r6
mov_bxsi_bx:
	mov_bxidx_reg16 r10 r7
mov_bxsi_sp:
	mov_bxidx_reg16 r10 r8
mov_bxsi_bp:
	mov_bxidx_reg16 r10 r9
mov_bxsi_si:
	mov_bxidx_reg16 r10 r10
mov_bxsi_di:
	mov_bxidx_reg16 r10 r11

mov_bxdi_ax:
	mov_bxidx_reg16 r11 r4
mov_bxdi_cx:
	mov_bxidx_reg16 r11 r5
mov_bxdi_dx:
	mov_bxidx_reg16 r11 r6
mov_bxdi_bx:
	mov_bxidx_reg16 r11 r7
mov_bxdi_sp:
	mov_bxidx_reg16 r11 r8
mov_bxdi_bp:
	mov_bxidx_reg16 r11 r9
mov_bxdi_si:
	mov_bxidx_reg16 r11 r10
mov_bxdi_di:
	mov_bxidx_reg16 r11 r11

.macro mov_bpidx_reg16 idx reg
	add		r0, r9, \idx
	b		mov_r0_r16_bp_\reg
.endm

mov_bpsi_ax:
	mov_bpidx_reg16 r10 r4
mov_bpsi_cx:
	mov_bpidx_reg16 r10 r5
mov_bpsi_dx:
	mov_bpidx_reg16 r10 r6
mov_bpsi_bx:
	mov_bpidx_reg16 r10 r7
mov_bpsi_sp:
	mov_bpidx_reg16 r10 r8
mov_bpsi_bp:
	mov_bpidx_reg16 r10 r9
mov_bpsi_si:
	mov_bpidx_reg16 r10 r10
mov_bpsi_di:
	mov_bpidx_reg16 r10 r11

mov_bpdi_ax:
	mov_bpidx_reg16 r11 r4
mov_bpdi_cx:
	mov_bpidx_reg16 r11 r5
mov_bpdi_dx:
	mov_bpidx_reg16 r11 r6
mov_bpdi_bx:
	mov_bpidx_reg16 r11 r7
mov_bpdi_sp:
	mov_bpidx_reg16 r11 r8
mov_bpdi_bp:
	mov_bpidx_reg16 r11 r9
mov_bpdi_si:
	mov_bpidx_reg16 r11 r10
mov_bpdi_di:
	mov_bpidx_reg16 r11 r11


.macro mov_idx_reg16 idx reg
	mov		r0, \idx				// r0high = idx register value
	b		mov_r0_r16_\reg
.endm

mov_siidx_ax:
	mov_idx_reg16 r10 r4
mov_siidx_cx:
	mov_idx_reg16 r10 r5
mov_siidx_dx:
	mov_idx_reg16 r10 r6
mov_siidx_bx:
	mov_idx_reg16 r10 r7
mov_siidx_sp:
	mov_idx_reg16 r10 r8
mov_siidx_bp:
	mov_idx_reg16 r10 r9
mov_siidx_si:
	mov_idx_reg16 r10 r10
mov_siidx_di:
	mov_idx_reg16 r10 r11
	
mov_diidx_ax:
	mov_idx_reg16 r11 r4
mov_diidx_cx:
	mov_idx_reg16 r11 r5
mov_diidx_dx:
	mov_idx_reg16 r11 r6
mov_diidx_bx:
	mov_idx_reg16 r11 r7
mov_diidx_sp:
	mov_idx_reg16 r11 r8
mov_diidx_bp:
	mov_idx_reg16 r11 r9
mov_diidx_si:
	mov_idx_reg16 r11 r10
mov_diidx_di:
	mov_idx_reg16 r11 r11
	
mov_bxidx_ax:
	mov_idx_reg16 r7 r4
mov_bxidx_cx:
	mov_idx_reg16 r7 r5
mov_bxidx_dx:
	mov_idx_reg16 r7 r6
mov_bxidx_bx:
	mov_idx_reg16 r7 r7
mov_bxidx_sp:
	mov_idx_reg16 r7 r8
mov_bxidx_bp:
	mov_idx_reg16 r7 r9
mov_bxidx_si:
	mov_idx_reg16 r7 r10
mov_bxidx_di:
	mov_idx_reg16 r7 r11

.macro mov_disp16_reg16 reg
	r0_from_disp16
	b		mov_r0_r16_\reg
.endm

	.global	op_a3
op_a3:											// "mov [1234],ax" == A3 34 12 == 89 06 34 12
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
mov_disp16_ax:
	r0_from_disp16
	b		mov_r0_r16_r4
	
mov_disp16_cx:
	mov_disp16_reg16 r5
mov_disp16_dx:
	mov_disp16_reg16 r6
mov_disp16_bx:
	mov_disp16_reg16 r7
mov_disp16_sp:
	mov_disp16_reg16 r8
mov_disp16_bp:
	mov_disp16_reg16 r9
mov_disp16_si:
	mov_disp16_reg16 r10
mov_disp16_di:
	mov_disp16_reg16 r11

// --- MOV [idx+disp8],reg16 ---

.macro mov_bxidxd8_reg16 idx reg
	r0_from_bxidxdisp8 \idx
	b		mov_r0_r16_\reg
.endm

mov_bxsid8_ax:
	mov_bxidxd8_reg16 r10 r4
mov_bxsid8_cx:
	mov_bxidxd8_reg16 r10 r5
mov_bxsid8_dx:
	mov_bxidxd8_reg16 r10 r6
mov_bxsid8_bx:
	mov_bxidxd8_reg16 r10 r7
mov_bxsid8_sp:
	mov_bxidxd8_reg16 r10 r8
mov_bxsid8_bp:
	mov_bxidxd8_reg16 r10 r9
mov_bxsid8_si:
	mov_bxidxd8_reg16 r10 r10
mov_bxsid8_di:
	mov_bxidxd8_reg16 r10 r11

mov_bxdid8_ax:
	mov_bxidxd8_reg16 r11 r4
mov_bxdid8_cx:
	mov_bxidxd8_reg16 r11 r5
mov_bxdid8_dx:
	mov_bxidxd8_reg16 r11 r6
mov_bxdid8_bx:
	mov_bxidxd8_reg16 r11 r7
mov_bxdid8_sp:
	mov_bxidxd8_reg16 r11 r8
mov_bxdid8_bp:
	mov_bxidxd8_reg16 r11 r9
mov_bxdid8_si:
	mov_bxidxd8_reg16 r11 r10
mov_bxdid8_di:
	mov_bxidxd8_reg16 r11 r11

.macro mov_bpidxd8_reg16 idx reg
	r0_from_bpidxdisp8 \idx
	b		mov_r0_r16_bp_\reg
.endm

mov_bpsid8_ax:
	mov_bpidxd8_reg16 r10 r4
mov_bpsid8_cx:
	mov_bpidxd8_reg16 r10 r5
mov_bpsid8_dx:
	mov_bpidxd8_reg16 r10 r6
mov_bpsid8_bx:
	mov_bpidxd8_reg16 r10 r7
mov_bpsid8_sp:
	mov_bpidxd8_reg16 r10 r8
mov_bpsid8_bp:
	mov_bpidxd8_reg16 r10 r9
mov_bpsid8_si:
	mov_bpidxd8_reg16 r10 r10
mov_bpsid8_di:
	mov_bpidxd8_reg16 r10 r11

mov_bpdid8_ax:
	mov_bpidxd8_reg16 r11 r4
mov_bpdid8_cx:
	mov_bpidxd8_reg16 r11 r5
mov_bpdid8_dx:
	mov_bpidxd8_reg16 r11 r6
mov_bpdid8_bx:
	mov_bpidxd8_reg16 r11 r7
mov_bpdid8_sp:
	mov_bpidxd8_reg16 r11 r8
mov_bpdid8_bp:
	mov_bpidxd8_reg16 r11 r9
mov_bpdid8_si:
	mov_bpidxd8_reg16 r11 r10
mov_bpdid8_di:
	mov_bpidxd8_reg16 r11 r11


.macro mov_idxd8_reg16 idx reg
	r0_from_idx_disp8 \idx
	b		mov_r0_r16_\reg
.endm

mov_sidisp8_ax:
	mov_idxd8_reg16 r10 r4
mov_sidisp8_cx:
	mov_idxd8_reg16 r10 r5
mov_sidisp8_dx:
	mov_idxd8_reg16 r10 r6
mov_sidisp8_bx:
	mov_idxd8_reg16 r10 r7
mov_sidisp8_sp:
	mov_idxd8_reg16 r10 r8
mov_sidisp8_bp:
	mov_idxd8_reg16 r10 r9
mov_sidisp8_si:
	mov_idxd8_reg16 r10 r10
mov_sidisp8_di:
	mov_idxd8_reg16 r10 r11

mov_didisp8_ax:
	mov_idxd8_reg16 r11 r4
mov_didisp8_cx:
	mov_idxd8_reg16 r11 r5
mov_didisp8_dx:
	mov_idxd8_reg16 r11 r6
mov_didisp8_bx:
	mov_idxd8_reg16 r11 r7
mov_didisp8_sp:
	mov_idxd8_reg16 r11 r8
mov_didisp8_bp:
	mov_idxd8_reg16 r11 r9
mov_didisp8_si:
	mov_idxd8_reg16 r11 r10
mov_didisp8_di:
	mov_idxd8_reg16 r11 r11

mov_bxdisp8_ax:
	mov_idxd8_reg16 r7 r4
mov_bxdisp8_cx:
	mov_idxd8_reg16 r7 r5
mov_bxdisp8_dx:
	mov_idxd8_reg16 r7 r6
mov_bxdisp8_bx:
	mov_idxd8_reg16 r7 r7
mov_bxdisp8_sp:
	mov_idxd8_reg16 r7 r8
mov_bxdisp8_bp:
	mov_idxd8_reg16 r7 r9
mov_bxdisp8_si:
	mov_idxd8_reg16 r7 r10
mov_bxdisp8_di:
	mov_idxd8_reg16 r7 r11

.macro mov_bpdisp8_reg16 reg
	r0_from_idx_disp8 r9
	b		mov_r0_r16_bp_\reg
.endm

mov_bpdisp8_ax:
	mov_bpdisp8_reg16 r4
mov_bpdisp8_cx:
	mov_bpdisp8_reg16 r5
mov_bpdisp8_dx:
	mov_bpdisp8_reg16 r6
mov_bpdisp8_bx:
	mov_bpdisp8_reg16 r7
mov_bpdisp8_sp:
	mov_bpdisp8_reg16 r8
mov_bpdisp8_bp:
	mov_bpdisp8_reg16 r9
mov_bpdisp8_si:
	mov_bpdisp8_reg16 r10
mov_bpdisp8_di:
	mov_bpdisp8_reg16 r11

// --- MOV [idx+disp16],reg16 ---
//
.macro mov_bxidxdisp16_reg16 idx reg
	r0_from_bxidxdisp16 \idx
	b		mov_r0_r16_\reg
.endm

mov_bxsid16_ax:
	mov_bxidxdisp16_reg16 r10 r4
mov_bxsid16_cx:
	mov_bxidxdisp16_reg16 r10 r5
mov_bxsid16_dx:
	mov_bxidxdisp16_reg16 r10 r6
mov_bxsid16_bx:
	mov_bxidxdisp16_reg16 r10 r7
mov_bxsid16_sp:
	mov_bxidxdisp16_reg16 r10 r8
mov_bxsid16_bp:
	mov_bxidxdisp16_reg16 r10 r9
mov_bxsid16_si:
	mov_bxidxdisp16_reg16 r10 r10
mov_bxsid16_di:
	mov_bxidxdisp16_reg16 r10 r11

mov_bxdid16_ax:
	mov_bxidxdisp16_reg16 r11 r4
mov_bxdid16_cx:
	mov_bxidxdisp16_reg16 r11 r5
mov_bxdid16_dx:
	mov_bxidxdisp16_reg16 r11 r6
mov_bxdid16_bx:
	mov_bxidxdisp16_reg16 r11 r7
mov_bxdid16_sp:
	mov_bxidxdisp16_reg16 r11 r8
mov_bxdid16_bp:
	mov_bxidxdisp16_reg16 r11 r9
mov_bxdid16_si:
	mov_bxidxdisp16_reg16 r11 r10
mov_bxdid16_di:
	mov_bxidxdisp16_reg16 r11 r11


.macro mov_bpidxd16_reg16 idx reg
	r0_from_bpidxdisp16 \idx
	b		mov_r0_r16_bp_\reg
.endm

mov_bpsid16_ax:
	mov_bpidxd16_reg16 r10 r4
mov_bpsid16_cx:
	mov_bpidxd16_reg16 r10 r5
mov_bpsid16_dx:
	mov_bpidxd16_reg16 r10 r6
mov_bpsid16_bx:
	mov_bpidxd16_reg16 r10 r7
mov_bpsid16_sp:
	mov_bpidxd16_reg16 r10 r8
mov_bpsid16_bp:
	mov_bpidxd16_reg16 r10 r9
mov_bpsid16_si:
	mov_bpidxd16_reg16 r10 r10
mov_bpsid16_di:
	mov_bpidxd16_reg16 r10 r11

mov_bpdid16_ax:
	mov_bpidxd16_reg16 r11 r4
mov_bpdid16_cx:
	mov_bpidxd16_reg16 r11 r5
mov_bpdid16_dx:
	mov_bpidxd16_reg16 r11 r6
mov_bpdid16_bx:
	mov_bpidxd16_reg16 r11 r7
mov_bpdid16_sp:
	mov_bpidxd16_reg16 r11 r8
mov_bpdid16_bp:
	mov_bpidxd16_reg16 r11 r9
mov_bpdid16_si:
	mov_bpidxd16_reg16 r11 r10
mov_bpdid16_di:
	mov_bpidxd16_reg16 r11 r11


.macro mov_idxdisp16_reg16 idx reg
	r0_from_idx_disp16 \idx
	b		mov_r0_r16_\reg
.endm

mov_sidisp16_ax:
	mov_idxdisp16_reg16 r10 r4
mov_sidisp16_cx:
	mov_idxdisp16_reg16 r10 r5
mov_sidisp16_dx:
	mov_idxdisp16_reg16 r10 r6
mov_sidisp16_bx:
	mov_idxdisp16_reg16 r10 r7
mov_sidisp16_sp:
	mov_idxdisp16_reg16 r10 r8
mov_sidisp16_bp:
	mov_idxdisp16_reg16 r10 r9
mov_sidisp16_si:
	mov_idxdisp16_reg16 r10 r10
mov_sidisp16_di:
	mov_idxdisp16_reg16 r10 r11

mov_didisp16_ax:
	mov_idxdisp16_reg16 r11 r4
mov_didisp16_cx:
	mov_idxdisp16_reg16 r11 r5
mov_didisp16_dx:
	mov_idxdisp16_reg16 r11 r6
mov_didisp16_bx:
	mov_idxdisp16_reg16 r11 r7
mov_didisp16_sp:
	mov_idxdisp16_reg16 r11 r8
mov_didisp16_bp:
	mov_idxdisp16_reg16 r11 r9
mov_didisp16_si:
	mov_idxdisp16_reg16 r11 r10
mov_didisp16_di:
	mov_idxdisp16_reg16 r11 r11

mov_bxdisp16_ax:
	mov_idxdisp16_reg16 r7 r4
mov_bxdisp16_cx:
	mov_idxdisp16_reg16 r7 r5
mov_bxdisp16_dx:
	mov_idxdisp16_reg16 r7 r6
mov_bxdisp16_bx:
	mov_idxdisp16_reg16 r7 r7
mov_bxdisp16_sp:
	mov_idxdisp16_reg16 r7 r8
mov_bxdisp16_bp:
	mov_idxdisp16_reg16 r7 r9
mov_bxdisp16_si:
	mov_idxdisp16_reg16 r7 r10
mov_bxdisp16_di:
	mov_idxdisp16_reg16 r7 r11

.macro mov_bpdisp16_reg16 reg
	r0_from_idx_disp16 r9
	b		mov_r0_r16_bp_\reg
.endm

mov_bpdisp16_ax:
	mov_bpdisp16_reg16 r4
mov_bpdisp16_cx:
	mov_bpdisp16_reg16 r5
mov_bpdisp16_dx:
	mov_bpdisp16_reg16 r6
mov_bpdisp16_bx:
	mov_bpdisp16_reg16 r7
mov_bpdisp16_sp:
	mov_bpdisp16_reg16 r8
mov_bpdisp16_bp:
	mov_bpdisp16_reg16 r9
mov_bpdisp16_si:
	mov_bpdisp16_reg16 r10
mov_bpdisp16_di:
	mov_bpdisp16_reg16 r11

// ------------------- 8A = MOV r8,r/m8 --------------------------------
// 
// All modrm bytes supported!
//
//
// This is the second most common opcode during Wing Commander II space flight!
//
	.global	op_8a
op_8a:
	modrm_jump_16
// 0 = mod = 01b => [idx]
	.word mov_al_bxsi, mov_al_bxdi, mov_al_bpsi, mov_al_bpdi, mov_al_siidx, mov_al_diidx, mov_al_disp16, mov_al_bxidx
	.word mov_cl_bxsi, mov_cl_bxdi, mov_cl_bpsi, mov_cl_bpdi, mov_cl_siidx, mov_cl_diidx, mov_cl_disp16, mov_cl_bxidx
	.word mov_dl_bxsi, mov_dl_bxdi, mov_dl_bpsi, mov_dl_bpdi, mov_dl_siidx, mov_dl_diidx, mov_dl_disp16, mov_dl_bxidx
	.word mov_bl_bxsi, mov_bl_bxdi, mov_bl_bpsi, mov_bl_bpdi, mov_bl_siidx, mov_bl_diidx, mov_bl_disp16, mov_bl_bxidx
	.word mov_ah_bxsi, mov_ah_bxdi, mov_ah_bpsi, mov_ah_bpdi, mov_ah_siidx, mov_ah_diidx, mov_ah_disp16, mov_ah_bxidx
	.word mov_ch_bxsi, mov_ch_bxdi, mov_ch_bpsi, mov_ch_bpdi, mov_ch_siidx, mov_ch_diidx, mov_ch_disp16, mov_ch_bxidx
	.word mov_dh_bxsi, mov_dh_bxdi, mov_dh_bpsi, mov_dh_bpdi, mov_dh_siidx, mov_dh_diidx, mov_dh_disp16, mov_dh_bxidx
	.word mov_bh_bxsi, mov_bh_bxdi, mov_bh_bpsi, mov_bh_bpdi, mov_bh_siidx, mov_bh_diidx, mov_bh_disp16, mov_bh_bxidx
//0x40 = mod = 01b => [idx+disp8]
	.word mov_al_bxsidisp8, mov_al_bxdidisp8, mov_al_bpsidisp8, mov_al_bpdidisp8, mov_al_sidisp8, mov_al_didisp8, mov_al_bpdisp8, mov_al_bxdisp8
	.word mov_cl_bxsidisp8, mov_cl_bxdidisp8, mov_cl_bpsidisp8, mov_cl_bpdidisp8, mov_cl_sidisp8, mov_cl_didisp8, mov_cl_bpdisp8, mov_cl_bxdisp8
	.word mov_dl_bxsidisp8, mov_dl_bxdidisp8, mov_dl_bpsidisp8, mov_dl_bpdidisp8, mov_dl_sidisp8, mov_dl_didisp8, mov_dl_bpdisp8, mov_dl_bxdisp8
	.word mov_bl_bxsidisp8, mov_bl_bxdidisp8, mov_bl_bpsidisp8, mov_bl_bpdidisp8, mov_bl_sidisp8, mov_bl_didisp8, mov_bl_bpdisp8, mov_bl_bxdisp8
	.word mov_ah_bxsidisp8, mov_ah_bxdidisp8, mov_ah_bpsidisp8, mov_ah_bpdidisp8, mov_ah_sidisp8, mov_ah_didisp8, mov_ah_bpdisp8, mov_ah_bxdisp8
	.word mov_ch_bxsidisp8, mov_ch_bxdidisp8, mov_ch_bpsidisp8, mov_ch_bpdidisp8, mov_ch_sidisp8, mov_ch_didisp8, mov_ch_bpdisp8, mov_ch_bxdisp8
	.word mov_dh_bxsidisp8, mov_dh_bxdidisp8, mov_dh_bpsidisp8, mov_dh_bpdidisp8, mov_dh_sidisp8, mov_dh_didisp8, mov_dh_bpdisp8, mov_dh_bxdisp8
	.word mov_bh_bxsidisp8, mov_bh_bxdidisp8, mov_bh_bpsidisp8, mov_bh_bpdidisp8, mov_bh_sidisp8, mov_bh_didisp8, mov_bh_bpdisp8, mov_bh_bxdisp8
//0x80 = mod = 10b => [idx+disp16]
	.word mov_al_bxsidisp16, mov_al_bxdidisp16, mov_al_bpsidisp16, mov_al_bpdidisp16, mov_al_si_disp16, mov_al_di_disp16, mov_al_bpdisp16, mov_al_bx_disp16
	.word mov_cl_bxsidisp16, mov_cl_bxdidisp16, mov_cl_bpsidisp16, mov_cl_bpdidisp16, mov_cl_si_disp16, mov_cl_di_disp16, mov_cl_bpdisp16, mov_cl_bx_disp16
	.word mov_dl_bxsidisp16, mov_dl_bxdidisp16, mov_dl_bpsidisp16, mov_dl_bpdidisp16, mov_dl_si_disp16, mov_dl_di_disp16, mov_dl_bpdisp16, mov_dl_bx_disp16
	.word mov_bl_bxsidisp16, mov_bl_bxdidisp16, mov_bl_bpsidisp16, mov_bl_bpdidisp16, mov_bl_si_disp16, mov_bl_di_disp16, mov_bl_bpdisp16, mov_bl_bx_disp16
	.word mov_ah_bxsidisp16, mov_ah_bxdidisp16, mov_ah_bpsidisp16, mov_ah_bpdidisp16, mov_ah_si_disp16, mov_ah_di_disp16, mov_ah_bpdisp16, mov_ah_bx_disp16
	.word mov_ch_bxsidisp16, mov_ch_bxdidisp16, mov_ch_bpsidisp16, mov_ch_bpdidisp16, mov_ch_si_disp16, mov_ch_di_disp16, mov_ch_bpdisp16, mov_ch_bx_disp16
	.word mov_dh_bxsidisp16, mov_dh_bxdidisp16, mov_dh_bpsidisp16, mov_dh_bpdidisp16, mov_dh_si_disp16, mov_dh_di_disp16, mov_dh_bpdisp16, mov_dh_bx_disp16
	.word mov_bh_bxsidisp16, mov_bh_bxdidisp16, mov_bh_bpsidisp16, mov_bh_bpdidisp16, mov_bh_si_disp16, mov_bh_di_disp16, mov_bh_bpdisp16, mov_bh_bx_disp16
//0xc0 = mod = 11b => two register operands
	.word loop, mov_al_cl, mov_al_dl, mov_al_bl, mov_al_ah, mov_al_ch, mov_al_dh, mov_al_bh
	.word mov_cl_al, loop, mov_cl_dl, mov_cl_bl, mov_cl_ah, mov_cl_ch, mov_cl_dh, mov_cl_bh
	.word mov_dl_al, mov_dl_cl, loop, mov_dl_bl, mov_dl_ah, mov_dl_ch, mov_dl_dh, mov_dl_bh
	.word mov_bl_al, mov_bl_cl, mov_bl_dl, loop, mov_bl_ah, mov_bl_ch, mov_bl_dh, mov_bl_bh
	.word mov_ah_al, mov_ah_cl, mov_ah_dl, mov_ah_bl, loop, mov_ah_ch, mov_ah_dh, mov_ah_bh
	.word mov_ch_al, mov_ch_cl, mov_ch_dl, mov_ch_bl, mov_ch_ah, loop, mov_ch_dh, mov_ch_bh
	.word mov_dh_al, mov_dh_cl, mov_dh_dl, mov_dh_bl, mov_dh_ah, mov_dh_ch, loop, mov_dh_bh
	.word mov_bh_al, mov_bh_cl, mov_bh_dl, mov_bh_bl, mov_bh_ah, mov_bh_ch, mov_bh_dh, loop

// These are called from "cpu_386.s":

	.global mov_al_siidx, mov_cl_siidx, mov_dl_siidx, mov_bl_siidx, mov_ah_siidx, mov_ch_siidx, mov_dh_siidx, mov_bh_siidx
	.global mov_al_diidx, mov_cl_diidx, mov_dl_diidx, mov_bl_diidx, mov_ah_diidx, mov_ch_diidx, mov_dh_diidx, mov_bh_diidx
	.global mov_al_bxidx, mov_cl_bxidx, mov_dl_bxidx, mov_bl_bxidx, mov_ah_bxidx, mov_ch_bxidx, mov_dh_bxidx, mov_bh_bxidx
	.global mov_al_sidisp8, mov_al_didisp8, mov_al_bpdisp8, mov_al_bxdisp8
	.global mov_cl_sidisp8, mov_cl_didisp8, mov_cl_bpdisp8, mov_cl_bxdisp8
	.global mov_dl_sidisp8, mov_dl_didisp8, mov_dl_bpdisp8, mov_dl_bxdisp8
	.global mov_bl_sidisp8, mov_bl_didisp8, mov_bl_bpdisp8, mov_bl_bxdisp8
	.global mov_ah_sidisp8, mov_ah_didisp8, mov_ah_bpdisp8, mov_ah_bxdisp8
	.global mov_ch_sidisp8, mov_ch_didisp8, mov_ch_bpdisp8, mov_ch_bxdisp8
	.global mov_dh_sidisp8, mov_dh_didisp8, mov_dh_bpdisp8, mov_dh_bxdisp8
	.global mov_bh_sidisp8, mov_bh_didisp8, mov_bh_bpdisp8, mov_bh_bxdisp8

.macro mov_reg8l_r0high reg
	.global	mov_r8l_r0_bp_\reg
mov_r8l_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r8l_r0_\reg
mov_r8l_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8a_RAM_l_\reg op_8a_EGA_l_\reg op_8a_MODEX_l_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8a_RAM_l_\reg:
	ldrb	r0,[r2]					// Get the byte from RAM
#if defined(RPi) || defined(Roku)
	bic		\reg, #0xFF
	orr		\reg, r0
#else
	bfi		\reg, r0, #0, #8
#endif
	b		loop
.endm
.macro mov_reg8h_r0high reg
	.global	mov_r8h_r0_bp_\reg
mov_r8h_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r8h_r0_\reg
mov_r8h_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8a_RAM_h_\reg op_8a_EGA_h_\reg op_8a_MODEX_h_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8a_RAM_h_\reg:
	ldrb	r0,[r2]					// Get the byte from RAM
#if defined(RPi) || defined(Roku)
	bic		\reg, #0xFF00
	orr		\reg, r0, lsl #8
#else
	bfi		\reg, r0, #8, #8
#endif
	b		loop
.endm

	mov_reg8l_r0high r4
	mov_reg8l_r0high r5
	mov_reg8l_r0high r6
	mov_reg8l_r0high r7
	mov_reg8h_r0high r4
	mov_reg8h_r0high r5
	mov_reg8h_r0high r6
	mov_reg8h_r0high r7


// --- idx ---

.macro mov_reg8l_bxidx reg idx
	add		r0, r7, \idx
	b		mov_r8l_r0_\reg
.endm
.macro mov_reg8h_bxidx reg idx
	add		r0, r7, \idx
	b		mov_r8h_r0_\reg
.endm

mov_al_bxsi:
	mov_reg8l_bxidx r4 r10
mov_cl_bxsi:
	mov_reg8l_bxidx r5 r10
mov_dl_bxsi:
	mov_reg8l_bxidx r6 r10
mov_bl_bxsi:
	mov_reg8l_bxidx r7 r10
mov_ah_bxsi:
	mov_reg8h_bxidx r4 r10
mov_ch_bxsi:
	mov_reg8h_bxidx r5 r10
mov_dh_bxsi:
	mov_reg8h_bxidx r6 r10
mov_bh_bxsi:
	mov_reg8h_bxidx r7 r10

mov_al_bxdi:
	mov_reg8l_bxidx r4 r11
mov_cl_bxdi:
	mov_reg8l_bxidx r5 r11
mov_dl_bxdi:
	mov_reg8l_bxidx r6 r11
mov_bl_bxdi:
	mov_reg8l_bxidx r7 r11
mov_ah_bxdi:
	mov_reg8h_bxidx r4 r11
mov_ch_bxdi:
	mov_reg8h_bxidx r5 r11
mov_dh_bxdi:
	mov_reg8h_bxidx r6 r11
mov_bh_bxdi:
	mov_reg8h_bxidx r7 r11

.macro mov_reg8l_bpidx reg idx
	add		r0, r9, \idx
	b		mov_r8l_r0_bp_\reg
.endm
.macro mov_reg8h_bpidx reg idx
	add		r0, r9, \idx
	b		mov_r8h_r0_bp_\reg
.endm

mov_al_bpsi:
	mov_reg8l_bpidx r4 r10
mov_cl_bpsi:
	mov_reg8l_bpidx r5 r10
mov_dl_bpsi:
	mov_reg8l_bpidx r6 r10
mov_bl_bpsi:
	mov_reg8l_bpidx r7 r10
mov_ah_bpsi:
	mov_reg8h_bpidx r4 r10
mov_ch_bpsi:
	mov_reg8h_bpidx r5 r10
mov_dh_bpsi:
	mov_reg8h_bpidx r6 r10
mov_bh_bpsi:
	mov_reg8h_bpidx r7 r10

mov_al_bpdi:
	mov_reg8l_bpidx r4 r11
mov_cl_bpdi:
	mov_reg8l_bpidx r5 r11
mov_dl_bpdi:
	mov_reg8l_bpidx r6 r11
mov_bl_bpdi:
	mov_reg8l_bpidx r7 r11
mov_ah_bpdi:
	mov_reg8h_bpidx r4 r11
mov_ch_bpdi:
	mov_reg8h_bpidx r5 r11
mov_dh_bpdi:
	mov_reg8h_bpidx r6 r11
mov_bh_bpdi:
	mov_reg8h_bpidx r7 r11


.macro mov_reg8l_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		mov_r8l_r0_\reg
.endm
.macro mov_reg8h_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		mov_r8h_r0_\reg
.endm

mov_al_siidx:
	mov_reg8l_idx r4 r10
mov_cl_siidx:
	mov_reg8l_idx r5 r10
mov_dl_siidx:
	mov_reg8l_idx r6 r10
mov_bl_siidx:
	mov_reg8l_idx r7 r10

mov_ah_siidx:
	mov_reg8h_idx r4 r10
mov_ch_siidx:
	mov_reg8h_idx r5 r10
mov_dh_siidx:
	mov_reg8h_idx r6 r10
mov_bh_siidx:
	mov_reg8h_idx r7 r10

mov_al_diidx:
	mov_reg8l_idx r4 r11
mov_cl_diidx:
	mov_reg8l_idx r5 r11
mov_dl_diidx:
	mov_reg8l_idx r6 r11
mov_bl_diidx:
	mov_reg8l_idx r7 r11

mov_ah_diidx:
	mov_reg8h_idx r4 r11
mov_ch_diidx:
	mov_reg8h_idx r5 r11
mov_dh_diidx:
	mov_reg8h_idx r6 r11
mov_bh_diidx:
	mov_reg8h_idx r7 r11

mov_al_bxidx:
	mov_reg8l_idx r4 r7
mov_cl_bxidx:
	mov_reg8l_idx r5 r7
mov_dl_bxidx:
	mov_reg8l_idx r6 r7
mov_bl_bxidx:
	mov_reg8l_idx r7 r7

mov_ah_bxidx:
	mov_reg8h_idx r4 r7
mov_ch_bxidx:
	mov_reg8h_idx r5 r7
mov_dh_bxidx:
	mov_reg8h_idx r6 r7
mov_bh_bxidx:
	mov_reg8h_idx r7 r7

.macro mov_reg8l_disp16 reg
	r0_from_disp16
	b		mov_r8l_r0_\reg
.endm
.macro mov_reg8h_disp16 reg
	r0_from_disp16
	b		mov_r8h_r0_\reg
.endm

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	op_a0
op_a0:									// "mov al,[1234]" == A0 34 12 == 8A 06 34 12
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
mov_al_disp16:
	r0_from_disp16
	mem_handler_jump_r0r3 .op_8a_RAM_l_r4 op_8a_EGA_l_r4 op_8a_MODEX_l_r4
	
	.text
	.align 2
	
mov_cl_disp16:
	mov_reg8l_disp16 r5
mov_dl_disp16:
	mov_reg8l_disp16 r6
mov_bl_disp16:
	mov_reg8l_disp16 r7

mov_ah_disp16:
	mov_reg8h_disp16 r4
mov_ch_disp16:
	mov_reg8h_disp16 r5
mov_dh_disp16:
	mov_reg8h_disp16 r6
mov_bh_disp16:
	mov_reg8h_disp16 r7

// --- idx + disp8 ---

.macro mov_reg8l_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		mov_r8l_r0_\reg
.endm
.macro mov_reg8h_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		mov_r8h_r0_\reg
.endm

mov_al_bxsidisp8:
	mov_reg8l_bxidxdisp8 r4 r10
mov_cl_bxsidisp8:
	mov_reg8l_bxidxdisp8 r5 r10
mov_dl_bxsidisp8:
	mov_reg8l_bxidxdisp8 r6 r10
mov_bl_bxsidisp8:
	mov_reg8l_bxidxdisp8 r7 r10
mov_ah_bxsidisp8:
	mov_reg8h_bxidxdisp8 r4 r10
mov_ch_bxsidisp8:
	mov_reg8h_bxidxdisp8 r5 r10
mov_dh_bxsidisp8:
	mov_reg8h_bxidxdisp8 r6 r10
mov_bh_bxsidisp8:
	mov_reg8h_bxidxdisp8 r7 r10

mov_al_bxdidisp8:
	mov_reg8l_bxidxdisp8 r4 r11
mov_cl_bxdidisp8:
	mov_reg8l_bxidxdisp8 r5 r11
mov_dl_bxdidisp8:
	mov_reg8l_bxidxdisp8 r6 r11
mov_bl_bxdidisp8:
	mov_reg8l_bxidxdisp8 r7 r11
mov_ah_bxdidisp8:
	mov_reg8h_bxidxdisp8 r4 r11
mov_ch_bxdidisp8:
	mov_reg8h_bxidxdisp8 r5 r11
mov_dh_bxdidisp8:
	mov_reg8h_bxidxdisp8 r6 r11
mov_bh_bxdidisp8:
	mov_reg8h_bxidxdisp8 r7 r11

.macro mov_reg8l_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		mov_r8l_r0_bp_\reg
.endm
.macro mov_reg8h_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		mov_r8h_r0_bp_\reg
.endm

mov_al_bpsidisp8:
	mov_reg8l_bpidxdisp8 r4 r10
mov_cl_bpsidisp8:
	mov_reg8l_bpidxdisp8 r5 r10
mov_dl_bpsidisp8:
	mov_reg8l_bpidxdisp8 r6 r10
mov_bl_bpsidisp8:
	mov_reg8l_bpidxdisp8 r7 r10
mov_ah_bpsidisp8:
	mov_reg8h_bpidxdisp8 r4 r10
mov_ch_bpsidisp8:
	mov_reg8h_bpidxdisp8 r5 r10
mov_dh_bpsidisp8:
	mov_reg8h_bpidxdisp8 r6 r10
mov_bh_bpsidisp8:
	mov_reg8h_bpidxdisp8 r7 r10

mov_al_bpdidisp8:
	mov_reg8l_bpidxdisp8 r4 r11
mov_cl_bpdidisp8:
	mov_reg8l_bpidxdisp8 r5 r11
mov_dl_bpdidisp8:
	mov_reg8l_bpidxdisp8 r6 r11
mov_bl_bpdidisp8:
	mov_reg8l_bpidxdisp8 r7 r11
mov_ah_bpdidisp8:
	mov_reg8h_bpidxdisp8 r4 r11
mov_ch_bpdidisp8:
	mov_reg8h_bpidxdisp8 r5 r11
mov_dh_bpdidisp8:
	mov_reg8h_bpidxdisp8 r6 r11
mov_bh_bpdidisp8:
	mov_reg8h_bpidxdisp8 r7 r11

.macro mov_reg8l_idx_disp8 reg idx
	r0_from_idx_disp8 \idx
	b		mov_r8l_r0_\reg
.endm
.macro mov_reg8h_idx_disp8 reg idx
	r0_from_idx_disp8 \idx
	b		mov_r8h_r0_\reg
.endm

mov_al_sidisp8:
	mov_reg8l_idx_disp8 r4 r10
mov_cl_sidisp8:
	mov_reg8l_idx_disp8 r5 r10
mov_dl_sidisp8:
	mov_reg8l_idx_disp8 r6 r10
mov_bl_sidisp8:
	mov_reg8l_idx_disp8 r7 r10
mov_ah_sidisp8:
	mov_reg8h_idx_disp8 r4 r10
mov_ch_sidisp8:
	mov_reg8h_idx_disp8 r5 r10
mov_dh_sidisp8:
	mov_reg8h_idx_disp8 r6 r10
mov_bh_sidisp8:
	mov_reg8h_idx_disp8 r7 r10

mov_al_didisp8:
	mov_reg8l_idx_disp8 r4 r11
mov_cl_didisp8:
	mov_reg8l_idx_disp8 r5 r11
mov_dl_didisp8:
	mov_reg8l_idx_disp8 r6 r11
mov_bl_didisp8:
	mov_reg8l_idx_disp8 r7 r11
mov_ah_didisp8:
	mov_reg8h_idx_disp8 r4 r11
mov_ch_didisp8:
	mov_reg8h_idx_disp8 r5 r11
mov_dh_didisp8:
	mov_reg8h_idx_disp8 r6 r11
mov_bh_didisp8:
	mov_reg8h_idx_disp8 r7 r11

mov_al_bxdisp8:
	mov_reg8l_idx_disp8 r4 r7
mov_cl_bxdisp8:
	mov_reg8l_idx_disp8 r5 r7
mov_dl_bxdisp8:
	mov_reg8l_idx_disp8 r6 r7
mov_bl_bxdisp8:
	mov_reg8l_idx_disp8 r7 r7
mov_ah_bxdisp8:
	mov_reg8h_idx_disp8 r4 r7
mov_ch_bxdisp8:
	mov_reg8h_idx_disp8 r5 r7
mov_dh_bxdisp8:
	mov_reg8h_idx_disp8 r6 r7
mov_bh_bxdisp8:
	mov_reg8h_idx_disp8 r7 r7

.macro mov_reg8l_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		mov_r8l_r0_bp_\reg
.endm
.macro mov_reg8h_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		mov_r8h_r0_bp_\reg
.endm

mov_al_bpdisp8:
	mov_reg8l_bpdisp8 r4
mov_cl_bpdisp8:
	mov_reg8l_bpdisp8 r5
mov_dl_bpdisp8:
	mov_reg8l_bpdisp8 r6
mov_bl_bpdisp8:
	mov_reg8l_bpdisp8 r7
mov_ah_bpdisp8:
	mov_reg8h_bpdisp8 r4
mov_ch_bpdisp8:
	mov_reg8h_bpdisp8 r5
mov_dh_bpdisp8:
	mov_reg8h_bpdisp8 r6
mov_bh_bpdisp8:
	mov_reg8h_bpdisp8 r7

// --- idx + disp16 ---

.macro mov_reg8l_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		mov_r8l_r0_\reg
.endm
.macro mov_reg8h_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		mov_r8h_r0_\reg
.endm

mov_al_bxsidisp16:
	mov_reg8l_bxidxdisp16 r4 r10
mov_cl_bxsidisp16:
	mov_reg8l_bxidxdisp16 r5 r10
mov_dl_bxsidisp16:
	mov_reg8l_bxidxdisp16 r6 r10
mov_bl_bxsidisp16:
	mov_reg8l_bxidxdisp16 r7 r10
mov_ah_bxsidisp16:
	mov_reg8h_bxidxdisp16 r4 r10
mov_ch_bxsidisp16:
	mov_reg8h_bxidxdisp16 r5 r10
mov_dh_bxsidisp16:
	mov_reg8h_bxidxdisp16 r6 r10
mov_bh_bxsidisp16:
	mov_reg8h_bxidxdisp16 r7 r10

mov_al_bxdidisp16:
	mov_reg8l_bxidxdisp16 r4 r11
mov_cl_bxdidisp16:
	mov_reg8l_bxidxdisp16 r5 r11
mov_dl_bxdidisp16:
	mov_reg8l_bxidxdisp16 r6 r11
mov_bl_bxdidisp16:
	mov_reg8l_bxidxdisp16 r7 r11
mov_ah_bxdidisp16:
	mov_reg8h_bxidxdisp16 r4 r11
mov_ch_bxdidisp16:
	mov_reg8h_bxidxdisp16 r5 r11
mov_dh_bxdidisp16:
	mov_reg8h_bxidxdisp16 r6 r11
mov_bh_bxdidisp16:
	mov_reg8h_bxidxdisp16 r7 r11

.macro mov_reg8l_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		mov_r8l_r0_bp_\reg
.endm
.macro mov_reg8h_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		mov_r8h_r0_bp_\reg
.endm

mov_al_bpsidisp16:
	mov_reg8l_bpidxdisp16 r4 r10
mov_cl_bpsidisp16:
	mov_reg8l_bpidxdisp16 r5 r10
mov_dl_bpsidisp16:
	mov_reg8l_bpidxdisp16 r6 r10
mov_bl_bpsidisp16:
	mov_reg8l_bpidxdisp16 r7 r10
mov_ah_bpsidisp16:
	mov_reg8h_bpidxdisp16 r4 r10
mov_ch_bpsidisp16:
	mov_reg8h_bpidxdisp16 r5 r10
mov_dh_bpsidisp16:
	mov_reg8h_bpidxdisp16 r6 r10
mov_bh_bpsidisp16:
	mov_reg8h_bpidxdisp16 r7 r10

mov_al_bpdidisp16:
	mov_reg8l_bpidxdisp16 r4 r11
mov_cl_bpdidisp16:
	mov_reg8l_bpidxdisp16 r5 r11
mov_dl_bpdidisp16:
	mov_reg8l_bpidxdisp16 r6 r11
mov_bl_bpdidisp16:
	mov_reg8l_bpidxdisp16 r7 r11
mov_ah_bpdidisp16:
	mov_reg8h_bpidxdisp16 r4 r11
mov_ch_bpdidisp16:
	mov_reg8h_bpidxdisp16 r5 r11
mov_dh_bpdidisp16:
	mov_reg8h_bpidxdisp16 r6 r11
mov_bh_bpdidisp16:
	mov_reg8h_bpidxdisp16 r7 r11

.macro mov_reg8l_idx_disp16 reg idx
	r0_from_idx_disp16 \idx
	b		mov_r8l_r0_\reg
.endm

.macro mov_reg8h_idx_disp16 reg idx
	r0_from_idx_disp16 \idx
	b		mov_r8h_r0_\reg
.endm

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

mov_al_si_disp16:
	r0_from_idx_disp16 r10
	mem_handler_jump_r0r3 .op_8a_RAM_l_r4 op_8a_EGA_l_r4 op_8a_MODEX_l_r4
	
	.text
	.align 2
	
mov_cl_si_disp16:
	mov_reg8l_idx_disp16 r5 r10
mov_dl_si_disp16:
	mov_reg8l_idx_disp16 r6 r10
mov_bl_si_disp16:
	mov_reg8l_idx_disp16 r7 r10
mov_ah_si_disp16:
	mov_reg8h_idx_disp16 r4 r10
mov_ch_si_disp16:
	mov_reg8h_idx_disp16 r5 r10
mov_dh_si_disp16:
	mov_reg8h_idx_disp16 r6 r10
mov_bh_si_disp16:
	mov_reg8h_idx_disp16 r7 r10

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

mov_al_di_disp16:
	r0_from_idx_disp16 r11
	mem_handler_jump_r0r3 .op_8a_RAM_l_r4 op_8a_EGA_l_r4 op_8a_MODEX_l_r4
	
	.text
	.align 2
	
mov_cl_di_disp16:
	mov_reg8l_idx_disp16 r5 r11
mov_dl_di_disp16:
	mov_reg8l_idx_disp16 r6 r11
mov_bl_di_disp16:
	mov_reg8l_idx_disp16 r7 r11
mov_ah_di_disp16:
	mov_reg8h_idx_disp16 r4 r11
mov_ch_di_disp16:
	mov_reg8h_idx_disp16 r5 r11
mov_dh_di_disp16:
	mov_reg8h_idx_disp16 r6 r11
mov_bh_di_disp16:
	mov_reg8h_idx_disp16 r7 r11

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

mov_al_bx_disp16:
	r0_from_idx_disp16 r7
	mem_handler_jump_r0r3 .op_8a_RAM_l_r4 op_8a_EGA_l_r4 op_8a_MODEX_l_r4
	
	.text
	.align 2
	
mov_cl_bx_disp16:
	mov_reg8l_idx_disp16 r5 r7
mov_dl_bx_disp16:
	mov_reg8l_idx_disp16 r6 r7
mov_bl_bx_disp16:
	mov_reg8l_idx_disp16 r7 r7
mov_ah_bx_disp16:
	mov_reg8h_idx_disp16 r4 r7
mov_ch_bx_disp16:
	mov_reg8h_idx_disp16 r5 r7
mov_dh_bx_disp16:
	mov_reg8h_idx_disp16 r6 r7
mov_bh_bx_disp16:
	mov_reg8h_idx_disp16 r7 r7

.macro mov_reg8l_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		mov_r8l_r0_bp_\reg
.endm
.macro mov_reg8h_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		mov_r8h_r0_bp_\reg
.endm

mov_al_bpdisp16:
	mov_reg8l_bpdisp16 r4
mov_cl_bpdisp16:
	mov_reg8l_bpdisp16 r5
mov_dl_bpdisp16:
	mov_reg8l_bpdisp16 r6
mov_bl_bpdisp16:
	mov_reg8l_bpdisp16 r7
mov_ah_bpdisp16:
	mov_reg8h_bpdisp16 r4
mov_ch_bpdisp16:
	mov_reg8h_bpdisp16 r5
mov_dh_bpdisp16:
	mov_reg8h_bpdisp16 r6
mov_bh_bpdisp16:
	mov_reg8h_bpdisp16 r7

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

// --- Register operands ---

.macro mov_reg8l_reg8l rto rfr
#if defined(RPi) || defined(Roku)
	and		r0, \rfr, #0xFF			// Now r0 contains only the reg8l value
	bic		\rto, #0xFF				// Clear the reg8l value from rto
	orr		\rto, r0				// and replace it with r0
#else
	bfi		\rto, \rfr, #0, #8
#endif	
	b		loop
.endm

.macro mov_reg8l_reg8h rto rfr
#if defined(RPi) || defined(Roku)
	and		r0, \rfr, #0xFF00		// Now r0 contains only the reg8h value
	bic		\rto, #0xFF				// Clear the reg8l value from rto
	orr		\rto, r0, lsr #8		// and replace it with r0 shifted to reg8l
#else
	ubfx	r0, \rfr, #8, #8
	bfi		\rto, r0, #0, #8
#endif	
	b		loop
.endm

.macro mov_reg8h_reg8l rto rfr
#if defined(RPi) || defined(Roku)
	and		r0, \rfr, #0xFF			// Now r0 contains only the reg8l value
	bic		\rto, #0xFF00			// Clear the reg8h value from rto
	orr		\rto, r0, lsl #8		// and replace it with r0 shifted to reg8h
#else
	bfi		\rto, \rfr, #8, #8
#endif	
	b		loop
.endm

.macro mov_reg8h_reg8h rto rfr
#if defined(RPi) || defined(Roku)
	and		r0, \rfr, #0xFF00		// Now r0 contains only the reg8h value
	bic		\rto, #0xFF00			// Clear the reg8h value from rto
	orr		\rto, r0				// and replace it with r0
#else
	ubfx	r0, \rfr, #8, #8
	bfi		\rto, r0, #8, #8
#endif	
	b		loop
.endm

mov_al_cl:
	mov_reg8l_reg8l r4 r5
mov_al_dl:
	mov_reg8l_reg8l r4 r6
mov_al_bl:
	mov_reg8l_reg8l r4 r7
mov_al_ah:
	mov_reg8l_reg8h r4 r4
mov_al_ch:
	mov_reg8l_reg8h r4 r5
mov_al_dh:
	mov_reg8l_reg8h r4 r6
mov_al_bh:
	mov_reg8l_reg8h r4 r7
	
mov_cl_al:
	mov_reg8l_reg8l r5 r4
mov_cl_dl:
	mov_reg8l_reg8l r5 r6
mov_cl_bl:
	mov_reg8l_reg8l r5 r7
mov_cl_ah:
	mov_reg8l_reg8h r5 r4
mov_cl_ch:
	mov_reg8l_reg8h r5 r5
mov_cl_dh:
	mov_reg8l_reg8h r5 r6
mov_cl_bh:
	mov_reg8l_reg8h r5 r7
	
mov_dl_al:
	mov_reg8l_reg8l r6 r4
mov_dl_cl:
	mov_reg8l_reg8l r6 r5
mov_dl_bl:
	mov_reg8l_reg8l r6 r7
mov_dl_ah:
	mov_reg8l_reg8h r6 r4
mov_dl_ch:
	mov_reg8l_reg8h r6 r5
mov_dl_dh:
	mov_reg8l_reg8h r6 r6
mov_dl_bh:
	mov_reg8l_reg8h r6 r7
	
mov_bl_al:
	mov_reg8l_reg8l r7 r4
mov_bl_cl:
	mov_reg8l_reg8l r7 r5
mov_bl_dl:
	mov_reg8l_reg8l r7 r6
mov_bl_ah:
	mov_reg8l_reg8h r7 r4
mov_bl_ch:
	mov_reg8l_reg8h r7 r5
mov_bl_dh:
	mov_reg8l_reg8h r7 r6
mov_bl_bh:
	mov_reg8l_reg8h r7 r7

mov_ah_al:
	mov_reg8h_reg8l r4 r4
mov_ah_cl:
	mov_reg8h_reg8l r4 r5
mov_ah_dl:
	mov_reg8h_reg8l r4 r6
mov_ah_bl:
	mov_reg8h_reg8l r4 r7
mov_ah_ch:
	mov_reg8h_reg8h r4 r5
mov_ah_dh:
	mov_reg8h_reg8h r4 r6
mov_ah_bh:
	mov_reg8h_reg8h r4 r7

mov_ch_al:
	mov_reg8h_reg8l r5 r4
mov_ch_cl:
	mov_reg8h_reg8l r5 r5
mov_ch_dl:
	mov_reg8h_reg8l r5 r6
mov_ch_bl:
	mov_reg8h_reg8l r5 r7
mov_ch_ah:
	mov_reg8h_reg8h r5 r4
mov_ch_dh:
	mov_reg8h_reg8h r5 r6
mov_ch_bh:
	mov_reg8h_reg8h r5 r7

mov_dh_al:
	mov_reg8h_reg8l r6 r4
mov_dh_cl:
	mov_reg8h_reg8l r6 r5
mov_dh_dl:
	mov_reg8h_reg8l r6 r6
mov_dh_bl:
	mov_reg8h_reg8l r6 r7
mov_dh_ah:
	mov_reg8h_reg8h r6 r4
mov_dh_ch:
	mov_reg8h_reg8h r6 r5
mov_dh_bh:
	mov_reg8h_reg8h r6 r7

mov_bh_al:
	mov_reg8h_reg8l r7 r4
mov_bh_cl:
	mov_reg8h_reg8l r7 r5
mov_bh_dl:
	mov_reg8h_reg8l r7 r6
mov_bh_bl:
	mov_reg8h_reg8l r7 r7
mov_bh_ah:
	mov_reg8h_reg8h r7 r4
mov_bh_ch:
	mov_reg8h_reg8h r7 r5
mov_bh_dh:
	mov_reg8h_reg8h r7 r6

	.text
	.align 2
	
// ------------------- 8B = MOV r16,r/m16 -------------------------------
// 
// All modrm bytes supported!
// We must not change the flags here!!!
// This is the most often used opcode in Wing Commander 2!
//
	.global	op_8b
op_8b:
	modrm_jump_16
// 0
	.word mov_ax_bxsi, mov_ax_bxdi, mov_ax_bpsi, mov_ax_bpdi, mov_ax_siidx, mov_ax_diidx, mov_ax_disp16, mov_ax_bxidx
	.word mov_cx_bxsi, mov_cx_bxdi, mov_cx_bpsi, mov_cx_bpdi, mov_cx_siidx, mov_cx_diidx, mov_cx_disp16, mov_cx_bxidx
	.word mov_dx_bxsi, mov_dx_bxdi, mov_dx_bpsi, mov_dx_bpdi, mov_dx_siidx, mov_dx_diidx, mov_dx_disp16, mov_dx_bxidx
	.word mov_bx_bxsi, mov_bx_bxdi, mov_bx_bpsi, mov_bx_bpdi, mov_bx_siidx, mov_bx_diidx, mov_bx_disp16, mov_bx_bxidx
	.word mov_sp_bxsi, mov_sp_bxdi, mov_sp_bpsi, mov_sp_bpdi, mov_sp_siidx, mov_sp_diidx, mov_sp_disp16, mov_sp_bxidx
	.word mov_bp_bxsi, mov_bp_bxdi, mov_bp_bpsi, mov_bp_bpdi, mov_bp_siidx, mov_bp_diidx, mov_bp_disp16, mov_bp_bxidx
	.word mov_si_bxsi, mov_si_bxdi, mov_si_bpsi, mov_si_bpdi, mov_si_siidx, mov_si_diidx, mov_si_disp16, mov_si_bxidx
	.word mov_di_bxsi, mov_di_bxdi, mov_di_bpsi, mov_di_bpdi, mov_di_siidx, mov_di_diidx, mov_di_disp16, mov_di_bxidx
//0x40
	.word mov_ax_bxsid8, mov_ax_bxdid8, mov_ax_bpsid8, mov_ax_bpdid8, mov_ax_sidisp8, mov_ax_didisp8, mov_ax_bpdisp8, mov_ax_bxdisp8
	.word mov_cx_bxsid8, mov_cx_bxdid8, mov_cx_bpsid8, mov_cx_bpdid8, mov_cx_sidisp8, mov_cx_didisp8, mov_cx_bpdisp8, mov_cx_bxdisp8
	.word mov_dx_bxsid8, mov_dx_bxdid8, mov_dx_bpsid8, mov_dx_bpdid8, mov_dx_sidisp8, mov_dx_didisp8, mov_dx_bpdisp8, mov_dx_bxdisp8
	.word mov_bx_bxsid8, mov_bx_bxdid8, mov_bx_bpsid8, mov_bx_bpdid8, mov_bx_sidisp8, mov_bx_didisp8, mov_bx_bpdisp8, mov_bx_bxdisp8
	.word mov_sp_bxsid8, mov_sp_bxdid8, mov_sp_bpsid8, mov_sp_bpdid8, mov_sp_sidisp8, mov_sp_didisp8, mov_sp_bpdisp8, mov_sp_bxdisp8
	.word mov_bp_bxsid8, mov_bp_bxdid8, mov_bp_bpsid8, mov_bp_bpdid8, mov_bp_sidisp8, mov_bp_didisp8, mov_bp_bpdisp8, mov_bp_bxdisp8
	.word mov_si_bxsid8, mov_si_bxdid8, mov_si_bpsid8, mov_si_bpdid8, mov_si_sidisp8, mov_si_didisp8, mov_si_bpdisp8, mov_si_bxdisp8
	.word mov_di_bxsid8, mov_di_bxdid8, mov_di_bpsid8, mov_di_bpdid8, mov_di_sidisp8, mov_di_didisp8, mov_di_bpdisp8, mov_di_bxdisp8
//0x80
	.word mov_ax_bxsid16, mov_ax_bxdid16, mov_ax_bpsid16, mov_ax_bpdid16, mov_ax_sidisp16, mov_ax_didisp16, mov_ax_bpdisp16, mov_ax_bxdisp16
	.word mov_cx_bxsid16, mov_cx_bxdid16, mov_cx_bpsid16, mov_cx_bpdid16, mov_cx_sidisp16, mov_cx_didisp16, mov_cx_bpdisp16, mov_cx_bxdisp16
	.word mov_dx_bxsid16, mov_dx_bxdid16, mov_dx_bpsid16, mov_dx_bpdid16, mov_dx_sidisp16, mov_dx_didisp16, mov_dx_bpdisp16, mov_dx_bxdisp16
	.word mov_bx_bxsid16, mov_bx_bxdid16, mov_bx_bpsid16, mov_bx_bpdid16, mov_bx_sidisp16, mov_bx_didisp16, mov_bx_bpdisp16, mov_bx_bxdisp16
	.word mov_sp_bxsid16, mov_sp_bxdid16, mov_sp_bpsid16, mov_sp_bpdid16, mov_sp_sidisp16, mov_sp_didisp16, mov_sp_bpdisp16, mov_sp_bxdisp16
	.word mov_bp_bxsid16, mov_bp_bxdid16, mov_bp_bpsid16, mov_bp_bpdid16, mov_bp_sidisp16, mov_bp_didisp16, mov_bp_bpdisp16, mov_bp_bxdisp16
	.word mov_si_bxsid16, mov_si_bxdid16, mov_si_bpsid16, mov_si_bpdid16, mov_si_sidisp16, mov_si_didisp16, mov_si_bpdisp16, mov_si_bxdisp16
	.word mov_di_bxsid16, mov_di_bxdid16, mov_di_bpsid16, mov_di_bpdid16, mov_di_sidisp16, mov_di_didisp16, mov_di_bpdisp16, mov_di_bxdisp16
// 0xC0 = two register operands
	.word loop, mov_ax_cx, mov_ax_dx, mov_ax_bx, mov_ax_sp, mov_ax_bp, mov_ax_si, mov_ax_di
	.word mov_cx_ax, loop, mov_cx_dx, mov_cx_bx, mov_cx_sp, mov_cx_bp, mov_cx_si, mov_cx_di
	.word mov_dx_ax, mov_dx_cx, loop, mov_dx_bx, mov_dx_sp, mov_dx_bp, mov_dx_si, mov_dx_di
	.word mov_bx_ax, mov_bx_cx, mov_bx_dx, loop, mov_bx_sp, mov_bx_bp, mov_bx_si, mov_bx_di
	.word mov_sp_ax, mov_sp_cx, mov_sp_dx, mov_sp_bx, loop, mov_sp_bp, mov_sp_si, mov_sp_di
	.word mov_bp_ax, mov_bp_cx, mov_bp_dx, mov_bp_bx, mov_bp_sp, loop, mov_bp_si, mov_bp_di
	.word mov_si_ax, mov_si_cx, mov_si_dx, mov_si_bx, mov_si_sp, mov_si_bp, loop, mov_si_di
	.word mov_di_ax, mov_di_cx, mov_di_dx, mov_di_bx, mov_di_sp, mov_di_bp, mov_di_si, loop

// These are called from "cpu_67.s":

	.global mov_ax_siidx, mov_ax_diidx, mov_ax_bxidx
	.global mov_cx_siidx, mov_cx_diidx, mov_cx_bxidx
	.global mov_dx_siidx, mov_dx_diidx, mov_dx_bxidx
	.global mov_bx_siidx, mov_bx_diidx, mov_bx_bxidx
	.global mov_sp_siidx, mov_sp_diidx, mov_sp_bxidx
	.global mov_bp_siidx, mov_bp_diidx, mov_bp_bxidx
	.global mov_si_siidx, mov_si_diidx, mov_si_bxidx
	.global mov_di_siidx, mov_di_diidx, mov_di_bxidx
	.global mov_ax_sidisp8, mov_ax_didisp8, mov_ax_bpdisp8, mov_ax_bxdisp8
	.global mov_cx_sidisp8, mov_cx_didisp8, mov_cx_bpdisp8, mov_cx_bxdisp8
	.global mov_dx_sidisp8, mov_dx_didisp8, mov_dx_bpdisp8, mov_dx_bxdisp8
	.global mov_bx_sidisp8, mov_bx_didisp8, mov_bx_bpdisp8, mov_bx_bxdisp8
	.global mov_sp_sidisp8, mov_sp_didisp8, mov_sp_bpdisp8, mov_sp_bxdisp8
	.global mov_bp_sidisp8, mov_bp_didisp8, mov_bp_bpdisp8, mov_bp_bxdisp8
	.global mov_si_sidisp8, mov_si_didisp8, mov_si_bpdisp8, mov_si_bxdisp8
	.global mov_di_sidisp8, mov_di_didisp8, mov_di_bpdisp8, mov_di_bxdisp8
	.global	mov_r16_r0_bp_r4, mov_r16_r0_bp_r5, mov_r16_r0_bp_r6, mov_r16_r0_bp_r7, mov_r16_r0_bp_r8, mov_r16_r0_bp_r9, mov_r16_r0_bp_r10, mov_r16_r0_bp_r11
	.global	mov_r16_r0_r4, mov_r16_r0_r5, mov_r16_r0_r6, mov_r16_r0_r7, mov_r16_r0_r8, mov_r16_r0_r9, mov_r16_r0_r10, mov_r16_r0_r11

.macro mov_reg16_r0 reg
mov_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
mov_r16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 1f op_8b_EGA_\reg op_8b_MODEX_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
1:	ldrb	r0,[r2]					// Get the byte from RAM
	ldrb	r1,[r2, #1]				// Get the byte from RAM
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, \reg, lsl #16
	orr		\reg, r1, lsl #8
#else
	bfi		\reg, r0, #0, #8
	bfi		\reg, r1, #8, #8
#endif
	b		loop
.endm

	mov_reg16_r0 eax
	mov_reg16_r0 ecx
	mov_reg16_r0 edx
	mov_reg16_r0 ebx
	mov_reg16_r0 esp
	mov_reg16_r0 ebp
	mov_reg16_r0 esi
	mov_reg16_r0 edi

// --- [idx] ---

.macro mov_reg16_bxidx reg idx
	add		r0, r7, \idx
	b		mov_r16_r0_\reg
.endm

mov_ax_bxsi:
	mov_reg16_bxidx r4 r10
mov_cx_bxsi:
	mov_reg16_bxidx r5 r10
mov_dx_bxsi:
	mov_reg16_bxidx r6 r10
mov_bx_bxsi:
	mov_reg16_bxidx r7 r10
mov_bp_bxsi:
	mov_reg16_bxidx r9 r10
mov_sp_bxsi:
	mov_reg16_bxidx r8 r10
mov_si_bxsi:
	mov_reg16_bxidx r10 r10
mov_di_bxsi:
	mov_reg16_bxidx r11 r10

mov_ax_bxdi:
	mov_reg16_bxidx r4 r11
mov_cx_bxdi:
	mov_reg16_bxidx r5 r11
mov_dx_bxdi:
	mov_reg16_bxidx r6 r11
mov_bx_bxdi:
	mov_reg16_bxidx r7 r11
mov_sp_bxdi:
	mov_reg16_bxidx r8 r11
mov_bp_bxdi:
	mov_reg16_bxidx r9 r11
mov_si_bxdi:
	mov_reg16_bxidx r10 r11
mov_di_bxdi:
	mov_reg16_bxidx r11 r11

.macro mov_reg16_bpidx reg idx
	add		r0, r9, \idx
	b		mov_r16_r0_bp_\reg
.endm

mov_ax_bpsi:
	mov_reg16_bpidx r4 r10
mov_cx_bpsi:
	mov_reg16_bpidx r5 r10
mov_dx_bpsi:
	mov_reg16_bpidx r6 r10
mov_bx_bpsi:
	mov_reg16_bpidx r7 r10
mov_sp_bpsi:
	mov_reg16_bpidx r8 r10
mov_bp_bpsi:
	mov_reg16_bpidx r9 r10
mov_si_bpsi:
	mov_reg16_bpidx r10 r10
mov_di_bpsi:
	mov_reg16_bpidx r11 r10

mov_ax_bpdi:
	mov_reg16_bpidx r4 r11
mov_cx_bpdi:
	mov_reg16_bpidx r5 r11
mov_dx_bpdi:
	mov_reg16_bpidx r6 r11
mov_bx_bpdi:
	mov_reg16_bpidx r7 r11
mov_sp_bpdi:
	mov_reg16_bpidx r8 r11
mov_bp_bpdi:
	mov_reg16_bpidx r9 r11
mov_si_bpdi:
	mov_reg16_bpidx r10 r11
mov_di_bpdi:
	mov_reg16_bpidx r11 r11

.macro mov_reg16_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		mov_r16_r0_\reg
.endm

mov_ax_siidx:
	mov_reg16_idx r4 r10
mov_cx_siidx:
	mov_reg16_idx r5 r10
mov_dx_siidx:
	mov_reg16_idx r6 r10
mov_bx_siidx:
	mov_reg16_idx r7 r10
mov_sp_siidx:
	mov_reg16_idx r8 r10
mov_bp_siidx:
	mov_reg16_idx r9 r10
mov_si_siidx:
	mov_reg16_idx r10 r10
mov_di_siidx:
	mov_reg16_idx r11 r10

mov_ax_diidx:
	mov_reg16_idx r4 r11
mov_cx_diidx:
	mov_reg16_idx r5 r11
mov_dx_diidx:
	mov_reg16_idx r6 r11
mov_bx_diidx:
	mov_reg16_idx r7 r11
mov_sp_diidx:
	mov_reg16_idx r8 r11
mov_bp_diidx:
	mov_reg16_idx r9 r11
mov_si_diidx:
	mov_reg16_idx r10 r11
mov_di_diidx:
	mov_reg16_idx r11 r11

mov_ax_bxidx:
	mov_reg16_idx r4 r7
mov_cx_bxidx:
	mov_reg16_idx r5 r7
mov_dx_bxidx:
	mov_reg16_idx r6 r7
mov_bx_bxidx:
	mov_reg16_idx r7 r7
mov_sp_bxidx:
	mov_reg16_idx r8 r7
mov_bp_bxidx:
	mov_reg16_idx r9 r7
mov_si_bxidx:
	mov_reg16_idx r10 r7
mov_di_bxidx:
	mov_reg16_idx r11 r7

.macro mov_reg16_disp16 reg
	r0_from_disp16
	b		mov_r16_r0_\reg
.endm

	.global	op_a1
op_a1:
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
mov_ax_disp16:
	mov_reg16_disp16 r4
mov_cx_disp16:
	mov_reg16_disp16 r5
mov_dx_disp16:
	mov_reg16_disp16 r6
mov_bx_disp16:
	mov_reg16_disp16 r7
mov_sp_disp16:
	mov_reg16_disp16 r8
mov_bp_disp16:
	mov_reg16_disp16 r9
mov_si_disp16:
	mov_reg16_disp16 r10
mov_di_disp16:
	mov_reg16_disp16 r11

// --- [idx+disp8] ---

.macro mov_reg16_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		mov_r16_r0_\reg
.endm

mov_ax_bxsid8:
	mov_reg16_bxidxdisp8 r4 r10
mov_cx_bxsid8:
	mov_reg16_bxidxdisp8 r5 r10
mov_dx_bxsid8:
	mov_reg16_bxidxdisp8 r6 r10
mov_bx_bxsid8:
	mov_reg16_bxidxdisp8 r7 r10
mov_sp_bxsid8:
	mov_reg16_bxidxdisp8 r8 r10
mov_bp_bxsid8:
	mov_reg16_bxidxdisp8 r9 r10
mov_si_bxsid8:
	mov_reg16_bxidxdisp8 r10 r10
mov_di_bxsid8:
	mov_reg16_bxidxdisp8 r11 r10

mov_ax_bxdid8:
	mov_reg16_bxidxdisp8 r4 r11
mov_cx_bxdid8:
	mov_reg16_bxidxdisp8 r5 r11
mov_dx_bxdid8:
	mov_reg16_bxidxdisp8 r6 r11
mov_bx_bxdid8:
	mov_reg16_bxidxdisp8 r7 r11
mov_sp_bxdid8:
	mov_reg16_bxidxdisp8 r8 r11
mov_bp_bxdid8:
	mov_reg16_bxidxdisp8 r9 r11
mov_si_bxdid8:
	mov_reg16_bxidxdisp8 r10 r11
mov_di_bxdid8:
	mov_reg16_bxidxdisp8 r11 r11

.macro mov_reg16_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		mov_r16_r0_bp_\reg
.endm

mov_ax_bpsid8:
	mov_reg16_bpidxdisp8 r4 r10
mov_cx_bpsid8:
	mov_reg16_bpidxdisp8 r5 r10
mov_dx_bpsid8:
	mov_reg16_bpidxdisp8 r6 r10
mov_bx_bpsid8:
	mov_reg16_bpidxdisp8 r7 r10
mov_sp_bpsid8:
	mov_reg16_bpidxdisp8 r8 r10
mov_bp_bpsid8:
	mov_reg16_bpidxdisp8 r9 r10
mov_si_bpsid8:
	mov_reg16_bpidxdisp8 r10 r10
mov_di_bpsid8:
	mov_reg16_bpidxdisp8 r11 r10

mov_ax_bpdid8:
	mov_reg16_bpidxdisp8 r4 r11
mov_cx_bpdid8:
	mov_reg16_bpidxdisp8 r5 r11
mov_dx_bpdid8:
	mov_reg16_bpidxdisp8 r6 r11
mov_bx_bpdid8:
	mov_reg16_bpidxdisp8 r7 r11
mov_sp_bpdid8:
	mov_reg16_bpidxdisp8 r8 r11
mov_bp_bpdid8:
	mov_reg16_bpidxdisp8 r9 r11
mov_si_bpdid8:
	mov_reg16_bpidxdisp8 r10 r11
mov_di_bpdid8:
	mov_reg16_bpidxdisp8 r11 r11

.macro mov_reg16_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		mov_r16_r0_\reg
.endm

mov_ax_sidisp8:
	mov_reg16_idxdisp8 r4 r10
mov_cx_sidisp8:
	mov_reg16_idxdisp8 r5 r10
mov_dx_sidisp8:
	mov_reg16_idxdisp8 r6 r10
mov_bx_sidisp8:
	mov_reg16_idxdisp8 r7 r10
mov_sp_sidisp8:
	mov_reg16_idxdisp8 r8 r10
mov_bp_sidisp8:
	mov_reg16_idxdisp8 r9 r10
mov_si_sidisp8:
	mov_reg16_idxdisp8 r10 r10
mov_di_sidisp8:
	mov_reg16_idxdisp8 r11 r10

mov_ax_didisp8:
	mov_reg16_idxdisp8 r4 r11
mov_cx_didisp8:
	mov_reg16_idxdisp8 r5 r11
mov_dx_didisp8:
	mov_reg16_idxdisp8 r6 r11
mov_bx_didisp8:
	mov_reg16_idxdisp8 r7 r11
mov_sp_didisp8:
	mov_reg16_idxdisp8 r8 r11
mov_bp_didisp8:
	mov_reg16_idxdisp8 r9 r11
mov_si_didisp8:
	mov_reg16_idxdisp8 r10 r11
mov_di_didisp8:
	mov_reg16_idxdisp8 r11 r11

mov_ax_bxdisp8:
	mov_reg16_idxdisp8 r4 r7
mov_cx_bxdisp8:
	mov_reg16_idxdisp8 r5 r7
mov_dx_bxdisp8:
	mov_reg16_idxdisp8 r6 r7
mov_bx_bxdisp8:
	mov_reg16_idxdisp8 r7 r7
mov_sp_bxdisp8:
	mov_reg16_idxdisp8 r8 r7
mov_bp_bxdisp8:
	mov_reg16_idxdisp8 r9 r7
mov_si_bxdisp8:
	mov_reg16_idxdisp8 r10 r7
mov_di_bxdisp8:
	mov_reg16_idxdisp8 r11 r7

.macro mov_reg16_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		mov_r16_r0_bp_\reg
.endm

mov_ax_bpdisp8:
	mov_reg16_bpdisp8 r4
mov_cx_bpdisp8:
	mov_reg16_bpdisp8 r5
mov_dx_bpdisp8:
	mov_reg16_bpdisp8 r6
mov_bx_bpdisp8:
	mov_reg16_bpdisp8 r7
mov_sp_bpdisp8:
	mov_reg16_bpdisp8 r8
mov_bp_bpdisp8:
	mov_reg16_bpdisp8 r9
mov_si_bpdisp8:
	mov_reg16_bpdisp8 r10
mov_di_bpdisp8:
	mov_reg16_bpdisp8 r11

// --- [idx+disp16] ---

.macro mov_reg16_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		mov_r16_r0_\reg
.endm

mov_ax_bxsid16:
	mov_reg16_bxidxdisp16 r4 r10
mov_cx_bxsid16:
	mov_reg16_bxidxdisp16 r5 r10
mov_dx_bxsid16:
	mov_reg16_bxidxdisp16 r6 r10
mov_bx_bxsid16:
	mov_reg16_bxidxdisp16 r7 r10
mov_sp_bxsid16:
	mov_reg16_bxidxdisp16 r8 r10
mov_bp_bxsid16:
	mov_reg16_bxidxdisp16 r9 r10
mov_si_bxsid16:
	mov_reg16_bxidxdisp16 r10 r10
mov_di_bxsid16:
	mov_reg16_bxidxdisp16 r11 r10

mov_ax_bxdid16:
	mov_reg16_bxidxdisp16 r4 r11
mov_cx_bxdid16:
	mov_reg16_bxidxdisp16 r5 r11
mov_dx_bxdid16:
	mov_reg16_bxidxdisp16 r6 r11
mov_bx_bxdid16:
	mov_reg16_bxidxdisp16 r7 r11
mov_sp_bxdid16:
	mov_reg16_bxidxdisp16 r8 r11
mov_bp_bxdid16:
	mov_reg16_bxidxdisp16 r9 r11
mov_si_bxdid16:
	mov_reg16_bxidxdisp16 r10 r11
mov_di_bxdid16:
	mov_reg16_bxidxdisp16 r11 r11

.macro mov_reg16_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		mov_r16_r0_bp_\reg
.endm

mov_ax_bpsid16:
	mov_reg16_bpidxdisp16 r4 r10
mov_cx_bpsid16:
	mov_reg16_bpidxdisp16 r5 r10
mov_dx_bpsid16:
	mov_reg16_bpidxdisp16 r6 r10
mov_bx_bpsid16:
	mov_reg16_bpidxdisp16 r7 r10
mov_sp_bpsid16:
	mov_reg16_bpidxdisp16 r8 r10
mov_bp_bpsid16:
	mov_reg16_bpidxdisp16 r9 r10
mov_si_bpsid16:
	mov_reg16_bpidxdisp16 r10 r10
mov_di_bpsid16:
	mov_reg16_bpidxdisp16 r11 r10

mov_ax_bpdid16:
	mov_reg16_bpidxdisp16 r4 r11
mov_cx_bpdid16:
	mov_reg16_bpidxdisp16 r5 r11
mov_dx_bpdid16:
	mov_reg16_bpidxdisp16 r6 r11
mov_bx_bpdid16:
	mov_reg16_bpidxdisp16 r7 r11
mov_sp_bpdid16:
	mov_reg16_bpidxdisp16 r8 r11
mov_bp_bpdid16:
	mov_reg16_bpidxdisp16 r9 r11
mov_si_bpdid16:
	mov_reg16_bpidxdisp16 r10 r11
mov_di_bpdid16:
	mov_reg16_bpidxdisp16 r11 r11

.macro mov_reg16_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		mov_r16_r0_\reg
.endm

mov_ax_sidisp16:
	mov_reg16_idxdisp16 r4 r10
mov_cx_sidisp16:
	mov_reg16_idxdisp16 r5 r10
mov_dx_sidisp16:
	mov_reg16_idxdisp16 r6 r10
mov_bx_sidisp16:
	mov_reg16_idxdisp16 r7 r10
mov_sp_sidisp16:
	mov_reg16_idxdisp16 r8 r10
mov_bp_sidisp16:
	mov_reg16_idxdisp16 r9 r10
mov_si_sidisp16:
	mov_reg16_idxdisp16 r10 r10
mov_di_sidisp16:
	mov_reg16_idxdisp16 r11 r10

mov_ax_didisp16:
	mov_reg16_idxdisp16 r4 r11
mov_cx_didisp16:
	mov_reg16_idxdisp16 r5 r11
mov_dx_didisp16:
	mov_reg16_idxdisp16 r6 r11
mov_bx_didisp16:
	mov_reg16_idxdisp16 r7 r11
mov_sp_didisp16:
	mov_reg16_idxdisp16 r8 r11
mov_bp_didisp16:
	mov_reg16_idxdisp16 r9 r11
mov_si_didisp16:
	mov_reg16_idxdisp16 r10 r11
mov_di_didisp16:
	mov_reg16_idxdisp16 r11 r11

mov_ax_bxdisp16:
	mov_reg16_idxdisp16 r4 r7
mov_cx_bxdisp16:
	mov_reg16_idxdisp16 r5 r7
mov_dx_bxdisp16:
	mov_reg16_idxdisp16 r6 r7
mov_bx_bxdisp16:
	mov_reg16_idxdisp16 r7 r7
mov_sp_bxdisp16:
	mov_reg16_idxdisp16 r8 r7
mov_bp_bxdisp16:
	mov_reg16_idxdisp16 r9 r7
mov_si_bxdisp16:
	mov_reg16_idxdisp16 r10 r7
mov_di_bxdisp16:
	mov_reg16_idxdisp16 r11 r7

.macro mov_reg16_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		mov_r16_r0_bp_\reg
.endm

mov_ax_bpdisp16:
	mov_reg16_bpdisp16 r4
mov_cx_bpdisp16:
	mov_reg16_bpdisp16 r5
mov_dx_bpdisp16:
	mov_reg16_bpdisp16 r6
mov_bx_bpdisp16:
	mov_reg16_bpdisp16 r7
mov_sp_bpdisp16:
	mov_reg16_bpdisp16 r8
mov_bp_bpdisp16:
	mov_reg16_bpdisp16 r9
mov_si_bpdisp16:
	mov_reg16_bpdisp16 r10
mov_di_bpdisp16:
	mov_reg16_bpdisp16 r11


// --- registers ---

.macro mov_reg16_reg16 rl rr
#if defined(RPi) || defined(Roku)
	lsr		\rl, #16
	orr		\rl, \rr, lsl #16
	ror		\rl, #16
#else
	bfi		\rl, \rr, #0, #16
#endif
	b		loop
.endm

mov_ax_cx:
	mov_reg16_reg16		r4 r5
mov_ax_dx:
	mov_reg16_reg16		r4 r6
mov_ax_bx:
	mov_reg16_reg16		r4 r7
mov_ax_sp:
	mov_reg16_reg16		r4 r8
mov_ax_bp:
	mov_reg16_reg16		r4 r9
mov_ax_si:
	mov_reg16_reg16		r4 r10
mov_ax_di:
	mov_reg16_reg16		r4 r11
mov_cx_ax:
	mov_reg16_reg16		r5 r4
mov_cx_dx:
	mov_reg16_reg16		r5 r6
mov_cx_bx:
	mov_reg16_reg16		r5 r7
mov_cx_sp:
	mov_reg16_reg16		r5 r8
mov_cx_bp:
	mov_reg16_reg16		r5 r9
mov_cx_si:
	mov_reg16_reg16		r5 r10
mov_cx_di:
	mov_reg16_reg16		r5 r11
mov_dx_ax:
	mov_reg16_reg16		r6 r4
mov_dx_cx:
	mov_reg16_reg16		r6 r5
mov_dx_bx:
	mov_reg16_reg16		r6 r7
mov_dx_sp:
	mov_reg16_reg16		r6 r8
mov_dx_bp:
	mov_reg16_reg16		r6 r9
mov_dx_si:
	mov_reg16_reg16		r6 r10
mov_dx_di:
	mov_reg16_reg16		r6 r11
mov_bx_ax:
	mov_reg16_reg16		r7 r4
mov_bx_cx:
	mov_reg16_reg16		r7 r5
mov_bx_dx:
	mov_reg16_reg16		r7 r6
mov_bx_sp:
	mov_reg16_reg16		r7 r8
mov_bx_bp:
	mov_reg16_reg16		r7 r9
mov_bx_si:
	mov_reg16_reg16		r7 r10
mov_bx_di:
	mov_reg16_reg16		r7 r11
mov_sp_ax:
	mov_reg16_reg16		r8 r4
mov_sp_cx:
	mov_reg16_reg16		r8 r5
mov_sp_dx:
	mov_reg16_reg16		r8 r6
mov_sp_bx:
	mov_reg16_reg16		r8 r7
mov_sp_bp:
	mov_reg16_reg16		r8 r9
mov_sp_si:
	mov_reg16_reg16		r8 r10
mov_sp_di:
	mov_reg16_reg16		r8 r11
mov_bp_ax:
	mov_reg16_reg16		r9 r4
mov_bp_cx:
	mov_reg16_reg16		r9 r5
mov_bp_dx:
	mov_reg16_reg16		r9 r6
mov_bp_bx:
	mov_reg16_reg16		r9 r7
mov_bp_sp:
	mov_reg16_reg16		r9 r8
mov_bp_si:
	mov_reg16_reg16		r9 r10
mov_bp_di:
	mov_reg16_reg16		r9 r11
mov_si_ax:
	mov_reg16_reg16		r10 r4
mov_si_cx:
	mov_reg16_reg16		r10 r5
mov_si_dx:
	mov_reg16_reg16		r10 r6
mov_si_bx:
	mov_reg16_reg16		r10 r7
mov_si_sp:
	mov_reg16_reg16		r10 r8
mov_si_bp:
	mov_reg16_reg16		r10 r9
mov_si_di:
	mov_reg16_reg16		r10 r11
mov_di_ax:
	mov_reg16_reg16		r11 r4
mov_di_cx:
	mov_reg16_reg16		r11 r5
mov_di_dx:
	mov_reg16_reg16		r11 r6
mov_di_bx:
	mov_reg16_reg16		r11 r7
mov_di_sp:
	mov_reg16_reg16		r11 r8
mov_di_bp:
	mov_reg16_reg16		r11 r9
mov_di_si:
	mov_reg16_reg16		r11 r10

// ------------------- 8C = MOV r/m16,Sreg -----------------------------
//
// All modrm variations supported!
//
// We must not change the flags here!!!
//
op_8c:
	modrm_jump_16
.macro tmp sreg
	.global mov_bxsi_\sreg, mov_bxdi_\sreg, mov_bpsi_\sreg, mov_bpdi_\sreg, mov_siidx_\sreg, mov_diidx_\sreg, mov_disp16_\sreg, mov_bxidx_\sreg
	.word mov_bxsi_\sreg, mov_bxdi_\sreg, mov_bpsi_\sreg, mov_bpdi_\sreg, mov_siidx_\sreg, mov_diidx_\sreg, mov_disp16_\sreg, mov_bxidx_\sreg
.endm
// 0
	tmp es
	tmp cs
	tmp ss
	tmp ds
	tmp fs
	tmp gs
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
.purgem tmp
.macro tmp sreg
	.global mov_bxsid8_\sreg, mov_bxdid8_\sreg, mov_bpsid8_\sreg, mov_bpdid8_\sreg, mov_sidisp8_\sreg, mov_didisp8_\sreg, mov_bpdisp8_\sreg, mov_bxdisp8_\sreg
	.word mov_bxsid8_\sreg, mov_bxdid8_\sreg, mov_bpsid8_\sreg, mov_bpdid8_\sreg, mov_sidisp8_\sreg, mov_didisp8_\sreg, mov_bpdisp8_\sreg, mov_bxdisp8_\sreg
.endm
//0x40
	tmp es
	tmp cs
	tmp ss
	tmp ds
	tmp fs
	tmp gs
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
.purgem tmp
.macro tmp sreg
	.global mov_bxsid16_\sreg, mov_bxdid16_\sreg, mov_bpsid16_\sreg, mov_bpdid16_\sreg, mov_sidisp16_\sreg, mov_didisp16_\sreg, mov_bpdisp16_\sreg, mov_bxdisp16_\sreg
	.word mov_bxsid16_\sreg, mov_bxdid16_\sreg, mov_bpsid16_\sreg, mov_bpdid16_\sreg, mov_sidisp16_\sreg, mov_didisp16_\sreg, mov_bpdisp16_\sreg, mov_bxdisp16_\sreg
.endm
//0x80
	tmp es
	tmp cs
	tmp ss
	tmp ds
	tmp fs
	tmp gs
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
.purgem tmp
// 0xC0 = mod = 11b = register
// ES
	.word mov_ax_es, mov_cx_es, mov_dx_es, mov_bx_es, mov_sp_es, mov_bp_es, mov_si_es, mov_di_es
// CS	
	.word mov_ax_cs, mov_cx_cs, mov_dx_cs, mov_bx_cs, mov_sp_cs, mov_bp_cs, mov_si_cs, mov_di_cs
// SS	
	.word mov_ax_ss, mov_cx_ss, mov_dx_ss, mov_bx_ss, mov_sp_ss, mov_bp_ss, mov_si_ss, mov_di_ss
// DS	
	.word mov_ax_ds, mov_cx_ds, mov_dx_ds, mov_bx_ds, mov_sp_ds, mov_bp_ds, mov_si_ds, mov_di_ds
// FS (386+ only!)	
	.word mov_ax_fs, mov_cx_fs, mov_dx_fs, mov_bx_fs, mov_sp_fs, mov_bp_fs, mov_si_fs, mov_di_fs
// GS (386+ only!)	
	.word mov_ax_gs, mov_cx_gs, mov_dx_gs, mov_bx_gs, mov_sp_gs, mov_bp_gs, mov_si_gs, mov_di_gs
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1

	.global mov_ax_es, mov_cx_es, mov_dx_es, mov_bx_es, mov_sp_es, mov_bp_es, mov_si_es, mov_di_es
	.global mov_ax_cs, mov_cx_cs, mov_dx_cs, mov_bx_cs, mov_sp_cs, mov_bp_cs, mov_si_cs, mov_di_cs
	.global mov_ax_ss, mov_cx_ss, mov_dx_ss, mov_bx_ss, mov_sp_ss, mov_bp_ss, mov_si_ss, mov_di_ss
	.global mov_ax_ds, mov_cx_ds, mov_dx_ds, mov_bx_ds, mov_sp_ds, mov_bp_ds, mov_si_ds, mov_di_ds
	.global mov_ax_fs, mov_cx_fs, mov_dx_fs, mov_bx_fs, mov_sp_fs, mov_bp_fs, mov_si_fs, mov_di_fs
	.global mov_ax_gs, mov_cx_gs, mov_dx_gs, mov_bx_gs, mov_sp_gs, mov_bp_gs, mov_si_gs, mov_di_gs

	.global	mov_r0_bp_es
mov_r0_bp_es:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_es
mov_r0_es:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8c_RAM_es bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8c_RAM_es:
	ldr		r1, [sp, #SP_ES_VALUE]	// r1 = Current logical ES
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	b		loop

	.global	mov_r0_bp_cs
mov_r0_bp_cs:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_cs
mov_r0_cs:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8c_RAM_cs bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8c_RAM_cs:
	ldr		r1, [sp, #SP_CS_VALUE]	// r1 = Current logical CS
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	b		loop

	.global	mov_r0_bp_ss
mov_r0_bp_ss:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_ss
mov_r0_ss:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8c_RAM_ss bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8c_RAM_ss:
	ldr		r1, [sp, #SP_SS_VALUE]
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	b		loop

	.global	mov_r0_bp_ds
mov_r0_bp_ds:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_ds
mov_r0_ds:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8c_RAM_ds bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8c_RAM_ds:
	ldr		r1, [sp, #SP_DS_VALUE]	
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	b		loop

	.global	mov_r0_bp_fs
mov_r0_bp_fs:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_fs
mov_r0_fs:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8c_RAM_fs bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8c_RAM_fs:
	ldr		r1, [sp, #SP_FS_VALUE]	
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	b		loop

	.global	mov_r0_bp_gs
mov_r0_bp_gs:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_gs
mov_r0_gs:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8c_RAM_gs bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8c_RAM_gs:
	ldr		r1, [sp, #SP_GS_VALUE]	
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	b		loop

.macro op8cgenall sreg

// -- [idx] --

mov_bxsi_\sreg:
	add		r0, r7, r10
	b		mov_r0_\sreg
mov_bxdi_\sreg:
	add		r0, r7, r11
	b		mov_r0_\sreg
mov_bpsi_\sreg:
	add		r0, r9, r10
	b		mov_r0_bp_\sreg
mov_bpdi_\sreg:
	add		r0, r9, r11
	b		mov_r0_bp_\sreg
mov_siidx_\sreg:
	mov		r0, r10
	b		mov_r0_\sreg
mov_diidx_\sreg:
	mov		r0, r11
	b		mov_r0_\sreg
mov_disp16_\sreg:
	r0_from_disp16
	b		mov_r0_\sreg
mov_bxidx_\sreg:
	mov		r0, r7
	b		mov_r0_\sreg

// -- [idx+disp8] --

mov_bxsid8_\sreg:
	r0_from_bxidxdisp8 r10
	b		mov_r0_\sreg
mov_bxdid8_\sreg:
	r0_from_bxidxdisp8 r11
	b		mov_r0_\sreg
mov_bpsid8_\sreg:
	r0_from_bpidxdisp8 r10
	b		mov_r0_bp_\sreg
mov_bpdid8_\sreg:
	r0_from_bpidxdisp8 r11
	b		mov_r0_bp_\sreg
mov_sidisp8_\sreg:
	r0_from_idx_disp8 r10
	b		mov_r0_\sreg
mov_didisp8_\sreg:
	r0_from_idx_disp8 r11
	b		mov_r0_\sreg
mov_bpdisp8_\sreg:
	r0_from_idx_disp8 r9
	b		mov_r0_bp_\sreg
mov_bxdisp8_\sreg:
	r0_from_idx_disp8 r7
	b		mov_r0_\sreg

// -- [idx+disp16] --

mov_bxsid16_\sreg:
	r0_from_bxidxdisp16 r10
	b		mov_r0_\sreg
mov_bxdid16_\sreg:
	r0_from_bxidxdisp16 r11
	b		mov_r0_\sreg
mov_bpsid16_\sreg:
	r0_from_bpidxdisp16 r10
	b		mov_r0_bp_\sreg
mov_bpdid16_\sreg:
	r0_from_bpidxdisp16 r11
	b		mov_r0_bp_\sreg
mov_sidisp16_\sreg:
	r0_from_idx_disp16 r10
	b		mov_r0_\sreg
mov_didisp16_\sreg:
	r0_from_idx_disp16 r11
	b		mov_r0_\sreg
mov_bpdisp16_\sreg:
	r0_from_idx_disp16 r9
	b		mov_r0_bp_\sreg
mov_bxdisp16_\sreg:
	r0_from_idx_disp16 r7
	b		mov_r0_\sreg

.endm

// --- ES ---

	op8cgenall es

.macro mov_reg_es reg
	ldr		r0, [sp, #SP_ES_VALUE]
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
	b		loop
.endm

mov_ax_es:
	mov_reg_es r4
mov_cx_es:
	mov_reg_es r5
mov_dx_es:
	mov_reg_es r6
mov_bx_es:
	mov_reg_es r7
mov_sp_es:
	mov_reg_es	r8
mov_bp_es:
	mov_reg_es r9
mov_si_es:
	mov_reg_es r10
mov_di_es:
	mov_reg_es r11

// --- CS ---

	op8cgenall cs

.macro mov_reg_cs reg
	ldr		r0, [sp, #SP_CS_VALUE]
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm
	
mov_ax_cs:
	mov_reg_cs	r4
mov_cx_cs:
	mov_reg_cs	r5
mov_dx_cs:
	mov_reg_cs	r6
mov_bx_cs:
	mov_reg_cs	r7
mov_sp_cs:
	mov_reg_cs	r8
mov_bp_cs:
	mov_reg_cs	r9
mov_si_cs:
	mov_reg_cs	r10
mov_di_cs:
	mov_reg_cs	r11

// --- SS ---

	op8cgenall ss

.macro mov_reg_ss reg
	ldr		r0, [sp, #SP_SS_VALUE]
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

mov_ax_ss:
	mov_reg_ss 	r4
mov_cx_ss:
	mov_reg_ss	r5
mov_dx_ss:
	mov_reg_ss	r6
mov_bx_ss:
	mov_reg_ss	r7
mov_sp_ss:
	mov_reg_ss	r8
mov_bp_ss:
	mov_reg_ss	r9
mov_si_ss:
	mov_reg_ss	r10
mov_di_ss:
	mov_reg_ss	r11

// --- DS ---

	op8cgenall ds

.macro mov_reg_ds reg
	ldr		r0, [sp, #SP_DS_VALUE]
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

mov_ax_ds:
	mov_reg_ds	r4
mov_cx_ds:
	mov_reg_ds	r5
mov_dx_ds:
	mov_reg_ds	r6
mov_bx_ds:
	mov_reg_ds	r7
mov_sp_ds:
	mov_reg_ds	r8
mov_bp_ds:
	mov_reg_ds	r9
mov_si_ds:
	mov_reg_ds	r10
mov_di_ds:
	mov_reg_ds	r11

// --- FS ---

	op8cgenall fs

.macro mov_reg_fs reg
	ldr		r0, [sp, #SP_FS_VALUE]
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

mov_ax_fs:
	mov_reg_fs	r4
mov_cx_fs:
	mov_reg_fs	r5
mov_dx_fs:
	mov_reg_fs	r6
mov_bx_fs:
	mov_reg_fs	r7
mov_sp_fs:
	mov_reg_fs	r8
mov_bp_fs:
	mov_reg_fs	r9
mov_si_fs:
	mov_reg_fs	r10
mov_di_fs:
	mov_reg_fs	r11

// --- GS ---

	op8cgenall gs

.macro mov_reg_gs reg
	ldr		r0, [sp, #SP_GS_VALUE]
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

mov_ax_gs:
	mov_reg_gs	r4
mov_cx_gs:
	mov_reg_gs	r5
mov_dx_gs:
	mov_reg_gs	r6
mov_bx_gs:
	mov_reg_gs	r7
mov_sp_gs:
	mov_reg_gs	r8
mov_bp_gs:
	mov_reg_gs	r9
mov_si_gs:
	mov_reg_gs	r10
mov_di_gs:
	mov_reg_gs	r11

.ltorg								// Dump the current literal pool here

// ------------------- 8D = LEA r16,m ----------------------------------
//
// All modrm variations supported!
//
op_8d:
	ldrb	r0,[r12],#1							// Load the second opcode byte to r0, increment r12 by 1
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8

// 0
	.word lea_ax_bxsi, lea_ax_bxdi, lea_ax_bpsi, lea_ax_bpdi, mov_ax_si, mov_ax_di, lea_ax_disp16, mov_ax_bx
	.word lea_cx_bxsi, lea_cx_bxdi, lea_cx_bpsi, lea_cx_bpdi, mov_cx_si, mov_cx_di, lea_cx_disp16, mov_cx_bx
	.word lea_dx_bxsi, lea_dx_bxdi, lea_dx_bpsi, lea_dx_bpdi, mov_dx_si, mov_dx_di, lea_dx_disp16, mov_dx_bx
	.word lea_bx_bxsi, lea_bx_bxdi, lea_bx_bpsi, lea_bx_bpdi, mov_bx_si, mov_bx_di, lea_bx_disp16, loop
	.word lea_sp_bxsi, lea_sp_bxdi, lea_sp_bpsi, lea_sp_bpdi, mov_sp_si, mov_sp_di, lea_sp_disp16, mov_sp_bx
	.word lea_bp_bxsi, lea_bp_bxdi, lea_bp_bpsi, lea_bp_bpdi, mov_bp_si, mov_bp_di, lea_bp_disp16, mov_bp_bx
	.word lea_si_bxsi, lea_si_bxdi, lea_si_bpsi, lea_si_bpdi, loop, mov_si_di, lea_si_disp16, mov_si_bx
	.word lea_di_bxsi, lea_di_bxdi, lea_di_bpsi, lea_di_bpdi, mov_di_si, loop, lea_di_disp16, mov_di_bx
//0x40
	.word lea_ax_bxsidisp8, lea_ax_bxdidisp8, lea_ax_bpsidisp8, lea_ax_bpdidisp8, lea_ax_sidisp8, lea_ax_didisp8, lea_ax_bpdisp8, lea_ax_bxdisp8
	.word lea_cx_bxsidisp8, lea_cx_bxdidisp8, lea_cx_bpsidisp8, lea_cx_bpdidisp8, lea_cx_sidisp8, lea_cx_didisp8, lea_cx_bpdisp8, lea_cx_bxdisp8
	.word lea_dx_bxsidisp8, lea_dx_bxdidisp8, lea_dx_bpsidisp8, lea_dx_bpdidisp8, lea_dx_sidisp8, lea_dx_didisp8, lea_dx_bpdisp8, lea_dx_bxdisp8
	.word lea_bx_bxsidisp8, lea_bx_bxdidisp8, lea_bx_bpsidisp8, lea_bx_bpdidisp8, lea_bx_sidisp8, lea_bx_didisp8, lea_bx_bpdisp8, lea_bx_bxdisp8
	.word lea_sp_bxsidisp8, lea_sp_bxdidisp8, lea_sp_bpsidisp8, lea_sp_bpdidisp8, lea_sp_sidisp8, lea_sp_didisp8, lea_sp_bpdisp8, lea_sp_bxdisp8
	.word lea_bp_bxsidisp8, lea_bp_bxdidisp8, lea_bp_bpsidisp8, lea_bp_bpdidisp8, lea_bp_sidisp8, lea_bp_didisp8, lea_bp_bpdisp8, lea_bp_bxdisp8
	.word lea_si_bxsidisp8, lea_si_bxdidisp8, lea_si_bpsidisp8, lea_si_bpdidisp8, lea_si_sidisp8, lea_si_didisp8, lea_si_bpdisp8, lea_si_bxdisp8
	.word lea_di_bxsidisp8, lea_di_bxdidisp8, lea_di_bpsidisp8, lea_di_bpdidisp8, lea_di_sidisp8, lea_di_didisp8, lea_di_bpdisp8, lea_di_bxdisp8
//0x80
	.word lea_ax_bxsidisp16, lea_ax_bxdidisp16, lea_ax_bpsidisp16, lea_ax_bpdidisp16, lea_ax_sidisp16, lea_ax_didisp16, lea_ax_bpdisp16, lea_ax_bxdisp16
	.word lea_cx_bxsidisp16, lea_cx_bxdidisp16, lea_cx_bpsidisp16, lea_cx_bpdidisp16, lea_cx_sidisp16, lea_cx_didisp16, lea_cx_bpdisp16, lea_cx_bxdisp16
	.word lea_dx_bxsidisp16, lea_dx_bxdidisp16, lea_dx_bpsidisp16, lea_dx_bpdidisp16, lea_dx_sidisp16, lea_dx_didisp16, lea_dx_bpdisp16, lea_dx_bxdisp16
	.word lea_bx_bxsidisp16, lea_bx_bxdidisp16, lea_bx_bpsidisp16, lea_bx_bpdidisp16, lea_bx_sidisp16, lea_bx_didisp16, lea_bx_bpdisp16, lea_bx_bxdisp16
	.word lea_sp_bxsidisp16, lea_sp_bxdidisp16, lea_sp_bpsidisp16, lea_sp_bpdidisp16, lea_sp_sidisp16, lea_sp_didisp16, lea_sp_bpdisp16, lea_sp_bxdisp16
	.word lea_bp_bxsidisp16, lea_bp_bxdidisp16, lea_bp_bpsidisp16, lea_bp_bpdidisp16, lea_bp_sidisp16, lea_bp_didisp16, lea_bp_bpdisp16, lea_bp_bxdisp16
	.word lea_si_bxsidisp16, lea_si_bxdidisp16, lea_si_bpsidisp16, lea_si_bpdidisp16, lea_si_sidisp16, lea_si_didisp16, lea_si_bpdisp16, lea_si_bxdisp16
	.word lea_di_bxsidisp16, lea_di_bxdidisp16, lea_di_bpsidisp16, lea_di_bpdidisp16, lea_di_sidisp16, lea_di_didisp16, lea_di_bpdisp16, lea_di_bxdisp16
// 0xC0 = mod = 11b = register (ILLEGAL INSTRUCTION!)
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1

// --- LEA reg16,[idx] ---
//
// Here segment override does not matter, we are only interested in the offset.
//

.macro lea_reg_idxidx reg idx1 idx2
	add		r0, \idx1, \idx2
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

lea_ax_bxsi:
	lea_reg_idxidx r4 r7 r10
lea_cx_bxsi:
	lea_reg_idxidx r5 r7 r10
lea_dx_bxsi:
	lea_reg_idxidx r6 r7 r10
lea_bx_bxsi:
	lea_reg_idxidx r7 r7 r10
lea_sp_bxsi:
	lea_reg_idxidx r8 r7 r10
lea_bp_bxsi:
	lea_reg_idxidx r9 r7 r10
lea_si_bxsi:
	lea_reg_idxidx r10 r7 r10
lea_di_bxsi:
	lea_reg_idxidx r11 r7 r10

lea_ax_bxdi:
	lea_reg_idxidx r4 r7 r11
lea_cx_bxdi:
	lea_reg_idxidx r5 r7 r11
lea_dx_bxdi:
	lea_reg_idxidx r6 r7 r11
lea_bx_bxdi:
	lea_reg_idxidx r7 r7 r11
lea_sp_bxdi:
	lea_reg_idxidx r8 r7 r11
lea_bp_bxdi:
	lea_reg_idxidx r9 r7 r11
lea_si_bxdi:
	lea_reg_idxidx r10 r7 r11
lea_di_bxdi:
	lea_reg_idxidx r11 r7 r11

lea_ax_bpsi:
	lea_reg_idxidx r4 r9 r10
lea_cx_bpsi:
	lea_reg_idxidx r5 r9 r10
lea_dx_bpsi:
	lea_reg_idxidx r6 r9 r10
lea_bx_bpsi:
	lea_reg_idxidx r7 r9 r10
lea_sp_bpsi:
	lea_reg_idxidx r8 r9 r10
lea_bp_bpsi:
	lea_reg_idxidx r9 r9 r10
lea_si_bpsi:
	lea_reg_idxidx r10 r9 r10
lea_di_bpsi:
	lea_reg_idxidx r11 r9 r10

lea_ax_bpdi:
	lea_reg_idxidx r4 r9 r11
lea_cx_bpdi:
	lea_reg_idxidx r5 r9 r11
lea_dx_bpdi:
	lea_reg_idxidx r6 r9 r11
lea_bx_bpdi:
	lea_reg_idxidx r7 r9 r11
lea_sp_bpdi:
	lea_reg_idxidx r8 r9 r11
lea_bp_bpdi:
	lea_reg_idxidx r9 r9 r11
lea_si_bpdi:
	lea_reg_idxidx r10 r9 r11
lea_di_bpdi:
	lea_reg_idxidx r11 r9 r11

.macro lea_reg_disp16 reg
	ldrb	r0,[r12],#1				// Load low byte to r0, increment r12 by 1
	ldrb	r1,[r12],#1				// Load high byte to r1, increment r12 by 1
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		r0, r1, lsl #8
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #8
	bfi		\reg, r1, #8, #8
#endif
	b		loop
.endm

lea_ax_disp16:
	lea_reg_disp16 r4
lea_cx_disp16:
	lea_reg_disp16 r5
lea_dx_disp16:
	lea_reg_disp16 r6
lea_bx_disp16:
	lea_reg_disp16 r7
lea_sp_disp16:
	lea_reg_disp16 r8
lea_bp_disp16:
	lea_reg_disp16 r9
lea_si_disp16:
	lea_reg_disp16 r10
lea_di_disp16:
	lea_reg_disp16 r11

// --- LEA reg16,[idx+disp8] ---
//
// Here segment override does not matter, we are only interested in the offset.
//

.macro lea_reg_idxidxdisp8 reg idx1 idx2
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	add		r0, \idx1, \idx2
	add		r0, r1
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

lea_ax_bxsidisp8:
	lea_reg_idxidxdisp8 r4 r7 r10
lea_cx_bxsidisp8:
	lea_reg_idxidxdisp8 r5 r7 r10
lea_dx_bxsidisp8:
	lea_reg_idxidxdisp8 r6 r7 r10
lea_bx_bxsidisp8:
	lea_reg_idxidxdisp8 r7 r7 r10
lea_sp_bxsidisp8:
	lea_reg_idxidxdisp8 r8 r7 r10
lea_bp_bxsidisp8:
	lea_reg_idxidxdisp8 r9 r7 r10
lea_si_bxsidisp8:
	lea_reg_idxidxdisp8 r10 r7 r10
lea_di_bxsidisp8:
	lea_reg_idxidxdisp8 r11 r7 r10

lea_ax_bxdidisp8:
	lea_reg_idxidxdisp8 r4 r7 r11
lea_cx_bxdidisp8:
	lea_reg_idxidxdisp8 r5 r7 r11
lea_dx_bxdidisp8:
	lea_reg_idxidxdisp8 r6 r7 r11
lea_bx_bxdidisp8:
	lea_reg_idxidxdisp8 r7 r7 r11
lea_sp_bxdidisp8:
	lea_reg_idxidxdisp8 r8 r7 r11
lea_bp_bxdidisp8:
	lea_reg_idxidxdisp8 r9 r7 r11
lea_si_bxdidisp8:
	lea_reg_idxidxdisp8 r10 r7 r11
lea_di_bxdidisp8:
	lea_reg_idxidxdisp8 r11 r7 r11

lea_ax_bpsidisp8:
	lea_reg_idxidxdisp8 r4 r9 r10
lea_cx_bpsidisp8:
	lea_reg_idxidxdisp8 r5 r9 r10
lea_dx_bpsidisp8:
	lea_reg_idxidxdisp8 r6 r9 r10
lea_bx_bpsidisp8:
	lea_reg_idxidxdisp8 r7 r9 r10
lea_sp_bpsidisp8:
	lea_reg_idxidxdisp8 r8 r9 r10
lea_bp_bpsidisp8:
	lea_reg_idxidxdisp8 r9 r9 r10
lea_si_bpsidisp8:
	lea_reg_idxidxdisp8 r10 r9 r10
lea_di_bpsidisp8:
	lea_reg_idxidxdisp8 r11 r9 r10

lea_ax_bpdidisp8:
	lea_reg_idxidxdisp8 r4 r9 r11
lea_cx_bpdidisp8:
	lea_reg_idxidxdisp8 r5 r9 r11
lea_dx_bpdidisp8:
	lea_reg_idxidxdisp8 r6 r9 r11
lea_bx_bpdidisp8:
	lea_reg_idxidxdisp8 r7 r9 r11
lea_sp_bpdidisp8:
	lea_reg_idxidxdisp8 r8 r9 r11
lea_bp_bpdidisp8:
	lea_reg_idxidxdisp8 r9 r9 r11
lea_si_bpdidisp8:
	lea_reg_idxidxdisp8 r10 r9 r11
lea_di_bpdidisp8:
	lea_reg_idxidxdisp8 r11 r9 r11

.macro lea_reg_idxdisp8 reg idx
	ldrsb	r0,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	add		r0, \idx
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

lea_ax_sidisp8:
	lea_reg_idxdisp8 r4 r10
lea_cx_sidisp8:
	lea_reg_idxdisp8 r5 r10
lea_dx_sidisp8:
	lea_reg_idxdisp8 r6 r10
lea_bx_sidisp8:
	lea_reg_idxdisp8 r7 r10
lea_sp_sidisp8:
	lea_reg_idxdisp8 r8 r10
lea_bp_sidisp8:
	lea_reg_idxdisp8 r9 r10
lea_si_sidisp8:
	lea_reg_idxdisp8 r10 r10
lea_di_sidisp8:
	lea_reg_idxdisp8 r11 r10

lea_ax_didisp8:
	lea_reg_idxdisp8 r4 r11
lea_cx_didisp8:
	lea_reg_idxdisp8 r5 r11
lea_dx_didisp8:
	lea_reg_idxdisp8 r6 r11
lea_bx_didisp8:
	lea_reg_idxdisp8 r7 r11
lea_sp_didisp8:
	lea_reg_idxdisp8 r8 r11
lea_bp_didisp8:
	lea_reg_idxdisp8 r9 r11
lea_si_didisp8:
	lea_reg_idxdisp8 r10 r11
lea_di_didisp8:
	lea_reg_idxdisp8 r11 r11

lea_ax_bpdisp8:
	lea_reg_idxdisp8 r4 r9
lea_cx_bpdisp8:
	lea_reg_idxdisp8 r5 r9
lea_dx_bpdisp8:
	lea_reg_idxdisp8 r6 r9
lea_bx_bpdisp8:
	lea_reg_idxdisp8 r7 r9
lea_sp_bpdisp8:
	lea_reg_idxdisp8 r8 r9
lea_bp_bpdisp8:
	lea_reg_idxdisp8 r9 r9
lea_si_bpdisp8:
	lea_reg_idxdisp8 r10 r9
lea_di_bpdisp8:
	lea_reg_idxdisp8 r11 r9

lea_ax_bxdisp8:
	lea_reg_idxdisp8 r4 r7
lea_cx_bxdisp8:
	lea_reg_idxdisp8 r5 r7
lea_dx_bxdisp8:
	lea_reg_idxdisp8 r6 r7
lea_bx_bxdisp8:
	lea_reg_idxdisp8 r7 r7
lea_sp_bxdisp8:
	lea_reg_idxdisp8 r8 r7
lea_bp_bxdisp8:
	lea_reg_idxdisp8 r9 r7
lea_si_bxdisp8:
	lea_reg_idxdisp8 r10 r7
lea_di_bxdisp8:
	lea_reg_idxdisp8 r11 r7

// --- LEA reg16,[idx+idx+disp16] ---
//
// Here segment override does not matter, we are only interested in the offset.
//
.macro lea_reg_idxidxdisp16 reg idx1 idx2
	ldrb	r0,[r12],#1				// Load low byte to r0, increment r12 by 1
	ldrb	r1,[r12],#1				// Load high byte to r1, increment r12 by 1
	add		r2, \idx1, \idx2
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	add		r0, r2
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	add		r0, r2
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

lea_ax_bxsidisp16:
	lea_reg_idxidxdisp16 r4 r7 r10
lea_cx_bxsidisp16:
	lea_reg_idxidxdisp16 r5 r7 r10
lea_dx_bxsidisp16:
	lea_reg_idxidxdisp16 r6 r7 r10
lea_bx_bxsidisp16:
	lea_reg_idxidxdisp16 r7 r7 r10
lea_sp_bxsidisp16:
	lea_reg_idxidxdisp16 r8 r7 r10
lea_bp_bxsidisp16:
	lea_reg_idxidxdisp16 r9 r7 r10
lea_si_bxsidisp16:
	lea_reg_idxidxdisp16 r10 r7 r10
lea_di_bxsidisp16:
	lea_reg_idxidxdisp16 r11 r7 r10

lea_ax_bxdidisp16:
	lea_reg_idxidxdisp16 r4 r7 r11
lea_cx_bxdidisp16:
	lea_reg_idxidxdisp16 r5 r7 r11
lea_dx_bxdidisp16:
	lea_reg_idxidxdisp16 r6 r7 r11
lea_bx_bxdidisp16:
	lea_reg_idxidxdisp16 r7 r7 r11
lea_sp_bxdidisp16:
	lea_reg_idxidxdisp16 r8 r7 r11
lea_bp_bxdidisp16:
	lea_reg_idxidxdisp16 r9 r7 r11
lea_si_bxdidisp16:
	lea_reg_idxidxdisp16 r10 r7 r11
lea_di_bxdidisp16:
	lea_reg_idxidxdisp16 r11 r7 r11

lea_ax_bpsidisp16:
	lea_reg_idxidxdisp16 r4 r9 r10
lea_cx_bpsidisp16:
	lea_reg_idxidxdisp16 r5 r9 r10
lea_dx_bpsidisp16:
	lea_reg_idxidxdisp16 r6 r9 r10
lea_bx_bpsidisp16:
	lea_reg_idxidxdisp16 r7 r9 r10
lea_sp_bpsidisp16:
	lea_reg_idxidxdisp16 r8 r9 r10
lea_bp_bpsidisp16:
	lea_reg_idxidxdisp16 r9 r9 r10
lea_si_bpsidisp16:
	lea_reg_idxidxdisp16 r10 r9 r10
lea_di_bpsidisp16:
	lea_reg_idxidxdisp16 r11 r9 r10

lea_ax_bpdidisp16:
	lea_reg_idxidxdisp16 r4 r9 r11
lea_cx_bpdidisp16:
	lea_reg_idxidxdisp16 r5 r9 r11
lea_dx_bpdidisp16:
	lea_reg_idxidxdisp16 r6 r9 r11
lea_bx_bpdidisp16:
	lea_reg_idxidxdisp16 r7 r9 r11
lea_sp_bpdidisp16:
	lea_reg_idxidxdisp16 r8 r9 r11
lea_bp_bpdidisp16:
	lea_reg_idxidxdisp16 r9 r9 r11
lea_si_bpdidisp16:
	lea_reg_idxidxdisp16 r10 r9 r11
lea_di_bpdidisp16:
	lea_reg_idxidxdisp16 r11 r9 r11

.macro lea_reg_idxdisp16 reg idx
	ldrb	r0,[r12],#1				// Load low byte to r0, increment r12 by 1
	ldrb	r1,[r12],#1				// Load high byte to r1, increment r12 by 1
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	add		r0, \idx
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
#else
	bfi		\reg, r0, #0, #16
#endif
	b		loop
.endm

lea_ax_sidisp16:
	lea_reg_idxdisp16 r4 r10
lea_cx_sidisp16:
	lea_reg_idxdisp16 r5 r10
lea_dx_sidisp16:
	lea_reg_idxdisp16 r6 r10
lea_bx_sidisp16:
	lea_reg_idxdisp16 r7 r10
lea_sp_sidisp16:
	lea_reg_idxdisp16 r8 r10
lea_bp_sidisp16:
	lea_reg_idxdisp16 r9 r10
lea_si_sidisp16:
	lea_reg_idxdisp16 r10 r10
lea_di_sidisp16:
	lea_reg_idxdisp16 r11 r10

lea_ax_didisp16:
	lea_reg_idxdisp16 r4 r11
lea_cx_didisp16:
	lea_reg_idxdisp16 r5 r11
lea_dx_didisp16:
	lea_reg_idxdisp16 r6 r11
lea_bx_didisp16:
	lea_reg_idxdisp16 r7 r11
lea_sp_didisp16:
	lea_reg_idxdisp16 r8 r11
lea_bp_didisp16:
	lea_reg_idxdisp16 r9 r11
lea_si_didisp16:
	lea_reg_idxdisp16 r10 r11
lea_di_didisp16:
	lea_reg_idxdisp16 r11 r11

lea_ax_bpdisp16:
	lea_reg_idxdisp16 r4 r9
lea_cx_bpdisp16:
	lea_reg_idxdisp16 r5 r9
lea_dx_bpdisp16:
	lea_reg_idxdisp16 r6 r9
lea_bx_bpdisp16:
	lea_reg_idxdisp16 r7 r9
lea_sp_bpdisp16:
	lea_reg_idxdisp16 r8 r9
lea_bp_bpdisp16:
	lea_reg_idxdisp16 r9 r9
lea_si_bpdisp16:
	lea_reg_idxdisp16 r10 r9
lea_di_bpdisp16:
	lea_reg_idxdisp16 r11 r9

lea_ax_bxdisp16:
	lea_reg_idxdisp16 r4 r7
lea_cx_bxdisp16:
	lea_reg_idxdisp16 r5 r7
lea_dx_bxdisp16:
	lea_reg_idxdisp16 r6 r7
lea_bx_bxdisp16:
	lea_reg_idxdisp16 r7 r7
lea_sp_bxdisp16:
	lea_reg_idxdisp16 r8 r7
lea_bp_bxdisp16:
	lea_reg_idxdisp16 r9 r7
lea_si_bxdisp16:
	lea_reg_idxdisp16 r10 r7
lea_di_bxdisp16:
	lea_reg_idxdisp16 r11 r7
	
// ------------------- 8E = MOV Sreg,r/m16 -----------------------------
// Profiler: 5493, 21, 113.66, 624308, 0.3%
//
// MOV ES,DI = 8EC7 => mod = 11, reg = 000 (ES), rm = 111 (DI)
// MOV DS,BX = 8EDB => mod = 11, reg = 011 (DS), rm = 011 (BX)
// MOV ES,[023C] = 8E063C02 => mod = 00, reg = 000 (ES), rm = 110 (disp16)
// MOV ES,[BP+06] = 8E4606 => mod = 01 (+disp8), reg = 000 (ES), rm = 110 ([BP+disp8])
//
// reg field values = ES, CS, SS, DS = 0, 1, 2, 3
//
// We must not change the flags here!!!
//
	.global	op_8e
op_8e:
	modrm_jump_16

.macro tmp sreg
	.word	mov_bxsi_to_\sreg, mov_bxdi_to_\sreg, mov_bpsi_to_\sreg, mov_bpdi_to_\sreg
	.word	mov_\sreg\()_siidx, mov_\sreg\()_diidx, mov_disp16_to_\sreg, mov_\sreg\()_bxidx
.endm
// 0
	tmp es
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	tmp ss
	tmp ds
	tmp fs
	tmp gs
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
.purgem tmp
.macro tmp sreg
	.word 	mov_bxsid8_to_\sreg, mov_bxdid8_to_\sreg, mov_bpsid8_to_\sreg, mov_bpdid8_to_\sreg
	.word	mov_\sreg\()_sidisp8, mov_\sreg\()_didisp8, mov_\sreg\()_bpdisp8, mov_\sreg\()_bxdisp8
.endm
//0x40
	tmp es
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	tmp ss
	tmp ds
	tmp fs
	tmp gs
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
.purgem tmp
.macro tmp sreg
	.word 	mov_bxsid16_to_\sreg, mov_bxdid16_to_\sreg, mov_bpsid16_to_\sreg, mov_bpdid16_to_\sreg
	.word	mov_sidisp16_to_\sreg, mov_didisp16_to_\sreg, mov_bpdisp16_to_\sreg, mov_bxdisp16_to_\sreg
.endm
//0x80
	tmp es
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	tmp ss
	tmp ds
	tmp fs
	tmp gs
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
.purgem tmp
// 0xC0 = mod = 11b = register
// ES
	.word mov_es_ax, mov_es_cx, mov_es_dx, mov_es_bx, mov_es_sp, mov_es_bp, mov_es_si, mov_es_di
// CS	
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
// SS	
	.word mov_ss_ax, mov_ss_cx, mov_ss_dx, mov_ss_bx, mov_ss_sp, mov_ss_bp, mov_ss_si, mov_ss_di
// DS	
	.word mov_ds_ax, mov_ds_cx, mov_ds_dx, mov_ds_bx, mov_ds_sp, mov_ds_bp, mov_ds_si, mov_ds_di
// FS (386+ only!)	
	.word mov_fs_ax, mov_fs_cx, mov_fs_dx, mov_fs_bx, mov_fs_sp, mov_fs_bp, mov_fs_si, mov_fs_di
// GS (386+ only!)	
	.word mov_gs_ax, mov_gs_cx, mov_gs_dx, mov_gs_bx, mov_gs_sp, mov_gs_bp, mov_gs_si, mov_gs_di
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1

	.global mov_es_ax, mov_es_cx, mov_es_dx, mov_es_bx, mov_es_sp, mov_es_bp, mov_es_si, mov_es_di
	.global mov_ss_ax, mov_ss_cx, mov_ss_dx, mov_ss_bx, mov_ss_sp, mov_ss_bp, mov_ss_si, mov_ss_di
	.global mov_ds_ax, mov_ds_cx, mov_ds_dx, mov_ds_bx, mov_ds_sp, mov_ds_bp, mov_ds_si, mov_ds_di
	.global mov_fs_ax, mov_fs_cx, mov_fs_dx, mov_fs_bx, mov_fs_sp, mov_fs_bp, mov_fs_si, mov_fs_di
	.global mov_gs_ax, mov_gs_cx, mov_gs_dx, mov_gs_bx, mov_gs_sp, mov_gs_bp, mov_gs_si, mov_gs_di

	.global	mov_bp_r0_to_es
mov_bp_r0_to_es:
mov_r0_bp_to_es:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_to_es
mov_r0_to_es:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8e_RAM_es op_8e_EGA_r2_es bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8e_RAM_es:
	ldrb	r0, [r2] 							// Load low byte
	ldrb	r2, [r2, #1]						// Load the zero-extended high byte
	orr		r2, r0, r2, lsl #8					// r2 = halfword unsigned value at [disp16]
	.global	mov_es_r2							// Called also from "EGA.s"!
mov_es_r2:
	ldrb	r1, [sp, #SP_CPU_CR0]				// r1 tells whether we are in protected mode
	mrs		r0, cpsr							// Save current flags to r0
	tst		r1, #1								// Are we in protected mode?
	bne		mov_es_r0r2_prot					// Go to the handler in "cpu_prot.s"
	.global	mov_es_r0r2_real
mov_es_r0r2_real:
	mov		r1, r2, lsl #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_ES_VALUE]
	str		r1, [sp, #SP_ES_BASE]
	b		restore_flags_from_r0

	.global	mov_bp_r0_to_ss
mov_bp_r0_to_ss:
mov_r0_bp_to_ss:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_to_ss
mov_r0_to_ss:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8e_RAM_ss bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8e_RAM_ss:
	ldrb	r0, [r2] 							// Load low byte
	ldrb	r2, [r2, #1]						// Load the zero-extended high byte
	orr		r2, r0, r2, lsl #8					// r2 = halfword unsigned value at [disp16]
.mov_ss_r2:										// Called from the register versions of the opcode
	ldrb	r1, [sp, #SP_CPU_CR0]				// r1 tells whether we are in protected mode
	mrs		r0, cpsr							// Save current flags to r0
	tst		r1, #1								// Are we in protected mode?
	bne		mov_ss_r0r2_prot					// Go to the handler in "cpu_prot.s"
	.global	mov_ss_r0r2_real
mov_ss_r0r2_real:
	msr		cpsr_f,r0							// Restore flags
	str		r2, [sp, #SP_SS_VALUE]
	lsl		r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_SS_BASE]
	mov		lr, r2
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_SS]
	//-------
	// NOTE! x86 disables interrupts until the next instruction has been executed.
	// Thus we must handle the next opcode immediately!
	//-------
	ldrb	r0,[r12],#1							// Load opcode byte to r0, increment r12 by 1	
	ldr		r2, [sp, #SP_DS_BASE]				// r2 high halfword = logical DS segment, clear segment override flags
	str		r12, [sp, #SP_EX_CSIP]				// Remember where this opcode started, for division-by-zero and exception handling
	ldr		pc,[sp, r0, lsl #2]					// Jump to the opcode handler

	.global	mov_bp_r0_to_ds
mov_bp_r0_to_ds:
mov_r0_bp_to_ds:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_to_ds
mov_r0_to_ds:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8e_RAM_ds bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8e_RAM_ds:
	ldrb	r0, [r2] 							// Load low byte
	ldrb	r2, [r2, #1]						// Load the zero-extended high byte
	orr		r2, r0, r2, lsl #8					// r2 = halfword unsigned value at [disp16]
.mov_ds_r2:										// Called from the register versions of the opcode
	ldrb	r1, [sp, #SP_CPU_CR0]				// r1 tells whether we are in protected mode
	mrs		r0, cpsr							// Save current flags to r0
	tst		r1, #1								// Are we in protected mode?
	bne		mov_ds_r0r2_prot					// Go to the handler in "cpu_prot.s"
	.global	mov_ds_r0r2_real
mov_ds_r0r2_real:
	mov		r1, r2, lsl #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_DS_VALUE]
	str		r1, [sp, #SP_DS_BASE]
	b		restore_flags_from_r0

	.global	mov_bp_r0_to_fs
mov_bp_r0_to_fs:
mov_r0_bp_to_fs:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_to_fs
mov_r0_to_fs:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8e_RAM_fs bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8e_RAM_fs:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r2, [r2, #1]			// Load the zero-extended high byte
	orr		r2, r0, r2, lsl #8		// r2 = halfword unsigned value at [disp16]
.mov_fs_r2:							// Called from the register versions of the opcode
	ldrb	r1, [sp, #SP_CPU_CR0]				// r1 tells whether we are in protected mode
	mrs		r0, cpsr							// Save current flags to r0
	tst		r1, #1								// Are we in protected mode?
	bne		mov_fs_r0r2_prot					// Go to the handler in "cpu_prot.s"
	.global	mov_fs_r0r2_real
mov_fs_r0r2_real:
	mov		r1, r2, lsl #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_FS_VALUE]
	str		r1, [sp, #SP_FS_BASE]
	b		restore_flags_from_r0

	.global	mov_bp_r0_to_gs
mov_bp_r0_to_gs:
mov_r0_bp_to_gs:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_to_gs
mov_r0_to_gs:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8e_RAM_gs bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8e_RAM_gs:
	ldrb	r0, [r2] 				// Load low byte
	ldrb	r2, [r2, #1]			// Load the zero-extended high byte
	orr		r2, r0, r2, lsl #8		// r2 = halfword unsigned value at [disp16]
.mov_gs_r2:							// Called from the register versions of the opcode
	ldrb	r1, [sp, #SP_CPU_CR0]				// r1 tells whether we are in protected mode
	mrs		r0, cpsr							// Save current flags to r0
	tst		r1, #1								// Are we in protected mode?
	bne		mov_gs_r0r2_prot					// Go to the handler in "cpu_prot.s"
	.global	mov_gs_r0r2_real
mov_gs_r0r2_real:
	mov		r1, r2, lsl #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_GS_VALUE]
	str		r1, [sp, #SP_GS_BASE]
	b		restore_flags_from_r0

.macro op8egenall sreg

// -- [idx] --

mov_bxsi_to_\sreg:
	add		r0, r7, r10
	b		mov_r0_to_\sreg
mov_bxdi_to_\sreg:
	add		r0, r7, r11
	b		mov_r0_to_\sreg
mov_bpsi_to_\sreg:
	add		r0, r9, r10
	b		mov_r0_bp_to_\sreg
mov_bpdi_to_\sreg:
	add		r0, r9, r11
	b		mov_r0_bp_to_\sreg
	.global	mov_\sreg\()_siidx
mov_\sreg\()_siidx:
	mov		r0, r10
	b		mov_r0_to_\sreg
	.global	mov_\sreg\()_diidx
mov_\sreg\()_diidx:
	mov		r0, r11
	b		mov_r0_to_\sreg
mov_disp16_to_\sreg:
	r0_from_disp16
	b		mov_r0_to_\sreg
	.global	mov_\sreg\()_bxidx
mov_\sreg\()_bxidx:
	mov		r0, r7
	b		mov_r0_to_\sreg

// -- [idx+disp8] --

mov_bxsid8_to_\sreg:
	r0_from_bxidxdisp8 r10
	b		mov_r0_to_\sreg
mov_bxdid8_to_\sreg:
	r0_from_bxidxdisp8 r11
	b		mov_r0_to_\sreg
mov_bpsid8_to_\sreg:
	r0_from_bpidxdisp8 r10
	b		mov_r0_bp_to_\sreg
mov_bpdid8_to_\sreg:
	r0_from_bpidxdisp8 r11
	b		mov_r0_bp_to_\sreg
	.global	mov_\sreg\()_sidisp8
mov_\sreg\()_sidisp8:
	r0_from_idx_disp8 r10
	b		mov_r0_to_\sreg
	.global	mov_\sreg\()_didisp8
mov_\sreg\()_didisp8:
	r0_from_idx_disp8 r11
	b		mov_r0_to_\sreg
	.global	mov_\sreg\()_bpdisp8
mov_\sreg\()_bpdisp8:
	r0_from_idx_disp8 r9
	b		mov_r0_bp_to_\sreg
	.global	mov_\sreg\()_bxdisp8
mov_\sreg\()_bxdisp8:
	r0_from_idx_disp8 r7
	b		mov_r0_to_\sreg

// -- [idx+disp16] --

mov_bxsid16_to_\sreg:
	r0_from_bxidxdisp16 r10
	b		mov_r0_to_\sreg
mov_bxdid16_to_\sreg:
	r0_from_bxidxdisp16 r11
	b		mov_r0_to_\sreg
mov_bpsid16_to_\sreg:
	r0_from_bpidxdisp16 r10
	b		mov_r0_bp_to_\sreg
mov_bpdid16_to_\sreg:
	r0_from_bpidxdisp16 r11
	b		mov_r0_bp_to_\sreg
mov_sidisp16_to_\sreg:
	r0_from_idx_disp16 r10
	b		mov_r0_to_\sreg
mov_didisp16_to_\sreg:
	r0_from_idx_disp16 r11
	b		mov_r0_to_\sreg
mov_bpdisp16_to_\sreg:
	r0_from_idx_disp16 r9
	b		mov_r0_bp_to_\sreg
mov_bxdisp16_to_\sreg:
	r0_from_idx_disp16 r7
	b		mov_r0_to_\sreg

.endm

op8egenall es
op8egenall ss
op8egenall ds
op8egenall fs
op8egenall gs

// --- MOV Sreg,reg16 ---

.macro mov_es_reg reg
#if defined(RPi) || defined(Roku)
	mov		r2, \reg, lsl #16		// Segment registers are saved as 16-bit unsigned values
	lsr		r2, #16
#else
	ubfx	r2, \reg, #0, #16
#endif
	b		mov_es_r2
.endm
.macro mov_ss_reg reg
#if defined(RPi) || defined(Roku)
	mov		r2, \reg, lsl #16		// Segment registers are saved as 16-bit unsigned values
	lsr		r2, #16
#else
	ubfx	r2, \reg, #0, #16
#endif
	b		.mov_ss_r2
.endm
.macro mov_ds_reg reg
#if defined(RPi) || defined(Roku)
	mov		r2, \reg, lsl #16		// Segment registers are saved as 16-bit unsigned values
	lsr		r2, #16
#else
	ubfx	r2, \reg, #0, #16
#endif
	b		.mov_ds_r2
.endm
.macro mov_fs_reg reg
#if defined(RPi) || defined(Roku)
	mov		r2, \reg, lsl #16		// Segment registers are saved as 16-bit unsigned values
	lsr		r2, #16
#else
	ubfx	r2, \reg, #0, #16
#endif
	b		.mov_fs_r2
.endm
.macro mov_gs_reg reg
#if defined(RPi) || defined(Roku)
	mov		r2, \reg, lsl #16		// Segment registers are saved as 16-bit unsigned values
	lsr		r2, #16
#else
	ubfx	r2, \reg, #0, #16
#endif
	b		.mov_gs_r2
.endm

mov_es_ax:
	mov_es_reg r4
mov_es_cx:
	mov_es_reg r5
mov_es_dx:
	mov_es_reg r6
mov_es_bx:
	mov_es_reg r7
mov_es_sp:
	mov_es_reg r8
mov_es_bp:
	mov_es_reg r9
mov_es_si:
	mov_es_reg r10
mov_es_di:
	mov_es_reg r11

mov_ss_ax:
	mov_ss_reg r4
mov_ss_cx:
	mov_ss_reg r5
mov_ss_dx:
	mov_ss_reg r6
mov_ss_bx:
	mov_ss_reg r7
mov_ss_sp:
	mov_ss_reg r8
mov_ss_bp:
	mov_ss_reg r9
mov_ss_si:
	mov_ss_reg r10
mov_ss_di:
	mov_ss_reg r11

mov_ds_ax:
	mov_ds_reg r4
mov_ds_cx:
	mov_ds_reg r5
mov_ds_dx:
	mov_ds_reg r6
mov_ds_bx:
	mov_ds_reg r7
mov_ds_sp:
	mov_ds_reg r8
mov_ds_bp:
	mov_ds_reg r9
mov_ds_si:
	mov_ds_reg r10
mov_ds_di:
	mov_ds_reg r11

mov_fs_ax:
	mov_fs_reg r4
mov_fs_cx:
	mov_fs_reg r5
mov_fs_dx:
	mov_fs_reg r6
mov_fs_bx:
	mov_fs_reg r7
mov_fs_sp:
	mov_fs_reg r8
mov_fs_bp:
	mov_fs_reg r9
mov_fs_si:
	mov_fs_reg r10
mov_fs_di:
	mov_fs_reg r11

mov_gs_ax:
	mov_gs_reg r4
mov_gs_cx:
	mov_gs_reg r5
mov_gs_dx:
	mov_gs_reg r6
mov_gs_bx:
	mov_gs_reg r7
mov_gs_sp:
	mov_gs_reg r8
mov_gs_bp:
	mov_gs_reg r9
mov_gs_si:
	mov_gs_reg r10
mov_gs_di:
	mov_gs_reg r11

.ltorg								// Dump the current literal pool here

// ------------------- 8F = POP m16 ------------------------------------
//
// This is a rare opcode, modrm = rm000mod
//
op_8f:
	ldrb	r0,[r12],#1							// Load the second opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	orr		r0, r0, lsr #3
	and		r0, #0x1F
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8

// 0
	.word pop_bxsi, pop_bxdi, pop_bpsi, pop_bpdi, pop_siidx, pop_diidx, pop_disp16, pop_bxidx
// 0x40
	.word pop_bxsid8, pop_bxdid8, pop_bpsid8, pop_bpdid8, pop_sidisp8, pop_didisp8, pop_bpdisp8, pop_bxdisp8
// 0x80
	.word pop_bxsid16, pop_bxdid16, pop_bpsid16, pop_bpdid16, pop_sidisp16, pop_didisp16, pop_bpdisp16, pop_bxdisp16
// 0xC0
	.word op_58, op_59, op_5a, op_5b, op_5c, op_5d, op_5e, op_5f

	.global pop_siidx, pop_diidx, pop_disp16, pop_bxidx
	.global pop_sidisp8, pop_didisp8, pop_bpdisp8, pop_bxdisp8
	.global op_58, op_59, op_5a, op_5b, op_5c, op_5d, op_5e, op_5f

	.global	pop_r0_bp
pop_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	pop_r0
pop_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_8f_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_8f_RAM:
	pop_reg_low_hi r0 r1
	strb	r0,[r2]					// Store the low byte
	strb	r1,[r2, #1]				// Store the high byte
	b		loop
.pop_addr_flags_r1:
	msr		cpsr_f,r1				// Restore flags from r1
	add		r0, pc, r2, lsr #24		// r0 = PC + 0x02, 0x06, 0x0A, 0x0E, ...
	ldr		pc,[r0, #-2]
	.word	.op_8f_RAM				// RAM
	.word	.unknown_back1			// MCGA Direct
	.word	bad_EGA_opcode			// EGA
	.word	bad_MODEX_opcode		// Mode-X

// --- [idx] ---

pop_bxsi:
	add		r0, r7, r10
	b		pop_r0
pop_bxdi:
	add		r0, r7, r11
	b		pop_r0
pop_bpsi:
	add		r0, r9, r10
	b		pop_r0_bp
pop_bpdi:
	add		r0, r9, r11
	b		pop_r0_bp
pop_siidx:
	mov		r0, r10
	b		pop_r0
pop_diidx:
	mov		r0, r11
	b		pop_r0
pop_disp16:
	r0_from_disp16
	b		pop_r0
pop_bxidx:
	mov		r0, r7
	b		pop_r0

// --- [idx+disp8] ---

pop_bxsid8:
	r0_from_bxidxdisp8 r10
	b		pop_r0
pop_bxdid8:
	r0_from_bxidxdisp8 r11
	b		pop_r0
pop_bpsid8:
	r0_from_bpidxdisp8 r10
	b		pop_r0_bp
pop_bpdid8:
	r0_from_bpidxdisp8 r11
	b		pop_r0_bp
pop_sidisp8:
	r0_from_idx_disp8 r10
	b		pop_r0
pop_didisp8:
	r0_from_idx_disp8 r11
	b		pop_r0
pop_bpdisp8:
	r0_from_idx_disp8 r9
	b		pop_r0_bp
pop_bxdisp8:
	r0_from_idx_disp8 r7
	b		pop_r0

// --- [idx+disp16] ---

pop_bxsid16:
	r0_from_bxidxdisp16 r10
	b		pop_r0
pop_bxdid16:
	r0_from_bxidxdisp16 r11
	b		pop_r0
pop_bpsid16:
	r0_from_bpidxdisp16 r10
	b		pop_r0_bp
pop_bpdid16:
	r0_from_bpidxdisp16 r11
	b		pop_r0_bp
pop_sidisp16:
	r0_from_idx_disp16 r10
	b		pop_r0
pop_didisp16:
	r0_from_idx_disp16 r11
	b		pop_r0
pop_bpdisp16:
	r0_from_idx_disp16 r9
	b		pop_r0_bp
pop_bxdisp16:
	r0_from_idx_disp16 r7
	b		pop_r0


#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

// ------------------- 98 = CBW ----------------------------------------
//
op_98:
#if defined(RPi) || defined(Roku)
	mov		r0, eax, lsl #24
	lsr		eax, #16
	orr		eax, r0, asr #8
	ror		eax, #16
#else
	sbfx	r0, eax, #0, #8
	bfi		eax, r0, #0, #16
#endif
	b		loop

// ------------------- 99 = CWD ----------------------------------------
//
op_99:
#if defined(RPi) || defined(Roku)
	lsr		edx, #16							// Clear DX
	lsl		edx, #16
	mov		r0, eax, lsl #16
	asr		r0, #16								// r0 high 16 bits = new DX value
	orr		edx, r0, lsr #16
#else
	sbfx	r0, eax, #0, #16
	ubfx	r0, r0, #16, #16
	bfi		edx, r0, #0, #16
#endif
	b		loop

// ------------------- 9A = CALL FAR ptr16:16 --------------------------
// Profiler: 7571, 31, 46.84, 354618, 0.18%
//
// CALL 1604:3228 = 9A28320416
//
op_9a:
	//-------
	// First get the call target :
	//	r1 = new IP (offset)
	//	r2 = new CS (segment)
	//-------
	mov		r0, #16
	str		r0, [sp, #SP_FREE3]		// Save the flag telling this is a USE16 call far
	ldrb	r0,[r12], #1
	ldrb	r1,[r12], #1
	ldrb	r2,[r12], #1
	ldrb	r3,[r12], #1
	orr		r1, r0, r1, lsl #8		// r1 = new logical IP
	orr		r2, r3, lsl #8			// r2 = new CS value
	.global	cpu_call_far_r1r2
cpu_call_far_r1r2:
	//-------
	// Then determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	mrs		r0,cpsr					// Save flags (we are not allowed to change any)
	tst		r3, #1					// Are we in protected mode (or in VM mode)?
	bne		cpu_call_prot_r0r1r2	// Yes we are, go handle protected mode CALL FAR!
	//-------
	// Real mode CALL FAR handling
	//-------
	.global	cpu_call_real_r0r1r2
cpu_call_real_r0r1r2:	
	// ----- Store current CS:IP to stack
	ldr		r3, [sp, #SP_CS_VALUE]
	msr		cpsr_f, r0				// Restore flags
	push_hword r3 r0 lr
	ldr		r3, [sp, #SP_PHYS_CS]	// get the physical CS:0000 into r3
	sub		r3, r12, r3				// r3 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	push_hword r3 r0 lr
	// ----- Then get new CS:IP
	mov		r12, r1
	// ----- Then save new logical CS
	str		r2, [sp, #SP_CS_VALUE]
	lsl		r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_CS_BASE]
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_CS]	// Store new physical CS into stack
	add		r12, r2 				// r12 = new physical CS:IP = new IP + physical base + (new CS << 4)
	b		loop

	.ltorg
	
// ------------------- 9C = PUSHF --------------------------------------
//	if (cpu.pmode && GETFLAG(VM) && (GETFLAG(IOPL)!=FLAG_IOPL)) {
//		/* Not enough privileges to execute PUSHF */
//		return CPU_PrepareException(EXCEPTION_GP,0);
//	}
//
op_9c:
	ldrb	r3, [sp, #SP_CPU_CR0]				// Get the lowest byte of cpu_cr0
	ldr		r1, [sp, #SP_FLAGS]					// Get the "Trap", "Interrupts Enabled" and "Direction" flags
	mrs		r0,cpsr								// Save flags (we are not allowed to change any)
	tst		r3, #1								// Are we in protected mode?
	bne		.op_9c_prot
.op_9c_cont:
	msr		cpsr_f, r0							// Restore flags
	join_ARM_to_X86_flags r1
	push_hword r1 r0 r2
	b		loop
.op_9c_prot:
	tst		r1, #FLAG_VM
	beq		.op_9c_cont
	and		r2, r1, #FLAG_IOPL
	cmp		r2, #FLAG_IOPL
	beq		.op_9c_cont
	b		.unknown							// EXCEPTION_GP!

// ------------------- 9D = POPF ---------------------------------------
//	if (cpu.pmode && GETFLAG(VM) && (GETFLAG(IOPL)!=FLAG_IOPL)) {
//		/* Not enough privileges to execute POPF */
//		return CPU_PrepareException(EXCEPTION_GP,0);
//	}
//	Bitu mask=FMASK_ALL;
//	/* IOPL field can only be modified when CPL=0 or in real mode: */
//	if (cpu.pmode && (cpu.cpl>0)) mask &= (~FLAG_IOPL);
//	if (cpu.pmode && !GETFLAG(VM) && (GETFLAG_IOPL<cpu.cpl)) mask &= (~FLAG_IF);
//	if (use32)
//		CPU_SetFlags(CPU_Pop32(),mask);
//	else CPU_SetFlags(CPU_Pop16(),mask & 0xffff);
//	DestroyConditionFlags();
//	return false;
//
//
op_9d:
	ldrb	r3, [sp, #SP_CPU_CR0]				// Get the lowest byte of cpu_cr0
	ldr		r1, [sp, #SP_FLAGS]					// Get the #SP_FLAGS
	ldr		r2, =FMASK_ALL						// r2 = mask of the flag bits we can change
	tst		r3, #1								// Are we in protected mode?
	bne		.op_9d_prot
.op_9d_cont:
	pop_reg_low_tmp	r0 r3						// r0 = new flags
	bic		r2, #0x00FF0000						// mask = mask & 0xFFFF
	and		r0, r2								// Leave only the bits we can change to r0
	bic		r2, r1, r2							// r1 = flags bits that will not change
	orr		r0, r2
	str		r0, [sp, #SP_FLAGS]					// Store the new #SP_FLAGS
	b		iret_cont_flags_old_r1_new_r0
.op_9d_prot:
	tst		r1, #FLAG_VM						// Are we in VM mode?
	and		r3, r1, #FLAG_IOPL
	cmpne	r3, #FLAG_IOPL						// If we are in VM mode, check FLAG_IOPL
	ldrb	r0, [sp, #SP_CPU_CPL]
	bne		.unknown							// EXCEPTION_GP!
	cmp		r0, #0								// if (cpu.pmode && (cpu.cpl>0)) 
	bicgt	r2, #FLAG_IOPL						//	mask &= (~FLAG_IOPL);
	cmp		r3, r0, lsl #12						// (GETFLAG_IOPL<cpu.cpl)
	biclt	r2, #FLAG_IF						//	mask &= (~FLAG_IF);
	b		.op_9d_cont

	.ltorg
	
// ------------------- 9E = SAHF ---------------------------------------
//
// ARM Flags bits:
// 	bit 0x80000000 = Negative Flag
//	bit 0x40000000 = Zero Flag
//	bit 0x20000000 = Carry flag
//	bit	0x10000000 = Overflow Flag
// x86 Flags bits:
//	0 	CF Carry flag
//	1 	1 Reserved   
//	2 	PF Parity flag
//	3 	0 Reserved   
//	4 	AF Adjust flag
//	5 	0 Reserved   
//	6 	ZF Zero flag
//	7 	SF Sign flag
//
op_9e:
	mov		r0, eax, lsr #8
	and		r0, #(FLAG_SF|FLAG_ZF|FLAG_AF|FLAG_PF|FLAG_CF)
	orr		r0, #2
	strb	r0, [sp, #SP_FLAGS]		// Save the AF and PF flags to emulated x86 flags
	popped_flags_to_ARM r0			// Move the flags in r0 to the ARM flag bits
	b		restore_flags_from_r0	// Go back to the opcode loop
	
// ------------------- 9F = LAHF ---------------------------------------
//
op_9f:
	mrs		r0, cpsr				// Save flags to r0
	ldrb	r1, [sp, #SP_FLAGS]		// Get the AF and PF flags from emulated x86 flags
	//-------
	// First set the flag bits that are common to ARM and x86
	//-------
	bic		eax, #0xFF00			// Clear current AH
	orrcs	eax, #((FLAG_CF)<<8)	// Set Carry flag
	orr		eax, #((1<<1)<<8)		// Set the Reserved flag
	orreq	eax, #((FLAG_ZF)<<8)	// Set Zero flag
	orrmi	eax, #((FLAG_SF)<<8)	// Set Sign flag
	//-------
	// Set the x86 emulated AF and PF flags
	//-------
	and		r1, #(FLAG_AF|FLAG_PF)
	orr		eax, r1, lsl #8
	//-------
	// Check if the following opcode is "TEST AH,10" = F6C410 (testing for Auxiliary Carry, Leisure Suit Larry III)
	//-------
	ldrb	r1, [r12]
	cmp		r1, #0xF6
	ldreqb	r1, [r12, #1]
	cmpeq	r1, #0xC4
	ldreqb	r1, [r12, #2]
	cmpeq	r1, #0x10
	bne		restore_flags_from_r0	// Go back to the opcode loop
	//-------
	// The next opcode is a check for the AC flag!
	// Check if the previous opcode is "CMP BL,[DI+7FF0]" = 3A9DF07F	(Leisure Suit Larry III)
	//-------
	ldrb	r1, [r12, #-5]
	cmp		r1, #0x3A
	ldreqb	r1, [r12, #-4]
	cmpeq	r1, #0x9D
	ldreqb	r1, [r12, #-3]
	cmpeq	r1, #0xF0
	ldreqb	r1, [r12, #-2]
	cmpeq	r1, #0x7F
	bne		1f
	//-------
	// The previous opcode was "CMP BL,[DI+7FF0]". Perform the compare again for the lowest 4 bits of each byte,
	// and put the resulting (complemented) carry to the AC flag bit of AH.
	//-------
	mov		r1, r0					// Save flags in r0 to r1
	ldr		r2, [sp, #SP_DS_BASE]	// r2 = current effective logical DS segment
	ldr		r3, [sp, #SP_MASK_16]	// Use 16-bit memory addressing
	mov		r0, edi					// r0 = DI
	add		r0, #0x00F0
	add		r0, #0x7F00				// r0 = DI+7FF0
	calc_linear_address_r2_from_r0r3
	mov		r0, r1					// Restore flags from r1 to r0
	ldrb	r1, [r2]				// r1 = byte from [DI+7FF0]
	mov		r2, ebx, lsl #(24+4)	// r2 = low nibble of BL in highest bits
	cmp		r2, r1, lsl #(24+4)		// CMP BL,[DI+7FF0], ARM Carry clear if we need to set FLAG_AF.
	orrcc	eax, #((FLAG_AF)<<8)	// Set FLAG_AF if needed
	b		restore_flags_from_r0	// Go back to the opcode loop
1:	msr		cpsr_f,r0
	b		debug_trap_false
	
// ------------------- A0 = MOV AL,moffs8 ------------------------------
//
// See op_8a (mov_al_disp16)

// ------------------- A1 = MOV AX,moffs16 -----------------------------
//
// See op_8b (mov_ax_disp16)

// ------------------- A2 = MOV moffs8,AL ------------------------------
//
// See op_88 (mov_disp16_al)

// ------------------- A3 = MOV moffs16,AX ------------------------------
//
// See op_89 (mov_disp16_ax)

// ------------------- A8 = TEST AL,imm8 -------------------------------
//
op_a8:
	ldrb	r0,[r12],#1				// Load the imm8 byte to r0, increment r12 by 1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r1, eax, lsl #24		// Move AL into high byte of r1
	ands	r1, r0, lsl #24			// Perform the test
	//-------
	// Save the resulting byte (for possible later parity check)
	//-------
	lsr		r1, #24
	strb	r1, [sp, #SP_PARITY_BYTE]	// For "Chess Genius 3", save the parity byte to stack.
	b		loop

// ------------------- A9 = TEST AX,imm16 ------------------------------
//
op_a9:
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	ldrb	r0,[r12],#1				// Load byte to reg, increment r12 by 1
	ldrb	r1,[r12],#1				// Load byte to r0, increment r12 by 1
	mov		r2, eax, lsl #16
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	tst		r2, r0, lsl #16			// Perform the test
	b		loop

// =================== B0..B7 = MOV reg8,imm8 ==========================
// Opcodes B0..B7 for AL, CL, DL, BL, AH, CH, DH, BH
//
.macro mov_regl_imm8 reg
	ldrb	r0,[r12],#1				// Load imm8 to r0, increment r12 by 1
	bic		\reg, #0xFF
	orr		\reg, r0
	b		loop
.endm
.macro mov_regh_imm8 reg
	ldrb	r0,[r12],#1				// Load imm8 to r0, increment r12 by 1
	bic		\reg, #0xFF00
	orr		\reg, r0, lsl #8
	b		loop
.endm

op_b0:								// MOV AL,imm8
	mov_regl_imm8 r4
op_b1:								// MOV CL,imm8
	mov_regl_imm8 r5
op_b2:								// MOV DL,imm8
	mov_regl_imm8 r6
op_b3:								// MOV BL,imm8
	mov_regl_imm8 r7
op_b4:								// MOV AH,imm8
	mov_regh_imm8 r4
op_b5:								// MOV CH,imm8
	mov_regh_imm8 r5
op_b6:								// MOV DH,imm8
	mov_regh_imm8 r6
op_b7:								// MOV BH,imm8
	mov_regh_imm8 r7

// =================== B8..BF = MOV reg16,imm16 ========================
// Opcodes B8..BF for AX, CX, DX, BX, SP, BP, SI, DI
//
.macro mov_reg_imm16 reg
	ldrb	r0,[r12],#1
	ldrb	r1,[r12],#1
#if defined(RPi) || defined(Roku)
	lsr		\reg, #16
	orr		\reg, r0, \reg, lsl #16
	orr		\reg, r1, lsl #8
#else
	bfi		\reg, r0, #0, #8
	bfi		\reg, r1, #8, #8
#endif
	b		loop
.endm

op_b8:
	mov_reg_imm16 r4
op_b9:
	mov_reg_imm16 r5
op_ba:
	mov_reg_imm16 r6
op_bb:
	mov_reg_imm16 r7
op_bc:
	mov_reg_imm16 r8
op_bd:
	mov_reg_imm16 r9
op_be:
	mov_reg_imm16 r10
op_bf:
	mov_reg_imm16 r11

	.text
	.align 2
	
// ------------------- C0 = ROL/ROR/RCL/RCR/SHL/SHR/SHL/SAR r/m8,imm8 ---
// 
// Note: This instruction is only available on 80186 and up.
//
// We must also setup the flags!
// - RCL/RCR/ROL/ROR change only the carry flag, and overflow flag if the rotation count == 1.
// - SHL/SHR/SHL/SAR change carry, sign and zero flags (ARM behaves exactly like 8086)
//
op_c0:
	ldrb	r0,[r12],#1							// Load the second opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8
// 0 (idx only)
.macro tmp oper
	.word \oper\()_b_bxsi_imm8, \oper\()_b_bxdi_imm8, \oper\()_b_bpsi_imm8, \oper\()_b_bpdi_imm8, \oper\()_b_siidx_imm8, \oper\()_b_diidx_imm8, \oper\()_b_disp16_imm8, \oper\()_b_bxidx_imm8
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x40 (idx+disp8)
.macro tmp oper
	.word \oper\()_b_bxsid8_imm8, \oper\()_b_bxdid8_imm8, \oper\()_b_bpsid8_imm8, \oper\()_b_bpdid8_imm8, \oper\()_b_sidisp8_imm8, \oper\()_b_didisp8_imm8, \oper\()_b_bpdisp8_imm8, \oper\()_b_bxdisp8_imm8
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x80 (idx+disp16)
.macro tmp oper
	.word \oper\()_b_bxsid16_imm8, \oper\()_b_bxdid16_imm8, \oper\()_b_bpsid16_imm8, \oper\()_b_bpdid16_imm8, \oper\()_b_sidisp16_imm8, \oper\()_b_didisp16_imm8, \oper\()_b_bpdisp16_imm8, \oper\()_b_bxdisp16_imm8
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
//0xc0 = mod = 11b => two register operands
// ROL
	.word rol_al_imm8, rol_cl_imm8, rol_dl_imm8, rol_bl_imm8, rol_ah_imm8, rol_ch_imm8, rol_dh_imm8, rol_bh_imm8
// ROR	
	.word ror_al_imm8, ror_cl_imm8, ror_dl_imm8, ror_bl_imm8, ror_ah_imm8, ror_ch_imm8, ror_dh_imm8, ror_bh_imm8
// RCL	
	.word rcl_al_imm8, rcl_cl_imm8, rcl_dl_imm8, rcl_bl_imm8, rcl_ah_imm8, rcl_ch_imm8, rcl_dh_imm8, rcl_bh_imm8
// RCR
	.word rcr_al_imm8, rcr_cl_imm8, rcr_dl_imm8, rcr_bl_imm8, rcr_ah_imm8, rcr_ch_imm8, rcr_dh_imm8, rcr_bh_imm8
// SHL	
	.word shl_al_imm8, shl_cl_imm8, shl_dl_imm8, shl_bl_imm8, shl_ah_imm8, shl_ch_imm8, shl_dh_imm8, shl_bh_imm8
// SHR	
	.word shr_al_imm8, shr_cl_imm8, shr_dl_imm8, shr_bl_imm8, shr_ah_imm8, shr_ch_imm8, shr_dh_imm8, shr_bh_imm8
// SAL (never used)	
	.word shl_al_imm8, shl_cl_imm8, shl_dl_imm8, shl_bl_imm8, shl_ah_imm8, shl_ch_imm8, shl_dh_imm8, shl_bh_imm8
// SAR	
	.word sar_al_imm8, sar_cl_imm8, sar_dl_imm8, sar_bl_imm8, sar_ah_imm8, sar_ch_imm8, sar_dh_imm8, sar_bh_imm8

	.global rol_al_imm8, rol_cl_imm8, rol_dl_imm8, rol_bl_imm8, rol_ah_imm8, rol_ch_imm8, rol_dh_imm8, rol_bh_imm8
	.global ror_al_imm8, ror_cl_imm8, ror_dl_imm8, ror_bl_imm8, ror_ah_imm8, ror_ch_imm8, ror_dh_imm8, ror_bh_imm8
	.global rcl_al_imm8, rcl_cl_imm8, rcl_dl_imm8, rcl_bl_imm8, rcl_ah_imm8, rcl_ch_imm8, rcl_dh_imm8, rcl_bh_imm8
	.global rcr_al_imm8, rcr_cl_imm8, rcr_dl_imm8, rcr_bl_imm8, rcr_ah_imm8, rcr_ch_imm8, rcr_dh_imm8, rcr_bh_imm8
	.global shl_al_imm8, shl_cl_imm8, shl_dl_imm8, shl_bl_imm8, shl_ah_imm8, shl_ch_imm8, shl_dh_imm8, shl_bh_imm8
	.global shr_al_imm8, shr_cl_imm8, shr_dl_imm8, shr_bl_imm8, shr_ah_imm8, shr_ch_imm8, shr_dh_imm8, shr_bh_imm8
	.global sar_al_imm8, sar_cl_imm8, sar_dl_imm8, sar_bl_imm8, sar_ah_imm8, sar_ch_imm8, sar_dh_imm8, sar_bh_imm8

.macro opc0genall oper
\oper\()_b_bxsi_imm8:
	add		r0, ebx, esi
	b		\oper\()_b_r0_imm8
\oper\()_b_bxdi_imm8:
	add		r0, ebx, edi
	b		\oper\()_b_r0_imm8
\oper\()_b_bpsi_imm8:
	add		r0, ebp, esi
	b		\oper\()_b_r0_bp_imm8
\oper\()_b_bpdi_imm8:
	add		r0, ebp, edi
	b		\oper\()_b_r0_bp_imm8
	.global	\oper\()_b_siidx_imm8
\oper\()_b_siidx_imm8:
	mov		r0, esi
	b		\oper\()_b_r0_imm8
	.global	\oper\()_b_diidx_imm8
\oper\()_b_diidx_imm8:
	mov		r0, edi
	b		\oper\()_b_r0_imm8
\oper\()_b_disp16_imm8:
	r0_from_disp16
	b		\oper\()_b_r0_imm8
	.global	\oper\()_b_bxidx_imm8
\oper\()_b_bxidx_imm8:
	mov		r0, ebx
	b		\oper\()_b_r0_imm8
\oper\()_b_bxsid8_imm8:
	r0_from_bxidxdisp8 esi
	b		\oper\()_b_r0_imm8
\oper\()_b_bxdid8_imm8:
	r0_from_bxidxdisp8 edi
	b		\oper\()_b_r0_imm8
\oper\()_b_bpsid8_imm8:
	r0_from_bpidxdisp8 esi
	b		\oper\()_b_r0_bp_imm8
\oper\()_b_bpdid8_imm8:
	r0_from_bpidxdisp8 edi
	b		\oper\()_b_r0_bp_imm8
	.global	\oper\()_b_sidisp8_imm8
\oper\()_b_sidisp8_imm8:
	r0_from_idx_disp8 esi
	b		\oper\()_b_r0_imm8
	.global	\oper\()_b_didisp8_imm8
\oper\()_b_didisp8_imm8:
	r0_from_idx_disp8 edi
	b		\oper\()_b_r0_imm8
	.global	\oper\()_b_bpdisp8_imm8
\oper\()_b_bpdisp8_imm8:
	r0_from_idx_disp8 ebp
	b		\oper\()_b_r0_bp_imm8
	.global	\oper\()_b_bxdisp8_imm8
\oper\()_b_bxdisp8_imm8:
	r0_from_idx_disp8 ebx
	b		\oper\()_b_r0_imm8
\oper\()_b_bxsid16_imm8:
	r0_from_bxidxdisp16 esi
	b		\oper\()_b_r0_imm8
\oper\()_b_bxdid16_imm8:
	r0_from_bxidxdisp16 edi
	b		\oper\()_b_r0_imm8
\oper\()_b_bpsid16_imm8:
	r0_from_bpidxdisp16 esi
	b		\oper\()_b_r0_bp_imm8
\oper\()_b_bpdid16_imm8:
	r0_from_bpidxdisp16 edi
	b		\oper\()_b_r0_bp_imm8
\oper\()_b_sidisp16_imm8:
	r0_from_idx_disp16 esi
	b		\oper\()_b_r0_imm8
\oper\()_b_didisp16_imm8:
	r0_from_idx_disp16 edi
	b		\oper\()_b_r0_imm8
\oper\()_b_bpdisp16_imm8:
	r0_from_idx_disp16 ebp
	b		\oper\()_b_r0_bp_imm8
\oper\()_b_bxdisp16_imm8:
	r0_from_idx_disp16 ebx
	b		\oper\()_b_r0_imm8
.endm

// ----- ROL -----

	.global	rol_b_r0_bp_imm8
rol_b_r0_bp_imm8:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	rol_b_r0_imm8
rol_b_r0_imm8:					// Rotate a byte at offset r0high in effective segment left by r1 value
	mem_handler_jump_r0r3 rol_byte_r2_imm8_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// We can only change the Carry flag, and overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
rol_byte_r2_imm8_RAM:
	ldrb	r1,[r12],#1				// Get the imm8 byte
rol_byte_r2_r1:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, 8, 16 or 24 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #7					// Are we to shift by a number divisible by 8, yet not zero bits?
	beq		8f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..7 bit positions.
	//=======
	bic		r0, #0xFF				// Clear the low byte of r0 (highest byte contains the saved flags)
	rsb		r1, #8					// r1 = 8-rol_count == ror_count
	orr		r0, r1					// Now r0 low byte is the number of bits to rotate the byte right 
	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	bic		r0, #ARM_CARRY			// Clear the Carry bit of the saved CPU flags
	mov		r1, r1, ror r0			// Rotate the value
	orr		r1, r1, lsr #24			// Move the bits we rotated from the bottom back to the lowest byte
	strb	r1, [r2]				// Save the byte back to RAM
	tst		r1, #1					// Is the lowest bit set (means we need to set Carry)?
	orrne	r0, #ARM_CARRY			// Yep, so set it.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
rol_byte_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsl #(24+1)		// First shift the register left 1 bit position, and set the flags
	orrcs	r1, #0x01000000			// If Carry is set, set the lowest bit of the register, ...
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	lsr		r1, #24
	strb	r1, [r2]				// Save the shifted value
	eor		r1, r0, r1, lsl #(24-2)	// Now r0 ARM_CARRY bit = new Overflow bit value
	and		r1, #ARM_CARRY			// Leave only the ARM_CARRY bit into r0
	orr		r0, r1, lsr #1			// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 8, 16 or 24 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the low bit of the byte value.
	//=======
8:	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	bic		r0, #ARM_CARRY
	tst		r1, #1
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc0genall	rol

.macro rol_reg8l_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
rol_r8l_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, 8, 16 or 24 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #7					// Are we to shift by a number divisible by 8, yet not zero bits?
	beq		8f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..7 bit positions.
	//=======
	rsb		r2, r1, #8				// r2 = 8-rol_count == ror_count
	and		r1, \reg, #0xFF
	bic		r0, #ARM_CARRY			// Clear the Carry bit of the saved CPU flags
	mov		r1, r1, ror r2			// Rotate the value
	orr		r1, r1, lsr #24			// Move the bits we rotated from the bottom back to the lowest byte
	and		r1, #0xFF
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1				// and replace it with r1 shifted to reg8l
	tst		r1, #1					// Is the lowest bit set (means we need to set Carry)?
	orrne	r0, #ARM_CARRY			// Yep, so set it.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
rol_reg8l_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	mov		r1, \reg, lsl #24		// r1 = reg8l value in the highest byte
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsl #1			// First shift the register left 1 bit position, and set the flags
	orrcs	r1, #0x01000000			// If Carry is set, set the lowest bit of the register, ...
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1, lsr #24		// and replace it with r1 shifted to reg8l
	eor		r1, r0, r1, lsr #2		// Now r0 ARM_CARRY bit = new Overflow bit value
	and		r1, #ARM_CARRY			// Leave only the ARM_CARRY bit into r0
	orr		r0, r1, lsr #1			// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 8, 16 or 24 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the low bit of the byte value.
	//=======
8:	bic		r0, #ARM_CARRY
	tst		\reg, #0x0001
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm
.macro rol_reg8h_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
rol_r8h_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, 8, 16 or 24 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #7					// Are we to shift by a number divisible by 8, yet not zero bits?
	beq		8f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..7 bit positions.
	//=======
	rsb		r2, r1, #8				// r2 = 8-rol_count == ror_count
	mov		r1, \reg, lsr #8		// r1 = reg8h value in the lowest byte
	and		r1, #0xFF
	bic		r0, #ARM_CARRY			// Clear the Carry bit of the saved CPU flags
	mov		r1, r1, ror r2			// Rotate the value
	orr		r1, r1, lsr #24			// Move the bits we rotated from the bottom back to the lowest byte
	and		r1, #0xFF
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsl #8		// and replace it with r1 shifted to reg8h
	tst		r1, #1					// Is the lowest bit set (means we need to set Carry)?
	orrne	r0, #ARM_CARRY			// Yep, so set it.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======
rol_reg8h_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	mov		r1, \reg, lsl #16		// r1 = reg8h value in the highest byte
	and		r1, #0xFF000000
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsl #1			// First shift the register left 1 bit position, and set the flags
	orrcs	r1, #0x01000000			// If Carry is set, set the lowest bit of the register, ...
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsr #16		// and replace it with r1 shifted to reg8h
	eor		r1, r0, r1, lsr #2		// Now r0 ARM_CARRY bit = new Overflow bit value
	and		r1, #ARM_CARRY			// Leave only the ARM_CARRY bit into r0
	orr		r0, r1, lsr #1			// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 8, 16 or 24 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the low bit of the byte value.
	//=======
8:	bic		r0, #ARM_CARRY
	tst		\reg, #0x0100
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

rol_al_imm8:
	rol_reg8l_imm8 r4
rol_cl_imm8:
	rol_reg8l_imm8 r5
rol_dl_imm8:
	rol_reg8l_imm8 r6
rol_bl_imm8:
	rol_reg8l_imm8 r7
rol_ah_imm8:
	rol_reg8h_imm8 r4
rol_ch_imm8:
	rol_reg8h_imm8 r5
rol_dh_imm8:
	rol_reg8h_imm8 r6
rol_bh_imm8:
	rol_reg8h_imm8 r7

// ----- ROR -----

	.global	ror_b_r0_bp_imm8
ror_b_r0_bp_imm8:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	ror_b_r0_imm8
ror_b_r0_imm8:					// Rotate a byte at offset r0high in effective segment right by r1 value
	mem_handler_jump_r0r3 ror_byte_r2_imm8_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// We can only change the Carry flag, and overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
ror_byte_r2_imm8_RAM:
	ldrb	r1,[r12],#1				// Get the imm8 byte
ror_byte_r2_r1:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, 8, 16 or 24 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #7					// Are we to shift by a number divisible by 8, yet not zero bits?
	beq		8f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..7 bit positions.
	//=======
	bic		r0, #0xFF				// Clear the low byte of r0 (highest byte contains the saved flags)
	orr		r0, r1					// Now r0 low byte is the number of bits to rotate the byte right 
	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	bic		r0, #ARM_CARRY			// Clear the Carry bit of the saved CPU flags
	movs	r1, r1, ror r0			// Rotate the value
	orr		r1, r1, lsr #24			// Move the bits we rotated from the bottom back to the lowest byte
	strb	r1, [r2]				// Save the byte back to RAM
	orrcs	r0, #ARM_CARRY			// If Carry is set, set it in the saved flags as well.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
ror_byte_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsr #1			// First shift the register right 1 bit position, and set the flags
	orrcs	r1, #0x80				// If Carry is set, set the highest bit of the register, ...
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	strb	r1, [r2]				// Save the shifted value
	eor		r1, r1, lsl #1			// Now r1 bit 0x80 = new Overflow bit value
	and		r1, #0x80				// Leave only the highest bit into r1
	orr		r0, r1, lsl #(24-3)		// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 8, 16 or 24 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the high bit of the byte value.
	//=======
8:	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	bic		r0, #ARM_CARRY
	tst		r1, #0x80
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc0genall	ror

.macro ror_reg8l_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
ror_r8l_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, 8, 16 or 24 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #7					// Are we to shift by a number divisible by 8, yet not zero bits?
	beq		8f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..7 bit positions.
	//=======
	and		r2, \reg, #0xFF			// r1 = reg8l value in the lowest byte
	bic		r0, #ARM_CARRY			// Clear the Carry bit of the saved CPU flags
	movs	r2, r2, ror r1			// Rotate the value
	orr		r2, r2, lsr #24			// Move the bits we rotated from the bottom back to the lowest byte
	and		r2, #0xFF
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r2				// and replace it with r1 shifted to reg8l
	orrcs	r0, #ARM_CARRY			// If Carry is set, set it in the saved flags as well.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
ror_reg8l_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	and		r1, \reg, #0xFF			// r1 = reg8l value in the lowest byte
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsr #1			// First shift the register right 1 bit position, and set the flags
	orrcs	r1, #0x80				// If Carry is set, set the highest bit of the register, ...
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1				// and replace it with r1 shifted to reg8l
	eor		r1, r1, lsl #1			// Now r1 bit 0x80 = new Overflow bit value
	and		r1, #0x80				// Leave only the highest bit into r1
	orr		r0, r1, lsl #(24-3)		// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 8, 16 or 24 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the high bit of the byte value.
	//=======
8:	bic		r0, #ARM_CARRY
	tst		\reg, #0x0080
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm
.macro ror_reg8h_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
ror_r8h_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, 8, 16 or 24 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #7					// Are we to shift by a number divisible by 8, yet not zero bits?
	beq		8f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..7 bit positions.
	//=======
	mov		r2, \reg, lsr #8		// r2 = reg8h value in the lowest byte
	and		r2, #0xFF
	bic		r0, #ARM_CARRY			// Clear the Carry bit of the saved CPU flags
	movs	r2, r2, ror r1			// Rotate the value
	orr		r2, r2, lsr #24			// Move the bits we rotated from the bottom back to the lowest byte
	and		r2, #0xFF
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r2, lsl #8		// and replace it with r2 shifted to reg8h
	orrcs	r0, #ARM_CARRY			// If Carry is set, set it in the saved flags as well.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
ror_reg8h_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	mov		r1, \reg, lsr #8		// r1 = reg8h value in the lowest byte
	and		r1, #0xFF
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsr #1			// First shift the register right 1 bit position, and set the flags
	orrcs	r1, #0x80				// If Carry is set, set the highest bit of the register, ...
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	bic		\reg, #0xFF00			// Clear the current reg8l value
	orr		\reg, r1, lsl #8		// and replace it with r1 shifted to reg8l
	eor		r1, r1, lsl #1			// Now r1 bit 0x80 = new Overflow bit value
	and		r1, #0x80				// Leave only the highest bit into r1
	orr		r0, r1, lsl #(24-3)		// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 8, 16 or 24 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the high bit of the byte value.
	//=======
8:	bic		r0, #ARM_CARRY
	tst		\reg, #0x8000
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

ror_al_imm8:
	ror_reg8l_imm8 r4
ror_cl_imm8:
	ror_reg8l_imm8 r5
ror_dl_imm8:
	ror_reg8l_imm8 r6
ror_bl_imm8:
	ror_reg8l_imm8 r7
ror_ah_imm8:
	ror_reg8h_imm8 r4
ror_ch_imm8:
	ror_reg8h_imm8 r5
ror_dh_imm8:
	ror_reg8h_imm8 r6
ror_bh_imm8:
	ror_reg8h_imm8 r7

// ----- RCL -----

	.global	rcl_b_r0_bp_imm8
rcl_b_r0_bp_imm8:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	rcl_b_r0_imm8
rcl_b_r0_imm8:					// Rotate a byte at offset r0high in effective segment left by r1 value
	mem_handler_jump_r0r3 rcl_byte_r2_imm8_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// We can only change the Carry flag, and overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
rcl_byte_r2_imm8_RAM:
	ldrb	r1,[r12],#1				// Get the imm8 byte
rcl_byte_r2_r1:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	bic		r0, #0xFF				// Clear the low byte of r0 (highest byte contains the saved flags)
	orr		r0, r1					// r0 low byte = number of bit positions to rotate
	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r1, #0x100				// If it was, set the 9th bit of the value
	//-------
	// Perform a 9-bit value rotate. Carry goes to the lowest bit, bit 0x100 will be the new Carry.
	//-------
2:	lsl		r1, #1					// Perform the rotate once
	tst		r1, #0x200				// Was the 9th bit set before the rotate?
	orrne	r1, #1					// It was, set the lowest bit
	sub		r0, #1					// One bit handled,
	tst		r0, #0xFF				// still bits to do?
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Save the result
	//-------
	strb	r1, [r2]
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r1, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the lowest bit.
	//=======	
rcl_byte_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	tst		r0, #ARM_CARRY
	lsl		r1, #1					// Shift left 1 bit
	orrne	r1, #1					// Move Carry into the lowest bit
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	strb	r1, [r2]				// Save the shifted value
	eor		r1, r1, lsr #1			// Now r1 bit 0x100 is the new Carry flag, bit 0x80 is the new Overflow flag
	and		r1, #0x180				// Leave only the new Carry and Overflow bits to r1
	orr		r0, r1, lsl #(24-3)		// and put them into the ARM_CARRY and ARM_OVER positions (0x30000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc0genall rcl

.macro rcl_reg8l_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
rcl_r8l_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	and		r2, \reg, #0xFF			// r2 = reg8l value in the lowest byte
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r2, #0x100				// If it was, set the 9th bit of the value
	//-------
	// Perform a 9-bit value rotate. Carry goes to the lowest bit, bit 0x100 will be the new Carry.
	//-------
2:	lsl		r2, #1					// Perform the rotate once
	tst		r2, #0x200				// Was the 9th bit set before the rotate?
	orrne	r2, #1					// It was, set the lowest bit
	subs	r1, #1					// One bit handled,
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r2, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	//-------
	// Save the result
	//-------
	bic		\reg, #0xFF				// Clear the current reg8l value
	and		r2, #0xFF				// Use only the low byte for result
	orr		\reg, r2				// and replace it with r1 shifted to reg8l
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the lowest bit.
	//=======	
rcl_reg8l_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	and		r1, \reg, #0xFF
	tst		r0, #ARM_CARRY
	lsl		r1, #1					// Shift left 1 bit
	orrne	r1, #1					// Move Carry into the lowest bit
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	bic		\reg, #0xFF				// Clear current reg8l value
	and		r2, r1, #0xFF			// Make sure r1 does not have any extra bits on
	orr		\reg, r2				// And put the new reg value into reg8l
	eor		r1, r1, lsr #1			// Now r1 bit 0x100 is the new Carry flag, bit 0x80 is the new Overflow flag
	and		r1, #0x180				// Leave only the new Carry and Overflow bits to r1
	orr		r0, r1, lsl #(24-3)		// and put them into the ARM_CARRY and ARM_OVER positions (0x30000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm
.macro rcl_reg8h_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
rcl_r8h_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	mov		r2, \reg, lsr #8		// r2 = reg8h value in the lowest byte
	and		r2, #0xFF
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r2, #0x100				// If it was, set the 9th bit of the value
	//-------
	// Perform a 9-bit value rotate. Carry goes to the lowest bit, bit 0x100 will be the new Carry.
	//-------
2:	lsl		r2, #1					// Perform the rotate once
	tst		r2, #0x200				// Was the 9th bit set before the rotate?
	orrne	r2, #1					// It was, set the lowest bit
	subs	r1, #1					// One bit handled,
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r2, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	//-------
	// Save the result
	//-------
	and		r2, #0xFF
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r2, lsl #8		// and replace it with r2 shifted to reg8h
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the lowest bit.
	//=======	
rcl_reg8h_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	mov		r1, \reg, lsr #8
	and		r1, #0xFF
	tst		r0, #ARM_CARRY
	lsl		r1, #1					// Shift left 1 bit
	orrne	r1, #1					// Move Carry into the lowest bit
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	bic		\reg, #0xFF00			// Clear current reg8h value
	and		r2, r1, #0xFF
	orr		\reg, r2, lsl #8		// And put the new reg value into reg8h
	eor		r1, r1, lsr #1			// Now r1 bit 0x100 is the new Carry flag, bit 0x80 is the new Overflow flag
	and		r1, #0x180				// Leave only the new Carry and Overflow bits to r1
	orr		r0, r1, lsl #(24-3)		// and put them into the ARM_CARRY and ARM_OVER positions (0x30000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

rcl_al_imm8:
	rcl_reg8l_imm8 r4
rcl_cl_imm8:
	rcl_reg8l_imm8 r5
rcl_dl_imm8:
	rcl_reg8l_imm8 r6
rcl_bl_imm8:
	rcl_reg8l_imm8 r7
rcl_ah_imm8:
	rcl_reg8h_imm8 r4
rcl_ch_imm8:
	rcl_reg8h_imm8 r5
rcl_dh_imm8:
	rcl_reg8h_imm8 r6
rcl_bh_imm8:
	rcl_reg8h_imm8 r7

// ----- RCR -----

	.global	rcr_b_r0_bp_imm8
rcr_b_r0_bp_imm8:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	rcr_b_r0_imm8
rcr_b_r0_imm8:					// Rotate a byte at offset r0high in effective segment right by r1 value
	mem_handler_jump_r0r3 rcr_byte_r2_imm8_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// We can only change the Carry flag, and also overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
rcr_byte_r2_imm8_RAM:
	ldrb	r1,[r12],#1				// Get the imm8 byte
rcr_byte_r2_r1:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	bic		r0, #0xFF				// Clear the low byte of r0 (highest byte contains the saved flags)
	orr		r0, r1					// r0 low byte = number of bit positions to rotate
	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r1, #0x100				// If it was, set the 9th bit of the value
	//-------
	// Perform a 9-bit value rotate. Carry goes to the 8th bit, bit 0 will go to Carry.
	//-------
2:	movs	r1, r1, lsr #1			// Perform the rotate once, adjusting real Carry flag
	orrcs	r1, #0x100				// Put the carry into the 9th bit of the value
	sub		r0, #1					// One bit handled,
	tst		r0, #0xFF				// still bits to do?
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Save the result
	//-------
	strb	r1, [r2]
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r1, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the highest bit.
	//=======	
rcr_byte_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	tst		r0, #ARM_CARRY			// If the input Carry was set, ...
	orrne	r1, #0x100				// ... set the 9th bit of the value to rotate.
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	tst		r1, #1					// If the lowest bit was set in the value to RCR, ...
	orrne	r0, #ARM_CARRY			// ... set the resulting Carry flag
	lsr		r1, #1					// Shift the value
	strb	r1, [r2]				// and save it to memory
	eor		r1, r1, lsl #1			// Now bit 0x80 has the new overflow flag value
	tst		r1, #0x80				// If the new Overflow bit is set, ...
	orrne	r0, #ARM_OVER			// ... set the resulting Overflow flag.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc0genall rcr

.macro rcr_reg8l_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
rcr_r8l_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	and		r2, \reg, #0xFF			// r2 = reg8l value in the lowest byte
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r2, #0x100				// If it was, set the 9th bit of the value
	//-------
	// Perform a 9-bit value rotate. Carry goes to the 8th bit, bit 0 will go to Carry.
	//-------
2:	movs	r2, r2, lsr #1			// Perform the rotate once, adjusting real Carry flag
	orrcs	r2, #0x100				// Put the carry into the 9th bit of the value
	subs	r1, #1					// One bit handled,
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r2, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	//-------
	// Save the result
	//-------
	bic		\reg, #0xFF				// Clear the current reg8l value
	and		r2, #0xFF				// Use only the low byte for result
	orr		\reg, r2				// and replace it with r1 shifted to reg8l
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the highest bit.
	//=======	
rcr_reg8l_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	and		r1, \reg, #0xFF			// r2 = reg8l value in the lowest byte
	tst		r0, #ARM_CARRY			// If the input Carry was set, ...
	orrne	r1, #0x100				// ... set the 9th bit of the value to rotate.
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsr #1			// Shift the value
	orrcs	r0, #ARM_CARRY			// Set the resulting Carry flag
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1				// and replace it with r1 shifted to reg8l
	eor		r1, r1, lsl #1			// Now bit 0x80 has the new overflow flag value
	tst		r1, #0x80				// If the new Overflow bit is set, ...
	orrne	r0, #ARM_OVER			// ... set the resulting Overflow flag.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm
.macro rcr_reg8h_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
rcr_r8h_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	mov		r2, \reg, lsr #8		// r2 = reg8h value in the lowest byte
	and		r2, #0xFF
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r2, #0x100				// If it was, set the 9th bit of the value
	//-------
	// Perform a 9-bit value rotate. Carry goes to the 8th bit, bit 0 will go to Carry.
	//-------
2:	movs	r2, r2, lsr #1			// Perform the rotate once, adjusting real Carry flag
	orrcs	r2, #0x100				// Put the carry into the 9th bit of the value
	subs	r1, #1					// One bit handled,
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r2, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	//-------
	// Save the result
	//-------
	and		r2, #0xFF
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r2, lsl #8		// and replace it with r2 shifted to reg8h
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the highest bit.
	//=======	
rcr_reg8h_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	mov		r1, \reg, lsr #8		// r2 = reg8l value in the lowest byte
	and		r1, #0xFF
	tst		r0, #ARM_CARRY			// If the input Carry was set, ...
	orrne	r1, #0x100				// ... set the 9th bit of the value to rotate.
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsr #1			// Shift the value
	orrcs	r0, #ARM_CARRY			// Set the resulting Carry flag
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsl #8		// and replace it with r1 shifted to reg8h
	eor		r1, r1, lsl #1			// Now bit 0x80 has the new overflow flag value
	tst		r1, #0x80				// If the new Overflow bit is set, ...
	orrne	r0, #ARM_OVER			// ... set the resulting Overflow flag.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

rcr_al_imm8:
	rcr_reg8l_imm8 r4
rcr_cl_imm8:
	rcr_reg8l_imm8 r5
rcr_dl_imm8:
	rcr_reg8l_imm8 r6
rcr_bl_imm8:
	rcr_reg8l_imm8 r7
rcr_ah_imm8:
	rcr_reg8h_imm8 r4
rcr_ch_imm8:
	rcr_reg8h_imm8 r5
rcr_dh_imm8:
	rcr_reg8h_imm8 r6
rcr_bh_imm8:
	rcr_reg8h_imm8 r7

// ----- SHL -----

	.global	shl_b_r0_bp_imm8
shl_b_r0_bp_imm8:				// Shift a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	shl_b_r0_imm8
shl_b_r0_imm8:					// Shift a byte at offset r0high in effective segment left by r1 value
	mem_handler_jump_r0r3 shl_byte_r2_imm8_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// Zero, Sign and Carry flags are set always, Overflow only if r1 == 1.
	//-------
shl_byte_r2_imm8_RAM:
	ldrb	r1,[r12],#1				// Get the imm8 byte
shl_byte_r2_r1:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift left by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		shl_byte_r2_1_RAM		// Yes, go handle that case.
	//=======
	// Shift left by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which sould not change)
	ldrb	r0, [r2]				// Get the byte to rotate from RAM
	lsl		r0, #24
	movs	r0, r0, lsl r1			// Perform the shift left, setting the flags
	lsr		r0, #24
	strb	r0, [r2]
	b		loop
	//=======
	// Shift left by 1 bit position, so handle overflow flag as well.
	//=======
shl_byte_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r0, [r2]				// Get the byte to rotate from RAM
	lsl		r0, #24
	adds	r0, r0					// Perform the shift left, setting all flags
	lsr		r0, #24
	strb	r0, [r2]				// Get the byte to rotate from RAM
	b		loop

	opc0genall shl

.macro shl_reg8l_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
shl_r8l_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift left by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		shl_reg8l_1_\reg		// Yes, go handle that case.
	//=======
	// Shift left by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which sould not change)
	mov		r0, \reg, lsl #24		// r0 = reg8l value in highest byte
	movs	r0, r0, lsl r1			// Perform the shift left, setting the flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r0, lsr #24		// and replace it with r0 shifted to reg8l
	b		loop
	//=======
	// Shift left by 1 bit position, so handle overflow flag as well.
	//=======
shl_reg8l_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mov		r0, \reg, lsl #24		// r0 = reg8l value in highest byte
	adds	r0, r0					// Perform the shift left, setting all flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r0, lsr #24		// and replace it with r0 shifted to reg8l
	b		loop
.endm
.macro shl_reg8h_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
shl_r8h_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift left by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		shl_reg8h_1_\reg		// Yes, go handle that case.
	//=======
	// Shift left by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	mov		r0, \reg, lsl #16		// r0 = reg8l value in highest byte
	and		r0, #0xFF000000			// r0 = reg8h value in highest byte
	movs	r0, r0, lsl r1			// Perform the shift left, setting the flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r0, lsr #16		// and replace it with r0 shifted to reg8h
	b		loop
	//=======
	// Shift left by 1 bit position, so handle overflow flag as well.
	//=======
shl_reg8h_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mov		r0, \reg, lsl #16		// r0 = reg8h value in highest byte
	and		r0, #0xFF000000			// r0 = reg8h value in highest byte
	adds	r0, r0					// Perform the shift left, setting all flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r0, lsr #16		// and replace it with r0 shifted to reg8h
	b		loop
.endm

shl_al_imm8:
	shl_reg8l_imm8 r4
shl_cl_imm8:
	shl_reg8l_imm8 r5
shl_dl_imm8:
	shl_reg8l_imm8 r6
shl_bl_imm8:
	shl_reg8l_imm8 r7
shl_ah_imm8:
	shl_reg8h_imm8 r4
shl_ch_imm8:
	shl_reg8h_imm8 r5
shl_dh_imm8:
	shl_reg8h_imm8 r6
shl_bh_imm8:
	shl_reg8h_imm8 r7


// ----- SHR -----

	.global	shr_b_r0_bp_imm8
shr_b_r0_bp_imm8:				// Shift a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	shr_b_r0_imm8
shr_b_r0_imm8:					// Shift a byte at offset r0high in effective segment right by r1 value
	mem_handler_jump_r0r3 shr_byte_r2_imm8_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// Zero, Sign and Carry flags are set always, Overflow only if r1 == 1.
	//-------
shr_byte_r2_imm8_RAM:
	ldrb	r1,[r12],#1				// Get the imm8 byte
shr_byte_r2_r1:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		shr_byte_r2_1_RAM		// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	ldrb	r0, [r2]				// Get the byte to rotate from RAM
	movs	r0, r0, lsr r1			// Perform the shift right, setting the flags
	strb	r0, [r2]
	b		loop
	//=======
	// Shift right by 1 bit position, so handle overflow flag as well.
	//=======
shr_byte_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	movs	r1, r1, lsr #1			// Perform the shift right, setting all other flags byt Overflow
	strb	r1, [r2]				// Save the byte back to RAM
	// ----- Setup the Overflow flag
	mrs		r0,cpsr					// Save flags to r0
	tst		r1, #0x40				// This is the new Overflow flag
	biceq	r0, #ARM_OVER
	orrne	r0, #ARM_OVER
	b		restore_flags_from_r0

	opc0genall shr

.macro shr_reg8l_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
shr_r8l_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		shr_reg8l_1_\reg		// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	and		r0, \reg, #0xFF			// r0 = reg8l value in lowest byte
	movs	r0, r0, lsr r1			// Perform the shift right, setting the flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r0				// and replace it with r0 shifted to reg8l
	b		loop
	//=======
	// Shift right by 1 bit position, so handle overflow flag as well.
	//=======
shr_reg8l_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	and		r1, \reg, #0xFF			// r1 = reg8l value in lowest byte
	movs	r1, r1, lsr #1			// Perform the shift right, setting all other flags but Overflow
	bic		\reg, #0xFF				// Clear the current reg8l value
	orr		\reg, r1				// and replace it with r1 shifted to reg8l
	// ----- Setup the Overflow flag
	mrs		r0,cpsr					// Save flags to r0
	tst		r1, #0x40				// This is the new Overflow flag
	biceq	r0, #ARM_OVER
	orrne	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm
.macro shr_reg8h_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
shr_r8h_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		shr_reg8h_1_\reg		// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	mov		r0, \reg, lsr #8		// r0 = reg8h value in lowest byte
	and		r0, #0xFF
	movs	r0, r0, lsr r1			// Perform the shift right, setting the flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r0, lsl #8		// and replace it with r0 shifted to reg8h
	b		loop
	//=======
	// Shift right by 1 bit position, so handle overflow flag as well.
	//=======
shr_reg8h_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mov		r1, \reg, lsr #8		// r1 = reg8h value in lowest byte
	and		r1, #0xFF
	movs	r1, r1, lsr #1			// Perform the shift right, setting all other flags but Overflow
	bic		\reg, #0xFF00			// Clear the current reg8h value
	orr		\reg, r1, lsl #8		// and replace it with r1 shifted to reg8h
	// ----- Setup the Overflow flag
	mrs		r0,cpsr					// Save flags to r0
	tst		r1, #0x40				// This is the new Overflow flag
	biceq	r0, #ARM_OVER
	orrne	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

shr_al_imm8:
	shr_reg8l_imm8 r4
shr_cl_imm8:
	shr_reg8l_imm8 r5
shr_dl_imm8:
	shr_reg8l_imm8 r6
shr_bl_imm8:
	shr_reg8l_imm8 r7
shr_ah_imm8:
	shr_reg8h_imm8 r4
shr_ch_imm8:
	shr_reg8h_imm8 r5
shr_dh_imm8:
	shr_reg8h_imm8 r6
shr_bh_imm8:
	shr_reg8h_imm8 r7


// ----- SAR -----

	.global	sar_b_r0_bp_imm8
sar_b_r0_bp_imm8:				// Shift a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	sar_b_r0_imm8
sar_b_r0_imm8:					// Shift a byte at offset r0high in effective segment right by r1 value
	mem_handler_jump_r0r3 sar_byte_r2_imm8_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// Zero, Sign and Carry flags are set always, Overflow only if r1 == 1.
	//-------
sar_byte_r2_imm8_RAM:
	ldrb	r1,[r12],#1				// Get the imm8 byte
sar_byte_r2_r1:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		sar_byte_r2_1_RAM		// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	ldrb	r0, [r2]				// Get the byte to rotate from RAM
	lsl		r0, #24					// 
	asr		r0, #24					// Fix all the high bits for asr
	movs	r0, r0, asr r1			// Perform the shift right, setting the flags
	strb	r0, [r2]
	b		loop
	//=======
	// Shift right by 1 bit position, so overflow flag must be cleared.
	//=======
sar_byte_r2_1_RAM:
	ldrb	r1, [r2]				// Get the byte to rotate from RAM
	msr		cpsr_f, #0				// Clear all flags (especially Overflow)
	lsl		r1, #24					// 
	asr		r1, #24					// Fix all the high bits for asr
	movs	r1, r1, asr #1			// Perform the shift right, setting all other flags but Overflow
	strb	r1, [r2]				// Save the byte back to RAM
	b		loop

	opc0genall sar

.macro sar_reg8l_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
sar_r8l_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		sar_reg8l_1_\reg		// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	mov		r0, \reg, lsl #24		// r0 = reg8l value in highest byte
	asr		r0, #24					// Fix all the high bits for asr
	movs	r0, r0, asr r1			// Perform the shift right, setting the flags
	bic		\reg, #0xFF				// Clear the current reg8l value
	and		r0, #0xFF
	orr		\reg, r0				// and replace it with r0 shifted to reg8l
	b		loop
	//=======
	// Shift right by 1 bit position, so overflow flag must be cleared.
	//=======
sar_reg8l_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mov		r0, \reg, lsl #24		// r0 = reg8l value in highest byte
	asr		r0, #24					// Fix all the high bits for asr
	msr		cpsr_f, #0				// Clear all flags (especially Overflow)
	movs	r0, r0, asr #1			// Perform the shift right, setting all other flags but Overflow
	bic		\reg, #0xFF				// Clear the current reg8l value
	and		r0, #0xFF
	orr		\reg, r0				// and replace it with r0 shifted to reg8l
	b		loop
.endm
.macro sar_reg8h_imm8 reg
	ldrb	r1,[r12],#1				// Get the imm8 byte
sar_r8h_r1_\reg:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		sar_reg8h_1_\reg		// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	mov		r0, \reg, lsl #16		// Fix all the high bits for asr
	asr		r0, #24
	movs	r0, r0, asr r1			// Perform the shift right, setting the flags
	bic		\reg, #0xFF00			// Clear the current reg8h value
	and		r0, #0xFF
	orr		\reg, r0, lsl #8		// and replace it with r0 shifted to reg8h
	b		loop
	//=======
	// Shift right by 1 bit position, so overflow flag must be cleared.
	//=======
sar_reg8h_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mov		r0, \reg, lsl #16		// Fix all the high bits for asr
	asr		r0, #24
	msr		cpsr_f, #0				// Clear all flags (especially Overflow)
	movs	r0, r0, asr #1			// Perform the shift right, setting all other flags but Overflow
	bic		\reg, #0xFF00			// Clear the current reg8h value
	and		r0, #0xFF
	orr		\reg, r0, lsl #8		// and replace it with r0 shifted to reg8h
	b		loop
.endm

sar_al_imm8:
	sar_reg8l_imm8 r4
sar_cl_imm8:
	sar_reg8l_imm8 r5
sar_dl_imm8:
	sar_reg8l_imm8 r6
sar_bl_imm8:
	sar_reg8l_imm8 r7
sar_ah_imm8:
	sar_reg8h_imm8 r4
sar_ch_imm8:
	sar_reg8h_imm8 r5
sar_dh_imm8:
	sar_reg8h_imm8 r6
sar_bh_imm8:
	sar_reg8h_imm8 r7

// ------------------- C1 = ROL/ROR/RCL/RCR/SHL/SHR/SHL/SAR r/m16,imm8 ---
// 
// Note: This instruction is only available on 80186 and up.
//
// SHR BX,4 = C1EB04 => mod = 11, reg = 101 (SHR), rm = 011 (BX)
// rol word [si],08 = C10408
//
// mod = whether we use reg or mem
// reg = the operation (010 = 2 = RCL, 101 = 5 = SHR)
// rm = register to use if mod == 11b, 001 = CX
//
// We must also setup the flags!
// - RCL/RCR/ROL/ROR change only the carry flag.
// - SHL/SHR/SHL/SAR change carry, sign and zero flags (ARM behaves exactly like 8086)
//
	.global	op_c1
op_c1:
	ldrb	r0,[r12],#1							// Load the second opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8
// 0 (idx only)
.macro tmp oper
	.global \oper\()_siidx_16_imm8, \oper\()_diidx_16_imm8, \oper\()_disp16_16_imm8, \oper\()_bxidx_16_imm8
	.word \oper\()_bxsi_16_imm8, \oper\()_bxdi_16_imm8, \oper\()_bpsi_16_imm8, \oper\()_bpdi_16_imm8, \oper\()_siidx_16_imm8, \oper\()_diidx_16_imm8, \oper\()_disp16_16_imm8, \oper\()_bxidx_16_imm8
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x40 (idx+disp8)
.macro tmp oper
	.global \oper\()_sidisp8_16_imm8, \oper\()_didisp8_16_imm8, \oper\()_bpdisp8_16_imm8, \oper\()_bxdisp8_16_imm8
	.word \oper\()_bxsid8_16_imm8, \oper\()_bxdid8_16_imm8, \oper\()_bpsid8_16_imm8, \oper\()_bpdid8_16_imm8, \oper\()_sidisp8_16_imm8, \oper\()_didisp8_16_imm8, \oper\()_bpdisp8_16_imm8, \oper\()_bxdisp8_16_imm8
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x80 (idx+disp16)
.macro tmp oper
	.word \oper\()_bxsid16_16_imm8, \oper\()_bxdid16_16_imm8, \oper\()_bpsid16_16_imm8, \oper\()_bpdid16_16_imm8, \oper\()_sidisp16_16_imm8, \oper\()_didisp16_16_imm8, \oper\()_bpdisp16_16_imm8, \oper\()_bxdisp16_16_imm8
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
//0xc0 = mod = 11b => two register operands (use the same handlers as opcode d3)
	.word rol_ax_imm8, rol_cx_imm8, rol_dx_imm8, rol_bx_imm8, rol_sp_imm8, rol_bp_imm8, rol_si_imm8, rol_di_imm8
	.word ror_ax_imm8, ror_cx_imm8, ror_dx_imm8, ror_bx_imm8, ror_sp_imm8, ror_bp_imm8, ror_si_imm8, ror_di_imm8
	.word rcl_ax_imm8, rcl_cx_imm8, rcl_dx_imm8, rcl_bx_imm8, rcl_sp_imm8, rcl_bp_imm8, rcl_si_imm8, rcl_di_imm8
	.word rcr_ax_imm8, rcr_cx_imm8, rcr_dx_imm8, rcr_bx_imm8, rcr_sp_imm8, rcr_bp_imm8, rcr_si_imm8, rcr_di_imm8
	.word shl_ax_imm8, shl_cx_imm8, shl_dx_imm8, shl_bx_imm8, shl_sp_imm8, shl_bp_imm8, shl_si_imm8, shl_di_imm8
	.word shr_ax_imm8, shr_cx_imm8, shr_dx_imm8, shr_bx_imm8, shr_sp_imm8, shr_bp_imm8, shr_si_imm8, shr_di_imm8
	.word shl_ax_imm8, shl_cx_imm8, shl_dx_imm8, shl_bx_imm8, shl_sp_imm8, shl_bp_imm8, shl_si_imm8, shl_di_imm8
	.word sar_ax_imm8, sar_cx_imm8, sar_dx_imm8, sar_bx_imm8, sar_sp_imm8, sar_bp_imm8, sar_si_imm8, sar_di_imm8

	.global rol_ax_imm8, rol_cx_imm8, rol_dx_imm8, rol_bx_imm8, rol_sp_imm8, rol_bp_imm8, rol_si_imm8, rol_di_imm8
	.global ror_ax_imm8, ror_cx_imm8, ror_dx_imm8, ror_bx_imm8, ror_sp_imm8, ror_bp_imm8, ror_si_imm8, ror_di_imm8
	.global rcl_ax_imm8, rcl_cx_imm8, rcl_dx_imm8, rcl_bx_imm8, rcl_sp_imm8, rcl_bp_imm8, rcl_si_imm8, rcl_di_imm8
	.global rcr_ax_imm8, rcr_cx_imm8, rcr_dx_imm8, rcr_bx_imm8, rcr_sp_imm8, rcr_bp_imm8, rcr_si_imm8, rcr_di_imm8
	.global shl_ax_imm8, shl_cx_imm8, shl_dx_imm8, shl_bx_imm8, shl_sp_imm8, shl_bp_imm8, shl_si_imm8, shl_di_imm8
	.global shr_ax_imm8, shr_cx_imm8, shr_dx_imm8, shr_bx_imm8, shr_sp_imm8, shr_bp_imm8, shr_si_imm8, shr_di_imm8
	.global sar_ax_imm8, sar_cx_imm8, sar_dx_imm8, sar_bx_imm8, sar_sp_imm8, sar_bp_imm8, sar_si_imm8, sar_di_imm8

.macro opc1genall oper
\oper\()_bxsi_16_imm8:
	add		r0, r7, r10
	b		\oper\()_r0_16_imm8
\oper\()_bxdi_16_imm8:
	add		r0, r7, r11
	b		\oper\()_r0_16_imm8
\oper\()_bpsi_16_imm8:
	add		r0, r9, r10
	b		\oper\()_r0_bp_16_imm8
\oper\()_bpdi_16_imm8:
	add		r0, r9, r11
	b		\oper\()_r0_bp_16_imm8
\oper\()_siidx_16_imm8:
	mov		r0, r10
	b		\oper\()_r0_16_imm8
\oper\()_diidx_16_imm8:
	mov		r0, r11
	b		\oper\()_r0_16_imm8
\oper\()_disp16_16_imm8:
	r0_from_disp16
	b		\oper\()_r0_16_imm8
\oper\()_bxidx_16_imm8:
	mov		r0, r7
	b		\oper\()_r0_16_imm8
\oper\()_bxsid8_16_imm8:
	r0_from_bxidxdisp8 r10
	b		\oper\()_r0_16_imm8
\oper\()_bxdid8_16_imm8:
	r0_from_bxidxdisp8 r11
	b		\oper\()_r0_16_imm8
\oper\()_bpsid8_16_imm8:
	r0_from_bpidxdisp8 r10
	b		\oper\()_r0_bp_16_imm8
\oper\()_bpdid8_16_imm8:
	r0_from_bpidxdisp8 r11
	b		\oper\()_r0_bp_16_imm8
\oper\()_sidisp8_16_imm8:
	r0_from_idx_disp8 r10
	b		\oper\()_r0_16_imm8
\oper\()_didisp8_16_imm8:
	r0_from_idx_disp8 r11
	b		\oper\()_r0_16_imm8
\oper\()_bpdisp8_16_imm8:
	r0_from_idx_disp8 r9
	b		\oper\()_r0_bp_16_imm8
\oper\()_bxdisp8_16_imm8:
	r0_from_idx_disp8 r7
	b		\oper\()_r0_16_imm8
\oper\()_bxsid16_16_imm8:
	r0_from_bxidxdisp16 r10
	b		\oper\()_r0_16_imm8
\oper\()_bxdid16_16_imm8:
	r0_from_bxidxdisp16 r11
	b		\oper\()_r0_16_imm8
\oper\()_bpsid16_16_imm8:
	r0_from_bpidxdisp16 r10
	b		\oper\()_r0_bp_16_imm8
\oper\()_bpdid16_16_imm8:
	r0_from_bpidxdisp16 r11
	b		\oper\()_r0_bp_16_imm8
\oper\()_sidisp16_16_imm8:
	r0_from_idx_disp16 r10
	b		\oper\()_r0_16_imm8
\oper\()_didisp16_16_imm8:
	r0_from_idx_disp16 r11
	b		\oper\()_r0_16_imm8
\oper\()_bpdisp16_16_imm8:
	r0_from_idx_disp16 r9
	b		\oper\()_r0_bp_16_imm8
\oper\()_bxdisp16_16_imm8:
	r0_from_idx_disp16 r7
	b		\oper\()_r0_16_imm8
.endm


// ----- ROL -----

	.global	rol_r0_bp_16_imm8
rol_r0_bp_16_imm8:				// Rotate a word when r0high offset is based on BP index
	mem_handler_bp
	.global	rol_r0_16_imm8
rol_r0_16_imm8:					// Rotate a word at offset r0high in effective segment left by r1 value
	ldrb	r1, [r12], #1			// r1 = imm8 value to shift/rotate with
	mem_handler_jump_r0r3 rol_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the word to rotate
	// We can only change the Carry flag, and overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
rol_word_r2_r1_RAM:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, or 16 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #15					// Are we to shift by 16 bits?
	beq		16f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..15 bit positions.
	//=======
	lsr		r0, #24					// r0 = flags in the lowest byte
	rsb		r1, #16					// r1 = 16-rol_count == ror_count
	orr		r0, r1, r0, ror #24		// Now r0 low byte is the number of bits to rotate the byte right, second lowest byte = flags
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	bic		r0, #(ARM_CARRY>>16)	// Clear the Carry bit of the saved CPU flags
	orr		r0, r1, lsl #24			// Save it to r0 high byte for a while
	ldrb	r1, [r2]				// Get the low byte to rotate from RAM
	orr		r1, r0, lsr #16			// Join the low and high bytes to r1
	mov		r1, r1, ror r0			// Rotate the value
	orr		r1, r1, lsr #16			// Move the bits we rotated from the bottom back to the low halfword
	lsl		r0, #16					// Put the flags back to the top byte of r0
	strb	r1, [r2]				// Save the low byte back to RAM
	tst		r1, #1					// Is the lowest bit set (means we need to set Carry)?
	lsr		r1, #8
	strb	r1, [r2, #1]			// Save the high byte back to RAM
	orrne	r0, #ARM_CARRY			// Yep, so set it.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
1:	msr		cpsr_f,r0				// Restore flags from r0
rol_word_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r0, [r2]				// Get the low byte to rotate from RAM
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	lsl		r0, #1					// Shift the low byte
	orr		r1, r0, r1, lsl #9		// r1 = the result, with bit 0x00010000 needed to move to bit 0x00000001
	mrs		r0,cpsr					// Save flags to r0
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	tst		r1, #0x00010000			// Should the carry and lowest bit be set?
	orrne	r1, #1					// Yes, so set the lowest bit, ...
	orrne	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	strb	r1, [r2]				// Save the low byte of the value
	lsr		r1, #8
	strb	r1, [r2, #1]			// Save the high byte of the value
	eor		r1, r0, r1, lsl #(24-2)	// Now r0 ARM_CARRY bit = new Overflow bit value
	and		r1, #ARM_CARRY			// Leave only the ARM_CARRY bit into r0
	orr		r0, r1, lsr #1			// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 16 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the low bit of the value.
	//=======
16:	ldrb	r1, [r2]				// Get the low byte of the value to rotate from RAM
	bic		r0, #ARM_CARRY
	tst		r1, #1
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc1genall rol

.macro rol_reg16_imm8 reg
	ldrb	r1, [r12], #1
rol_reg16_r1_\reg:					// Directly jump here for CL-based opcodes
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, or 16 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #15					// Are we to shift by a number divisible by 16, yet not zero bits?
	beq		16f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..15 bit positions.
	//=======
	rsb		r1, #16					// r1 = 16-rol_count == ror_count
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
	orr		r2, r2, lsr #16			// r2 = register value in both low and high 16 bits
	mov		r2, r2, ror r1			// Rotate the register value
	orr		\reg, r2, lsr #16		// Set the register value
16:	tst		\reg, #1				// Is the lowest bit set (means we need to set Carry)?
	biceq	r0, #ARM_CARRY			// No, so clear it.
	orrne	r0, #ARM_CARRY			// Yep, so set it.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
rol_reg16_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
	movs	r2, r2, lsl #1			// First shift the register left 1 bit position, and set the flags
	orrcs	r2, #0x00010000			// If Carry is set, set the lowest bit of the register, ...
	orr		\reg, r2, lsr #16		// Set the register value
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	eor		r1, r0, r2, lsr #2		// Now r1 ARM_CARRY bit = new Overflow bit value
	and		r1, #ARM_CARRY			// Leave only the ARM_CARRY bit into r1
	orr		r0, r1, lsr #1			// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

rol_ax_imm8:
	rol_reg16_imm8 r4
rol_cx_imm8:
	rol_reg16_imm8 r5
rol_dx_imm8:
	rol_reg16_imm8 r6
rol_bx_imm8:
	rol_reg16_imm8 r7
rol_sp_imm8:
	rol_reg16_imm8 r8
rol_bp_imm8:
	rol_reg16_imm8 r9
rol_si_imm8:
	rol_reg16_imm8 r10
rol_di_imm8:
	rol_reg16_imm8 r11


// ----- ROR -----

	.global	ror_r0_bp_16_imm8
ror_r0_bp_16_imm8:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	ror_r0_16_imm8
ror_r0_16_imm8:					// Rotate a byte at offset r0high in effective segment right by r1 value
	ldrb	r1, [r12], #1			// r1 = imm8 value to shift/rotate with
	mem_handler_jump_r0r3 ror_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// We can only change the Carry flag, and overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
ror_word_r2_r1_RAM:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, or 16 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #15					// Are we to shift by a number divisible by 16, yet not zero bits?
	beq		16f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..15 bit positions.
	//=======
	lsr		r0, #24					// r0 = flags in the lowest byte
	orr		r0, r1, r0, ror #24		// Now r0 low byte is the number of bits to rotate the byte right, second lowest byte = flags
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	bic		r0, #(ARM_CARRY>>16)	// Clear the Carry bit of the saved CPU flags
	orr		r0, r1, lsl #24			// Save it to r0 high byte for a while
	ldrb	r1, [r2]				// Get the low byte to rotate from RAM
	orr		r1, r0, lsr #16			// Join the low and high bytes to r1
	movs	r1, r1, ror r0			// Rotate the value, setting the carry flag
	orr		r1, r1, lsr #16			// Move the bits we rotated from the bottom back to the low halfword
	lsl		r0, #16					// Put the flags back to the top byte of r0
	strb	r1, [r2]				// Save the low byte back to RAM
	lsr		r1, #8
	strb	r1, [r2, #1]			// Save the high byte back to RAM
	orrcs	r0, #ARM_CARRY			// If Carry is set, set it in the saved flags as well.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
1:	msr		cpsr_f,r0				// Restore flags from r0
ror_word_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r0, [r2]				// Get the low byte to rotate from RAM
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	orr		r1, r0, r1, lsl #8		// r1 = the value to rotate
	mrs		r0,cpsr					// Save flags to r0
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r1, r1, lsr #1			// First shift the register right 1 bit position, and set the flags
	orrcs	r1, #0x8000				// If Carry is set, set the highest bit of the register, ...
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	strb	r1, [r2]				// Save the low byte of the shifted value
	lsr		r1, #8
	strb	r1, [r2, #1]			// Save the high byte of the shifted value
	eor		r1, r1, lsl #1			// Now r1 bit 0x80 = new Overflow bit value
	and		r1, #0x80				// Leave only the highest bit into r1
	orr		r0, r1, lsl #(24-3)		// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by 16 bit positions, so the value will stay unchanged
	// but the carry flag needs to be set to the high bit of the byte value.
	//=======
16:	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	bic		r0, #ARM_CARRY
	tst		r1, #0x80
	orrne	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc1genall	ror
	
.macro ror_reg16_imm8 reg
	ldrb	r1, [r12], #1
ror_reg16_r1_\reg:					// Directly jump here for CL-based opcodes
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0, 1, or 16 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	ands	r1, #15					// Are we to shift by a number divisible by 16, yet not zero bits?
	beq		16f						// Yes, go handle that special case.
	//=======
	// Rotate the value by 2..15 bit positions.
	//=======
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16
	orr		r2, r2, lsr #16
	mov		r2, r2, ror r1			// Rotate the register value
	orr		\reg, r2, lsr #16
16:	tst		\reg, #0x8000			// Is the highest bit set (means we need to set Carry)?
	biceq	r0, #ARM_CARRY			// No, so clear it.
	orrne	r0, #ARM_CARRY			// Yep, so set it.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position.
	//=======	
ror_reg16_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
1:	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16
	movs	r2, r2, lsr #17			// First shift the register right 1 bit position, and set the flags
	orrcs	r2, #0x8000				// If Carry is set, set the highest bit of the register, ...
	orr		\reg, r2
	orrcs	r0, #ARM_CARRY			// ... and set the Carry bit of the CPU flags (Carry bit is 0x20000000) in r0
	eor		r1, r2, r2, lsl #1		// Now r1 bit 0x8000 = new Overflow bit value
	and		r1, #0x8000				// Leave only the highest bit into r1
	orr		r0, r1, lsl #(16-3)		// and put it into CPU Overflow flag (Overflow bit is 0x10000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

ror_ax_imm8:
	ror_reg16_imm8 r4
ror_cx_imm8:
	ror_reg16_imm8 r5
ror_dx_imm8:
	ror_reg16_imm8 r6
ror_bx_imm8:
	ror_reg16_imm8 r7
ror_sp_imm8:
	ror_reg16_imm8 r8
ror_bp_imm8:
	ror_reg16_imm8 r9
ror_si_imm8:
	ror_reg16_imm8 r10
ror_di_imm8:
	ror_reg16_imm8 r11


// ----- RCL -----

	.global	rcl_r0_bp_16_imm8
rcl_r0_bp_16_imm8:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	rcl_r0_16_imm8
rcl_r0_16_imm8:					// Rotate a byte at offset r0high in effective segment left by r1 value
	ldrb	r1, [r12], #1			// r1 = imm8 value to shift/rotate with
	mem_handler_jump_r0r3 rcl_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// We can only change the Carry flag, and overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
rcl_word_r2_r1_RAM:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	orr		r0, r1, r0, lsr #16		// Now r0 low byte is the number of bits to rotate the byte right, second lowest byte = flags
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	orr		r0, r1, lsl #24			// Save it to r0 high byte for a while
	ldrb	r1, [r2]				// Get the low byte to rotate from RAM
	orr		r1, r0, lsr #16			// Join the low and high bytes to r1
	lsl		r0, #16					// Put the flags back to the top byte of r0
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r1, #0x10000			// If it was, set the 17th bit of the value
	//-------
	// Perform a 17-bit value rotate. Carry goes to the lowest bit, bit 0x10000 will be the new Carry.
	//-------
2:	lsl		r1, #1					// Perform the rotate once
	tst		r1, #0x20000			// Was the 17th bit set before the rotate?
	orrne	r1, #1					// It was, set the lowest bit
	sub		r0, #0x010000			// One bit handled,
	tst		r0, #0xFF0000			// still bits to do?
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Save the result
	//-------
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r1, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the lowest bit.
	//=======	
1:	msr		cpsr_f,r0				// Restore flags from r0
rcl_word_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r0, [r2]				// Get the low byte to rotate from RAM
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	lsl		r0, #1					// Shift the low byte
	orr		r1, r0, r1, lsl #9		// r1 = the result, with bit 0x00010000 telling the new Carry flag
	orrcs	r1, #1					// Lowest bit set from the Carry flag
	mrs		r0,cpsr					// Save flags to r0
	strb	r1, [r2]				// Save the shifted value
	lsr		r1, #8
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	strb	r1, [r2, #1]			// Save the shifted value
	eor		r1, r1, lsr #1			// Now r1 bit 0x100 is the new Carry flag, bit 0x80 is the new Overflow flag
	and		r1, #0x180				// Leave only the new Carry and Overflow bits to r1
	orr		r0, r1, lsl #(24-3)		// and put them into the ARM_CARRY and ARM_OVER positions (0x30000000) in r0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc1genall rcl

.macro rcl_reg16_imm8 reg
	ldrb	r1, [r12], #1
rcl_reg16_r1_\reg:					// Directly jump here for CL-based opcodes
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r2, #0x8000				// If it was, set the 17th bit of the value
	//-------
	// Perform a 9-bit value rotate. Carry goes to the lowest bit, bit 0x100 will be the new Carry.
	//-------
2:	movs	r2, r2, lsl #1			// Perform the rotate once, setting the Carry flag
	orrcs	r2, #0x8000				// It Carry got set, set the (low) 17th bit
	subs	r1, #1					// One bit handled, more bits to do?
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r2, #0x8000
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	//-------
	// Save the result
	//-------
	orr		\reg, r2, lsr #16
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the lowest bit.
	//=======	
rcl_reg16_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
1:	lsr		r2, #16
	tst		r0, #ARM_CARRY
	lsl		r2, #1					// Shift left 1 bit
	orrne	r2, #1					// Move Carry into the lowest bit
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	eor		r1, r2, r2, lsr #1		// Now r1 bit 0x10000 is the new Carry flag, bit 0x8000 is the new Overflow flag
	and		r1, #0x18000			// Leave only the new Carry and Overflow bits to r1
	orr		r0, r1, lsl #(16-3)		// and put them into the ARM_CARRY and ARM_OVER positions (0x30000000) in r0
	lsl		r2, #16
	orr		\reg, r2, lsr #16
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

rcl_ax_imm8:
	rcl_reg16_imm8 r4
rcl_cx_imm8:
	rcl_reg16_imm8 r5
rcl_dx_imm8:
	rcl_reg16_imm8 r6
rcl_bx_imm8:
	rcl_reg16_imm8 r7
rcl_sp_imm8:
	rcl_reg16_imm8 r8
rcl_bp_imm8:
	rcl_reg16_imm8 r9
rcl_si_imm8:
	rcl_reg16_imm8 r10
rcl_di_imm8:
	rcl_reg16_imm8 r11


// ----- RCR -----

	.global	rcr_r0_bp_16_imm8
rcr_r0_bp_16_imm8:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	rcr_r0_16_imm8
rcr_r0_16_imm8:					// Rotate a byte at offset r0high in effective segment right by r1 value
	ldrb	r1, [r12], #1			// r1 = imm8 value to shift/rotate with
	mem_handler_jump_r0r3 rcr_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// We can only change the Carry flag, and also overflow flag if r1 == 1. All other flags must remain unchanged.
	//-------
rcr_word_r2_r1_RAM:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	orr		r0, r1, r0, lsr #16		// Now r0 low byte is the number of bits to rotate the byte right, second lowest byte = flags
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	orr		r0, r1, lsl #24			// Save it to r0 high byte for a while
	ldrb	r1, [r2]				// Get the low byte to rotate from RAM
	orr		r1, r0, lsr #16			// Join the low and high bytes to r1
	lsl		r0, #16					// Put the flags back to the top byte of r0
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r1, #0x10000			// If it was, set the 17th bit of the value
	//-------
	// Perform a 17-bit value rotate. Carry goes to the lowest bit, bit 0x10000 will be the new Carry.
	//-------
2:	movs	r1, r1, lsr #1			// Perform the rotate once, adjusting real Carry flag
	orrcs	r1, #0x10000			// Put the carry into the 17th bit of the value
	sub		r0, #0x010000			// One bit handled,
	tst		r0, #0xFF0000			// still bits to do?
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Save the result
	//-------
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r1, #0x100
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the highest bit.
	//=======	
1:	msr		cpsr_f,r0				// Restore flags from r0
rcr_word_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r0, [r2]				// Get the low byte to rotate from RAM
	ldrb	r1, [r2, #1]			// Get the high byte to rotate from RAM
	orr		r1, r0, r1, lsl #8		// r1 = the result, with bit 0x00010000 telling the new Carry flag
	mrs		r0,cpsr					// Save flags to r0
	orrcs	r1, #0x10000			// If input Carry was set, set the 17th bit of the value.
	movs	r1, r1, lsr #1			// Rotate the value, setting the Carry flag
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	orrcs	r0, #ARM_CARRY			// Set the resulting Carry flag if the lowest bit was set
	strb	r1, [r2]				// Save the shifted value
	lsr		r1, #8
	strb	r1, [r2, #1]			// Save the shifted value
	eor		r1, r1, lsl #1			// Now bit 0x80 has the new overflow flag value
	tst		r1, #0x80				// If the new Overflow bit is set, ...
	orrne	r0, #ARM_OVER			// ... set the resulting Overflow flag.
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	opc1genall rcr

.macro rcr_reg16_imm8 reg
	ldrb	r1, [r12], #1
rcr_reg16_r1_\reg:					// Directly jump here for CL-based opcodes
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (rotate by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
	beq		1f						// Yes, go handle that case.
	//=======
	// Rotate the value by 2..31 bit positions.
	//=======
	lsr		r2, #16
	tst		r0, #ARM_CARRY			// Was the input Carry set?
	orrne	r2, #0x10000			// If it was, set the 17th bit of the value
	//-------
	// Perform a 17-bit value rotate. Carry goes to the 16th bit, bit 0 will go to Carry.
	//-------
2:	movs	r2, r2, lsr #1		// Perform the rotate once, adjusting real Carry flag
	orrcs	r2, #0x10000			// Put the carry into the 17th bit of the value
	subs	r1, #1					// One bit handled,
	bne		2b						// Yep, handle the remaining bits.
	//-------
	// Fix the resulting Carry flag
	//-------
	tst		r2, #0x10000
	orrne	r0, #ARM_CARRY
	biceq	r0, #ARM_CARRY
	//-------
	// Save the result
	//-------
	lsl		r2, #16
	orr		\reg, r2, lsr #16
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	//=======
	// Rotate by a single bit position, putting current Carry flag into the highest bit.
	//=======	
rcr_reg16_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mrs		r0,cpsr					// Save flags to r0
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
1:	lsr		r2, #16
	tst		r0, #ARM_CARRY			// If the input Carry was set, ...
	orrne	r2, #0x10000			// ... set the 17th bit of the value to rotate.
	bic		r0, #ARM_CARRY|ARM_OVER	// Clear the Carry and Overflow bits of the saved CPU flags
	movs	r2, r2, lsr #1		// Shift the value
	orrcs	r0, #ARM_CARRY			// Set the resulting Carry flag
	eor		r1, r2, r2, lsl #1	// Now bit 0x8000 has the new overflow flag value
	tst		r1, #0x8000				// If the new Overflow bit is set, ...
	orrne	r0, #ARM_OVER			// ... set the resulting Overflow flag.
	lsl		r2, #16
	orr		\reg, r2, lsr #16
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
.endm

rcr_ax_imm8:
	rcr_reg16_imm8 r4
rcr_cx_imm8:
	rcr_reg16_imm8 r5
rcr_dx_imm8:
	rcr_reg16_imm8 r6
rcr_bx_imm8:
	rcr_reg16_imm8 r7
rcr_sp_imm8:
	rcr_reg16_imm8 r8
rcr_bp_imm8:
	rcr_reg16_imm8 r9
rcr_si_imm8:
	rcr_reg16_imm8 r10
rcr_di_imm8:
	rcr_reg16_imm8 r11


// ----- SHL -----

	.global	shl_r0_bp_16_imm8
shl_r0_bp_16_imm8:				// Shift a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	shl_r0_16_imm8
shl_r0_16_imm8:					// Shift a byte at offset r0high in effective segment left by r1 value
	ldrb	r1, [r12], #1			// r1 = imm8 value to shift/rotate with
	mem_handler_jump_r0r3 shl_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// Zero, Sign and Carry flags are set always, Overflow only if r1 == 1.
	//-------
shl_word_r2_r1_RAM:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift left by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		shl_word_r2_1_RAM		// Yes, go handle that case.
	//=======
	// Shift left by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	ldrb	r0, [r2]				// Get the low byte to shift from RAM
	orr		r1, r0, r1, ror #8
	ldrb	r0, [r2, #1]			// Get the high byte to shift from RAM
	orr		r1, r0, lsl #8			// Now r1 high byte = the number of bits to shift, r1 low halfword = value to shift
	mov		r0, r1, lsr #24			// r0 = number of bits to shift the value left
	lsl		r1, #16					// r1 = value to shift in high halfword
	movs	r1, r1, lsl r0			// Perform the shift left, setting the flags
	lsr		r1, #16
	strb	r1, [r2]
	lsr		r1, #8
	strb	r1, [r2, #1]
	b		loop
	//=======
	// Shift left by 1 bit position, so handle overflow flag as well.
	//=======
shl_word_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r0, [r2]				// Get the byte to rotate from RAM
	ldrb	r1, [r2, #1]			// Get the high byte to shift from RAM
	lsl		r0, #16
	orr		r0, r1, lsl #24
	adds	r0, r0					// Perform the shift left, setting all flags
	lsr		r0, #16
	strb	r0, [r2]				// Save the low byte
	lsr		r0, #8
	strb	r0, [r2, #1]			// Save the high byte
	b		loop

	opc1genall shl

.macro shl_reg16_imm8 reg
	ldrb	r1, [r12], #1
shl_reg16_r1_\reg:					// Directly jump here for CL-based opcodes
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift left by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to rotate by a single bit position (so we need to handle overflow flag as well)?
	beq		shl_reg16_1_\reg		// Yes, go handle that case. (See "add_ax_ax" etc)
	//=======
	// Shift left by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
	movs	r2, r2, lsl r1			// Perform the shift left, setting the flags
	orr		\reg, r2, lsr #16
	b		loop
.endm

shl_ax_imm8:
	shl_reg16_imm8 r4
shl_cx_imm8:
	shl_reg16_imm8 r5
shl_dx_imm8:
	shl_reg16_imm8 r6
shl_bx_imm8:
	shl_reg16_imm8 r7
shl_sp_imm8:
	shl_reg16_imm8 r8
shl_bp_imm8:
	shl_reg16_imm8 r9
shl_si_imm8:
	shl_reg16_imm8 r10
shl_di_imm8:
	shl_reg16_imm8 r11


// ----- SHR -----

	.global	shr_r0_bp_16_imm8
shr_r0_bp_16_imm8:				// Shift a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	shr_r0_16_imm8
shr_r0_16_imm8:					// Shift a byte at offset r0high in effective segment right by r1 value
	ldrb	r1, [r12], #1			// r1 = imm8 value to shift/rotate with
	mem_handler_jump_r0r3 shr_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// Zero, Sign and Carry flags are set always, Overflow only if r1 == 1.
	//-------
shr_word_r2_r1_RAM:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		shr_word_r2_1_RAM		// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	ldrb	r0, [r2, #1]			// Get the high byte to shift from RAM
	orr		r1, r0, lsl #24			// Now r1 high byte = high byte of value to shift
	ldrb	r0, [r2]				// Get the low byte to shift from RAM
	orr		r0, r1, lsr #16			// r0 = 16-bit value to shift in low halfword
	and		r1, #31					// r1 = number of bits to shift the value
	movs	r0, r0, lsr r1			// Perform the shift, setting the flags
	strb	r0, [r2]
	lsr		r0, #8
	strb	r0, [r2, #1]
	b		loop
	//=======
	// Shift right by 1 bit position, so handle overflow flag as well.
	//=======
shr_word_r2_1_RAM:					// Directly jump here from single-bit-shift opcodes
	ldrb	r0, [r2]				// Get the low byte to shift from RAM
	ldrb	r1, [r2, #1]			// Get the high byte to shift from RAM
	orr		r1, r0, r1, lsl #8
	movs	r1, r1, lsr #1			// Perform the shift right, setting all other flags but Overflow
	strb	r1, [r2]				// Save the low byte
	lsr		r1, #8
	strb	r1, [r2, #1]			// Save the high byte
	// ----- Setup the Overflow flag
	mrs		r0,cpsr					// Save flags to r0
	tst		r1, #0x40				// This is the new Overflow flag
	biceq	r0, #ARM_OVER
	orrne	r0, #ARM_OVER
	b		restore_flags_from_r0

	opc1genall shr

.macro shr_reg16_imm8 reg
	ldrb	r1, [r12], #1
shr_reg16_r1_\reg:					// Directly jump here for CL-based opcodes
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
	beq		1f						// Yes, go handle that case.
	//=======
	// Shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	lsr		r2, #16
	movs	r2, r2, lsr r1			// Perform the shift right, setting the flags
	orr		\reg, r2
	b		loop
	//=======
	// Shift right by 1 bit position, so handle overflow flag as well.
	//=======
shr_reg16_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
1:	lsr		r2, #16
	movs	r2, r2, lsr #1			// Perform the shift right, setting the flags
	orr		\reg, r2
	// ----- Setup the Overflow flag
	mrs		r0,cpsr					// Save flags to r0
	tst		\reg, #0x4000			// This is the new Overflow flag
	biceq	r0, #ARM_OVER
	orrne	r0, #ARM_OVER
	b		restore_flags_from_r0
.endm

shr_ax_imm8:
	shr_reg16_imm8 r4
shr_cx_imm8:
	shr_reg16_imm8 r5
shr_dx_imm8:
	shr_reg16_imm8 r6
shr_bx_imm8:
	shr_reg16_imm8 r7
shr_sp_imm8:
	shr_reg16_imm8 r8
shr_bp_imm8:
	shr_reg16_imm8 r9
shr_si_imm8:
	shr_reg16_imm8 r10
shr_di_imm8:
	shr_reg16_imm8 r11

// ----- SAR -----

	.global	sar_r0_bp_16_imm8
sar_r0_bp_16_imm8:				// Shift a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	sar_r0_16_imm8
sar_r0_16_imm8:					// Shift a byte at offset r0high in effective segment right by r1 value
	ldrb	r1, [r12], #1			// r1 = imm8 value to shift/rotate with
	mem_handler_jump_r0r3 sar_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// On input:
	//	r0 = free
	//	r1 = number of bits to rotate the value with
	//	r2 = address of the byte to rotate
	// Zero, Sign and Carry flags are set always, Overflow only if r1 == 1.
	//-------
sar_word_r2_r1_RAM:
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	beq		sar_word_r2_1_RAM		// Yes, go handle that case.
	//=======
	// Arithmetic shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	ldrb	r0, [r2, #1]			// Get the high byte to shift from RAM
	orr		r1, r0, lsl #24			// Now r1 high byte = high byte of value to shift
	ldrb	r0, [r2]				// Get the low byte to shift from RAM
	orr		r0, r1, asr #16			// r0 = 16-bit value to shift in low halfword
	and		r1, #31					// r1 = number of bits to shift the value
	movs	r0, r0, asr r1			// Perform the shift, setting the flags
	strb	r0, [r2]
	lsr		r0, #8
	strb	r0, [r2, #1]
	b		loop
	//=======
	// Arithmetic shift right by 1 bit position, so overflow flag must be cleared.
	//=======
sar_word_r2_1_RAM:
	ldrb	r1, [r2, #1]			// Get the high byte to shift from RAM
	ldrb	r0, [r2]				// Get the low byte to shift from RAM
	msr		cpsr_f, #0				// Clear all flags (especially Overflow)
	lsl		r1, #24
	orr		r1, r0, r1, asr #16
	movs	r1, r1, asr #1			// Perform the shift right, setting all other flags but Overflow
	strb	r1, [r2]				// Save the low byte
	lsr		r1, #8
	strb	r1, [r2, #1]			// Save the high byte
	b		loop

	opc1genall sar

.macro sar_reg16_imm8 reg
	ldrb	r1, [r12], #1
sar_reg16_r1_\reg:					// Directly jump here for CL-based opcodes
	mrs		r0,cpsr					// Save flags to r0
	//=======
	// Check for special cases (shift by 0 or 1 bit positions)
	//=======
	ands	r1, #31					// Mask the rotation count
	beq		restore_flags_from_r0	// If the masked rotation count == 0, jump back to loop, restoring the flags.
	cmp		r1, #1					// Are we to shift by a single bit position (so we need to handle overflow flag as well)?
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
	beq		1f						// Yes, go handle that case.
	//=======
	// Arithmetic shift right by 2..31 bit positions.
	//=======
	msr		cpsr_f,r0				// Restore flags (for Overflow flag, which should not change)
	asr		r2, #16
	movs	r2, r2, asr r1			// Perform the shift right, setting the flags
	lsl		r2, #16
	orr		\reg, r2, lsr #16
	b		loop
	//=======
	// Arithmetic shift right by 1 bit position, so overflow flag must be cleared.
	//=======
sar_reg16_1_\reg:					// Directly jump here for single-bit-rotate opcodes
	mov		r2, \reg, lsl #16
	eor		\reg, r2, lsr #16		// Clean the current register value
1:	asr		r2, #16
	msr		cpsr_f, #0				// Clear all flags (especially Overflow)
	movs	r2, r2, asr #1			// Perform the shift right, setting all other flags but Overflow
	lsl		r2, #16
	orr		\reg, r2, lsr #16
	b		loop
.endm

sar_ax_imm8:
	sar_reg16_imm8 r4
sar_cx_imm8:
	sar_reg16_imm8 r5
sar_dx_imm8:
	sar_reg16_imm8 r6
sar_bx_imm8:
	sar_reg16_imm8 r7
sar_sp_imm8:
	sar_reg16_imm8 r8
sar_bp_imm8:
	sar_reg16_imm8 r9
sar_si_imm8:
	sar_reg16_imm8 r10
sar_di_imm8:
	sar_reg16_imm8 r11

	
#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

// ------------------- C2 = RETN imm16 ---------------------------------
op_c2:
	ldrb	r1,[r12],#1				// Load byte to r1, increment r12 by 1
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	ldr		r2,[sp, #SP_PHYS_CS]	// get the physical CS:0000 into r2
	orr		r1, r0, lsl #8			// r1 = low byte | (high byte << 8)
	pop_reg_low_tmp	r12 r0
#if defined(RPi) || defined(Roku)
	mov		r0, esp, lsl #16
	eor		esp, r0, lsr #16
	add		r0, r1, lsl #16
	orr		esp, r0, lsr #16
#else
	add		r1, esp
	bfi		esp, r1, #0, #16
#endif
	add		r12, r2					// r12 = new IP + physical CS
	b		loop

// ------------------- C3 = RETN ---------------------------------------
op_c3:
	ldr		r2,[sp, #SP_PHYS_CS]	// get the physical CS:0000 into r2
	pop_reg_low_tmp	r12 r0
	add		r12, r2					// r12 = new IP + physical CS
	b		loop


	.text
	.align 2
	
// ------------------- C4 = LES r16,m16:16 -----------------------------
//
// All modrm variations supported!
//
op_c4:
	modrm_jump_16
// 0
	.word les_ax_bxsi, les_ax_bxdi, les_ax_bpsi, les_ax_bpdi, les_ax_siidx, les_ax_diidx, les_ax_disp16, les_ax_bxidx
	.word les_cx_bxsi, les_cx_bxdi, les_cx_bpsi, les_cx_bpdi, les_cx_siidx, les_cx_diidx, les_cx_disp16, les_cx_bxidx
	.word les_dx_bxsi, les_dx_bxdi, les_dx_bpsi, les_dx_bpdi, les_dx_siidx, les_dx_diidx, les_dx_disp16, les_dx_bxidx
	.word les_bx_bxsi, les_bx_bxdi, les_bx_bpsi, les_bx_bpdi, les_bx_siidx, les_bx_diidx, les_bx_disp16, les_bx_bxidx
	.word les_sp_bxsi, les_sp_bxdi, les_sp_bpsi, les_sp_bpdi, les_sp_siidx, les_sp_diidx, les_sp_disp16, les_sp_bxidx
	.word les_bp_bxsi, les_bp_bxdi, les_bp_bpsi, les_bp_bpdi, les_bp_siidx, les_bp_diidx, les_bp_disp16, les_bp_bxidx
	.word les_si_bxsi, les_si_bxdi, les_si_bpsi, les_si_bpdi, les_si_siidx, les_si_diidx, les_si_disp16, les_si_bxidx
	.word les_di_bxsi, les_di_bxdi, les_di_bpsi, les_di_bpdi, les_di_siidx, les_di_diidx, les_di_disp16, les_di_bxidx
//0x40 (idx+disp8)
	.word les_ax_bxsidisp8, les_ax_bxdidisp8, les_ax_bpsid8, les_ax_bpdid8, les_ax_sidisp8, les_ax_didisp8, les_ax_bpdisp8, les_ax_bxdisp8
	.word les_cx_bxsidisp8, les_cx_bxdidisp8, les_cx_bpsid8, les_cx_bpdid8, les_cx_sidisp8, les_cx_didisp8, les_cx_bpdisp8, les_cx_bxdisp8
	.word les_dx_bxsidisp8, les_dx_bxdidisp8, les_dx_bpsid8, les_dx_bpdid8, les_dx_sidisp8, les_dx_didisp8, les_dx_bpdisp8, les_dx_bxdisp8
	.word les_bx_bxsidisp8, les_bx_bxdidisp8, les_bx_bpsid8, les_bx_bpdid8, les_bx_sidisp8, les_bx_didisp8, les_bx_bpdisp8, les_bx_bxdisp8
	.word les_sp_bxsidisp8, les_sp_bxdidisp8, les_sp_bpsid8, les_sp_bpdid8, les_sp_sidisp8, les_sp_didisp8, les_sp_bpdisp8, les_sp_bxdisp8
	.word les_bp_bxsidisp8, les_bp_bxdidisp8, les_bp_bpsid8, les_bp_bpdid8, les_bp_sidisp8, les_bp_didisp8, les_bp_bpdisp8, les_bp_bxdisp8
	.word les_si_bxsidisp8, les_si_bxdidisp8, les_si_bpsid8, les_si_bpdid8, les_si_sidisp8, les_si_didisp8, les_si_bpdisp8, les_si_bxdisp8
	.word les_di_bxsidisp8, les_di_bxdidisp8, les_di_bpsid8, les_di_bpdid8, les_di_sidisp8, les_di_didisp8, les_di_bpdisp8, les_di_bxdisp8
//0x80
	.word les_ax_bxsidisp16, les_ax_bxdidisp16, les_ax_bpsid16, les_ax_bpdid16, les_ax_sidisp16, les_ax_didisp16, les_ax_bpdisp16, les_ax_bxdisp16
	.word les_cx_bxsidisp16, les_cx_bxdidisp16, les_cx_bpsid16, les_cx_bpdid16, les_cx_sidisp16, les_cx_didisp16, les_cx_bpdisp16, les_cx_bxdisp16
	.word les_dx_bxsidisp16, les_dx_bxdidisp16, les_dx_bpsid16, les_dx_bpdid16, les_dx_sidisp16, les_dx_didisp16, les_dx_bpdisp16, les_dx_bxdisp16
	.word les_bx_bxsidisp16, les_bx_bxdidisp16, les_bx_bpsid16, les_bx_bpdid16, les_bx_sidisp16, les_bx_didisp16, les_bx_bpdisp16, les_bx_bxdisp16
	.word les_sp_bxsidisp16, les_sp_bxdidisp16, les_sp_bpsid16, les_sp_bpdid16, les_sp_sidisp16, les_sp_didisp16, les_sp_bpdisp16, les_sp_bxdisp16
	.word les_bp_bxsidisp16, les_bp_bxdidisp16, les_bp_bpsid16, les_bp_bpdid16, les_bp_sidisp16, les_bp_didisp16, les_bp_bpdisp16, les_bp_bxdisp16
	.word les_si_bxsidisp16, les_si_bxdidisp16, les_si_bpsid16, les_si_bpdid16, les_si_sidisp16, les_si_didisp16, les_si_bpdisp16, les_si_bxdisp16
	.word les_di_bxsidisp16, les_di_bxdidisp16, les_di_bpsid16, les_di_bpdid16, les_di_sidisp16, les_di_didisp16, les_di_bpdisp16, les_di_bxdisp16
// 0xC0 = mod = 11b = register
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1

	.global les_ax_bxsi, les_ax_bxdi, les_ax_bpsi, les_ax_bpdi, les_ax_siidx, les_ax_diidx, les_ax_disp16, les_ax_bxidx
	.global les_cx_bxsi, les_cx_bxdi, les_cx_bpsi, les_cx_bpdi, les_cx_siidx, les_cx_diidx, les_cx_disp16, les_cx_bxidx
	.global les_dx_bxsi, les_dx_bxdi, les_dx_bpsi, les_dx_bpdi, les_dx_siidx, les_dx_diidx, les_dx_disp16, les_dx_bxidx
	.global les_bx_bxsi, les_bx_bxdi, les_bx_bpsi, les_bx_bpdi, les_bx_siidx, les_bx_diidx, les_bx_disp16, les_bx_bxidx
	.global les_sp_bxsi, les_sp_bxdi, les_sp_bpsi, les_sp_bpdi, les_sp_siidx, les_sp_diidx, les_sp_disp16, les_sp_bxidx
	.global les_bp_bxsi, les_bp_bxdi, les_bp_bpsi, les_bp_bpdi, les_bp_siidx, les_bp_diidx, les_bp_disp16, les_bp_bxidx
	.global les_si_bxsi, les_si_bxdi, les_si_bpsi, les_si_bpdi, les_si_siidx, les_si_diidx, les_si_disp16, les_si_bxidx
	.global les_di_bxsi, les_di_bxdi, les_di_bpsi, les_di_bpdi, les_di_siidx, les_di_diidx, les_di_disp16, les_di_bxidx
	.global les_ax_bxsidisp8, les_ax_bxdidisp8, les_ax_bpsid8, les_ax_bpdid8, les_ax_sidisp8, les_ax_didisp8, les_ax_bpdisp8, les_ax_bxdisp8
	.global les_cx_bxsidisp8, les_cx_bxdidisp8, les_cx_bpsid8, les_cx_bpdid8, les_cx_sidisp8, les_cx_didisp8, les_cx_bpdisp8, les_cx_bxdisp8
	.global les_dx_bxsidisp8, les_dx_bxdidisp8, les_dx_bpsid8, les_dx_bpdid8, les_dx_sidisp8, les_dx_didisp8, les_dx_bpdisp8, les_dx_bxdisp8
	.global les_bx_bxsidisp8, les_bx_bxdidisp8, les_bx_bpsid8, les_bx_bpdid8, les_bx_sidisp8, les_bx_didisp8, les_bx_bpdisp8, les_bx_bxdisp8
	.global les_sp_bxsidisp8, les_sp_bxdidisp8, les_sp_bpsid8, les_sp_bpdid8, les_sp_sidisp8, les_sp_didisp8, les_sp_bpdisp8, les_sp_bxdisp8
	.global les_bp_bxsidisp8, les_bp_bxdidisp8, les_bp_bpsid8, les_bp_bpdid8, les_bp_sidisp8, les_bp_didisp8, les_bp_bpdisp8, les_bp_bxdisp8
	.global les_si_bxsidisp8, les_si_bxdidisp8, les_si_bpsid8, les_si_bpdid8, les_si_sidisp8, les_si_didisp8, les_si_bpdisp8, les_si_bxdisp8
	.global les_di_bxsidisp8, les_di_bxdidisp8, les_di_bpsid8, les_di_bpdid8, les_di_sidisp8, les_di_didisp8, les_di_bpdisp8, les_di_bxdisp8

.macro les_r16_r0_reg reg
	.global	les_r16_r0_bp_\reg
les_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	les_r16_r0_\reg
les_r16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .les_r2_RAM_\reg bad_EGA_opcode les_MODEX_r2_\reg
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.les_r2_RAM_\reg:
	// ----- Load offset
	ldrb	r0, [r2] 				// Load low byte of offset
	ldrb	r1, [r2, #1]			// Load high byte of offset
#if defined(RPi) || defined(Roku)
	mov		r3, \reg, lsl #16
	eor		\reg, r3, lsr #16
	orr		\reg, r0
	// ----- Load segment
	ldrb	r0,[r2, #2]				// Load low byte of ES from [r2+2]
	ldrb	r2,[r2, #3]				// Load high byte of ES from [r2+3]
	orr		\reg, r1, lsl #8		// Put offset to result register
#else
	bfi		\reg, r0, #0, #8
	// ----- Load segment
	ldrb	r0,[r2, #2]				// Load low byte of ES from [r2+2]
	ldrb	r2,[r2, #3]				// Load high byte of ES from [r2+3]
	bfi		\reg, r1, #8, #8
#endif
	orr		r2, r0, r2, lsl #8		// r2 = low byte | (high byte << 8) = new ES value
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	.global	les_r2_cont_\reg
les_r2_cont_\reg:
	ldrb	r3, [sp, #SP_CPU_CR0]				// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr							// Save current flags to r0
	tst		r3, #1								// Are we in protected mode (or in VM mode)?
	bne		mov_es_r0r2_prot					// Yes we are, go handle protected mode version!
	//-------
	// We are in real mode, so use the simple handling.
	//-------
	mov		r1, r2, lsl #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_ES_VALUE]
	str		r1, [sp, #SP_ES_BASE]
	b		restore_flags_from_r0
.endm

	les_r16_r0_reg r4
	les_r16_r0_reg r5
	les_r16_r0_reg r6
	les_r16_r0_reg r7
	les_r16_r0_reg r8
	les_r16_r0_reg r9
	les_r16_r0_reg r10
	les_r16_r0_reg r11

	.ltorg
	
// --- les reg16,[idx] ---

.macro les_bxidx reg idx
	add		r0, r7, \idx			// r0 = BX+idx
	b		les_r16_r0_\reg
.endm

les_ax_bxsi:
	les_bxidx r4 r10
les_cx_bxsi:
	les_bxidx r5 r10
les_dx_bxsi:
	les_bxidx r6 r10
les_bx_bxsi:
	les_bxidx r7 r10
les_sp_bxsi:
	les_bxidx r8 r10
les_bp_bxsi:
	les_bxidx r9 r10
les_si_bxsi:
	les_bxidx r10 r10
les_di_bxsi:
	les_bxidx r11 r10

les_ax_bxdi:
	les_bxidx r4 r11
les_cx_bxdi:
	les_bxidx r5 r11
les_dx_bxdi:
	les_bxidx r6 r11
les_bx_bxdi:
	les_bxidx r7 r11
les_sp_bxdi:
	les_bxidx r8 r11
les_bp_bxdi:
	les_bxidx r9 r11
les_si_bxdi:
	les_bxidx r10 r11
les_di_bxdi:
	les_bxidx r11 r11

.macro les_bpidx reg idx
	add		r0, r9, \idx
	b		les_r16_r0_bp_\reg
.endm

les_ax_bpsi:
	les_bpidx r4 r10
les_cx_bpsi:
	les_bpidx r5 r10
les_dx_bpsi:
	les_bpidx r6 r10
les_bx_bpsi:
	les_bpidx r7 r10
les_sp_bpsi:
	les_bpidx r8 r10
les_bp_bpsi:
	les_bpidx r9 r10
les_si_bpsi:
	les_bpidx r10 r10
les_di_bpsi:
	les_bpidx r11 r10

les_ax_bpdi:
	les_bpidx r4 r11
les_cx_bpdi:
	les_bpidx r5 r11
les_dx_bpdi:
	les_bpidx r6 r11
les_bx_bpdi:
	les_bpidx r7 r11
les_sp_bpdi:
	les_bpidx r8 r11
les_bp_bpdi:
	les_bpidx r9 r11
les_si_bpdi:
	les_bpidx r10 r11
les_di_bpdi:
	les_bpidx r11 r11

.macro les_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		les_r16_r0_\reg
.endm

les_ax_siidx:
	les_idx r4 r10
les_cx_siidx:
	les_idx r5 r10
les_dx_siidx:
	les_idx r6 r10
les_bx_siidx:
	les_idx r7 r10
les_sp_siidx:
	les_idx r8 r10
les_bp_siidx:
	les_idx r9 r10
les_si_siidx:
	les_idx r10 r10
les_di_siidx:
	les_idx r11 r10

les_ax_diidx:
	les_idx r4 r11
les_cx_diidx:
	les_idx r5 r11
les_dx_diidx:
	les_idx r6 r11
les_bx_diidx:
	les_idx r7 r11
les_sp_diidx:
	les_idx r8 r11
les_bp_diidx:
	les_idx r9 r11
les_si_diidx:
	les_idx r10 r11
les_di_diidx:
	les_idx r11 r11

les_ax_bxidx:
	les_idx r4 r7
les_cx_bxidx:
	les_idx r5 r7
les_dx_bxidx:
	les_idx r6 r7
les_bx_bxidx:
	les_idx r7 r7
les_sp_bxidx:
	les_idx r8 r7
les_bp_bxidx:
	les_idx r9 r7
les_si_bxidx:
	les_idx r10 r7
les_di_bxidx:
	les_idx r11 r7

.macro les_disp16 reg
	r0_from_disp16
	b		les_r16_r0_\reg
.endm

les_ax_disp16:
	les_disp16 r4
les_cx_disp16:
	les_disp16 r5
les_dx_disp16:
	les_disp16 r6
les_bx_disp16:
	les_disp16 r7
les_sp_disp16:
	les_disp16 r8
les_bp_disp16:
	les_disp16 r9
les_si_disp16:
	les_disp16 r10
les_di_disp16:
	les_disp16 r11

// --- les reg16,[idx+disp8] ---
//

.macro les_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		les_r16_r0_\reg
.endm

les_ax_bxsidisp8:
	les_bxidxdisp8 r4 r10
les_cx_bxsidisp8:
	les_bxidxdisp8 r5 r10
les_dx_bxsidisp8:
	les_bxidxdisp8 r6 r10
les_bx_bxsidisp8:
	les_bxidxdisp8 r7 r10
les_sp_bxsidisp8:
	les_bxidxdisp8 r8 r10
les_bp_bxsidisp8:
	les_bxidxdisp8 r9 r10
les_si_bxsidisp8:
	les_bxidxdisp8 r10 r10
les_di_bxsidisp8:
	les_bxidxdisp8 r11 r10

les_ax_bxdidisp8:
	les_bxidxdisp8 r4 r11
les_cx_bxdidisp8:
	les_bxidxdisp8 r5 r11
les_dx_bxdidisp8:
	les_bxidxdisp8 r6 r11
les_bx_bxdidisp8:
	les_bxidxdisp8 r7 r11
les_sp_bxdidisp8:
	les_bxidxdisp8 r8 r11
les_bp_bxdidisp8:
	les_bxidxdisp8 r9 r11
les_si_bxdidisp8:
	les_bxidxdisp8 r10 r11
les_di_bxdidisp8:
	les_bxidxdisp8 r11 r11

.macro les_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		les_r16_r0_bp_\reg
.endm

les_ax_bpsid8:
	les_bpidxdisp8 r4 r10
les_cx_bpsid8:
	les_bpidxdisp8 r5 r10
les_dx_bpsid8:
	les_bpidxdisp8 r6 r10
les_bx_bpsid8:
	les_bpidxdisp8 r7 r10
les_sp_bpsid8:
	les_bpidxdisp8 r8 r10
les_bp_bpsid8:
	les_bpidxdisp8 r9 r10
les_si_bpsid8:
	les_bpidxdisp8 r10 r10
les_di_bpsid8:
	les_bpidxdisp8 r11 r10

les_ax_bpdid8:
	les_bpidxdisp8 r4 r11
les_cx_bpdid8:
	les_bpidxdisp8 r5 r11
les_dx_bpdid8:
	les_bpidxdisp8 r6 r11
les_bx_bpdid8:
	les_bpidxdisp8 r7 r11
les_sp_bpdid8:
	les_bpidxdisp8 r8 r11
les_bp_bpdid8:
	les_bpidxdisp8 r9 r11
les_si_bpdid8:
	les_bpidxdisp8 r10 r11
les_di_bpdid8:
	les_bpidxdisp8 r11 r11

.macro les_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		les_r16_r0_\reg
.endm

les_ax_sidisp8:
	les_idxdisp8 r4 r10
les_cx_sidisp8:
	les_idxdisp8 r5 r10
les_dx_sidisp8:
	les_idxdisp8 r6 r10
les_bx_sidisp8:
	les_idxdisp8 r7 r10
les_sp_sidisp8:
	les_idxdisp8 r8 r10
les_bp_sidisp8:
	les_idxdisp8 r9 r10
les_si_sidisp8:
	les_idxdisp8 r10 r10
les_di_sidisp8:
	les_idxdisp8 r11 r10

les_ax_didisp8:
	les_idxdisp8 r4 r11
les_cx_didisp8:
	les_idxdisp8 r5 r11
les_dx_didisp8:
	les_idxdisp8 r6 r11
les_bx_didisp8:
	les_idxdisp8 r7 r11
les_sp_didisp8:
	les_idxdisp8 r8 r11
les_bp_didisp8:
	les_idxdisp8 r9 r11
les_si_didisp8:
	les_idxdisp8 r10 r11
les_di_didisp8:
	les_idxdisp8 r11 r11

les_ax_bxdisp8:
	les_idxdisp8 r4 r7
les_cx_bxdisp8:
	les_idxdisp8 r5 r7
les_dx_bxdisp8:
	les_idxdisp8 r6 r7
les_bx_bxdisp8:
	les_idxdisp8 r7 r7
les_sp_bxdisp8:
	les_idxdisp8 r8 r7
les_bp_bxdisp8:
	les_idxdisp8 r9 r7
les_si_bxdisp8:
	les_idxdisp8 r10 r7
les_di_bxdisp8:
	les_idxdisp8 r11 r7

.macro les_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		les_r16_r0_bp_\reg
.endm

les_ax_bpdisp8:
	les_bpdisp8 r4
les_cx_bpdisp8:
	les_bpdisp8 r5
les_dx_bpdisp8:
	les_bpdisp8 r6
les_bx_bpdisp8:
	les_bpdisp8 r7
les_sp_bpdisp8:
	les_bpdisp8 r8
les_bp_bpdisp8:
	les_bpdisp8 r9
les_si_bpdisp8:
	les_bpdisp8 r10
les_di_bpdisp8:
	les_bpdisp8 r11

// --- les reg16,[idx+disp16] ---
//
.macro les_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		les_r16_r0_\reg
.endm

les_ax_bxsidisp16:
	les_bxidxdisp16 r4 r10
les_cx_bxsidisp16:
	les_bxidxdisp16 r5 r10
les_dx_bxsidisp16:
	les_bxidxdisp16 r6 r10
les_bx_bxsidisp16:
	les_bxidxdisp16 r7 r10
les_sp_bxsidisp16:
	les_bxidxdisp16 r8 r10
les_bp_bxsidisp16:
	les_bxidxdisp16 r9 r10
les_si_bxsidisp16:
	les_bxidxdisp16 r10 r10
les_di_bxsidisp16:
	les_bxidxdisp16 r11 r10

les_ax_bxdidisp16:
	les_bxidxdisp16 r4 r11
les_cx_bxdidisp16:
	les_bxidxdisp16 r5 r11
les_dx_bxdidisp16:
	les_bxidxdisp16 r6 r11
les_bx_bxdidisp16:
	les_bxidxdisp16 r7 r11
les_sp_bxdidisp16:
	les_bxidxdisp16 r8 r11
les_bp_bxdidisp16:
	les_bxidxdisp16 r9 r11
les_si_bxdidisp16:
	les_bxidxdisp16 r10 r11
les_di_bxdidisp16:
	les_bxidxdisp16 r11 r11

.macro les_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		les_r16_r0_bp_\reg
.endm

les_ax_bpsid16:
	les_bpidxdisp16 r4 r10
les_cx_bpsid16:
	les_bpidxdisp16 r5 r10
les_dx_bpsid16:
	les_bpidxdisp16 r6 r10
les_bx_bpsid16:
	les_bpidxdisp16 r7 r10
les_sp_bpsid16:
	les_bpidxdisp16 r8 r10
les_bp_bpsid16:
	les_bpidxdisp16 r9 r10
les_si_bpsid16:
	les_bpidxdisp16 r10 r10
les_di_bpsid16:
	les_bpidxdisp16 r11 r10

les_ax_bpdid16:
	les_bpidxdisp16 r4 r11
les_cx_bpdid16:
	les_bpidxdisp16 r5 r11
les_dx_bpdid16:
	les_bpidxdisp16 r6 r11
les_bx_bpdid16:
	les_bpidxdisp16 r7 r11
les_sp_bpdid16:
	les_bpidxdisp16 r8 r11
les_bp_bpdid16:
	les_bpidxdisp16 r9 r11
les_si_bpdid16:
	les_bpidxdisp16 r10 r11
les_di_bpdid16:
	les_bpidxdisp16 r11 r11

.macro les_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		les_r16_r0_\reg
.endm

les_ax_sidisp16:
	les_idxdisp16 r4 r10
les_cx_sidisp16:
	les_idxdisp16 r5 r10
les_dx_sidisp16:
	les_idxdisp16 r6 r10
les_bx_sidisp16:
	les_idxdisp16 r7 r10
les_sp_sidisp16:
	les_idxdisp16 r8 r10
les_bp_sidisp16:
	les_idxdisp16 r9 r10
les_si_sidisp16:
	les_idxdisp16 r10 r10
les_di_sidisp16:
	les_idxdisp16 r11 r10

les_ax_didisp16:
	les_idxdisp16 r4 r11
les_cx_didisp16:
	les_idxdisp16 r5 r11
les_dx_didisp16:
	les_idxdisp16 r6 r11
les_bx_didisp16:
	les_idxdisp16 r7 r11
les_sp_didisp16:
	les_idxdisp16 r8 r11
les_bp_didisp16:
	les_idxdisp16 r9 r11
les_si_didisp16:
	les_idxdisp16 r10 r11
les_di_didisp16:
	les_idxdisp16 r11 r11

les_ax_bxdisp16:
	les_idxdisp16 r4 r7
les_cx_bxdisp16:
	les_idxdisp16 r5 r7
les_dx_bxdisp16:
	les_idxdisp16 r6 r7
les_bx_bxdisp16:
	les_idxdisp16 r7 r7
les_sp_bxdisp16:
	les_idxdisp16 r8 r7
les_bp_bxdisp16:
	les_idxdisp16 r9 r7
les_si_bxdisp16:
	les_idxdisp16 r10 r7
les_di_bxdisp16:
	les_idxdisp16 r11 r7

.macro les_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		les_r16_r0_bp_\reg
.endm

les_ax_bpdisp16:
	les_bpdisp16 r4
les_cx_bpdisp16:
	les_bpdisp16 r5
les_dx_bpdisp16:
	les_bpdisp16 r6
les_bx_bpdisp16:
	les_bpdisp16 r7
les_sp_bpdisp16:
	les_bpdisp16 r8
les_bp_bpdisp16:
	les_bpdisp16 r9
les_si_bpdisp16:
	les_bpdisp16 r10
les_di_bpdisp16:
	les_bpdisp16 r11

// ------------------- C5 = LDS r16,m16:16 -----------------------------
//
// All modrm variations (except SP) supported!
//
op_c5:
	modrm_jump_16
// 0
	.word lds_ax_bxsi, lds_ax_bxdi, lds_ax_bpsi, lds_ax_bpdi, lds_ax_siidx, lds_ax_diidx, lds_ax_disp16, lds_ax_bxidx
	.word lds_cx_bxsi, lds_cx_bxdi, lds_cx_bpsi, lds_cx_bpdi, lds_cx_siidx, lds_cx_diidx, lds_cx_disp16, lds_cx_bxidx
	.word lds_dx_bxsi, lds_dx_bxdi, lds_dx_bpsi, lds_dx_bpdi, lds_dx_siidx, lds_dx_diidx, lds_dx_disp16, lds_dx_bxidx
	.word lds_bx_bxsi, lds_bx_bxdi, lds_bx_bpsi, lds_bx_bpdi, lds_bx_siidx, lds_bx_diidx, lds_bx_disp16, lds_bx_bxidx
	.word lds_sp_bxsi, lds_sp_bxdi, lds_sp_bpsi, lds_sp_bpdi, lds_sp_siidx, lds_sp_diidx, lds_sp_disp16, lds_sp_bxidx
	.word lds_bp_bxsi, lds_bp_bxdi, lds_bp_bpsi, lds_bp_bpdi, lds_bp_siidx, lds_bp_diidx, lds_bp_disp16, lds_bp_bxidx
	.word lds_si_bxsi, lds_si_bxdi, lds_si_bpsi, lds_si_bpdi, lds_si_siidx, lds_si_diidx, lds_si_disp16, lds_si_bxidx
	.word lds_di_bxsi, lds_di_bxdi, lds_di_bpsi, lds_di_bpdi, lds_di_siidx, lds_di_diidx, lds_di_disp16, lds_di_bxidx
//0x40 (idx+disp8)
	.word lds_ax_bxsidisp8, lds_ax_bxdidisp8, lds_ax_bpsid8, lds_ax_bpdid8, lds_ax_sidisp8, lds_ax_didisp8, lds_ax_bpdisp8, lds_ax_bxdisp8
	.word lds_cx_bxsidisp8, lds_cx_bxdidisp8, lds_cx_bpsid8, lds_cx_bpdid8, lds_cx_sidisp8, lds_cx_didisp8, lds_cx_bpdisp8, lds_cx_bxdisp8
	.word lds_dx_bxsidisp8, lds_dx_bxdidisp8, lds_dx_bpsid8, lds_dx_bpdid8, lds_dx_sidisp8, lds_dx_didisp8, lds_dx_bpdisp8, lds_dx_bxdisp8
	.word lds_bx_bxsidisp8, lds_bx_bxdidisp8, lds_bx_bpsid8, lds_bx_bpdid8, lds_bx_sidisp8, lds_bx_didisp8, lds_bx_bpdisp8, lds_bx_bxdisp8
	.word lds_sp_bxsidisp8, lds_sp_bxdidisp8, lds_sp_bpsid8, lds_sp_bpdid8, lds_sp_sidisp8, lds_sp_didisp8, lds_sp_bpdisp8, lds_sp_bxdisp8
	.word lds_bp_bxsidisp8, lds_bp_bxdidisp8, lds_bp_bpsid8, lds_bp_bpdid8, lds_bp_sidisp8, lds_bp_didisp8, lds_bp_bpdisp8, lds_bp_bxdisp8
	.word lds_si_bxsidisp8, lds_si_bxdidisp8, lds_si_bpsid8, lds_si_bpdid8, lds_si_sidisp8, lds_si_didisp8, lds_si_bpdisp8, lds_si_bxdisp8
	.word lds_di_bxsidisp8, lds_di_bxdidisp8, lds_di_bpsid8, lds_di_bpdid8, lds_di_sidisp8, lds_di_didisp8, lds_di_bpdisp8, lds_di_bxdisp8
//0x80
	.word lds_ax_bxsidisp16, lds_ax_bxdidisp16, lds_ax_bpsid16, lds_ax_bpdid16, lds_ax_sidisp16, lds_ax_didisp16, lds_ax_bpdisp16, lds_ax_bxdisp16
	.word lds_cx_bxsidisp16, lds_cx_bxdidisp16, lds_cx_bpsid16, lds_cx_bpdid16, lds_cx_sidisp16, lds_cx_didisp16, lds_cx_bpdisp16, lds_cx_bxdisp16
	.word lds_dx_bxsidisp16, lds_dx_bxdidisp16, lds_dx_bpsid16, lds_dx_bpdid16, lds_dx_sidisp16, lds_dx_didisp16, lds_dx_bpdisp16, lds_dx_bxdisp16
	.word lds_bx_bxsidisp16, lds_bx_bxdidisp16, lds_bx_bpsid16, lds_bx_bpdid16, lds_bx_sidisp16, lds_bx_didisp16, lds_bx_bpdisp16, lds_bx_bxdisp16
	.word lds_sp_bxsidisp16, lds_sp_bxdidisp16, lds_sp_bpsid16, lds_sp_bpdid16, lds_sp_sidisp16, lds_sp_didisp16, lds_sp_bpdisp16, lds_sp_bxdisp16
	.word lds_bp_bxsidisp16, lds_bp_bxdidisp16, lds_bp_bpsid16, lds_bp_bpdid16, lds_bp_sidisp16, lds_bp_didisp16, lds_bp_bpdisp16, lds_bp_bxdisp16
	.word lds_si_bxsidisp16, lds_si_bxdidisp16, lds_si_bpsid16, lds_si_bpdid16, lds_si_sidisp16, lds_si_didisp16, lds_si_bpdisp16, lds_si_bxdisp16
	.word lds_di_bxsidisp16, lds_di_bxdidisp16, lds_di_bpsid16, lds_di_bpdid16, lds_di_sidisp16, lds_di_didisp16, lds_di_bpdisp16, lds_di_bxdisp16
// 0xC0 = mod = 11b = register
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1

	.global lds_ax_bxsi, lds_ax_bxdi, lds_ax_bpsi, lds_ax_bpdi, lds_ax_siidx, lds_ax_diidx, lds_ax_disp16, lds_ax_bxidx
	.global lds_cx_bxsi, lds_cx_bxdi, lds_cx_bpsi, lds_cx_bpdi, lds_cx_siidx, lds_cx_diidx, lds_cx_disp16, lds_cx_bxidx
	.global lds_dx_bxsi, lds_dx_bxdi, lds_dx_bpsi, lds_dx_bpdi, lds_dx_siidx, lds_dx_diidx, lds_dx_disp16, lds_dx_bxidx
	.global lds_bx_bxsi, lds_bx_bxdi, lds_bx_bpsi, lds_bx_bpdi, lds_bx_siidx, lds_bx_diidx, lds_bx_disp16, lds_bx_bxidx
	.global lds_sp_bxsi, lds_sp_bxdi, lds_sp_bpsi, lds_sp_bpdi, lds_sp_siidx, lds_sp_diidx, lds_sp_disp16, lds_sp_bxidx
	.global lds_bp_bxsi, lds_bp_bxdi, lds_bp_bpsi, lds_bp_bpdi, lds_bp_siidx, lds_bp_diidx, lds_bp_disp16, lds_bp_bxidx
	.global lds_si_bxsi, lds_si_bxdi, lds_si_bpsi, lds_si_bpdi, lds_si_siidx, lds_si_diidx, lds_si_disp16, lds_si_bxidx
	.global lds_di_bxsi, lds_di_bxdi, lds_di_bpsi, lds_di_bpdi, lds_di_siidx, lds_di_diidx, lds_di_disp16, lds_di_bxidx
	.global lds_ax_bxsidisp8, lds_ax_bxdidisp8, lds_ax_bpsid8, lds_ax_bpdid8, lds_ax_sidisp8, lds_ax_didisp8, lds_ax_bpdisp8, lds_ax_bxdisp8
	.global lds_cx_bxsidisp8, lds_cx_bxdidisp8, lds_cx_bpsid8, lds_cx_bpdid8, lds_cx_sidisp8, lds_cx_didisp8, lds_cx_bpdisp8, lds_cx_bxdisp8
	.global lds_dx_bxsidisp8, lds_dx_bxdidisp8, lds_dx_bpsid8, lds_dx_bpdid8, lds_dx_sidisp8, lds_dx_didisp8, lds_dx_bpdisp8, lds_dx_bxdisp8
	.global lds_bx_bxsidisp8, lds_bx_bxdidisp8, lds_bx_bpsid8, lds_bx_bpdid8, lds_bx_sidisp8, lds_bx_didisp8, lds_bx_bpdisp8, lds_bx_bxdisp8
	.global lds_sp_bxsidisp8, lds_sp_bxdidisp8, lds_sp_bpsid8, lds_sp_bpdid8, lds_sp_sidisp8, lds_sp_didisp8, lds_sp_bpdisp8, lds_sp_bxdisp8
	.global lds_bp_bxsidisp8, lds_bp_bxdidisp8, lds_bp_bpsid8, lds_bp_bpdid8, lds_bp_sidisp8, lds_bp_didisp8, lds_bp_bpdisp8, lds_bp_bxdisp8
	.global lds_si_bxsidisp8, lds_si_bxdidisp8, lds_si_bpsid8, lds_si_bpdid8, lds_si_sidisp8, lds_si_didisp8, lds_si_bpdisp8, lds_si_bxdisp8
	.global lds_di_bxsidisp8, lds_di_bxdidisp8, lds_di_bpsid8, lds_di_bpdid8, lds_di_sidisp8, lds_di_didisp8, lds_di_bpdisp8, lds_di_bxdisp8

.macro lds_r16_r0_reg reg
	.global	lds_r16_r0_bp_\reg
lds_r16_r0_bp_\reg:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	lds_r16_r0_\reg
lds_r16_r0_\reg:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .lds_r2_RAM_\reg bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.lds_r2_RAM_\reg:
	// ----- Load offset
	ldrb	r0, [r2] 				// Load low byte of offset
	ldrb	r1, [r2, #1]			// Load high byte of offset
#if defined(RPi) || defined(Roku)
	mov		r3, \reg, lsl #16
	eor		\reg, r3, lsr #16
	orr		\reg, r0
	// ----- Load segment
	ldrb	r0,[r2, #2]				// Load low byte of ES from [r2+2]
	ldrb	r2,[r2, #3]				// Load high byte of ES from [r2+3]
	orr		\reg, r1, lsl #8		// Put offset to result register
#else
	bfi		\reg, r0, #0, #8
	// ----- Load segment
	ldrb	r0,[r2, #2]				// Load low byte of ES from [r2+2]
	ldrb	r2,[r2, #3]				// Load high byte of ES from [r2+3]
	bfi		\reg, r1, #8, #8
#endif
	orr		r2, r0, r2, lsl #8		// r2 = low byte | (high byte << 8) = new ES value
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]				// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr							// Save current flags to r0
	tst		r3, #1								// Are we in protected mode (or in VM mode)?
	bne		mov_ds_r0r2_prot					// Yes we are, go handle protected mode version!
	//-------
	// We are in real mode, so use the simple handling.
	//-------
	mov		r1, r2, lsl #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_DS_VALUE]
	str		r1, [sp, #SP_DS_BASE]
	b		restore_flags_from_r0
.endm

	lds_r16_r0_reg r4
	lds_r16_r0_reg r5
	lds_r16_r0_reg r6
	lds_r16_r0_reg r7
	lds_r16_r0_reg r8
	lds_r16_r0_reg r9
	lds_r16_r0_reg r10
	lds_r16_r0_reg r11

	.ltorg
	
// --- lds reg16,[idx] ---

.macro lds_bxidx reg idx
	add		r0, r7, \idx			// r0 = BX+idx
	b		lds_r16_r0_\reg
.endm

lds_ax_bxsi:
	lds_bxidx r4 r10
lds_cx_bxsi:
	lds_bxidx r5 r10
lds_dx_bxsi:
	lds_bxidx r6 r10
lds_bx_bxsi:
	lds_bxidx r7 r10
lds_sp_bxsi:
	lds_bxidx r8 r10
lds_bp_bxsi:
	lds_bxidx r9 r10
lds_si_bxsi:
	lds_bxidx r10 r10
lds_di_bxsi:
	lds_bxidx r11 r10

lds_ax_bxdi:
	lds_bxidx r4 r11
lds_cx_bxdi:
	lds_bxidx r5 r11
lds_dx_bxdi:
	lds_bxidx r6 r11
lds_bx_bxdi:
	lds_bxidx r7 r11
lds_sp_bxdi:
	lds_bxidx r8 r11
lds_bp_bxdi:
	lds_bxidx r9 r11
lds_si_bxdi:
	lds_bxidx r10 r11
lds_di_bxdi:
	lds_bxidx r11 r11

.macro lds_bpidx reg idx
	add		r0, r9, \idx
	b		lds_r16_r0_bp_\reg
.endm

lds_ax_bpsi:
	lds_bpidx r4 r10
lds_cx_bpsi:
	lds_bpidx r5 r10
lds_dx_bpsi:
	lds_bpidx r6 r10
lds_bx_bpsi:
	lds_bpidx r7 r10
lds_sp_bpsi:
	lds_bpidx r8 r10
lds_bp_bpsi:
	lds_bpidx r9 r10
lds_si_bpsi:
	lds_bpidx r10 r10
lds_di_bpsi:
	lds_bpidx r11 r10

lds_ax_bpdi:
	lds_bpidx r4 r11
lds_cx_bpdi:
	lds_bpidx r5 r11
lds_dx_bpdi:
	lds_bpidx r6 r11
lds_bx_bpdi:
	lds_bpidx r7 r11
lds_sp_bpdi:
	lds_bpidx r8 r11
lds_bp_bpdi:
	lds_bpidx r9 r11
lds_si_bpdi:
	lds_bpidx r10 r11
lds_di_bpdi:
	lds_bpidx r11 r11

.macro lds_idx reg idx
	mov		r0, \idx				// r0high = idx register value
	b		lds_r16_r0_\reg
.endm

lds_ax_siidx:
	lds_idx r4 r10
lds_cx_siidx:
	lds_idx r5 r10
lds_dx_siidx:
	lds_idx r6 r10
lds_bx_siidx:
	lds_idx r7 r10
lds_sp_siidx:
	lds_idx r8 r10
lds_bp_siidx:
	lds_idx r9 r10
lds_si_siidx:
	lds_idx r10 r10
lds_di_siidx:
	lds_idx r11 r10

lds_ax_diidx:
	lds_idx r4 r11
lds_cx_diidx:
	lds_idx r5 r11
lds_dx_diidx:
	lds_idx r6 r11
lds_bx_diidx:
	lds_idx r7 r11
lds_sp_diidx:
	lds_idx r8 r11
lds_bp_diidx:
	lds_idx r9 r11
lds_si_diidx:
	lds_idx r10 r11
lds_di_diidx:
	lds_idx r11 r11

lds_ax_bxidx:
	lds_idx r4 r7
lds_cx_bxidx:
	lds_idx r5 r7
lds_dx_bxidx:
	lds_idx r6 r7
lds_bx_bxidx:
	lds_idx r7 r7
lds_sp_bxidx:
	lds_idx r8 r7
lds_bp_bxidx:
	lds_idx r9 r7
lds_si_bxidx:
	lds_idx r10 r7
lds_di_bxidx:
	lds_idx r11 r7

.macro lds_disp16 reg
	r0_from_disp16
	b		lds_r16_r0_\reg
.endm

lds_ax_disp16:
	lds_disp16 r4
lds_cx_disp16:
	lds_disp16 r5
lds_dx_disp16:
	lds_disp16 r6
lds_bx_disp16:
	lds_disp16 r7
lds_sp_disp16:
	lds_disp16 r8
lds_bp_disp16:
	lds_disp16 r9
lds_si_disp16:
	lds_disp16 r10
lds_di_disp16:
	lds_disp16 r11

// --- lds reg16,[idx+disp8] ---
//

.macro lds_bxidxdisp8 reg idx
	r0_from_bxidxdisp8 \idx
	b		lds_r16_r0_\reg
.endm

lds_ax_bxsidisp8:
	lds_bxidxdisp8 r4 r10
lds_cx_bxsidisp8:
	lds_bxidxdisp8 r5 r10
lds_dx_bxsidisp8:
	lds_bxidxdisp8 r6 r10
lds_bx_bxsidisp8:
	lds_bxidxdisp8 r7 r10
lds_sp_bxsidisp8:
	lds_bxidxdisp8 r8 r10
lds_bp_bxsidisp8:
	lds_bxidxdisp8 r9 r10
lds_si_bxsidisp8:
	lds_bxidxdisp8 r10 r10
lds_di_bxsidisp8:
	lds_bxidxdisp8 r11 r10

lds_ax_bxdidisp8:
	lds_bxidxdisp8 r4 r11
lds_cx_bxdidisp8:
	lds_bxidxdisp8 r5 r11
lds_dx_bxdidisp8:
	lds_bxidxdisp8 r6 r11
lds_bx_bxdidisp8:
	lds_bxidxdisp8 r7 r11
lds_sp_bxdidisp8:
	lds_bxidxdisp8 r8 r11
lds_bp_bxdidisp8:
	lds_bxidxdisp8 r9 r11
lds_si_bxdidisp8:
	lds_bxidxdisp8 r10 r11
lds_di_bxdidisp8:
	lds_bxidxdisp8 r11 r11

.macro lds_bpidxdisp8 reg idx
	r0_from_bpidxdisp8 \idx
	b		lds_r16_r0_bp_\reg
.endm

lds_ax_bpsid8:
	lds_bpidxdisp8 r4 r10
lds_cx_bpsid8:
	lds_bpidxdisp8 r5 r10
lds_dx_bpsid8:
	lds_bpidxdisp8 r6 r10
lds_bx_bpsid8:
	lds_bpidxdisp8 r7 r10
lds_sp_bpsid8:
	lds_bpidxdisp8 r8 r10
lds_bp_bpsid8:
	lds_bpidxdisp8 r9 r10
lds_si_bpsid8:
	lds_bpidxdisp8 r10 r10
lds_di_bpsid8:
	lds_bpidxdisp8 r11 r10

lds_ax_bpdid8:
	lds_bpidxdisp8 r4 r11
lds_cx_bpdid8:
	lds_bpidxdisp8 r5 r11
lds_dx_bpdid8:
	lds_bpidxdisp8 r6 r11
lds_bx_bpdid8:
	lds_bpidxdisp8 r7 r11
lds_sp_bpdid8:
	lds_bpidxdisp8 r8 r11
lds_bp_bpdid8:
	lds_bpidxdisp8 r9 r11
lds_si_bpdid8:
	lds_bpidxdisp8 r10 r11
lds_di_bpdid8:
	lds_bpidxdisp8 r11 r11

.macro lds_idxdisp8 reg idx
	r0_from_idx_disp8 \idx
	b		lds_r16_r0_\reg
.endm

lds_ax_sidisp8:
	lds_idxdisp8 r4 r10
lds_cx_sidisp8:
	lds_idxdisp8 r5 r10
lds_dx_sidisp8:
	lds_idxdisp8 r6 r10
lds_bx_sidisp8:
	lds_idxdisp8 r7 r10
lds_sp_sidisp8:
	lds_idxdisp8 r8 r10
lds_bp_sidisp8:
	lds_idxdisp8 r9 r10
lds_si_sidisp8:
	lds_idxdisp8 r10 r10
lds_di_sidisp8:
	lds_idxdisp8 r11 r10

lds_ax_didisp8:
	lds_idxdisp8 r4 r11
lds_cx_didisp8:
	lds_idxdisp8 r5 r11
lds_dx_didisp8:
	lds_idxdisp8 r6 r11
lds_bx_didisp8:
	lds_idxdisp8 r7 r11
lds_sp_didisp8:
	lds_idxdisp8 r8 r11
lds_bp_didisp8:
	lds_idxdisp8 r9 r11
lds_si_didisp8:
	lds_idxdisp8 r10 r11
lds_di_didisp8:
	lds_idxdisp8 r11 r11

lds_ax_bxdisp8:
	lds_idxdisp8 r4 r7
lds_cx_bxdisp8:
	lds_idxdisp8 r5 r7
lds_dx_bxdisp8:
	lds_idxdisp8 r6 r7
lds_bx_bxdisp8:
	lds_idxdisp8 r7 r7
lds_sp_bxdisp8:
	lds_idxdisp8 r8 r7
lds_bp_bxdisp8:
	lds_idxdisp8 r9 r7
lds_si_bxdisp8:
	lds_idxdisp8 r10 r7
lds_di_bxdisp8:
	lds_idxdisp8 r11 r7

.macro lds_bpdisp8 reg
	r0_from_idx_disp8 r9
	b		lds_r16_r0_bp_\reg
.endm

lds_ax_bpdisp8:
	lds_bpdisp8 r4
lds_cx_bpdisp8:
	lds_bpdisp8 r5
lds_dx_bpdisp8:
	lds_bpdisp8 r6
lds_bx_bpdisp8:
	lds_bpdisp8 r7
lds_sp_bpdisp8:
	lds_bpdisp8 r8
lds_bp_bpdisp8:
	lds_bpdisp8 r9
lds_si_bpdisp8:
	lds_bpdisp8 r10
lds_di_bpdisp8:
	lds_bpdisp8 r11

// --- lds reg16,[idx+disp16] ---
//
.macro lds_bxidxdisp16 reg idx
	r0_from_bxidxdisp16 \idx
	b		lds_r16_r0_\reg
.endm

lds_ax_bxsidisp16:
	lds_bxidxdisp16 r4 r10
lds_cx_bxsidisp16:
	lds_bxidxdisp16 r5 r10
lds_dx_bxsidisp16:
	lds_bxidxdisp16 r6 r10
lds_bx_bxsidisp16:
	lds_bxidxdisp16 r7 r10
lds_sp_bxsidisp16:
	lds_bxidxdisp16 r8 r10
lds_bp_bxsidisp16:
	lds_bxidxdisp16 r9 r10
lds_si_bxsidisp16:
	lds_bxidxdisp16 r10 r10
lds_di_bxsidisp16:
	lds_bxidxdisp16 r11 r10

lds_ax_bxdidisp16:
	lds_bxidxdisp16 r4 r11
lds_cx_bxdidisp16:
	lds_bxidxdisp16 r5 r11
lds_dx_bxdidisp16:
	lds_bxidxdisp16 r6 r11
lds_bx_bxdidisp16:
	lds_bxidxdisp16 r7 r11
lds_sp_bxdidisp16:
	lds_bxidxdisp16 r8 r11
lds_bp_bxdidisp16:
	lds_bxidxdisp16 r9 r11
lds_si_bxdidisp16:
	lds_bxidxdisp16 r10 r11
lds_di_bxdidisp16:
	lds_bxidxdisp16 r11 r11

.macro lds_bpidxdisp16 reg idx
	r0_from_bpidxdisp16 \idx
	b		lds_r16_r0_bp_\reg
.endm

lds_ax_bpsid16:
	lds_bpidxdisp16 r4 r10
lds_cx_bpsid16:
	lds_bpidxdisp16 r5 r10
lds_dx_bpsid16:
	lds_bpidxdisp16 r6 r10
lds_bx_bpsid16:
	lds_bpidxdisp16 r7 r10
lds_sp_bpsid16:
	lds_bpidxdisp16 r8 r10
lds_bp_bpsid16:
	lds_bpidxdisp16 r9 r10
lds_si_bpsid16:
	lds_bpidxdisp16 r10 r10
lds_di_bpsid16:
	lds_bpidxdisp16 r11 r10

lds_ax_bpdid16:
	lds_bpidxdisp16 r4 r11
lds_cx_bpdid16:
	lds_bpidxdisp16 r5 r11
lds_dx_bpdid16:
	lds_bpidxdisp16 r6 r11
lds_bx_bpdid16:
	lds_bpidxdisp16 r7 r11
lds_sp_bpdid16:
	lds_bpidxdisp16 r8 r11
lds_bp_bpdid16:
	lds_bpidxdisp16 r9 r11
lds_si_bpdid16:
	lds_bpidxdisp16 r10 r11
lds_di_bpdid16:
	lds_bpidxdisp16 r11 r11

.macro lds_idxdisp16 reg idx
	r0_from_idx_disp16 \idx
	b		lds_r16_r0_\reg
.endm

lds_ax_sidisp16:
	lds_idxdisp16 r4 r10
lds_cx_sidisp16:
	lds_idxdisp16 r5 r10
lds_dx_sidisp16:
	lds_idxdisp16 r6 r10
lds_bx_sidisp16:
	lds_idxdisp16 r7 r10
lds_sp_sidisp16:
	lds_idxdisp16 r8 r10
lds_bp_sidisp16:
	lds_idxdisp16 r9 r10
lds_si_sidisp16:
	lds_idxdisp16 r10 r10
lds_di_sidisp16:
	lds_idxdisp16 r11 r10

lds_ax_didisp16:
	lds_idxdisp16 r4 r11
lds_cx_didisp16:
	lds_idxdisp16 r5 r11
lds_dx_didisp16:
	lds_idxdisp16 r6 r11
lds_bx_didisp16:
	lds_idxdisp16 r7 r11
lds_sp_didisp16:
	lds_idxdisp16 r8 r11
lds_bp_didisp16:
	lds_idxdisp16 r9 r11
lds_si_didisp16:
	lds_idxdisp16 r10 r11
lds_di_didisp16:
	lds_idxdisp16 r11 r11

lds_ax_bxdisp16:
	lds_idxdisp16 r4 r7
lds_cx_bxdisp16:
	lds_idxdisp16 r5 r7
lds_dx_bxdisp16:
	lds_idxdisp16 r6 r7
lds_bx_bxdisp16:
	lds_idxdisp16 r7 r7
lds_sp_bxdisp16:
	lds_idxdisp16 r8 r7
lds_bp_bxdisp16:
	lds_idxdisp16 r9 r7
lds_si_bxdisp16:
	lds_idxdisp16 r10 r7
lds_di_bxdisp16:
	lds_idxdisp16 r11 r7

.macro lds_bpdisp16 reg
	r0_from_idx_disp16 r9
	b		lds_r16_r0_bp_\reg
.endm

lds_ax_bpdisp16:
	lds_bpdisp16 r4
lds_cx_bpdisp16:
	lds_bpdisp16 r5
lds_dx_bpdisp16:
	lds_bpdisp16 r6
lds_bx_bpdisp16:
	lds_bpdisp16 r7
lds_sp_bpdisp16:
	lds_bpdisp16 r8
lds_bp_bpdisp16:
	lds_bpdisp16 r9
lds_si_bpdisp16:
	lds_bpdisp16 r10
lds_di_bpdisp16:
	lds_bpdisp16 r11


#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	


// ------------------- C6 = MOV r/m8, imm8 -----------------------------
//
// All modrm variations supported!
//
	.global	op_c6
op_c6:
	ldrb	r0,[r12],#1							// Load next opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	orr		r0, r0, lsr #3
	and		r0, #0x1F
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8

// 0
	.word mov_bxsi_imm8, mov_bxdi_imm8, mov_bpsi_imm8, mov_bpdi_imm8, mov_siidx_imm8, mov_diidx_imm8, mov_disp16_imm8, mov_bxidx_imm8
//0x40
	.word mov_bxsidisp8_imm8, mov_bxdidisp8_imm8, mov_bpsidisp8_imm8, mov_bpdidisp8_imm8, mov_sidisp8_imm8, mov_didisp8_imm8, mov_bpdisp8_imm8, mov_bxdisp8_imm8
//0x80
	.word mov_bxsid16_imm8, mov_bxdid16_imm8, mov_bpsidisp16_imm8, mov_bpdidisp16_imm8, mov_sidisp16_imm8, mov_didisp16_imm8, mov_bpdisp16_imm8, mov_bxdisp16_imm8
//0xC0
	.word op_b0, op_b1, op_b2, op_b3, op_b4, op_b5, op_b6, op_b7

	.global	mov_r0_bp_imm8
mov_r0_bp_imm8:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_imm8
mov_r0_imm8:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .op_c6_RAM_r2 op_c6_EGA_r2 op_c6_MODEX_r2
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.op_c6_RAM_r2:
	ldrb	r0, [r12],#1			// Load the imm8 value to r0
	strb	r0, [r2]				// Store the imm8 byte into RAM
	b		loop

// --- [idx] ---

mov_bxsi_imm8:
	add		r0, r7, r10
	b		mov_r0_imm8
mov_bxdi_imm8:
	add		r0, r7, r11
	b		mov_r0_imm8
mov_bpsi_imm8:
	add		r0, r9, r10
	b		mov_r0_bp_imm8
mov_bpdi_imm8:
	add		r0, r9, r11
	b		mov_r0_bp_imm8
mov_siidx_imm8:
	mov		r0, r10
	b		mov_r0_imm8
mov_diidx_imm8:
	mov		r0, r11
	b		mov_r0_imm8
mov_disp16_imm8:
	r0_from_disp16
	b		mov_r0_imm8
mov_bxidx_imm8:
	mov		r0, r7
	b		mov_r0_imm8

// --- [idx+disp8] ---

mov_bxsidisp8_imm8:
	r0_from_bxidxdisp8 r10
	b		mov_r0_imm8
mov_bxdidisp8_imm8:
	r0_from_bxidxdisp8 r11
	b		mov_r0_imm8
mov_bpsidisp8_imm8:
	r0_from_bpidxdisp8 r10
	b		mov_r0_bp_imm8
mov_bpdidisp8_imm8:
	r0_from_bpidxdisp8 r11
	b		mov_r0_bp_imm8
mov_sidisp8_imm8:
	r0_from_idx_disp8 r10
	b		mov_r0_imm8
mov_didisp8_imm8:
	r0_from_idx_disp8 r11
	b		mov_r0_imm8
mov_bpdisp8_imm8:
	r0_from_idx_disp8 r9
	b		mov_r0_bp_imm8
mov_bxdisp8_imm8:
	r0_from_idx_disp8 r7
	b		mov_r0_imm8

// --- [idx+disp16] ---

mov_bxsid16_imm8:
	r0_from_bxidxdisp16 r10
	b		mov_r0_imm8
mov_bxdid16_imm8:
	r0_from_bxidxdisp16 r11
	b		mov_r0_imm8
mov_bpsidisp16_imm8:
	r0_from_bpidxdisp16 r10
	b		mov_r0_bp_imm8
mov_bpdidisp16_imm8:
	r0_from_bpidxdisp16 r11
	b		mov_r0_bp_imm8
mov_sidisp16_imm8:
	r0_from_idx_disp16 r10
	b		mov_r0_imm8
mov_didisp16_imm8:
	r0_from_idx_disp16 r11
	b		mov_r0_imm8
mov_bpdisp16_imm8:
	r0_from_idx_disp16 r9
	b		mov_r0_bp_imm8
mov_bxdisp16_imm8:
	r0_from_idx_disp16 r7
	b		mov_r0_imm8

// ------------------- C7 = MOV r/m16, imm16 -----------------------------
//
// All modrm variations supported!
//
	.global	op_c7
op_c7:
	ldrb	r0,[r12],#1							// Load next opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	orr		r0, r0, lsr #3
	and		r0, #0x1F
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8

// 0
	.word mov_bxsi_imm16, mov_bxdi_imm16, mov_bpsi_imm16, mov_bpdi_imm16, mov_siidx_imm16, mov_diidx_imm16, mov_disp16_imm16, mov_bxidx_imm16
//0x40 (+disp8)
	.word mov_bxsid8_imm16, mov_bxdid8_imm16, mov_bpsid8_imm16, mov_bpdid8_imm16, mov_sidisp8_imm16, mov_didisp8_imm16, mov_bpdisp8_imm16, mov_bxdisp8_imm16
//0x80 (+disp16)
	.word mov_bxsid16_imm16, mov_bxdid16_imm16, mov_bpsid16_imm16, mov_bpdid16_imm16, mov_sidisp16_imm16, mov_didisp16_imm16, mov_bpdisp16_imm16, mov_bxdisp16_imm16
//0xC0
	.word op_b8, op_b9, op_ba, op_bb, op_bc, op_bd, op_be, op_bf

	.global mov_siidx_imm16, mov_diidx_imm16, mov_disp16_imm16, mov_bxidx_imm16
	.global mov_sidisp8_imm16, mov_didisp8_imm16, mov_bpdisp8_imm16, mov_bxdisp8_imm16
	.global op_b8, op_b9, op_ba, op_bb, op_bc, op_bd, op_be, op_bf

	.global	mov_r0_bp_imm16
mov_r0_bp_imm16:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mov_r0_imm16
mov_r0_imm16:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 1f op_c7_EGA_r2 op_c7_MODEX_r2
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
1:	ldrb	r0, [r12],#1			// Load the low byte of imm16 value to r0
	ldrb	r1, [r12],#1			// Load the high byte of imm16 value to r0
	strb	r0, [r2]				// Store the low byte into RAM
	strb	r1, [r2, #1]			// Store the high byte into RAM
	b		loop

// --- [idx] ---

mov_bxsi_imm16:
	add		r0, r7, r10
	b		mov_r0_imm16
mov_bxdi_imm16:
	add		r0, r7, r11
	b		mov_r0_imm16
mov_bpsi_imm16:
	add		r0, r9, r10
	b		mov_r0_bp_imm16
mov_bpdi_imm16:
	add		r0, r9, r11
	b		mov_r0_bp_imm16
mov_siidx_imm16:
	mov		r0, r10
	b		mov_r0_imm16
mov_diidx_imm16:
	mov		r0, r11
	b		mov_r0_imm16
mov_disp16_imm16:
	r0_from_disp16
	b		mov_r0_imm16
mov_bxidx_imm16:
	mov		r0, r7
	b		mov_r0_imm16

// --- [idx+disp8] ---

mov_bxsid8_imm16:
	r0_from_bxidxdisp8 r10
	b		mov_r0_imm16
mov_bxdid8_imm16:
	r0_from_bxidxdisp8 r11
	b		mov_r0_imm16
mov_bpsid8_imm16:
	r0_from_bpidxdisp8 r10
	b		mov_r0_bp_imm16
mov_bpdid8_imm16:
	r0_from_bpidxdisp8 r11
	b		mov_r0_bp_imm16
mov_sidisp8_imm16:
	r0_from_idx_disp8 r10
	b		mov_r0_imm16
mov_didisp8_imm16:
	r0_from_idx_disp8 r11
	b		mov_r0_imm16
mov_bpdisp8_imm16:
	r0_from_idx_disp8 r9
	b		mov_r0_bp_imm16
mov_bxdisp8_imm16:
	r0_from_idx_disp8 r7
	b		mov_r0_imm16

// --- [idx+disp16] ---

mov_bxsid16_imm16:
	r0_from_bxidxdisp16 r10
	b		mov_r0_imm16
mov_bxdid16_imm16:
	r0_from_bxidxdisp16 r11
	b		mov_r0_imm16
mov_bpsid16_imm16:
	r0_from_bpidxdisp16 r10
	b		mov_r0_bp_imm16
mov_bpdid16_imm16:
	r0_from_bpidxdisp16 r11
	b		mov_r0_bp_imm16
mov_sidisp16_imm16:
	r0_from_idx_disp16 r10
	b		mov_r0_imm16
mov_didisp16_imm16:
	r0_from_idx_disp16 r11
	b		mov_r0_imm16
mov_bpdisp16_imm16:
	r0_from_idx_disp16 r9
	b		mov_r0_bp_imm16
mov_bxdisp16_imm16:
	r0_from_idx_disp16 r7
	b		mov_r0_imm16


// ------------------- C8 = ENTER imm16,imm8 ---------------------------
//
// Note! This is a 80186+ opcode!
// If imm8 = 00, this is a combination of PUSH BP, MOV BP,SP, SUB SP, imm16
//
op_c8:
	push_hword ebp r0 r1			// PUSH BP
	mov		r0, ebp, lsl #16
	mov		r1, esp, lsl #16		// r1 = SP in high 16 bits
	eor		ebp, r0, lsr #16
	eor		esp, r1, lsr #16
	orr		ebp, r1, lsr #16		// MOV BP, SP
	ldrb	r0,[r12],#1				// Load the low byte of imm16 value to r0
	ldrb	r2,[r12],#1				// Load the high byte of imm16 value to r1
	ldrb	r3,[r12],#1				// Load the imm8 value to r2
	orr		r0, r2, lsl #8
	sub		r1, r0, lsl #16
	orr		esp, r1, lsr #16		// SUB SP,imm16
	//------ The code below is temporary, until the code is completed!
	mrs		r0, cpsr				// Save current flags
	cmp		r3, #0
	beq		restore_flags_from_r0
	sub		r12, #3
	b		.unknown
	
// ------------------- C9 = LEAVE --------------------------------------
//
// Note! This is a 80186+ opcode!
// This is a combination of MOV SP,BP and POP BP
//
op_c9:
	mov		r0, ebp, lsl #16
	mov		r1, esp, lsl #16		// r1 = SP in high 16 bits
	eor		ebp, r0, lsr #16
	eor		esp, r1, lsr #16
	orr		esp, r0, lsr #16		// MOV SP, BP
	pop_reg_low_tmp r0 r1
	orr		ebp, r0					// POP BP
	b		loop
	
// ------------------- CA = RETF imm16 ---------------------------------
// Profiler: 25767, 22, 25.61, 659836, 0.34%
//
	.global	op_ca
op_ca:
	ldrb	r3,[r12],#1				// Load byte to r1, increment r12 by 1
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	orr		r3, r0, lsl #8			// r3 = low byte | (high byte << 8)
	b		retf_common_r3			// Continue with the common handler

// ------------------- CB = RETF ---------------------------------------
// Profiler: 9596, 20, 27.29, 261900, 0.14%
//
	.global	op_cb
op_cb:
	//-------
	// First prepare the parameter value:
	//	r3 = use32<<16 | (extra_words_to_pop)
	//-------
	mov		r3, #0					// USE16 RETF, no extra words to pop.
	.global	retf_common_r3
retf_common_r3:	
	//-------
	// Then determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r1, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	mrs		r0,cpsr					// Save flags (we are not allowed to change any)
	tst		r1, #1					// Are we in protected mode (or in VM mode)?
	bne		cpu_retf_prot_r0r3		// Yes we are, go handle protected mode RETF!
	//-------
	// Real mode RETF handling
	//-------
	.global	cpu_retf_real_r0r3
cpu_retf_real_r0r3:
	tst		r3, #0x10000			// USE32 RETF?
	bne		.retf_USE32				// Yep, go handle it (rare)
	msr		cpsr_f, r0				// restore flags
	pop_reg_low_tmp r12 r2			// Get new logical IP (zero-extended) to r12
	pop_reg_low_tmp r2 r1			// Get new logical CS (zero-extended) to r2
	add		esp, r3					// Pop the extra bytes from the stack. NOTE! Stack underflow not properly handled!
	str		r2, [sp, #SP_CS_VALUE]
	lsl		r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_CS_BASE]
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_CS]
	add		r12, r2
	b		loop
.retf_USE32:	
	b		.unknown

	.text
	.align 2

// ------------------- CC = INT 03 -------------------------------------
// See opcode D6 for generic INT handler call
// This opcode used in Crystal Cave, for example.
//
	.global	op_cc
op_cc:
	mov		r2, #3					// INT #3
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr				// Save current flags to r0
	tst		r3, #1					// Are we in protected mode (or in VM mode)?
	bne		cpu_int_prot_r0r2		// Yes we are, go handle protected mode INT!
	msr		cpsr_f,r0				// Restore the real flags again
	//------
	// Push current CPU flags to stack
	//------
	push_flags_16 r0 r1 r3	
	//------
	// Clear the Trap and Interrupt flags
	//------
	ldr		r1, [sp, #SP_FLAGS]		// Get the #SP_FLAGSS
	mrs		r0, cpsr				// Save flags to r0
	tst		r1, #FLAG_TF
	bic		r1, #(FLAG_TF|FLAG_IF)	// Clear interrupts and the TRAP flag
	str		r1, [sp, #SP_FLAGS]		// Save the #SP_FLAGS
	movne	r1, #IRQ_OFF
	strne	r1, [sp, #SP_IRQFLAG]	// Turn off the IRQ flag if trap flag was on
	msr		cpsr_f,r0				// Restore the real flags again
	b		.op_cc_cont				// Continue with common code with opcode 0xCD = INT imm8
	
// ------------------- CD = INT imm8 -----------------------------------
// See opcode D6 for generic INT handler call
//
op_cd:
	ldrb	r2,[r12],#1				// Load next opcode byte to r2, increment r12 by 1
.op_cd_cont:
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr				// Save current flags to r0
	tst		r3, #1					// Are we in protected mode (or in VM mode)?
	bne		cpu_int_prot_r0r2		// Yes we are, go handle protected mode INT!
	.global	cpu_int_real_r0r2
cpu_int_real_r0r2:
	msr		cpsr_f,r0				// Restore the real flags again
	//------
	// Push current CPU flags to stack
	//------
	push_flags_16 r0 r1 r3			
.op_cc_cont:
	//------
	// Get the interrupt vector address
	//------
	mov		r1, r2					// r1 = INT number
	mov		r2, #0
	calc_linear_address_r2
	ldr		r2, [r2, r1, lsl #2]	// r2 = interrupt vector address, high halfword = segment, low halfword = offset
	//------
	// Push current CS:IP to stack
	//------
	ldr		r0, [sp, #SP_CS_VALUE]	// r0 = Current logical CS
	push_hword r0 r1 r3
	ldr		r1, [sp, #SP_PHYS_CS]	// r1 = Current physical CS
	sub		r1, r12, r1				// r1 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	push_hword r1 r0 r3
	//------
	// Get new logical CS:IP to r0:r12
	//------
	mov		r12, r2, lsl #16
	mov		r0, r2, lsr #16			// Now r0 = new logical CS
	//------
	// Save the new logical CS
	//------
	mov		r2, r0, lsl #REAL_SEGMENT_SHIFT
	str		r0, [sp, #SP_CS_VALUE]
	str		r2, [sp, #SP_CS_BASE]
	//------
	// Finally calculate new physical IP
	//------
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_CS]	// Store new physical CS into stack
	add		r12, r2, r12, lsr #16	// r12 = new physical CS:IP = physical base + new IP + (new CS << 4)
	b		loop

// ------------------- CE = INTO ---------------------------------------
// See opcode D6 for generic INT handler call
//
op_ce:
	bvc		loop					// NOP if Overflow flag is not set
	mov		r2, #4					// INT #4
	b		.op_cd_cont				// Else go perform INT 4

// ------------------- CF = IRET ---------------------------------------
// Profiler: 5240, 24, 69.58, 364614, 0.19%
//
	.global	op_cf					// Called from "cpu_prot.S" when performing a triple fault reset.
op_cf:
	//-------
	// Determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	mrs		r0, cpsr				// Save current flags to r0
	tst		r3, #1					// Are we in protected mode (or in VM mode)?
	bic		r0, #0x10000			// Mark that this is a 16-bit IRET
	bne		cpu_iret_prot_r0		// Yes we are, go handle protected mode IRET!
	//-------
	// We are in real mode, so continue.
	//-------
	msr		cpsr_f, r0				// restore flags
	pop_reg_low_tmp r12 r0			// Get new logical IP (zero-extended) to r12
	pop_reg_low_tmp r2 r0			// Get new logical CS (zero-extended) to r2
	str		r2, [sp, #SP_CS_VALUE]
	lsl		r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_CS_BASE]
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_CS]
	add		r12, r2
	pop_reg_low_tmp	r0 r1			// r0 = new flags
	ldr		r2, =FMASK_ALL			// r2 = mask of the flag bits we can change
	ldr		r1, [sp, #SP_FLAGS]		// Get the #SP_FLAGS
	bic		r2, #0x00FF0000			// mask = mask & 0xFFFF
	and		r0, r2					// Leave only the bits we can change to r0
	bic		r2, r1, r2				// r2 = flags bits that will not change
	orr		r0, r2
	str		r0, [sp, #SP_FLAGS]		// Store the new #SP_FLAGS
	.global	iret_cont_flags_old_r1_new_r0
iret_cont_flags_old_r1_new_r0:		// Called from "cpu_prot.s" after a protected mode IRET!
	eor		r2, r0, r1				// r2 tells which flags have changed
	popped_flags_to_ARM r0			// Convert the flags to ARM flags
	ands	r2, #(FLAG_TF|FLAG_IF)	// Have the Trap or Interrupt flags changed?
	beq		restore_flags_from_r0	// Nope, so go restore CPU flags and continue running.
	//-------
	// Extra flags have changed! 
	//	r0 = new flags (in x86 and ARM format)
	//	r1 = old flags (in x86 format)
	//	r2 = bit mask telling the changed flags
	//-------
	// If the trap flag is now on, make sure we have a proper handler for INT01!
	// For example "catacomb" sets the trap flag accidentally when pressing a key.
	//-------
	tst		r2, #FLAG_TF
	bne		.trap_flag_on
	//-------
	// If the INT flags is now on, go test for pending interrupts. See "pic.s".
	//-------
.trap_flag_ignore:	
	tst		r2, #FLAG_IF
	tstne	r0, #FLAG_IF
	bne		int_flag_on
	//-------
	// Neither INT or TRAP flags on, just continue.
	//-------
	b		restore_flags_from_r0	
	
	//-------
	// Trap flag turned on, go to single step mode (but only if we have a proper INT01 handler!)
	// On input:
	//	r0 = new flags (in x86 and ARM format)
	//	r1 = old flags (in x86 format)
	//	r2 = bit mask telling the changed flags
	// 	r3 = free
	//-------
.trap_flag_on:
	ldr		r3, [sp, #SP_TLBTABLE]	// r3 = physical start address of the first memory page (INTVectors)
	ldr		r3, [r3, #4]			// r3 = INT01 vector handler address
	cmp		r3, #0xF0000001			// Is it our own placeholder?
	biceq	r0, #FLAG_TF			// If yes, turn the flag back off.
	beq		.trap_flag_ignore		// and ignore the trap flag handling.
	mov		r1, #IRQ_ON
	str		r1,[sp, #SP_IRQFLAG]	// Set the IRQFlag
	ldr		r2, =TrapFlag
	mov		r1, #0
	str		r1, [r2]
	b		restore_flags_from_r0

.ltorg								// Dump the current literal pool here

// ------------------- D0 = ROL/ROR/RCL/RCR/SHL/SHR/SHL/SAR r/m8,1 ---
// 
// All modrm variations supported!
// Note: The actual handlers are by op_c0, as rotating by 1 bit is a special case of the full rotate functionality.
//
// - RCL/RCR/ROL/ROR change the carry and overflow flags only, must not change the Sign and Zero flags.
// - SHL/SHR/SHL/SAR change carry, sign, overflow and zero flags
//
op_d0:
	modrm_jump_16
// 0
	.word rol_b_bxsi_1, rol_b_bxdi_1, rol_b_bpsi_1, rol_b_bpdi_1, rol_b_siidx_1, rol_b_diidx_1, rol_b_disp16_1, rol_b_bxidx_1
	.word ror_b_bxsi_1, ror_b_bxdi_1, ror_b_bpsi_1, ror_b_bpdi_1, ror_b_siidx_1, ror_b_diidx_1, ror_b_disp16_1, ror_b_bxidx_1
	.word rcl_b_bxsi_1, rcl_b_bxdi_1, rcl_b_bpsi_1, rcl_b_bpdi_1, rcl_b_siidx_1, rcl_b_diidx_1, rcl_b_disp16_1, rcl_b_bxidx_1
	.word rcr_b_bxsi_1, rcr_b_bxdi_1, rcr_b_bpsi_1, rcr_b_bpdi_1, rcr_b_siidx_1, rcr_b_diidx_1, rcr_b_disp16_1, rcr_b_bxidx_1
	.word shl_b_bxsi_1, shl_b_bxdi_1, shl_b_bpsi_1, shl_b_bpdi_1, shl_b_siidx_1, shl_b_diidx_1, shl_b_disp16_1, shl_b_bxidx_1
	.word shr_b_bxsi_1, shr_b_bxdi_1, shr_b_bpsi_1, shr_b_bpdi_1, shr_b_siidx_1, shr_b_diidx_1, shr_b_disp16_1, shr_b_bxidx_1
	.word shl_b_bxsi_1, shl_b_bxdi_1, shl_b_bpsi_1, shl_b_bpdi_1, shl_b_siidx_1, shl_b_diidx_1, shl_b_disp16_1, shl_b_bxidx_1
	.word sar_b_bxsi_1, sar_b_bxdi_1, sar_b_bpsi_1, sar_b_bpdi_1, sar_b_siidx_1, sar_b_diidx_1, sar_b_disp16_1, sar_b_bxidx_1
//0x40
	.word rol_b_bxsid8_1, rol_b_bxdid8_1, rol_b_bpsid8_1, rol_b_bpdid8_1, rol_b_sidisp8_1, rol_b_didisp8_1, rol_b_bpdisp8_1, rol_b_bxdisp8_1
	.word ror_b_bxsid8_1, ror_b_bxdid8_1, ror_b_bpsid8_1, ror_b_bpdid8_1, ror_b_sidisp8_1, ror_b_didisp8_1, ror_b_bpdisp8_1, ror_b_bxdisp8_1
	.word rcl_b_bxsid8_1, rcl_b_bxdid8_1, rcl_b_bpsid8_1, rcl_b_bpdid8_1, rcl_b_sidisp8_1, rcl_b_didisp8_1, rcl_b_bpdisp8_1, rcl_b_bxdisp8_1
	.word rcr_b_bxsid8_1, rcr_b_bxdid8_1, rcr_b_bpsid8_1, rcr_b_bpdid8_1, rcr_b_sidisp8_1, rcr_b_didisp8_1, rcr_b_bpdisp8_1, rcr_b_bxdisp8_1
	.word shl_b_bxsid8_1, shl_b_bxdid8_1, shl_b_bpsid8_1, shl_b_bpdid8_1, shl_b_sidisp8_1, shl_b_didisp8_1, shl_b_bpdisp8_1, shl_b_bxdisp8_1
	.word shr_b_bxsid8_1, shr_b_bxdid8_1, shr_b_bpsid8_1, shr_b_bpdid8_1, shr_b_sidisp8_1, shr_b_didisp8_1, shr_b_bpdisp8_1, shr_b_bxdisp8_1
	.word shl_b_bxsid8_1, shl_b_bxdid8_1, shl_b_bpsid8_1, shl_b_bpdid8_1, shl_b_sidisp8_1, shl_b_didisp8_1, shl_b_bpdisp8_1, shl_b_bxdisp8_1
	.word sar_b_bxsid8_1, sar_b_bxdid8_1, sar_b_bpsid8_1, sar_b_bpdid8_1, sar_b_sidisp8_1, sar_b_didisp8_1, sar_b_bpdisp8_1, sar_b_bxdisp8_1
//0x80
	.word rol_b_bxsid16_1, rol_b_bxdid16_1, rol_b_bpsid16_1, rol_b_bpdid16_1, rol_b_sidisp16_1, rol_b_didisp16_1, rol_b_bpdisp16_1, rol_b_bxdisp16_1
	.word ror_b_bxsid16_1, ror_b_bxdid16_1, ror_b_bpsid16_1, ror_b_bpdid16_1, ror_b_sidisp16_1, ror_b_didisp16_1, ror_b_bpdisp16_1, ror_b_bxdisp16_1
	.word rcl_b_bxsid16_1, rcl_b_bxdid16_1, rcl_b_bpsid16_1, rcl_b_bpdid16_1, rcl_b_sidisp16_1, rcl_b_didisp16_1, rcl_b_bpdisp16_1, rcl_b_bxdisp16_1
	.word rcr_b_bxsid16_1, rcr_b_bxdid16_1, rcr_b_bpsid16_1, rcr_b_bpdid16_1, rcr_b_sidisp16_1, rcr_b_didisp16_1, rcr_b_bpdisp16_1, rcr_b_bxdisp16_1
	.word shl_b_bxsid16_1, shl_b_bxdid16_1, shl_b_bpsid16_1, shl_b_bpdid16_1, shl_b_sidisp16_1, shl_b_didisp16_1, shl_b_bpdisp16_1, shl_b_bxdisp16_1
	.word shr_b_bxsid16_1, shr_b_bxdid16_1, shr_b_bpsid16_1, shr_b_bpdid16_1, shr_b_sidisp16_1, shr_b_didisp16_1, shr_b_bpdisp16_1, shr_b_bxdisp16_1
	.word shl_b_bxsid16_1, shl_b_bxdid16_1, shl_b_bpsid16_1, shl_b_bpdid16_1, shl_b_sidisp16_1, shl_b_didisp16_1, shl_b_bpdisp16_1, shl_b_bxdisp16_1
	.word sar_b_bxsid16_1, sar_b_bxdid16_1, sar_b_bpsid16_1, sar_b_bpdid16_1, sar_b_sidisp16_1, sar_b_didisp16_1, sar_b_bpdisp16_1, sar_b_bxdisp16_1
//0xc0 = mod = 11b => two register operands
// ROL
	.word rol_reg8l_1_r4, rol_reg8l_1_r5, rol_reg8l_1_r6, rol_reg8l_1_r7, rol_reg8h_1_r4, rol_reg8h_1_r5, rol_reg8h_1_r6, rol_reg8h_1_r7
// ROR	
	.word ror_reg8l_1_r4, ror_reg8l_1_r5, ror_reg8l_1_r6, ror_reg8l_1_r7, ror_reg8h_1_r4, ror_reg8h_1_r5, ror_reg8h_1_r6, ror_reg8h_1_r7
// RCL
	.word rcl_reg8l_1_r4, rcl_reg8l_1_r5, rcl_reg8l_1_r6, rcl_reg8l_1_r7, rcl_reg8h_1_r4, rcl_reg8h_1_r5, rcl_reg8h_1_r6, rcl_reg8h_1_r7
// RCR
	.word rcr_reg8l_1_r4, rcr_reg8l_1_r5, rcr_reg8l_1_r6, rcr_reg8l_1_r7, rcr_reg8h_1_r4, rcr_reg8h_1_r5, rcr_reg8h_1_r6, rcr_reg8h_1_r7
// SHL
	.word shl_reg8l_1_r4, shl_reg8l_1_r5, shl_reg8l_1_r6, shl_reg8l_1_r7, shl_reg8h_1_r4, shl_reg8h_1_r5, shl_reg8h_1_r6, shl_reg8h_1_r7
// SHR
	.word shr_reg8l_1_r4, shr_reg8l_1_r5, shr_reg8l_1_r6, shr_reg8l_1_r7, shr_reg8h_1_r4, shr_reg8h_1_r5, shr_reg8h_1_r6, shr_reg8h_1_r7
// SHL	
	.word shl_reg8l_1_r4, shl_reg8l_1_r5, shl_reg8l_1_r6, shl_reg8l_1_r7, shl_reg8h_1_r4, shl_reg8h_1_r5, shl_reg8h_1_r6, shl_reg8h_1_r7
// SAR	
	.word sar_reg8l_1_r4, sar_reg8l_1_r5, sar_reg8l_1_r6, sar_reg8l_1_r7, sar_reg8h_1_r4, sar_reg8h_1_r5, sar_reg8h_1_r6, sar_reg8h_1_r7

	.global rol_b_siidx_1, rol_b_diidx_1, rol_b_bxidx_1
	.global ror_b_siidx_1, ror_b_diidx_1, ror_b_bxidx_1
	.global rcl_b_siidx_1, rcl_b_diidx_1, rcl_b_bxidx_1
	.global rcr_b_siidx_1, rcr_b_diidx_1, rcr_b_bxidx_1
	.global shl_b_siidx_1, shl_b_diidx_1, shl_b_bxidx_1
	.global shr_b_siidx_1, shr_b_diidx_1, shr_b_bxidx_1
	.global sar_b_siidx_1, sar_b_diidx_1, sar_b_bxidx_1
	.global rol_b_sidisp8_1, rol_b_didisp8_1, rol_b_bpdisp8_1, rol_b_bxdisp8_1
	.global ror_b_sidisp8_1, ror_b_didisp8_1, ror_b_bpdisp8_1, ror_b_bxdisp8_1
	.global rcl_b_sidisp8_1, rcl_b_didisp8_1, rcl_b_bpdisp8_1, rcl_b_bxdisp8_1
	.global rcr_b_sidisp8_1, rcr_b_didisp8_1, rcr_b_bpdisp8_1, rcr_b_bxdisp8_1
	.global shl_b_sidisp8_1, shl_b_didisp8_1, shl_b_bpdisp8_1, shl_b_bxdisp8_1
	.global shr_b_sidisp8_1, shr_b_didisp8_1, shr_b_bpdisp8_1, shr_b_bxdisp8_1
	.global sar_b_sidisp8_1, sar_b_didisp8_1, sar_b_bpdisp8_1, sar_b_bxdisp8_1
	.global rol_reg8l_1_r4, rol_reg8l_1_r5, rol_reg8l_1_r6, rol_reg8l_1_r7, rol_reg8h_1_r4, rol_reg8h_1_r5, rol_reg8h_1_r6, rol_reg8h_1_r7
	.global ror_reg8l_1_r4, ror_reg8l_1_r5, ror_reg8l_1_r6, ror_reg8l_1_r7, ror_reg8h_1_r4, ror_reg8h_1_r5, ror_reg8h_1_r6, ror_reg8h_1_r7
	.global rcl_reg8l_1_r4, rcl_reg8l_1_r5, rcl_reg8l_1_r6, rcl_reg8l_1_r7, rcl_reg8h_1_r4, rcl_reg8h_1_r5, rcl_reg8h_1_r6, rcl_reg8h_1_r7
	.global rcr_reg8l_1_r4, rcr_reg8l_1_r5, rcr_reg8l_1_r6, rcr_reg8l_1_r7, rcr_reg8h_1_r4, rcr_reg8h_1_r5, rcr_reg8h_1_r6, rcr_reg8h_1_r7
	.global shl_reg8l_1_r4, shl_reg8l_1_r5, shl_reg8l_1_r6, shl_reg8l_1_r7, shl_reg8h_1_r4, shl_reg8h_1_r5, shl_reg8h_1_r6, shl_reg8h_1_r7
	.global shr_reg8l_1_r4, shr_reg8l_1_r5, shr_reg8l_1_r6, shr_reg8l_1_r7, shr_reg8h_1_r4, shr_reg8h_1_r5, shr_reg8h_1_r6, shr_reg8h_1_r7
	.global sar_reg8l_1_r4, sar_reg8l_1_r5, sar_reg8l_1_r6, sar_reg8l_1_r7, sar_reg8h_1_r4, sar_reg8h_1_r5, sar_reg8h_1_r6, sar_reg8h_1_r7

.macro opd0common oper
	.global	\oper\()_byte_r0_bp_1
\oper\()_byte_r0_bp_1:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	\oper\()_byte_r0_1
\oper\()_byte_r0_1:					// Rotate a byte at offset r0high in effective segment left by r1 value
	mem_handler_jump_r0r3 \oper\()_byte_r2_1_RAM bad_EGA_opcode bad_MODEX_opcode

\oper\()_b_bxsi_1:
	add		r0, r7, r10
	b		\oper\()_byte_r0_1
\oper\()_b_bxdi_1:
	add		r0, r7, r11
	b		\oper\()_byte_r0_1
\oper\()_b_bpsi_1:
	add		r0, r9, r10
	b		\oper\()_byte_r0_bp_1
\oper\()_b_bpdi_1:
	add		r0, r9, r11
	b		\oper\()_byte_r0_bp_1
\oper\()_b_siidx_1:
	mov		r0, r10
	b		\oper\()_byte_r0_1
\oper\()_b_diidx_1:
	mov		r0, r11
	b		\oper\()_byte_r0_1
\oper\()_b_disp16_1:
	r0_from_disp16
	b		\oper\()_byte_r0_1
\oper\()_b_bxidx_1:
	mov		r0, r7
	b		\oper\()_byte_r0_1

\oper\()_b_bxsid8_1:
	r0_from_bxidxdisp8 r10
	b		\oper\()_byte_r0_1
\oper\()_b_bxdid8_1:
	r0_from_bxidxdisp8 r11
	b		\oper\()_byte_r0_1
\oper\()_b_bpsid8_1:
	r0_from_bpidxdisp8 r10
	b		\oper\()_byte_r0_bp_1
\oper\()_b_bpdid8_1:
	r0_from_bpidxdisp8 r11
	b		\oper\()_byte_r0_bp_1
\oper\()_b_sidisp8_1:
	r0_from_idx_disp8 r10
	b		\oper\()_byte_r0_1
\oper\()_b_didisp8_1:
	r0_from_idx_disp8 r11
	b		\oper\()_byte_r0_1
\oper\()_b_bpdisp8_1:
	r0_from_idx_disp8 r9
	b		\oper\()_byte_r0_bp_1
\oper\()_b_bxdisp8_1:
	r0_from_idx_disp8 r7
	b		\oper\()_byte_r0_1

\oper\()_b_bxsid16_1:
	r0_from_bxidxdisp16 r10
	b		\oper\()_byte_r0_1
\oper\()_b_bxdid16_1:
	r0_from_bxidxdisp16 r11
	b		\oper\()_byte_r0_1
\oper\()_b_bpsid16_1:
	r0_from_bpidxdisp16 r10
	b		\oper\()_byte_r0_bp_1
\oper\()_b_bpdid16_1:
	r0_from_bpidxdisp16 r11
	b		\oper\()_byte_r0_bp_1
\oper\()_b_sidisp16_1:
	r0_from_idx_disp16 r10
	b		\oper\()_byte_r0_1
\oper\()_b_didisp16_1:
	r0_from_idx_disp16 r11
	b		\oper\()_byte_r0_1
\oper\()_b_bpdisp16_1:
	r0_from_idx_disp16 r9
	b		\oper\()_byte_r0_bp_1
\oper\()_b_bxdisp16_1:
	r0_from_idx_disp16 r7
	b		\oper\()_byte_r0_1
.endm

	opd0common rol
	opd0common ror
	opd0common rcl
	opd0common rcr
	opd0common shl
	opd0common shr
	opd0common sar
	
// ------------------- D1 = ROL/ROR/RCL/RCR/SHL/SHR/SHL/SAR r/m16,1 ---
// 
// All modrm variations supported!
//
// - RCL/RCR/ROL/ROR change the carry and overflow flags only, must not change the Sign and Zero flags.
// - SHL/SHR/SHL/SAR change carry, sign, overflow and zero flags
//
op_d1:
	modrm_jump_16
// 0
	.word rol_bxsi_16_1, rol_bxdi_16_1, rol_bpsi_16_1, rol_bpdi_16_1, rol_siidx_16_1, rol_diidx_16_1, rol_disp16_16_1, rol_bxidx_16_1
	.word ror_bxsi_16_1, ror_bxdi_16_1, ror_bpsi_16_1, ror_bpdi_16_1, ror_siidx_16_1, ror_diidx_16_1, ror_disp16_16_1, ror_bxidx_16_1
	.word rcl_bxsi_16_1, rcl_bxdi_16_1, rcl_bpsi_16_1, rcl_bpdi_16_1, rcl_siidx_16_1, rcl_diidx_16_1, rcl_disp16_16_1, rcl_bxidx_16_1
	.word rcr_bxsi_16_1, rcr_bxdi_16_1, rcr_bpsi_16_1, rcr_bpdi_16_1, rcr_siidx_16_1, rcr_diidx_16_1, rcr_disp16_16_1, rcr_bxidx_16_1
	.word shl_bxsi_16_1, shl_bxdi_16_1, shl_bpsi_16_1, shl_bpdi_16_1, shl_siidx_16_1, shl_diidx_16_1, shl_disp16_16_1, shl_bxidx_16_1
	.word shr_bxsi_16_1, shr_bxdi_16_1, shr_bpsi_16_1, shr_bpdi_16_1, shr_siidx_16_1, shr_diidx_16_1, shr_disp16_16_1, shr_bxidx_16_1
	.word shl_bxsi_16_1, shl_bxdi_16_1, shl_bpsi_16_1, shl_bpdi_16_1, shl_siidx_16_1, shl_diidx_16_1, shl_disp16_16_1, shl_bxidx_16_1
	.word sar_bxsi_16_1, sar_bxdi_16_1, sar_bpsi_16_1, sar_bpdi_16_1, sar_siidx_16_1, sar_diidx_16_1, sar_disp16_16_1, sar_bxidx_16_1
//0x40
	.word rol_bxsid8_16_1, rol_bxdid8_16_1, rol_bpsid8_16_1, rol_bpdid8_16_1, rol_sidisp8_16_1, rol_didisp8_16_1, rol_bpdisp8_16_1, rol_bxdisp8_16_1
	.word ror_bxsid8_16_1, ror_bxdid8_16_1, ror_bpsid8_16_1, ror_bpdid8_16_1, ror_sidisp8_16_1, ror_didisp8_16_1, ror_bpdisp8_16_1, ror_bxdisp8_16_1
	.word rcl_bxsid8_16_1, rcl_bxdid8_16_1, rcl_bpsid8_16_1, rcl_bpdid8_16_1, rcl_sidisp8_16_1, rcl_didisp8_16_1, rcl_bpdisp8_16_1, rcl_bxdisp8_16_1
	.word rcr_bxsid8_16_1, rcr_bxdid8_16_1, rcr_bpsid8_16_1, rcr_bpdid8_16_1, rcr_sidisp8_16_1, rcr_didisp8_16_1, rcr_bpdisp8_16_1, rcr_bxdisp8_16_1
	.word shl_bxsid8_16_1, shl_bxdid8_16_1, shl_bpsid8_16_1, shl_bpdid8_16_1, shl_sidisp8_16_1, shl_didisp8_16_1, shl_bpdisp8_16_1, shl_bxdisp8_16_1
	.word shr_bxsid8_16_1, shr_bxdid8_16_1, shr_bpsid8_16_1, shr_bpdid8_16_1, shr_sidisp8_16_1, shr_didisp8_16_1, shr_bpdisp8_16_1, shr_bxdisp8_16_1
	.word shl_bxsid8_16_1, shl_bxdid8_16_1, shl_bpsid8_16_1, shl_bpdid8_16_1, shl_sidisp8_16_1, shl_didisp8_16_1, shl_bpdisp8_16_1, shl_bxdisp8_16_1
	.word sar_bxsid8_16_1, sar_bxdid8_16_1, sar_bpsid8_16_1, sar_bpdid8_16_1, sar_sidisp8_16_1, sar_didisp8_16_1, sar_bpdisp8_16_1, sar_bxdisp8_16_1
//0x80
	.word rol_bxsid16_16_1, rol_bxdid16_16_1, rol_bpsid16_16_1, rol_bpdid16_16_1, rol_sidisp16_16_1, rol_didisp16_16_1, rol_bpdisp16_16_1, rol_bxdisp16_16_1
	.word ror_bxsid16_16_1, ror_bxdid16_16_1, ror_bpsid16_16_1, ror_bpdid16_16_1, ror_sidisp16_16_1, ror_didisp16_16_1, ror_bpdisp16_16_1, ror_bxdisp16_16_1
	.word rcl_bxsid16_16_1, rcl_bxdid16_16_1, rcl_bpsid16_16_1, rcl_bpdid16_16_1, rcl_sidisp16_16_1, rcl_didisp16_16_1, rcl_bpdisp16_16_1, rcl_bxdisp16_16_1
	.word rcr_bxsid16_16_1, rcr_bxdid16_16_1, rcr_bpsid16_16_1, rcr_bpdid16_16_1, rcr_sidisp16_16_1, rcr_didisp16_16_1, rcr_bpdisp16_16_1, rcr_bxdisp16_16_1
	.word shl_bxsid16_16_1, shl_bxdid16_16_1, shl_bpsid16_16_1, shl_bpdid16_16_1, shl_sidisp16_16_1, shl_didisp16_16_1, shl_bpdisp16_16_1, shl_bxdisp16_16_1
	.word shr_bxsid16_16_1, shr_bxdid16_16_1, shr_bpsid16_16_1, shr_bpdid16_16_1, shr_sidisp16_16_1, shr_didisp16_16_1, shr_bpdisp16_16_1, shr_bxdisp16_16_1
	.word shl_bxsid16_16_1, shl_bxdid16_16_1, shl_bpsid16_16_1, shl_bpdid16_16_1, shl_sidisp16_16_1, shl_didisp16_16_1, shl_bpdisp16_16_1, shl_bxdisp16_16_1
	.word sar_bxsid16_16_1, sar_bxdid16_16_1, sar_bpsid16_16_1, sar_bpdid16_16_1, sar_sidisp16_16_1, sar_didisp16_16_1, sar_bpdisp16_16_1, sar_bxdisp16_16_1
//0xc0 = mod = 11b => two register operands
// ROL
	.word rol_reg16_1_r4, rol_reg16_1_r5, rol_reg16_1_r6, rol_reg16_1_r7, rol_reg16_1_r8, rol_reg16_1_r9, rol_reg16_1_r10, rol_reg16_1_r11
// ROR	
	.word ror_reg16_1_r4, ror_reg16_1_r5, ror_reg16_1_r6, ror_reg16_1_r7, ror_reg16_1_r8, ror_reg16_1_r9, ror_reg16_1_r10, ror_reg16_1_r11
// RCL
	.word rcl_reg16_1_r4, rcl_reg16_1_r5, rcl_reg16_1_r6, rcl_reg16_1_r7, rcl_reg16_1_r8, rcl_reg16_1_r9, rcl_reg16_1_r10, rcl_reg16_1_r11
// RCR
	.word rcr_reg16_1_r4, rcr_reg16_1_r5, rcr_reg16_1_r6, rcr_reg16_1_r7, rcr_reg16_1_r8, rcr_reg16_1_r9, rcr_reg16_1_r10, rcr_reg16_1_r11
// SHL
	.word shl_reg16_1_r4, shl_reg16_1_r5, shl_reg16_1_r6, shl_reg16_1_r7, shl_reg16_1_r8, shl_reg16_1_r9, shl_reg16_1_r10, shl_reg16_1_r11
// SHR
	.word shr_reg16_1_r4, shr_reg16_1_r5, shr_reg16_1_r6, shr_reg16_1_r7, shr_reg16_1_r8, shr_reg16_1_r9, shr_reg16_1_r10, shr_reg16_1_r11
// SHL	
	.word shl_reg16_1_r4, shl_reg16_1_r5, shl_reg16_1_r6, shl_reg16_1_r7, shl_reg16_1_r8, shl_reg16_1_r9, shl_reg16_1_r10, shl_reg16_1_r11
// SAR	
	.word sar_reg16_1_r4, sar_reg16_1_r5, sar_reg16_1_r6, sar_reg16_1_r7, sar_reg16_1_r8, sar_reg16_1_r9, sar_reg16_1_r10, sar_reg16_1_r11

	.global rol_siidx_16_1, rol_diidx_16_1, rol_disp16_16_1, rol_bxidx_16_1
	.global ror_siidx_16_1, ror_diidx_16_1, ror_disp16_16_1, ror_bxidx_16_1
	.global rcl_siidx_16_1, rcl_diidx_16_1, rcl_disp16_16_1, rcl_bxidx_16_1
	.global rcr_siidx_16_1, rcr_diidx_16_1, rcr_disp16_16_1, rcr_bxidx_16_1
	.global shl_siidx_16_1, shl_diidx_16_1, shl_disp16_16_1, shl_bxidx_16_1
	.global shr_siidx_16_1, shr_diidx_16_1, shr_disp16_16_1, shr_bxidx_16_1
	.global sar_siidx_16_1, sar_diidx_16_1, sar_disp16_16_1, sar_bxidx_16_1
	.global rol_sidisp8_16_1, rol_didisp8_16_1, rol_bpdisp8_16_1, rol_bxdisp8_16_1
	.global ror_sidisp8_16_1, ror_didisp8_16_1, ror_bpdisp8_16_1, ror_bxdisp8_16_1
	.global rcl_sidisp8_16_1, rcl_didisp8_16_1, rcl_bpdisp8_16_1, rcl_bxdisp8_16_1
	.global rcr_sidisp8_16_1, rcr_didisp8_16_1, rcr_bpdisp8_16_1, rcr_bxdisp8_16_1
	.global shl_sidisp8_16_1, shl_didisp8_16_1, shl_bpdisp8_16_1, shl_bxdisp8_16_1
	.global shr_sidisp8_16_1, shr_didisp8_16_1, shr_bpdisp8_16_1, shr_bxdisp8_16_1
	.global sar_sidisp8_16_1, sar_didisp8_16_1, sar_bpdisp8_16_1, sar_bxdisp8_16_1
	.global rol_reg16_1_r4, rol_reg16_1_r5, rol_reg16_1_r6, rol_reg16_1_r7, rol_reg16_1_r8, rol_reg16_1_r9, rol_reg16_1_r10, rol_reg16_1_r11
	.global ror_reg16_1_r4, ror_reg16_1_r5, ror_reg16_1_r6, ror_reg16_1_r7, ror_reg16_1_r8, ror_reg16_1_r9, ror_reg16_1_r10, ror_reg16_1_r11
	.global rcl_reg16_1_r4, rcl_reg16_1_r5, rcl_reg16_1_r6, rcl_reg16_1_r7, rcl_reg16_1_r8, rcl_reg16_1_r9, rcl_reg16_1_r10, rcl_reg16_1_r11
	.global rcr_reg16_1_r4, rcr_reg16_1_r5, rcr_reg16_1_r6, rcr_reg16_1_r7, rcr_reg16_1_r8, rcr_reg16_1_r9, rcr_reg16_1_r10, rcr_reg16_1_r11
	.global shl_reg16_1_r4, shl_reg16_1_r5, shl_reg16_1_r6, shl_reg16_1_r7, shl_reg16_1_r8, shl_reg16_1_r9, shl_reg16_1_r10, shl_reg16_1_r11
	.global shr_reg16_1_r4, shr_reg16_1_r5, shr_reg16_1_r6, shr_reg16_1_r7, shr_reg16_1_r8, shr_reg16_1_r9, shr_reg16_1_r10, shr_reg16_1_r11
	.global sar_reg16_1_r4, sar_reg16_1_r5, sar_reg16_1_r6, sar_reg16_1_r7, sar_reg16_1_r8, sar_reg16_1_r9, sar_reg16_1_r10, sar_reg16_1_r11

.macro opd1common oper
	.global	\oper\()_r0_bp_16_1
\oper\()_r0_bp_16_1:				// Rotate a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	\oper\()_r0_16_1
\oper\()_r0_16_1:					// Rotate a byte at offset r0high in effective segment left by r1 value
	mem_handler_jump_r0r3 \oper\()_word_r2_1_RAM bad_EGA_opcode bad_MODEX_opcode
.endm

// ----- ROL r/m16,1 -----

	opd1common rol

rol_bxsi_16_1:
	add		r0, r7, r10
	b		rol_r0_16_1
rol_bxdi_16_1:
	add		r0, r7, r11
	b		rol_r0_16_1
rol_bpsi_16_1:
	add		r0, r9, r10
	b		rol_r0_bp_16_1
rol_bpdi_16_1:
	add		r0, r9, r11
	b		rol_r0_bp_16_1
rol_siidx_16_1:
	mov		r0, r10
	b		rol_r0_16_1
rol_diidx_16_1:
	mov		r0, r11
	b		rol_r0_16_1
rol_disp16_16_1:
	r0_from_disp16
	b		rol_r0_16_1
rol_bxidx_16_1:
	mov		r0, r7
	b		rol_r0_16_1

rol_bxsid8_16_1:
	r0_from_bxidxdisp8 r10
	b		rol_r0_16_1
rol_bxdid8_16_1:
	r0_from_bxidxdisp8 r11
	b		rol_r0_16_1
rol_bpsid8_16_1:
	r0_from_bpidxdisp8 r10
	b		rol_r0_bp_16_1
rol_bpdid8_16_1:
	r0_from_bpidxdisp8 r11
	b		rol_r0_bp_16_1
rol_sidisp8_16_1:
	r0_from_idx_disp8 r10
	b		rol_r0_16_1
rol_didisp8_16_1:
	r0_from_idx_disp8 r11
	b		rol_r0_16_1
rol_bpdisp8_16_1:
	r0_from_idx_disp8 r9
	b		rol_r0_bp_16_1
rol_bxdisp8_16_1:
	r0_from_idx_disp8 r7
	b		rol_r0_16_1

rol_bxsid16_16_1:
	r0_from_bxidxdisp16 r10
	b		rol_r0_16_1
rol_bxdid16_16_1:
	r0_from_bxidxdisp16 r11
	b		rol_r0_16_1
rol_bpsid16_16_1:
	r0_from_bpidxdisp16 r10
	b		rol_r0_bp_16_1
rol_bpdid16_16_1:
	r0_from_bpidxdisp16 r11
	b		rol_r0_bp_16_1
rol_sidisp16_16_1:
	r0_from_idx_disp16 r10
	b		rol_r0_16_1
rol_didisp16_16_1:
	r0_from_idx_disp16 r11
	b		rol_r0_16_1
rol_bpdisp16_16_1:
	r0_from_idx_disp16 r9
	b		rol_r0_bp_16_1
rol_bxdisp16_16_1:
	r0_from_idx_disp16 r7
	b		rol_r0_16_1

// ----- ROR r/m16,1 -----

	opd1common ror

ror_bxsi_16_1:
	add		r0, r7, r10
	b		ror_r0_16_1
ror_bxdi_16_1:
	add		r0, r7, r11
	b		ror_r0_16_1
ror_bpsi_16_1:
	add		r0, r9, r10
	b		ror_r0_bp_16_1
ror_bpdi_16_1:
	add		r0, r9, r11
	b		ror_r0_bp_16_1
ror_siidx_16_1:
	mov		r0, r10
	b		ror_r0_16_1
ror_diidx_16_1:
	mov		r0, r11
	b		ror_r0_16_1
ror_disp16_16_1:
	r0_from_disp16
	b		ror_r0_16_1
ror_bxidx_16_1:
	mov		r0, r7
	b		ror_r0_16_1

ror_bxsid8_16_1:
	r0_from_bxidxdisp8 r10
	b		ror_r0_16_1
ror_bxdid8_16_1:
	r0_from_bxidxdisp8 r11
	b		ror_r0_16_1
ror_bpsid8_16_1:
	r0_from_bpidxdisp8 r10
	b		ror_r0_bp_16_1
ror_bpdid8_16_1:
	r0_from_bpidxdisp8 r11
	b		ror_r0_bp_16_1
ror_sidisp8_16_1:
	r0_from_idx_disp8 r10
	b		ror_r0_16_1
ror_didisp8_16_1:
	r0_from_idx_disp8 r11
	b		ror_r0_16_1
ror_bpdisp8_16_1:
	r0_from_idx_disp8 r9
	b		ror_r0_bp_16_1
ror_bxdisp8_16_1:
	r0_from_idx_disp8 r7
	b		ror_r0_16_1

ror_bxsid16_16_1:
	r0_from_bxidxdisp16 r10
	b		ror_r0_16_1
ror_bxdid16_16_1:
	r0_from_bxidxdisp16 r11
	b		ror_r0_16_1
ror_bpsid16_16_1:
	r0_from_bpidxdisp16 r10
	b		ror_r0_bp_16_1
ror_bpdid16_16_1:
	r0_from_bpidxdisp16 r11
	b		ror_r0_bp_16_1
ror_sidisp16_16_1:
	r0_from_idx_disp16 r10
	b		ror_r0_16_1
ror_didisp16_16_1:
	r0_from_idx_disp16 r11
	b		ror_r0_16_1
ror_bpdisp16_16_1:
	r0_from_idx_disp16 r9
	b		ror_r0_bp_16_1
ror_bxdisp16_16_1:
	r0_from_idx_disp16 r7
	b		ror_r0_16_1

// ----- RCL r/m16,1 -----

	opd1common rcl

rcl_bxsi_16_1:
	add		r0, r7, r10
	b		rcl_r0_16_1
rcl_bxdi_16_1:
	add		r0, r7, r11
	b		rcl_r0_16_1
rcl_bpsi_16_1:
	add		r0, r9, r10
	b		rcl_r0_bp_16_1
rcl_bpdi_16_1:
	add		r0, r9, r11
	b		rcl_r0_bp_16_1
rcl_siidx_16_1:
	mov		r0, r10
	b		rcl_r0_16_1
rcl_diidx_16_1:
	mov		r0, r11
	b		rcl_r0_16_1
rcl_disp16_16_1:
	r0_from_disp16
	b		rcl_r0_16_1
rcl_bxidx_16_1:
	mov		r0, r7
	b		rcl_r0_16_1

rcl_bxsid8_16_1:
	r0_from_bxidxdisp8 r10
	b		rcl_r0_16_1
rcl_bxdid8_16_1:
	r0_from_bxidxdisp8 r11
	b		rcl_r0_16_1
rcl_bpsid8_16_1:
	r0_from_bpidxdisp8 r10
	b		rcl_r0_bp_16_1
rcl_bpdid8_16_1:
	r0_from_bpidxdisp8 r11
	b		rcl_r0_bp_16_1
rcl_sidisp8_16_1:
	r0_from_idx_disp8 r10
	b		rcl_r0_16_1
rcl_didisp8_16_1:
	r0_from_idx_disp8 r11
	b		rcl_r0_16_1
rcl_bpdisp8_16_1:
	r0_from_idx_disp8 r9
	b		rcl_r0_bp_16_1
rcl_bxdisp8_16_1:
	r0_from_idx_disp8 r7
	b		rcl_r0_16_1

rcl_bxsid16_16_1:
	r0_from_bxidxdisp16 r10
	b		rcl_r0_16_1
rcl_bxdid16_16_1:
	r0_from_bxidxdisp16 r11
	b		rcl_r0_16_1
rcl_bpsid16_16_1:
	r0_from_bpidxdisp16 r10
	b		rcl_r0_bp_16_1
rcl_bpdid16_16_1:
	r0_from_bpidxdisp16 r11
	b		rcl_r0_bp_16_1
rcl_sidisp16_16_1:
	r0_from_idx_disp16 r10
	b		rcl_r0_16_1
rcl_didisp16_16_1:
	r0_from_idx_disp16 r11
	b		rcl_r0_16_1
rcl_bpdisp16_16_1:
	r0_from_idx_disp16 r9
	b		rcl_r0_bp_16_1
rcl_bxdisp16_16_1:
	r0_from_idx_disp16 r7
	b		rcl_r0_16_1

// ----- RCR r/m16,1 -----

	opd1common rcr

rcr_bxsi_16_1:
	add		r0, r7, r10
	b		rcr_r0_16_1
rcr_bxdi_16_1:
	add		r0, r7, r11
	b		rcr_r0_16_1
rcr_bpsi_16_1:
	add		r0, r9, r10
	b		rcr_r0_bp_16_1
rcr_bpdi_16_1:
	add		r0, r9, r11
	b		rcr_r0_bp_16_1
rcr_siidx_16_1:
	mov		r0, r10
	b		rcr_r0_16_1
rcr_diidx_16_1:
	mov		r0, r11
	b		rcr_r0_16_1
rcr_disp16_16_1:
	r0_from_disp16
	b		rcr_r0_16_1
rcr_bxidx_16_1:
	mov		r0, r7
	b		rcr_r0_16_1

rcr_bxsid8_16_1:
	r0_from_bxidxdisp8 r10
	b		rcr_r0_16_1
rcr_bxdid8_16_1:
	r0_from_bxidxdisp8 r11
	b		rcr_r0_16_1
rcr_bpsid8_16_1:
	r0_from_bpidxdisp8 r10
	b		rcr_r0_bp_16_1
rcr_bpdid8_16_1:
	r0_from_bpidxdisp8 r11
	b		rcr_r0_bp_16_1
rcr_sidisp8_16_1:
	r0_from_idx_disp8 r10
	b		rcr_r0_16_1
rcr_didisp8_16_1:
	r0_from_idx_disp8 r11
	b		rcr_r0_16_1
rcr_bpdisp8_16_1:
	r0_from_idx_disp8 r9
	b		rcr_r0_bp_16_1
rcr_bxdisp8_16_1:
	r0_from_idx_disp8 r7
	b		rcr_r0_16_1

rcr_bxsid16_16_1:
	r0_from_bxidxdisp16 r10
	b		rcr_r0_16_1
rcr_bxdid16_16_1:
	r0_from_bxidxdisp16 r11
	b		rcr_r0_16_1
rcr_bpsid16_16_1:
	r0_from_bpidxdisp16 r10
	b		rcr_r0_bp_16_1
rcr_bpdid16_16_1:
	r0_from_bpidxdisp16 r11
	b		rcr_r0_bp_16_1
rcr_sidisp16_16_1:
	r0_from_idx_disp16 r10
	b		rcr_r0_16_1
rcr_didisp16_16_1:
	r0_from_idx_disp16 r11
	b		rcr_r0_16_1
rcr_bpdisp16_16_1:
	r0_from_idx_disp16 r9
	b		rcr_r0_bp_16_1
rcr_bxdisp16_16_1:
	r0_from_idx_disp16 r7
	b		rcr_r0_16_1

// ----- SHL r/m16,1 -----

	opd1common shl

shl_bxsi_16_1:
	add		r0, r7, r10
	b		shl_r0_16_1
shl_bxdi_16_1:
	add		r0, r7, r11
	b		shl_r0_16_1
shl_bpsi_16_1:
	add		r0, r9, r10
	b		shl_r0_bp_16_1
shl_bpdi_16_1:
	add		r0, r9, r11
	b		shl_r0_bp_16_1
shl_siidx_16_1:
	mov		r0, r10
	b		shl_r0_16_1
shl_diidx_16_1:
	mov		r0, r11
	b		shl_r0_16_1
shl_disp16_16_1:
	r0_from_disp16
	b		shl_r0_16_1
shl_bxidx_16_1:
	mov		r0, r7
	b		shl_r0_16_1

shl_bxsid8_16_1:
	r0_from_bxidxdisp8 r10
	b		shl_r0_16_1
shl_bxdid8_16_1:
	r0_from_bxidxdisp8 r11
	b		shl_r0_16_1
shl_bpsid8_16_1:
	r0_from_bpidxdisp8 r10
	b		shl_r0_bp_16_1
shl_bpdid8_16_1:
	r0_from_bpidxdisp8 r11
	b		shl_r0_bp_16_1
shl_sidisp8_16_1:
	r0_from_idx_disp8 r10
	b		shl_r0_16_1
shl_didisp8_16_1:
	r0_from_idx_disp8 r11
	b		shl_r0_16_1
shl_bpdisp8_16_1:
	r0_from_idx_disp8 r9
	b		shl_r0_bp_16_1
shl_bxdisp8_16_1:
	r0_from_idx_disp8 r7
	b		shl_r0_16_1

shl_bxsid16_16_1:
	r0_from_bxidxdisp16 r10
	b		shl_r0_16_1
shl_bxdid16_16_1:
	r0_from_bxidxdisp16 r11
	b		shl_r0_16_1
shl_bpsid16_16_1:
	r0_from_bpidxdisp16 r10
	b		shl_r0_bp_16_1
shl_bpdid16_16_1:
	r0_from_bpidxdisp16 r11
	b		shl_r0_bp_16_1
shl_sidisp16_16_1:
	r0_from_idx_disp16 r10
	b		shl_r0_16_1
shl_didisp16_16_1:
	r0_from_idx_disp16 r11
	b		shl_r0_16_1
shl_bpdisp16_16_1:
	r0_from_idx_disp16 r9
	b		shl_r0_bp_16_1
shl_bxdisp16_16_1:
	r0_from_idx_disp16 r7
	b		shl_r0_16_1

// ----- SHR r/m16,1 -----

	opd1common shr

shr_bxsi_16_1:
	add		r0, r7, r10
	b		shr_r0_16_1
shr_bxdi_16_1:
	add		r0, r7, r11
	b		shr_r0_16_1
shr_bpsi_16_1:
	add		r0, r9, r10
	b		shr_r0_bp_16_1
shr_bpdi_16_1:
	add		r0, r9, r11
	b		shr_r0_bp_16_1
shr_siidx_16_1:
	mov		r0, r10
	b		shr_r0_16_1
shr_diidx_16_1:
	mov		r0, r11
	b		shr_r0_16_1
shr_disp16_16_1:
	r0_from_disp16
	b		shr_r0_16_1
shr_bxidx_16_1:
	mov		r0, r7
	b		shr_r0_16_1

shr_bxsid8_16_1:
	r0_from_bxidxdisp8 r10
	b		shr_r0_16_1
shr_bxdid8_16_1:
	r0_from_bxidxdisp8 r11
	b		shr_r0_16_1
shr_bpsid8_16_1:
	r0_from_bpidxdisp8 r10
	b		shr_r0_bp_16_1
shr_bpdid8_16_1:
	r0_from_bpidxdisp8 r11
	b		shr_r0_bp_16_1
shr_sidisp8_16_1:
	r0_from_idx_disp8 r10
	b		shr_r0_16_1
shr_didisp8_16_1:
	r0_from_idx_disp8 r11
	b		shr_r0_16_1
shr_bpdisp8_16_1:
	r0_from_idx_disp8 r9
	b		shr_r0_bp_16_1
shr_bxdisp8_16_1:
	r0_from_idx_disp8 r7
	b		shr_r0_16_1

shr_bxsid16_16_1:
	r0_from_bxidxdisp16 r10
	b		shr_r0_16_1
shr_bxdid16_16_1:
	r0_from_bxidxdisp16 r11
	b		shr_r0_16_1
shr_bpsid16_16_1:
	r0_from_bpidxdisp16 r10
	b		shr_r0_bp_16_1
shr_bpdid16_16_1:
	r0_from_bpidxdisp16 r11
	b		shr_r0_bp_16_1
shr_sidisp16_16_1:
	r0_from_idx_disp16 r10
	b		shr_r0_16_1
shr_didisp16_16_1:
	r0_from_idx_disp16 r11
	b		shr_r0_16_1
shr_bpdisp16_16_1:
	r0_from_idx_disp16 r9
	b		shr_r0_bp_16_1
shr_bxdisp16_16_1:
	r0_from_idx_disp16 r7
	b		shr_r0_16_1
	
// ----- SAR r/m16,1 -----

	opd1common sar

sar_bxsi_16_1:
	add		r0, r7, r10
	b		sar_r0_16_1
sar_bxdi_16_1:
	add		r0, r7, r11
	b		sar_r0_16_1
sar_bpsi_16_1:
	add		r0, r9, r10
	b		sar_r0_bp_16_1
sar_bpdi_16_1:
	add		r0, r9, r11
	b		sar_r0_bp_16_1
sar_siidx_16_1:
	mov		r0, r10
	b		sar_r0_16_1
sar_diidx_16_1:
	mov		r0, r11
	b		sar_r0_16_1
sar_disp16_16_1:
	r0_from_disp16
	b		sar_r0_16_1
sar_bxidx_16_1:
	mov		r0, r7
	b		sar_r0_16_1

sar_bxsid8_16_1:
	r0_from_bxidxdisp8 r10
	b		sar_r0_16_1
sar_bxdid8_16_1:
	r0_from_bxidxdisp8 r11
	b		sar_r0_16_1
sar_bpsid8_16_1:
	r0_from_bpidxdisp8 r10
	b		sar_r0_bp_16_1
sar_bpdid8_16_1:
	r0_from_bpidxdisp8 r11
	b		sar_r0_bp_16_1
sar_sidisp8_16_1:
	r0_from_idx_disp8 r10
	b		sar_r0_16_1
sar_didisp8_16_1:
	r0_from_idx_disp8 r11
	b		sar_r0_16_1
sar_bpdisp8_16_1:
	r0_from_idx_disp8 r9
	b		sar_r0_bp_16_1
sar_bxdisp8_16_1:
	r0_from_idx_disp8 r7
	b		sar_r0_16_1

sar_bxsid16_16_1:
	r0_from_bxidxdisp16 r10
	b		sar_r0_16_1
sar_bxdid16_16_1:
	r0_from_bxidxdisp16 r11
	b		sar_r0_16_1
sar_bpsid16_16_1:
	r0_from_bpidxdisp16 r10
	b		sar_r0_bp_16_1
sar_bpdid16_16_1:
	r0_from_bpidxdisp16 r11
	b		sar_r0_bp_16_1
sar_sidisp16_16_1:
	r0_from_idx_disp16 r10
	b		sar_r0_16_1
sar_didisp16_16_1:
	r0_from_idx_disp16 r11
	b		sar_r0_16_1
sar_bpdisp16_16_1:
	r0_from_idx_disp16 r9
	b		sar_r0_bp_16_1
sar_bxdisp16_16_1:
	r0_from_idx_disp16 r7
	b		sar_r0_16_1

// ------------------- D2 = ROL/ROR/RCL/RCR/SHL/SHR/SHL/SAR r/m8,CL ---
// 
// All modrm variations supported!
// Note: The actual handlers are by op_c0
//
op_d2:
	ldrb	r0,[r12],#1							// Load next opcode byte to r1, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8
// 0 (idx only)
.macro tmp oper
	.word \oper\()_bxsi_8_CL, \oper\()_bxdi_8_CL, \oper\()_bpsi_8_CL, \oper\()_bpdi_8_CL, \oper\()_siidx_8_CL, \oper\()_diidx_8_CL, \oper\()_disp16_8_CL, \oper\()_bxidx_8_CL
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x40 (idx+disp8)
.macro tmp oper
	.word \oper\()_bxsid8_8_CL, \oper\()_bxdid8_8_CL, \oper\()_bpsid8_8_CL, \oper\()_bpdid8_8_CL, \oper\()_sidisp8_8_CL, \oper\()_didisp8_8_CL, \oper\()_bpdisp8_8_CL, \oper\()_bxdisp8_8_CL
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x80 (idx+disp16)
.macro tmp oper
	.word \oper\()_bxsid16_8_CL, \oper\()_bxdid16_8_CL, \oper\()_bpsid16_8_CL, \oper\()_bpdid16_8_CL, \oper\()_sidisp16_8_CL, \oper\()_didisp16_8_CL, \oper\()_bpdisp16_8_CL, \oper\()_bxdisp16_8_CL
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
//0xC0 = mod = 11b => two register operands
// ROL
	.word rol_al_CL, rol_cl_CL, rol_dl_CL, rol_bl_CL, rol_ah_CL, rol_ch_CL, rol_dh_CL, rol_bh_CL
// ROR	
	.word ror_al_CL, ror_cl_CL, ror_dl_CL, ror_bl_CL, ror_ah_CL, ror_ch_CL, ror_dh_CL, ror_bh_CL
// RCL	
	.word rcl_al_CL, rcl_cl_CL, rcl_dl_CL, rcl_bl_CL, rcl_ah_CL, rcl_ch_CL, rcl_dh_CL, rcl_bh_CL
// RCR
	.word rcr_al_CL, rcr_cl_CL, rcr_dl_CL, rcr_bl_CL, rcr_ah_CL, rcr_ch_CL, rcr_dh_CL, rcr_bh_CL
// SHL	
	.word shl_al_CL, shl_cl_CL, shl_dl_CL, shl_bl_CL, shl_ah_CL, shl_ch_CL, shl_dh_CL, shl_bh_CL
// SHR	
	.word shr_al_CL, shr_cl_CL, shr_dl_CL, shr_bl_CL, shr_ah_CL, shr_ch_CL, shr_dh_CL, shr_bh_CL
// SAL (never used)	
	.word shl_al_CL, shl_cl_CL, shl_dl_CL, shl_bl_CL, shl_ah_CL, shl_ch_CL, shl_dh_CL, shl_bh_CL
// SAR	
	.word sar_al_CL, sar_cl_CL, sar_dl_CL, sar_bl_CL, sar_ah_CL, sar_ch_CL, sar_dh_CL, sar_bh_CL


.macro opd2genall oper
\oper\()_bxsi_8_CL:
	add		r0, ebx, esi
	b		\oper\()_t0_8_CL
\oper\()_bxdi_8_CL:
	add		r0, ebx, edi
	b		\oper\()_t0_8_CL
\oper\()_bpsi_8_CL:
	add		r0, ebp, esi
	b		\oper\()_t0_bp_8_CL
\oper\()_bpdi_8_CL:
	add		r0, ebp, edi
	b		\oper\()_t0_bp_8_CL
	.global	\oper\()_siidx_8_CL
\oper\()_siidx_8_CL:
	mov		r0, esi
	b		\oper\()_t0_8_CL
	.global	\oper\()_diidx_8_CL
\oper\()_diidx_8_CL:
	mov		r0, edi
	b		\oper\()_t0_8_CL
\oper\()_disp16_8_CL:
	r0_from_disp16
	b		\oper\()_t0_8_CL
	.global	\oper\()_bxidx_8_CL
\oper\()_bxidx_8_CL:
	mov		r0, ebx
	b		\oper\()_t0_8_CL
\oper\()_bxsid8_8_CL:
	r0_from_bxidxdisp8 esi
	b		\oper\()_t0_8_CL
\oper\()_bxdid8_8_CL:
	r0_from_bxidxdisp8 edi
	b		\oper\()_t0_8_CL
\oper\()_bpsid8_8_CL:
	r0_from_bpidxdisp8 esi
	b		\oper\()_t0_bp_8_CL
\oper\()_bpdid8_8_CL:
	r0_from_bpidxdisp8 edi
	b		\oper\()_t0_bp_8_CL
	.global	\oper\()_sidisp8_8_CL
\oper\()_sidisp8_8_CL:
	r0_from_idx_disp8 esi
	b		\oper\()_t0_8_CL
	.global	\oper\()_didisp8_8_CL
\oper\()_didisp8_8_CL:
	r0_from_idx_disp8 edi
	b		\oper\()_t0_8_CL
	.global	\oper\()_bpdisp8_8_CL
\oper\()_bpdisp8_8_CL:
	r0_from_idx_disp8 ebp
	b		\oper\()_t0_bp_8_CL
	.global	\oper\()_bxdisp8_8_CL
\oper\()_bxdisp8_8_CL:
	r0_from_idx_disp8 ebx
	b		\oper\()_t0_8_CL
\oper\()_bxsid16_8_CL:
	r0_from_bxidxdisp16 esi
	b		\oper\()_t0_8_CL
\oper\()_bxdid16_8_CL:
	r0_from_bxidxdisp16 edi
	b		\oper\()_t0_8_CL
\oper\()_bpsid16_8_CL:
	r0_from_bpidxdisp16 esi
	b		\oper\()_t0_bp_8_CL
\oper\()_bpdid16_8_CL:
	r0_from_bpidxdisp16 edi
	b		\oper\()_t0_bp_8_CL
\oper\()_sidisp16_8_CL:
	r0_from_idx_disp16 esi
	b		\oper\()_t0_8_CL
\oper\()_didisp16_8_CL:
	r0_from_idx_disp16 edi
	b		\oper\()_t0_8_CL
\oper\()_bpdisp16_8_CL:
	r0_from_idx_disp16 ebp
	b		\oper\()_t0_bp_8_CL
\oper\()_bxdisp16_8_CL:
	r0_from_idx_disp16 ebx
	b		\oper\()_t0_8_CL
.endm

	opd2genall rol
	opd2genall ror
	opd2genall rcl
	opd2genall rcr
	opd2genall shl
	opd2genall shr
	opd2genall sar

.macro opd2common oper
	.global	\oper\()_t0_bp_8_CL
\oper\()_t0_bp_8_CL:
	mem_handler_bp
	.global	\oper\()_t0_8_CL
\oper\()_t0_8_CL:
	mem_handler_jump_r0r3 2f bad_EGA_opcode bad_MODEX_opcode
2:	and		r1, ecx, #31						// Mask the rotation count
	b		\oper\()_byte_r2_r1					// Jump to a common handler with "op_c0"
.endm

	opd2common rol
	opd2common ror
	opd2common rcl
	opd2common rcr
	opd2common shl
	opd2common shr
	opd2common sar

	.global rol_al_CL, rol_cl_CL, rol_dl_CL, rol_bl_CL, rol_ah_CL, rol_ch_CL, rol_dh_CL, rol_bh_CL
	.global ror_al_CL, ror_cl_CL, ror_dl_CL, ror_bl_CL, ror_ah_CL, ror_ch_CL, ror_dh_CL, ror_bh_CL
	.global rcl_al_CL, rcl_cl_CL, rcl_dl_CL, rcl_bl_CL, rcl_ah_CL, rcl_ch_CL, rcl_dh_CL, rcl_bh_CL
	.global rcr_al_CL, rcr_cl_CL, rcr_dl_CL, rcr_bl_CL, rcr_ah_CL, rcr_ch_CL, rcr_dh_CL, rcr_bh_CL
	.global shl_al_CL, shl_cl_CL, shl_dl_CL, shl_bl_CL, shl_ah_CL, shl_ch_CL, shl_dh_CL, shl_bh_CL
	.global shr_al_CL, shr_cl_CL, shr_dl_CL, shr_bl_CL, shr_ah_CL, shr_ch_CL, shr_dh_CL, shr_bh_CL
	.global sar_al_CL, sar_cl_CL, sar_dl_CL, sar_bl_CL, sar_ah_CL, sar_ch_CL, sar_dh_CL, sar_bh_CL

.macro opd2reg8l_CL oper reg
	and		r1, ecx, #31
	b	\oper\()_r8l_r1_\reg	
.endm
.macro opd2reg8h_CL oper reg
	and		r1, ecx, #31
	b	\oper\()_r8h_r1_\reg	
.endm
	
rol_al_CL:
	opd2reg8l_CL rol eax
rol_cl_CL:
	opd2reg8l_CL rol ecx
rol_dl_CL:
	opd2reg8l_CL rol edx
rol_bl_CL:
	opd2reg8l_CL rol ebx
rol_ah_CL:
	opd2reg8h_CL rol eax
rol_ch_CL:
	opd2reg8h_CL rol ecx
rol_dh_CL:
	opd2reg8h_CL rol edx
rol_bh_CL:
	opd2reg8h_CL rol ebx
	
ror_al_CL:
	opd2reg8l_CL ror eax
ror_cl_CL:
	opd2reg8l_CL ror ecx
ror_dl_CL:
	opd2reg8l_CL ror edx
ror_bl_CL:
	opd2reg8l_CL ror ebx
ror_ah_CL:
	opd2reg8h_CL ror eax
ror_ch_CL:
	opd2reg8h_CL ror ecx
ror_dh_CL:
	opd2reg8h_CL ror edx
ror_bh_CL:
	opd2reg8h_CL ror ebx

rcl_al_CL:
	opd2reg8l_CL rcl eax
rcl_cl_CL:
	opd2reg8l_CL rcl ecx
rcl_dl_CL:
	opd2reg8l_CL rcl edx
rcl_bl_CL:
	opd2reg8l_CL rcl ebx
rcl_ah_CL:
	opd2reg8h_CL rcl eax
rcl_ch_CL:
	opd2reg8h_CL rcl ecx
rcl_dh_CL:
	opd2reg8h_CL rcl edx
rcl_bh_CL:
	opd2reg8h_CL rcl ebx
	
rcr_al_CL:
	opd2reg8l_CL rcr eax
rcr_cl_CL:
	opd2reg8l_CL rcr ecx
rcr_dl_CL:
	opd2reg8l_CL rcr edx
rcr_bl_CL:
	opd2reg8l_CL rcr ebx
rcr_ah_CL:
	opd2reg8h_CL rcr eax
rcr_ch_CL:
	opd2reg8h_CL rcr ecx
rcr_dh_CL:
	opd2reg8h_CL rcr edx
rcr_bh_CL:
	opd2reg8h_CL rcr ebx
	
shl_al_CL:
	opd2reg8l_CL shl eax
shl_cl_CL:
	opd2reg8l_CL shl ecx
shl_dl_CL:
	opd2reg8l_CL shl edx
shl_bl_CL:
	opd2reg8l_CL shl ebx
shl_ah_CL:
	opd2reg8h_CL shl eax
shl_ch_CL:
	opd2reg8h_CL shl ecx
shl_dh_CL:
	opd2reg8h_CL shl edx
shl_bh_CL:
	opd2reg8h_CL shl ebx
	
shr_al_CL:
	opd2reg8l_CL shr eax
shr_cl_CL:
	opd2reg8l_CL shr ecx
shr_dl_CL:
	opd2reg8l_CL shr edx
shr_bl_CL:
	opd2reg8l_CL shr ebx
shr_ah_CL:
	opd2reg8h_CL shr eax
shr_ch_CL:
	opd2reg8h_CL shr ecx
shr_dh_CL:
	opd2reg8h_CL shr edx
shr_bh_CL:
	opd2reg8h_CL shr ebx

sar_al_CL:
	opd2reg8l_CL sar eax
sar_cl_CL:
	opd2reg8l_CL sar ecx
sar_dl_CL:
	opd2reg8l_CL sar edx
sar_bl_CL:
	opd2reg8l_CL sar ebx
sar_ah_CL:
	opd2reg8h_CL sar eax
sar_ch_CL:
	opd2reg8h_CL sar ecx
sar_dh_CL:
	opd2reg8h_CL sar edx
sar_bh_CL:
	opd2reg8h_CL sar ebx
	
// ------------------- D3 = ROL/ROR/RCL/RCR/SHL/SHR/SHL/SAR r/m16,CL ---
// 
// All modrm variations supported!
//
// We must also setup the flags!
// - RCL/RCR/ROL/ROR only change the carry flag
// - SHL/SHR/SHL/SAR change carry, sign and zero flags (ARM behaves exactly like 8086)
//
// We can use the same handlers as opcode C1, but only if the handlers do not need to
// load additional immediate bytes!
//
op_d3:
	ldrb	r0,[r12],#1							// Load next opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8
// 0 (idx only)
.macro tmp oper
	.global \oper\()_siidx_16_CL, \oper\()_diidx_16_CL, \oper\()_disp16_16_CL, \oper\()_bxidx_16_CL
	.word \oper\()_bxsi_16_CL, \oper\()_bxdi_16_CL, \oper\()_bpsi_16_CL, \oper\()_bpdi_16_CL, \oper\()_siidx_16_CL, \oper\()_diidx_16_CL, \oper\()_disp16_16_CL, \oper\()_bxidx_16_CL
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x40 (idx+disp8)
.macro tmp oper
	.global \oper\()_sidisp8_16_CL, \oper\()_didisp8_16_CL, \oper\()_bpdisp8_16_CL, \oper\()_bxdisp8_16_CL
	.word \oper\()_bxsid8_16_CL, \oper\()_bxdid8_16_CL, \oper\()_bpsid8_16_CL, \oper\()_bpdid8_16_CL, \oper\()_sidisp8_16_CL, \oper\()_didisp8_16_CL, \oper\()_bpdisp8_16_CL, \oper\()_bxdisp8_16_CL
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
// 0x80 (idx+disp16)
.macro tmp oper
	.word \oper\()_bxsid16_16_CL, \oper\()_bxdid16_16_CL, \oper\()_bpsid16_16_CL, \oper\()_bpdid16_16_CL, \oper\()_sidisp16_16_CL, \oper\()_didisp16_16_CL, \oper\()_bpdisp16_16_CL, \oper\()_bxdisp16_16_CL
.endm
tmp rol
tmp ror
tmp rcl
tmp rcr
tmp shl
tmp shr
tmp shl
tmp sar
.purgem tmp	
//0xC0 = mod = 11b => two register operands
	.word rol_ax_CL, rol_cx_CL, rol_dx_CL, rol_bx_CL, rol_sp_CL, rol_bp_CL, rol_si_CL, rol_di_CL
	.word ror_ax_CL, ror_cx_CL, ror_dx_CL, ror_bx_CL, ror_sp_CL, ror_bp_CL, ror_si_CL, ror_di_CL
	.word rcl_ax_CL, rcl_cx_CL, rcl_dx_CL, rcl_bx_CL, rcl_sp_CL, rcl_bp_CL, rcl_si_CL, rcl_di_CL
	.word rcr_ax_CL, rcr_cx_CL, rcr_dx_CL, rcr_bx_CL, rcr_sp_CL, rcr_bp_CL, rcr_si_CL, rcr_di_CL
	.word shl_ax_CL, shl_cx_CL, shl_dx_CL, shl_bx_CL, shl_sp_CL, shl_bp_CL, shl_si_CL, shl_di_CL
	.word shr_ax_CL, shr_cx_CL, shr_dx_CL, shr_bx_CL, shr_sp_CL, shr_bp_CL, shr_si_CL, shr_di_CL
	.word shl_ax_CL, shl_cx_CL, shl_dx_CL, shl_bx_CL, shl_sp_CL, shl_bp_CL, shl_si_CL, shl_di_CL
	.word sar_ax_CL, sar_cx_CL, sar_dx_CL, sar_bx_CL, sar_sp_CL, sar_bp_CL, sar_si_CL, sar_di_CL

	.global rol_ax_CL, rol_cx_CL, rol_dx_CL, rol_bx_CL, rol_sp_CL, rol_bp_CL, rol_si_CL, rol_di_CL
	.global ror_ax_CL, ror_cx_CL, ror_dx_CL, ror_bx_CL, ror_sp_CL, ror_bp_CL, ror_si_CL, ror_di_CL
	.global rcl_ax_CL, rcl_cx_CL, rcl_dx_CL, rcl_bx_CL, rcl_sp_CL, rcl_bp_CL, rcl_si_CL, rcl_di_CL
	.global rcr_ax_CL, rcr_cx_CL, rcr_dx_CL, rcr_bx_CL, rcr_sp_CL, rcr_bp_CL, rcr_si_CL, rcr_di_CL
	.global shl_ax_CL, shl_cx_CL, shl_dx_CL, shl_bx_CL, shl_sp_CL, shl_bp_CL, shl_si_CL, shl_di_CL
	.global shr_ax_CL, shr_cx_CL, shr_dx_CL, shr_bx_CL, shr_sp_CL, shr_bp_CL, shr_si_CL, shr_di_CL
	.global sar_ax_CL, sar_cx_CL, sar_dx_CL, sar_bx_CL, sar_sp_CL, sar_bp_CL, sar_si_CL, sar_di_CL

.macro opd3common oper
	.global	\oper\()_r0_bp_16_CL
\oper\()_r0_bp_16_CL:				// Shift a byte when r0high offset is based on BP index
	mem_handler_bp
	.global	\oper\()_r0_16_CL
\oper\()_r0_16_CL:					// Shift a byte at offset r0high in effective segment right by r1 value
	and		r1, ecx, #31		// r1 = CL value to shift/rotate with
	mem_handler_jump_r0r3 \oper\()_word_r2_r1_RAM bad_EGA_opcode bad_MODEX_opcode
.endm

.macro opd3genall oper
\oper\()_bxsi_16_CL:
	add		r0, r7, r10
	b		\oper\()_r0_16_CL
\oper\()_bxdi_16_CL:
	add		r0, r7, r11
	b		\oper\()_r0_16_CL
\oper\()_bpsi_16_CL:
	add		r0, r9, r10
	b		\oper\()_r0_bp_16_CL
\oper\()_bpdi_16_CL:
	add		r0, r9, r11
	b		\oper\()_r0_bp_16_CL
\oper\()_siidx_16_CL:
	mov		r0, r10
	b		\oper\()_r0_16_CL
\oper\()_diidx_16_CL:
	mov		r0, r11
	b		\oper\()_r0_16_CL
\oper\()_disp16_16_CL:
	r0_from_disp16
	b		\oper\()_r0_16_CL
\oper\()_bxidx_16_CL:
	mov		r0, r7
	b		\oper\()_r0_16_CL
\oper\()_bxsid8_16_CL:
	r0_from_bxidxdisp8 r10
	b		\oper\()_r0_16_CL
\oper\()_bxdid8_16_CL:
	r0_from_bxidxdisp8 r11
	b		\oper\()_r0_16_CL
\oper\()_bpsid8_16_CL:
	r0_from_bpidxdisp8 r10
	b		\oper\()_r0_bp_16_CL
\oper\()_bpdid8_16_CL:
	r0_from_bpidxdisp8 r11
	b		\oper\()_r0_bp_16_CL
\oper\()_sidisp8_16_CL:
	r0_from_idx_disp8 r10
	b		\oper\()_r0_16_CL
\oper\()_didisp8_16_CL:
	r0_from_idx_disp8 r11
	b		\oper\()_r0_16_CL
\oper\()_bpdisp8_16_CL:
	r0_from_idx_disp8 r9
	b		\oper\()_r0_bp_16_CL
\oper\()_bxdisp8_16_CL:
	r0_from_idx_disp8 r7
	b		\oper\()_r0_16_CL
\oper\()_bxsid16_16_CL:
	r0_from_bxidxdisp16 r10
	b		\oper\()_r0_16_CL
\oper\()_bxdid16_16_CL:
	r0_from_bxidxdisp16 r11
	b		\oper\()_r0_16_CL
\oper\()_bpsid16_16_CL:
	r0_from_bpidxdisp16 r10
	b		\oper\()_r0_bp_16_CL
\oper\()_bpdid16_16_CL:
	r0_from_bpidxdisp16 r11
	b		\oper\()_r0_bp_16_CL
\oper\()_sidisp16_16_CL:
	r0_from_idx_disp16 r10
	b		\oper\()_r0_16_CL
\oper\()_didisp16_16_CL:
	r0_from_idx_disp16 r11
	b		\oper\()_r0_16_CL
\oper\()_bpdisp16_16_CL:
	r0_from_idx_disp16 r9
	b		\oper\()_r0_bp_16_CL
\oper\()_bxdisp16_16_CL:
	r0_from_idx_disp16 r7
	b		\oper\()_r0_16_CL
.endm


// ----- ROL -----

	opd3common	rol
	opd3genall	rol

rol_ax_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r4
rol_cx_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r5
rol_dx_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r6
rol_bx_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r7
rol_sp_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r8
rol_bp_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r9
rol_si_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r10
rol_di_CL:
	and		r1, ecx, #31
	b		rol_reg16_r1_r11
	
// ----- ROR -----

	opd3common	ror
	opd3genall	ror

ror_ax_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r4
ror_cx_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r5
ror_dx_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r6
ror_bx_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r7
ror_sp_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r8
ror_bp_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r9
ror_si_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r10
ror_di_CL:
	and		r1, ecx, #31
	b		ror_reg16_r1_r11

// ----- RCL -----

	opd3common	rcl
	opd3genall	rcl

rcl_ax_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r4
rcl_cx_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r5
rcl_dx_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r6
rcl_bx_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r7
rcl_sp_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r8
rcl_bp_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r9
rcl_si_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r10
rcl_di_CL:
	and		r1, ecx, #31
	b		rcl_reg16_r1_r11

// ----- RCR -----

	opd3common	rcr
	opd3genall	rcr

rcr_ax_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r4
rcr_cx_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r5
rcr_dx_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r6
rcr_bx_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r7
rcr_sp_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r8
rcr_bp_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r9
rcr_si_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r10
rcr_di_CL:
	and		r1, ecx, #31
	b		rcr_reg16_r1_r11

// ----- SHL -----

	opd3common	shl
	opd3genall	shl

shl_ax_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r4
shl_cx_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r5
shl_dx_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r6
shl_bx_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r7
shl_sp_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r8
shl_bp_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r9
shl_si_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r10
shl_di_CL:
	and		r1, ecx, #31
	b		shl_reg16_r1_r11

// ----- SHR -----

	opd3common	shr
	opd3genall	shr

shr_ax_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r4
shr_cx_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r5
shr_dx_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r6
shr_bx_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r7
shr_sp_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r8
shr_bp_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r9
shr_si_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r10
shr_di_CL:
	and		r1, ecx, #31
	b		shr_reg16_r1_r11

// ----- SAR -----

	opd3common	sar
	opd3genall	sar

sar_ax_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r4
sar_cx_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r5
sar_dx_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r6
sar_bx_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r7
sar_sp_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r8
sar_bp_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r9
sar_si_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r10
sar_di_CL:
	and		r1, ecx, #31
	b		sar_reg16_r1_r11


// ------------------- D4 = AAM ----------------------------------------
// AAM divides AL by 10 (imm8), leaving the quotient in AH and remainder in AL
//
op_d4:
	ldrb	r2,[r12],#1				// Get the divider (usually 0x0A = 10)
	//-------
	// Same code as in div_reg8_by_r2
	//-------
#if SOFTWARE_DIV
	//-------
	// Software division routine. Algorithm taken from
	// "http://www.peter-cockerell.net/aalp/html/ch-6.html"
	// 	r0 = div (result)
	// 	r1 = mod (result)
	// 	r2 = rhs
	// 	r3 = lhs
	//	r4 = count
	//-------
	teq  	r2, #0    				// Trap div by zero
	beq		.div8_by_zero			// division by zero!!
	push	{r4}
	movs	r3, eax, lsl #24
	mov  	r1, #0    				// Init remainder
	mov  	r0, #0    				// and result
	mov  	r4, #8    				// Set up count
	bmi		2f						// Skip first loop if highest bit of r3 set
1:	subs 	r4, r4, #1  			// Get first 1 bit of lhs
	beq		3f    					// into bit 31. Return if 0
	movs 	r3, r3, ASL #1
	bpl  	1b
2:	movs 	r3, r3, ASL #1  		// Get next bit into...
	adc  	r1, r1, r1   			// r1 for trial subtract
	cmp  	r1, r2    				// Can we subtract?
	subcs 	r1, r1, r2   			// Yes, so do
	adc  	r0, r0, r0   			// Shift carry into result
	subs 	r4, r4, #1  			// Next loop
	bne  	2b
3:	pop		{r4}
	lsr		eax, #16
	orr		eax, r1, eax, lsl #16	// AL = remainder
	orr		eax, r0, lsl #8			// AH = result
	b		loop					// Go back to loop
#else
	mov		r0, #0x280
	orr		r0, #0x04000000			// #define REG_DIVCNT			(*(vu16*)(0x04000280))
	cmp		r2, #0
	beq		.div8_by_zero			// Division by zero!! (See F7 opcode handler)
	mov		r1, #0
	strh	r1, [r0]				// REG_DIVCNT = DIV_32_32 = 0
	and		r1, eax, #0xFF			// r1 = AL value
	str		r1, [r0, #0x10]			// #define REG_DIV_NUMER_L		(*(vs32*) (0x04000290)),	REG_DIV_NUMER_L = num
	str		r2, [r0, #0x18]			// #define REG_DIV_DENOM_L		(*(vs32*) (0x04000298)),	REG_DIV_DENOM_L = den
1:	ldrh	r1, [r0]				// while(REG_DIVCNT & DIV_BUSY)
	tst		r1, #0x8000
	bne		1b
	ldr		r2,[r0, #0x20]			// #define REG_DIV_RESULT_L		(*(vs32*) (0x040002A0)),	r4 (AL) is the result of the division
	cmp		r2, #0x100
	bhs		.div8_by_zero			// If result is >= 256, divide overflow! (See F7 opcode handler)
	ldr		r1,[r0, #0x28]			// #define REG_DIVREM_RESULT_L	(*(vs32*) (0x040002A8)),	r1 (AH) is the remainder of the division
	mov		r0, eax, lsl #16
	eor		eax, r0, lsr #16
	and		r2, #0xFF
	orr		eax, r2, lsl #8			// AH = quotient
	and		r1, #0xFF
	orr		eax, r1					// AL = remainder
	b		loop
#endif

// ------------------- D5 = AAD ----------------------------------------
// AAD calculates AL = AL + AH * 10 (imm8), AH = 0
// Sign and Zero flags are set from result, FLAG_CF, FLAG_OF and FLAG_AF are cleared.
//
op_d5:
	ldrb	r2,[r12],#1				// Get the multiplier (usually 0x0A = 10)
	mov		r0, eax, lsl #16
	mov		r3, eax, lsl #24		// r3 = AL in highest byte
	eor		eax, r0, lsr #16		// Clean AX
	lsr		r0, #24					// r0 = AH
	mul		r1, r0, r2				// r1 = AH * imm8 value
	adds	r3, r1, lsl #24			// r3 = AL + AH * imm8 in highest byte, flags set as per result
	ldr		r0,[sp, #SP_FLAGS]		// Get the EXTRAFLAGS value
	orr		eax, r3, lsr #24		// AL = AL + AH*imm8, AH = 0
	bic		r0, #FLAG_AF
	str		r0,[sp, #SP_FLAGS]		// Save the new extra flags
	mov		r0, #0
	tst		eax, #0xFF
	orreq	r0, #ARM_ZERO
	tst		eax, #0x80
	orrne	r0, #ARM_NEG
	b		restore_flags_from_r0

// ------------------- D6 = SETALC (undocumented) ----------------------
// If Carry Then AL=0xFF Else AL=00
//
// DSx86: Interrupt call if CS:IP between F000:0000 and F000:0200
//
op_d6:
#if !EXTERNAL_TLB
	ldr		r3, =BIOS_F000
	ldr		r3, [r3]				// r3 = address of BIOS_F000
	mrs		r0, cpsr				// Save current flags to r0
	subs	r3, r12, r3
	ble		1f
	//=======
	// Call our generic interrupt handler, r3 = interrupt number + 1
	//=======
	sub		r3, #1					// r3 = interrupt number to call
	//-------
	// Perform an IRET first, so that the IRQ handler will return to the correct place.
	//-------
	pop_reg_low_tmp r12 r0			// Get new logical IP (zero-extended) to r12
	pop_reg_low_tmp r2 r0			// Get new logical CS (zero-extended) to r2
	str		r2, [sp, #SP_CS_VALUE]
	lsl		r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_CS_BASE]
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_CS]
	add		r12, r2
	pop_reg_low_tmp	r1 r0						// r1 = new flags
	//-------
	// Fix the extra flags, as starting an interrupt has cleared the interrupt flag.
	//-------
	ldr		r2, =FMASK_ALL						// r2 = mask of the flag bits we can change
	ldr		r0, [sp, #SP_FLAGS]					// Get the #SP_FLAGS
	and		r1, r2								// Leave only the bits we can change to r1
	bic		r0, r2								// r0 = flags bits that will not change
	orr		r1, r0
	//-------
	// Save registers to memory
	//-------
	ldr		r2,=registers
	stmia	r2!,{r4-r12}						// Save emulation registers to global memory
	str		r1, [r2], #4						// Save flags to global memory
	//-------
	// Save the logical segment registers (ES, CS, SS, DS, FS, GS)
	//-------
	add		r1, sp, #SP_ES_VALUE
	ldmia	r1, {r4-r9}							// ES, CS, SS, DS, FS, GS values
	stmia	r2, {r4-r9}							// Save to REG_ES .. REG_GS to global memory
	//-------
	// Call the INT handler, r0 = interrupt number
	//-------
	mov		r0, r3
	bl		INTHandler							// Call the external INT handler function, parameter r0 = interrupt number, return whether we can continue
	mov		r10, r0								// r10 = INTHandler return value
	//-------
	// Setup (possibly changed) segment registers
	//-------
	ldr		r1, REG_ES
	add		r2, sp, #SP_ES_VALUE
	ldmia	r1, {r4-r9}							// ES, CS, SS, DS, FS, GS values
	stmia	r2, {r4-r9}							// Save the segment register values to stack
	add		r2, #(SP_ES_BASE - SP_ES_VALUE)
	mov		r4, r4, lsl #REAL_SEGMENT_SHIFT
	mov		r5, r5, lsl #REAL_SEGMENT_SHIFT
	mov		r6, r6, lsl #REAL_SEGMENT_SHIFT
	mov		r7, r7, lsl #REAL_SEGMENT_SHIFT
	mov		r8, r8, lsl #REAL_SEGMENT_SHIFT
	mov		r9, r9, lsl #REAL_SEGMENT_SHIFT
	stmia	r2, {r4-r9}							// Save the segment register base values to stack
#if LDMIA_LOOP
	str		r6, [sp, #SP_SS_BASE]				// SP_SS_BASE
	str		r7, [sp, #SP_DS_BASE]				// SP_DS_BASE
#endif
	ldr		r2,[sp, #SP_CS_BASE]
	calc_linear_address_r2
	str		r2,[sp, #SP_PHYS_CS]				// Store new physical CS into stack
	ldr		r2,[sp, #SP_SS_BASE]
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_SS]
	//-------
	// Load the (possibly changed) registers
	//-------
	ldr		r1,=registers
	mov		r0, r10								// r0 = INTHandler return value
	ldmia	r1!,{r4-r12}						// Load emulation registers from global memory
	//-------
	// Restore flags and continue running
	//-------
	cmp		r0, #0								// Did the INTHandler return 0?
	ldr		r0, [r1]							// Get the flags from global memory
	ldr		r1, [sp, #SP_FLAGS]					// Get the old flags
	str		r0, [sp, #SP_FLAGS]					// Save the new flags
	beq		iret_cont_flags_old_r1_new_r0		// INTHandler returned 0, we can continue running. Go setup proper flags.

	//-------
	// Unsupported INT call, break into debugger
	//-------
	ldr		r2, =BreakReason					// Check if the INT handler has already set a break reason...
	ldr		r1, [r2]
	cmp		r1, #0
	ldreq	r1, =BRUnsINT						// ... tell "Unsupported INT call" if not, ...
	streq	r1, [r2]
	popped_flags_to_ARM r0						// ... set the processor flags, ...
	msr		cpsr_f,r0
	b		debug_trap_false					// ... stop running and go to the debugger.
#endif
	//=======
	// Perform SETALC
	//=======
1:	tst		r0, #ARM_CARRY
	biceq	eax, #0xFF
	orrne	eax, #0xFF
	b		restore_flags_from_r0

	.ltorg
	
// ------------------- D7 = XLAT ---------------------------------------
// AL = [BX + unsigned AL]
//
op_d7:
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	and		r0, eax, #0xFF						// r0 = unsigned AL
	add		r0, ebx								// r0 = BX + (unsigned)AL
	mem_handler_jump_r0r3 op_d7_RAM .unknown .unknown

	.global	op_d7_RAM
op_d7_RAM:
	ldrb	r0,[r2]
	bic		eax, #0xFF
	orr		eax, r0								// AL = byte at [BX + unsigned AL]
	b		loop


// ------------------- D8 .. DF = FPU ESC opcodes ---------------------
// Math coprocessor opcode, unsupported!
// DBE3				finit
// D93F				fstcw [bx] (Comptest, Turbo Pascal 7)
// DD7EFE			fstsw [bp-02] (Warcraft 2, Settlers, Game, Abuse, RAP)
//
op_db:
	mrs		r0, cpsr				// Save current flags to r0
	ldrb	r1, [r12]				// Get the modrm byte
	cmp		r1, #0xE3				// Is it 0xE3 == finit?
	bne		1f
	msr		cpsr_f, r0
	add		r12, #1
	b		loop					// in "fpu.S"
1:	msr		cpsr_f, r0

op_d8:
op_da:
op_dc:
op_de:
op_df:
	//------
	// Show a warning message, if this is the first time we encounter FPU opcodes in this game.
	//------
//	sw		sp, NeedFPUWarn
op_d9:											// Skip warning message, could be fstcw
op_dd:											// Skip warning message, could be fstsw
	modrm_jump_16
// 0
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
	.word fpu_bxsi, fpu_bxdi, fpu_bpsi, fpu_bpdi, fpu_siidx_, fpu_diidx_, fpu_disp16, fpu_bxidx_
// 0x40
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
	.word fpu_bxsid8, fpu_bxdid8, fpu_bpsid8, fpu_bpdid8, fpu_sidisp8_, fpu_didisp8_, fpu_bpdisp8_, fpu_bxdisp8_
// 0x80
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
	.word fpu_bxsid16, fpu_bxdid16, fpu_bpsid16, fpu_bpdid16, fpu_sidisp16, fpu_didisp16, fpu_bpdisp16, fpu_bxdisp16
// 0xC0
	.word loop, loop, loop, loop, loop, loop, loop, loop
	.word loop, loop, loop, loop, loop, loop, loop, loop
	.word loop, loop, loop, loop, loop, loop, loop, loop
	.word loop, loop, loop, loop, loop, loop, loop, loop
	.word loop, loop, loop, loop, loop, loop, loop, loop
	.word loop, loop, loop, loop, loop, loop, loop, loop
	.word loop, loop, loop, loop, loop, loop, loop, loop
	.word loop, loop, loop, loop, loop, loop, loop, loop

	.global	fpu_r0_bp_
fpu_r0_bp_:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	fpu_r0_
fpu_r0_:
	//------
	// Test if we possibly need to give a warning message.
	//------
//	lw		t0, NeedFPUWarn
//	bnez	t0, 1f
	//-------
	// Ignore = go back to loop.
	//-------
	b		loop						// Back to loop
	

// -- fpu [idx] --

fpu_bxsi:
	add		r0, r7, r10
	b		fpu_r0_
fpu_bxdi:
	add		r0, r7, r11
	b		fpu_r0_
fpu_bpsi:
	add		r0, r9, r10
	b		fpu_r0_bp_
fpu_bpdi:
	add		r0, r9, r11
	b		fpu_r0_bp_
	.global	fpu_siidx_
fpu_siidx_:
	mov		r0, r10
	b		fpu_r0_
	.global	fpu_diidx_
fpu_diidx_:
	mov		r0, r11
	b		fpu_r0_
fpu_disp16:
	r0_from_disp16
	b		fpu_r0_
	.global	fpu_bxidx_
fpu_bxidx_:
	mov		r0, r7
	b		fpu_r0_

// -- fpu [idx+disp8] --

fpu_bxsid8:
	r0_from_bxidxdisp8 r10
	b		fpu_r0_
fpu_bxdid8:
	r0_from_bxidxdisp8 r11
	b		fpu_r0_
fpu_bpsid8:
	r0_from_bpidxdisp8 r10
	b		fpu_r0_bp_
fpu_bpdid8:
	r0_from_bpidxdisp8 r11
	b		fpu_r0_bp_
	.global	fpu_sidisp8_
fpu_sidisp8_:
	r0_from_idx_disp8 r10
	b		fpu_r0_
	.global	fpu_didisp8_
fpu_didisp8_:
	r0_from_idx_disp8 r11
	b		fpu_r0_
	.global	fpu_bpdisp8_
fpu_bpdisp8_:
	r0_from_idx_disp8 r9
	b		fpu_r0_bp_
	.global	fpu_bxdisp8_
fpu_bxdisp8_:
	r0_from_idx_disp8 r7
	b		fpu_r0_

// -- fpu [idx+disp16] --

fpu_bxsid16:
	r0_from_bxidxdisp16 r10
	b		fpu_r0_
fpu_bxdid16:
	r0_from_bxidxdisp16 r11
	b		fpu_r0_
fpu_bpsid16:
	r0_from_bpidxdisp16  r10
	b		fpu_r0_bp_
fpu_bpdid16:
	r0_from_bpidxdisp16 r11
	b		fpu_r0_bp_
fpu_sidisp16:
	r0_from_idx_disp16 r10
	b		fpu_r0_
fpu_didisp16:
	r0_from_idx_disp16 r11
	b		fpu_r0_
fpu_bpdisp16:
	r0_from_idx_disp16 r9
	b		fpu_r0_bp_
fpu_bxdisp16:
	r0_from_idx_disp16 r7
	b		fpu_r0_

	
// ------------------- E0 = LOOPNE/LOOPNZ ------------------------------
// We are not allowed to change any flags here!
//
op_e0:
	mrs		r0, cpsr				// Save current flags to r0
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	mov		r2, ecx, lsl #16
	eor		ecx, r2, lsr #16
	sub		r2, #0x00010000			// Decrement CX
	orr		ecx, r2, lsr #16
	tst		r0, #0x40000000			// Is the Zero flag set?
	bne		restore_flags_from_r0	// If Zero flag is set, do not take the jump.
	cmp		r2, #0					// Is CX zero?
	addne	r12, r12, r1			// Adjust program counter by the jump amount, if CX != 0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

// ------------------- E1 = LOOPE/LOOPZ --------------------------------
// We are not allowed to change any flags here!
//
op_e1:
	mrs		r0, cpsr				// Save current flags to r0
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	mov		r2, ecx, lsl #16
	eor		ecx, r2, lsr #16
	sub		r2, #0x00010000			// Decrement CX
	orr		ecx, r2, lsr #16
	tst		r0, #0x40000000			// Is the Zero flag set?
	beq		restore_flags_from_r0	// If Zero flag is not set, do not take the jump.
	cmp		r2, #0					// Is CX zero?
	addne	r12, r12, r1			// Adjust program counter by the jump amount, if CX != 0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

// ------------------- E2 = LOOP ---------------------------------------
// We are not allowed to change any flags here!
//
op_e2:
	mrs		r0, cpsr				// Save current flags to r0
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	mov		r2, ecx, lsl #16
	eor		ecx, r2, lsr #16
	subs	r2, #0x00010000			// Decrement CX
	orr		ecx, r2, lsr #16
	addne	r12, r12, r1			// Adjust program counter by the jump amount, if CX != 0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags
	
// ------------------- E3 = JCXZ ---------------------------------------
// We are not allowed to change any flags here!
//
op_e3:
	mrs		r0, cpsr				// Save current flags to r0
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	movs	r2, ecx, lsl #16		// Is CX zero?
	addeq	r12, r12, r1			// Adjust program counter by the jump amount, if CX == 0
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

// ------------------- E8 = CALL near ----------------------------------
op_e8:
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	ldr		r2,[sp, #SP_PHYS_CS]	// Get current physical CS from stack
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	sub		r1, r12, r2				// r1 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	push_hword r1 r3 lr
	add		r1, r0					// r1 = current IP + jump amount
	lsl		r1, #16					// Make the result unsigned
	add		r12, r2, r1, lsr #16	// Adjust program counter by the jump amount
	b		loop

// ------------------- E9 = JMP near -----------------------------------
op_e9:
	ldrb	r0,[r12],#1				// Load byte to r0, increment r12 by 1
	ldrsb	r1,[r12],#1				// Load sign-extended byte to r1, increment r12 by 1
	ldr		r2,[sp, #SP_PHYS_CS]	// Get current physical CS from stack
	orr		r0, r1, lsl #8			// r0 = low byte | (high byte << 8)
	sub		r1, r12, r2				// r1 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	add		r1, r0					// r1 = current IP + jump amount
	lsl		r1, #16					// Make the result unsigned
	add		r12, r2, r1, lsr #16	// Adjust program counter by the jump amount
#if 0
	ldr		r0, =registers
	str		r12, [r0, #4*16]
#endif	
	b		loop

// ------------------- EA = JMP FAR ------------------------------------
// Profiler: 2059, 24, 25.61, 52739, 0.03%
//
op_ea:
	//-------
	// First get the jump target :
	//	r1 = new IP (offset)
	//	r2 = new CS (segment)
	//-------
	ldrb	r0,[r12]
	ldrb	r1,[r12, #1]
	ldrb	r2,[r12, #2]
	ldrb	r3,[r12, #3]
	orr		r1, r0, r1, lsl #8		// r1 = new logical IP
	orr		r2, r3, lsl #8			// r2 = new CS value
	.global	cpu_jmp_far_r1r2
cpu_jmp_far_r1r2:
	//-------
	// Then determine if we are in real mode, and jump to a handler in "cpu_prot.s" if not.
	//-------
	ldrb	r3, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	mrs		r0,cpsr					// Save flags (we are not allowed to change any)
	tst		r3, #1					// Are we in protected mode (or in VM mode)?
	bne		cpu_jmp_prot_r0r1r2		// Yes we are, go handle protected mode JMP FAR!
	//-------
	// Real mode JMP FAR handling
	//-------
	.global	cpu_jmp_real_r0r1r2
cpu_jmp_real_r0r1r2:	
	msr		cpsr_f, r0				// Restore flags
	mov		r12, r1					// r12 = r1 = new logical IP
	str		r2, [sp, #SP_CS_VALUE]	// Store new logical CS value
	lsl		r2, #REAL_SEGMENT_SHIFT
	str		r2, [sp, #SP_CS_BASE]	// Store new logical CS base
	calc_linear_address_r2
	str		r2, [sp, #SP_PHYS_CS]	// Store new physical CS into stack
	add		r12, r2					// r12 = new physical CS:IP = new logical IP + new physical CS:0000
	b		loop

// ------------------- EB = JMP short ----------------------------------
op_eb:
	ldrsb	r0,[r12],#1				// Load sign-extended byte to r0, increment r12 by 1
	add		r12, r0					// Adjust program counter by the jump amount
	b		loop

	.text
	.align 2

// ------------------- F4 = HLT ----------------------------------------
//
	.global	op_f4					// Prot mode HLT used in Fragile Alliance
op_f4:
	mrs		r0,cpsr					// Save flags (we are not allowed to change any)
.op_f4_loop:
	ldr		r2, [sp, #SP_IRQFLAG]
	mov		r1, #IRQ_ON
	cmp		r2, r1
	bne		.op_f4_loop				// Nope, continue looping
	b		restore_flags_from_r0	// Jump back to loop, restoring the flags

	.ltorg
	
// ------------------- F6 = ??? r/m8 -----------------------------------
//
// All modrm variations supported!
//
op_f6:
	modrm_jump_16
// 0
	.word test_bxsi_imm8, test_bxdi_imm8, test_bpsi_imm8, test_bpdi_imm8, test_siidx_b, test_diidx_b, test_disp16_imm8, test_bxidx_b
	.word .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown
	.word not_b_bxsi, not_b_bxdi, not_b_bpsi, not_b_bpdi, not_siidx_b, not_diidx_b, not_b_disp16, not_bxidx_b
	.word neg_b_bxsi, neg_b_bxdi, neg_b_bpsi, neg_b_bpdi, neg_siidx_b, neg_diidx_b, neg_b_disp16, neg_bxidx_b
	.word mul_b_bxsi, mul_b_bxdi, mul_b_bpsi, mul_b_bpdi, mul_siidx_b, mul_diidx_b, mul_b_disp16, mul_bxidx_b
	.word imul_b_bxsi, imul_b_bxdi, imul_b_bpsi, imul_b_bpdi, imul_siidx_b, imul_diidx_b, imul_b_disp16, imul_bxidx_b
	.word div_b_bxsi, div_b_bxdi, div_b_bpsi, div_b_bpdi, div_siidx_b, div_diidx_b, div_b_disp16, div_bxidx_b
	.word idiv_b_bxsi, idiv_b_bxdi, idiv_b_bpsi, idiv_b_bpdi, idiv_siidx_b, idiv_diidx_b, idiv_b_disp16, idiv_bxidx_b
//0x40
	.word test_bxsid8_imm8, test_bxdid8_imm8, test_bpsid8_imm8, test_bpdid8_imm8, test_sidisp8_b, test_didisp8_b, test_bpdisp8_b, test_bxdisp8_b
	.word .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown
	.word not_b_bxsid8, not_b_bxdid8, not_b_bpsid8, not_b_bpdid8, not_sidisp8_b, not_didisp8_b, not_bpdisp8_b, not_bxdisp8_b
	.word neg_b_bxsid8, neg_b_bxdid8, neg_b_bpsid8, neg_b_bpdid8, neg_sidisp8_b, neg_didisp8_b, neg_bpdisp8_b, neg_bxdisp8_b
	.word mul_b_bxsid8, mul_b_bxdid8, mul_b_bpsid8, mul_b_bpdid8, mul_sidisp8_b, mul_didisp8_b, mul_bpdisp8_b, mul_bxdisp8_b
	.word imul_b_bxsid8, imul_b_bxdid8, imul_b_bpsid8, imul_b_bpdid8, imul_sidisp8_b, imul_didisp8_b, imul_bpdisp8_b, imul_bxdisp8_b
	.word div_b_bxsid8, div_b_bxdid8, div_b_bpsid8, div_b_bpdid8, div_sidisp8_b, div_didisp8_b, div_bpdisp8_b, div_bxdisp8_b
	.word idiv_b_bxsid8, idiv_b_bxdid8, idiv_b_bpsid8, idiv_b_bpdid8, idiv_sidisp8_b, idiv_didisp8_b, idiv_bpdisp8_b, idiv_bxdisp8_b
//0x80
	.word test_bxsid16_imm8, test_bxdid16_imm8, test_bpsid16_imm8, test_bpdid16_imm8, test_sidisp16_imm8, test_didisp16_imm8, test_bpdisp16_imm8, test_bxdisp16_imm8
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word not_b_bxsid16, not_b_bxdid16, not_b_bpsid16, not_b_bpdid16, not_b_sidisp16, not_b_didisp16, not_b_bpdisp16, not_b_bxdisp16
	.word neg_b_bxsid16, neg_b_bxdid16, neg_b_bpsid16, neg_b_bpdid16, neg_b_sidisp16, neg_b_didisp16, neg_b_bpdisp16, neg_b_bxdisp16
	.word mul_b_bxsid16, mul_b_bxdid16, mul_b_bpsid16, mul_b_bpdid16, mul_b_sidisp16, mul_b_didisp16, mul_b_bpdisp16, mul_b_bxdisp16
	.word imul_b_bxsid16, imul_b_bxdid16, imul_b_bpsid16, imul_b_bpdid16, imul_b_sidisp16, imul_b_didisp16, imul_b_bpdisp16, imul_b_bxdisp16
	.word div_b_bxsid16, div_b_bxdid16, div_b_bpsid16, div_b_bpdid16, div_b_sidisp16, div_b_didisp16, div_b_bpdisp16, div_b_bxdisp16
	.word idiv_b_bxsid16, idiv_b_bxdid16, idiv_b_bpsid16, idiv_b_bpdid16, idiv_b_sidisp16, idiv_b_didisp16, idiv_b_bpdisp16, idiv_b_bxdisp16
//0xc0 = mod = 11b => register operand
// TEST	
	.word test_al_imm8, test_cl_imm8, test_dl_imm8, test_bl_imm8, test_ah_imm8, test_ch_imm8, test_dh_imm8, test_bh_imm8
// (invalid opcode)	
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
// NOT	
	.word not_al, not_cl, not_dl, not_bl, not_ah, not_ch, not_dh, not_bh
// NEG	
	.word neg_al, neg_cl, neg_dl, neg_bl, neg_ah, neg_ch, neg_dh, neg_bh
// MUL
	.word mul_al, mul_cl, mul_dl, mul_bl, mul_ah, mul_ch, mul_dh, mul_bh
// IMUL
	.word imul_al, imul_cl, imul_dl, imul_bl, imul_ah, imul_ch, imul_dh, imul_bh
// DIV r8
	.word div_al, div_cl, div_dl, div_bl, div_ah, div_ch, div_dh, div_bh
// IDIV r8
	.word idiv_al, idiv_cl, idiv_dl, idiv_bl, idiv_ah, idiv_ch, idiv_dh, idiv_bh

	.global test_siidx_b, test_diidx_b, test_bxidx_b
	.global not_siidx_b, not_diidx_b, not_bxidx_b
	.global neg_siidx_b, neg_diidx_b, neg_bxidx_b
	.global mul_siidx_b, mul_diidx_b, mul_bxidx_b
	.global imul_siidx_b, imul_diidx_b, imul_bxidx_b
	.global div_siidx_b, div_diidx_b, div_bxidx_b
	.global idiv_siidx_b, idiv_diidx_b, idiv_bxidx_b
	.global test_sidisp8_b, test_didisp8_b, test_bpdisp8_b, test_bxdisp8_b
	.global not_sidisp8_b, not_didisp8_b, not_bpdisp8_b, not_bxdisp8_b
	.global neg_sidisp8_b, neg_didisp8_b, neg_bpdisp8_b, neg_bxdisp8_b
	.global mul_sidisp8_b, mul_didisp8_b, mul_bpdisp8_b, mul_bxdisp8_b
	.global imul_sidisp8_b, imul_didisp8_b, imul_bpdisp8_b, imul_bxdisp8_b
	.global div_sidisp8_b, div_didisp8_b, div_bpdisp8_b, div_bxdisp8_b
	.global idiv_sidisp8_b, idiv_didisp8_b, idiv_bpdisp8_b, idiv_bxdisp8_b

	.global test_al_imm8, test_cl_imm8, test_dl_imm8, test_bl_imm8, test_ah_imm8, test_ch_imm8, test_dh_imm8, test_bh_imm8
	.global not_al, not_cl, not_dl, not_bl, not_ah, not_ch, not_dh, not_bh
	.global neg_al, neg_cl, neg_dl, neg_bl, neg_ah, neg_ch, neg_dh, neg_bh
	.global mul_al, mul_cl, mul_dl, mul_bl, mul_ah, mul_ch, mul_dh, mul_bh
	.global imul_al, imul_cl, imul_dl, imul_bl, imul_ah, imul_ch, imul_dh, imul_bh
	.global div_al, div_cl, div_dl, div_bl, div_ah, div_ch, div_dh, div_bh
	.global idiv_al, idiv_cl, idiv_dl, idiv_bl, idiv_ah, idiv_ch, idiv_dh, idiv_bh

// ----- TEST -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	test_r0_bp_b
test_r0_bp_b:
test_r0_bp_imm8:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	test_r0_b
test_r0_b:	
test_r0_imm8:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .test_RAM_imm8 test_EGA_r2_imm8 test_MODEX_r2_imm8
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.test_RAM_imm8:
	ldrb	r0, [r2]
	ldrb	r1, [r12], #1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	lsl		r0, #24					// r0 = byte at address [r2], shifted to high byte
	tst		r0, r1, lsl #24
	b		loop

	.text
	.align 2
	
// -- TEST [idx] --

test_bxsi_imm8:
	add		r0, r7, r10
	b		test_r0_imm8
test_bxdi_imm8:
	add		r0, r7, r11
	b		test_r0_imm8
test_bpsi_imm8:
	add		r0, r9, r10
	b		test_r0_bp_imm8
test_bpdi_imm8:
	add		r0, r9, r11
	b		test_r0_bp_imm8
test_siidx_b:
	mov		r0, r10
	b		test_r0_imm8
test_diidx_b:
	mov		r0, r11
	b		test_r0_imm8
test_disp16_imm8:
	r0_from_disp16
	b		test_r0_imm8
test_bxidx_b:
	mov		r0, r7
	b		test_r0_imm8

// -- TEST [idx+disp8] --

test_bxsid8_imm8:
	r0_from_bxidxdisp8 r10
	b		test_r0_imm8
test_bxdid8_imm8:
	r0_from_bxidxdisp8 r11
	b		test_r0_imm8
test_bpsid8_imm8:
	r0_from_bpidxdisp8 r10
	b		test_r0_bp_imm8
test_bpdid8_imm8:
	r0_from_bpidxdisp8 r11
	b		test_r0_bp_imm8
test_sidisp8_b:
	r0_from_idx_disp8 r10
	b		test_r0_imm8
test_didisp8_b:
	r0_from_idx_disp8 r11
	b		test_r0_imm8
test_bpdisp8_b:
	r0_from_idx_disp8 r9
	b		test_r0_bp_imm8
test_bxdisp8_b:
	r0_from_idx_disp8 r7
	b		test_r0_imm8

// -- TEST [idx+disp16] --

test_bxsid16_imm8:
	r0_from_bxidxdisp16 r10
	b		test_r0_imm8
test_bxdid16_imm8:
	r0_from_bxidxdisp16 r11
	b		test_r0_imm8
test_bpsid16_imm8:
	r0_from_bpidxdisp16  r10
	b		test_r0_bp_imm8
test_bpdid16_imm8:
	r0_from_bpidxdisp16 r11
	b		test_r0_bp_imm8
test_sidisp16_imm8:
	r0_from_idx_disp16 r10
	b		test_r0_imm8
test_didisp16_imm8:
	r0_from_idx_disp16 r11
	b		test_r0_imm8
test_bpdisp16_imm8:
	r0_from_idx_disp16 r9
	b		test_r0_bp_imm8
test_bxdisp16_imm8:
	r0_from_idx_disp16 r7
	b		test_r0_imm8

// -- TEST register --

.macro test_reg8l_imm8 reg
	ldrb	r1, [r12], #1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r0, \reg, lsl #24
	tst		r0, r1, lsl #24
	b		loop
.endm
.macro test_reg8h_imm8 reg
	ldrb	r1, [r12], #1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	mov		r0, \reg, lsl #16
	tst		r0, r1, lsl #24
	b		loop
.endm

test_al_imm8:
	test_reg8l_imm8	r4
test_cl_imm8:
	test_reg8l_imm8	r5
test_dl_imm8:
	test_reg8l_imm8	r6
test_bl_imm8:
	test_reg8l_imm8	r7
	
test_ah_imm8:
	test_reg8h_imm8	r4
test_ch_imm8:
	test_reg8h_imm8	r5
test_dh_imm8:
	test_reg8h_imm8	r6
test_bh_imm8:
	test_reg8h_imm8	r7

// ----- NOT -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	not_r0_bp_b
not_r0_bp_b:
not_b_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	not_r0_b
not_r0_b:
not_b_r0high:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .not_b_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.not_b_RAM:
	ldrb	r0, [r2]
	mvn		r0, r0
	strb	r0, [r2]
	b		loop

	.text
	.align 2

// -- NOT [idx] --

not_b_bxsi:
	add		r0, r7, r10
	b		not_b_r0high
not_b_bxdi:
	add		r0, r7, r11
	b		not_b_r0high
not_b_bpsi:
	add		r0, r9, r10
	b		not_b_r0_bp
not_b_bpdi:
	add		r0, r9, r11
	b		not_b_r0_bp
not_siidx_b:
	mov		r0, r10
	b		not_b_r0high
not_diidx_b:
	mov		r0, r11
	b		not_b_r0high
not_b_disp16:
	r0_from_disp16
	b		not_b_r0high
not_bxidx_b:
	mov		r0, r7
	b		not_b_r0high

// -- NOT [idx+disp8] --

not_b_bxsid8:
	r0_from_bxidxdisp8 r10
	b		not_b_r0high
not_b_bxdid8:
	r0_from_bxidxdisp8 r11
	b		not_b_r0high
not_b_bpsid8:
	r0_from_bpidxdisp8 r10
	b		not_b_r0_bp
not_b_bpdid8:
	r0_from_bpidxdisp8 r11
	b		not_b_r0_bp
not_sidisp8_b:
	r0_from_idx_disp8 r10
	b		not_b_r0high
not_didisp8_b:
	r0_from_idx_disp8 r11
	b		not_b_r0high
not_bpdisp8_b:
	r0_from_idx_disp8 r9
	b		not_b_r0_bp
not_bxdisp8_b:
	r0_from_idx_disp8 r7
	b		not_b_r0high

// -- NOT [idx+disp16] --

not_b_bxsid16:
	r0_from_bxidxdisp16 r10
	b		not_b_r0high
not_b_bxdid16:
	r0_from_bxidxdisp16 r11
	b		not_b_r0high
not_b_bpsid16:
	r0_from_bpidxdisp16  r10
	b		not_b_r0_bp
not_b_bpdid16:
	r0_from_bpidxdisp16 r11
	b		not_b_r0_bp
not_b_sidisp16:
	r0_from_idx_disp16 r10
	b		not_b_r0high
not_b_didisp16:
	r0_from_idx_disp16 r11
	b		not_b_r0high
not_b_bpdisp16:
	r0_from_idx_disp16 r9
	b		not_b_r0_bp
not_b_bxdisp16:
	r0_from_idx_disp16 r7
	b		not_b_r0high

// -- NOT register --

.macro not_reg8l reg
	mvn		r0, \reg, lsl #24
	bic		\reg, #0xFF
	orr		\reg, r0, lsr #24
	b		loop
.endm
.macro not_reg8h reg
	mvn		r0, \reg
	bic		\reg, #0xFF00
	and		r0, #0xFF00
	orr		\reg, r0
	b		loop
.endm

not_al:
	not_reg8l r4
not_cl:
	not_reg8l r5
not_dl:
	not_reg8l r6
not_bl:
	not_reg8l r7
not_ah:
	not_reg8h r4
not_ch:
	not_reg8h r5
not_dh:
	not_reg8h r6
not_bh:
	not_reg8h r7

// ----- NEG -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	neg_r0_bp_b
neg_r0_bp_b:
neg_b_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	neg_r0_b
neg_r0_b:
neg_b_r0high:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .neg_b_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.neg_b_RAM:
	ldrb	r0, [r2]
	lsl		r0, #24
	rsbs	r0, #0
	lsr		r0, #24
	strb	r0, [r2]
	b		complement_carry

	.text
	.align 2

// -- neg [idx] --

neg_b_bxsi:
	add		r0, r7, r10
	b		neg_b_r0high
neg_b_bxdi:
	add		r0, r7, r11
	b		neg_b_r0high
neg_b_bpsi:
	add		r0, r9, r10
	b		neg_b_r0_bp
neg_b_bpdi:
	add		r0, r9, r11
	b		neg_b_r0_bp
neg_siidx_b:
	mov		r0, r10
	b		neg_b_r0high
neg_diidx_b:
	mov		r0, r11
	b		neg_b_r0high
neg_b_disp16:
	r0_from_disp16
	b		neg_b_r0high
neg_bxidx_b:
	mov		r0, r7
	b		neg_b_r0high

// -- neg [idx+disp8] --

neg_b_bxsid8:
	r0_from_bxidxdisp8 r10
	b		neg_b_r0high
neg_b_bxdid8:
	r0_from_bxidxdisp8 r11
	b		neg_b_r0high
neg_b_bpsid8:
	r0_from_bpidxdisp8 r10
	b		neg_b_r0_bp
neg_b_bpdid8:
	r0_from_bpidxdisp8 r11
	b		neg_b_r0_bp
neg_sidisp8_b:
	r0_from_idx_disp8 r10
	b		neg_b_r0high
neg_didisp8_b:
	r0_from_idx_disp8 r11
	b		neg_b_r0high
neg_bpdisp8_b:
	r0_from_idx_disp8 r9
	b		neg_b_r0_bp
neg_bxdisp8_b:
	r0_from_idx_disp8 r7
	b		neg_b_r0high

// -- neg [idx+disp16] --

neg_b_bxsid16:
	r0_from_bxidxdisp16 r10
	b		neg_b_r0high
neg_b_bxdid16:
	r0_from_bxidxdisp16 r11
	b		neg_b_r0high
neg_b_bpsid16:
	r0_from_bpidxdisp16  r10
	b		neg_b_r0_bp
neg_b_bpdid16:
	r0_from_bpidxdisp16 r11
	b		neg_b_r0_bp
neg_b_sidisp16:
	r0_from_idx_disp16 r10
	b		neg_b_r0high
neg_b_didisp16:
	r0_from_idx_disp16 r11
	b		neg_b_r0high
neg_b_bpdisp16:
	r0_from_idx_disp16 r9
	b		neg_b_r0_bp
neg_b_bxdisp16:
	r0_from_idx_disp16 r7
	b		neg_b_r0high

// -- neg register --

.macro neg_reg8l reg
	mov		r0, \reg, lsl #24
	rsbs	r0, #0
	bic		\reg, #0xFF
	orr		\reg, r0, lsr #24
	b		complement_carry
.endm
.macro neg_reg8h reg
	mov		r0, \reg, lsl #16
	and		r0, #0xFF000000
	rsbs	r0, #0
	bic		\reg, #0xFF00
	orr		\reg, r0, lsr #16
	b		complement_carry
.endm

neg_al:
	neg_reg8l r4
neg_cl:
	neg_reg8l r5
neg_dl:
	neg_reg8l r6
neg_bl:
	neg_reg8l r7
neg_ah:
	neg_reg8h r4
neg_ch:
	neg_reg8h r5
neg_dh:
	neg_reg8h r6
neg_bh:
	neg_reg8h r7
	
// ----- MUL -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	mul_r0_bp_b
mul_r0_bp_b:
mul_b_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mul_r0_b
mul_r0_b:
mul_b_r0high:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .mul_b_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.mul_b_RAM:
	ldrb	r0, [r2]
	msr		cpsr_f,#0				// Clear all flags
	and		r1, eax, #0xFF
	lsr		eax, #16
	mul		r2, r0, r1
	tst		r2, #0xFF00				// Is the result > 255?
	msrne	cpsr_f,#0x30000000		// Set Carry and Overflow flags if it is
	orr		eax, r2, eax, lsl #16
	b		loop

	.text
	.align 2

// -- mul [idx] --

mul_b_bxsi:
	add		r0, r7, r10
	b		mul_b_r0high
mul_b_bxdi:
	add		r0, r7, r11
	b		mul_b_r0high
mul_b_bpsi:
	add		r0, r9, r10
	b		mul_b_r0_bp
mul_b_bpdi:
	add		r0, r9, r11
	b		mul_b_r0_bp
mul_siidx_b:
	mov		r0, r10
	b		mul_b_r0high
mul_diidx_b:
	mov		r0, r11
	b		mul_b_r0high
mul_b_disp16:
	r0_from_disp16
	b		mul_b_r0high
mul_bxidx_b:
	mov		r0, r7
	b		mul_b_r0high

// -- mul [idx+disp8] --

mul_b_bxsid8:
	r0_from_bxidxdisp8 r10
	b		mul_b_r0high
mul_b_bxdid8:
	r0_from_bxidxdisp8 r11
	b		mul_b_r0high
mul_b_bpsid8:
	r0_from_bpidxdisp8 r10
	b		mul_b_r0_bp
mul_b_bpdid8:
	r0_from_bpidxdisp8 r11
	b		mul_b_r0_bp
mul_sidisp8_b:
	r0_from_idx_disp8 r10
	b		mul_b_r0high
mul_didisp8_b:
	r0_from_idx_disp8 r11
	b		mul_b_r0high
mul_bpdisp8_b:
	r0_from_idx_disp8 r9
	b		mul_b_r0_bp
mul_bxdisp8_b:
	r0_from_idx_disp8 r7
	b		mul_b_r0high

// -- mul [idx+disp16] --

mul_b_bxsid16:
	r0_from_bxidxdisp16 r10
	b		mul_b_r0high
mul_b_bxdid16:
	r0_from_bxidxdisp16 r11
	b		mul_b_r0high
mul_b_bpsid16:
	r0_from_bpidxdisp16  r10
	b		mul_b_r0_bp
mul_b_bpdid16:
	r0_from_bpidxdisp16 r11
	b		mul_b_r0_bp
mul_b_sidisp16:
	r0_from_idx_disp16 r10
	b		mul_b_r0high
mul_b_didisp16:
	r0_from_idx_disp16 r11
	b		mul_b_r0high
mul_b_bpdisp16:
	r0_from_idx_disp16 r9
	b		mul_b_r0_bp
mul_b_bxdisp16:
	r0_from_idx_disp16 r7
	b		mul_b_r0high

// -- mul register --

.macro mul_reg8l reg
	// One of the operands is always AL and the result goes to AX
	// Carry and Overflow are set if the result is > 255, other flags are undeterminate
	msr		cpsr_f,#0				// Clear all flags
	and		r0, \reg, #0xFF
	and		r1, eax, #0xFF
	lsr		eax, #16
	mul		r2, r0, r1
	tst		r2, #0xFF00				// Is the result > 255?
	msrne	cpsr_f,#0x30000000		// Set Carry and Overflow flags if it is
	orr		eax, r2, eax, lsl #16
	b		loop
.endm

.macro mul_reg8h reg
	// One of the operands is always AL and the result goes to AX
	// Carry and Overflow are set if the result is > 255, other flags are undeterminate
	msr		cpsr_f,#0				// Clear all flags
	mov		r0, \reg, lsr #8		// r0 = reg8h
	and		r0, #0xFF
	and		r1, eax, #0xFF
	lsr		eax, #16
	mul		r2, r0, r1
	tst		r2, #0xFF00				// Is the result > 255?
	msrne	cpsr_f,#0x30000000		// Set Carry and Overflow flags if it is
	orr		eax, r2, eax, lsl #16
	b		loop
.endm

mul_al:
	mul_reg8l r4
mul_cl:
	mul_reg8l r5
mul_dl:
	mul_reg8l r6
mul_bl:
	mul_reg8l r7
mul_ah:
	mul_reg8h r4
mul_ch:
	mul_reg8h r5
mul_dh:
	mul_reg8h r6
mul_bh:
	mul_reg8h r7

// ----- IMUL -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	imul_r0_bp_b
imul_r0_bp_b:
imul_b_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	imul_r0_b
imul_r0_b:
imul_b_r0high:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .imul_b_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.imul_b_RAM:
	ldrsb	r0, [r2]				// Load signed byte
	msr		cpsr_f,#0				// Clear all flags
	mov		r1, eax, lsl #24
	lsr		eax, #16
	asr		r1, #24					// r1 = signed AL value
	mul		r2, r1, r0
	orr		eax, r2, lsl #16
	ror		eax, #16
	b		loop

	.text
	.align 2

// -- imul [idx] --

imul_b_bxsi:
	add		r0, r7, r10
	b		imul_b_r0high
imul_b_bxdi:
	add		r0, r7, r11
	b		imul_b_r0high
imul_b_bpsi:
	add		r0, r9, r10
	b		imul_b_r0_bp
imul_b_bpdi:
	add		r0, r9, r11
	b		imul_b_r0_bp
imul_siidx_b:
	mov		r0, r10
	b		imul_b_r0high
imul_diidx_b:
	mov		r0, r11
	b		imul_b_r0high
imul_b_disp16:
	r0_from_disp16
	b		imul_b_r0high
imul_bxidx_b:
	mov		r0, r7
	b		imul_b_r0high

// -- imul [idx+disp8] --

imul_b_bxsid8:
	r0_from_bxidxdisp8 r10
	b		imul_b_r0high
imul_b_bxdid8:
	r0_from_bxidxdisp8 r11
	b		imul_b_r0high
imul_b_bpsid8:
	r0_from_bpidxdisp8 r10
	b		imul_b_r0_bp
imul_b_bpdid8:
	r0_from_bpidxdisp8 r11
	b		imul_b_r0_bp
imul_sidisp8_b:
	r0_from_idx_disp8 r10
	b		imul_b_r0high
imul_didisp8_b:
	r0_from_idx_disp8 r11
	b		imul_b_r0high
imul_bpdisp8_b:
	r0_from_idx_disp8 r9
	b		imul_b_r0_bp
imul_bxdisp8_b:
	r0_from_idx_disp8 r7
	b		imul_b_r0high

// -- imul [idx+disp16] --

imul_b_bxsid16:
	r0_from_bxidxdisp16 r10
	b		imul_b_r0high
imul_b_bxdid16:
	r0_from_bxidxdisp16 r11
	b		imul_b_r0high
imul_b_bpsid16:
	r0_from_bpidxdisp16  r10
	b		imul_b_r0_bp
imul_b_bpdid16:
	r0_from_bpidxdisp16 r11
	b		imul_b_r0_bp
imul_b_sidisp16:
	r0_from_idx_disp16 r10
	b		imul_b_r0high
imul_b_didisp16:
	r0_from_idx_disp16 r11
	b		imul_b_r0high
imul_b_bpdisp16:
	r0_from_idx_disp16 r9
	b		imul_b_r0_bp
imul_b_bxdisp16:
	r0_from_idx_disp16 r7
	b		imul_b_r0high

// -- imul register --

.macro imul_reg8l reg
	// One of the operands is always AL and the result goes to AX
	// Carry and Overflow are set if the result is > 255, other flags are undeterminate
	msr		cpsr_f,#0				// Clear all flags
	mov		r0, \reg, lsl #24
	asr		r0, #24
	mov		r1, eax, lsl #24
	lsr		eax, #16
	asr		r1, #24
	mul		r2, r1, r0
	orr		eax, r2, lsl #16
	ror		eax, #16
	b		loop
.endm

.macro imul_reg8h reg
	// One of the operands is always AL and the result goes to AX
	// Carry and Overflow are set if the result is > 255, other flags are undeterminate
	msr		cpsr_f,#0				// Clear all flags
	mov		r0, \reg, lsl #16
	asr		r0, #24
	mov		r1, eax, lsl #24
	lsr		eax, #16
	asr		r1, #24					// r1 = AL
	mul		r2, r1, r0
	orr		eax, r2, lsl #16
	ror		eax, #16
	b		loop
.endm

imul_al:
	imul_reg8l r4
imul_cl:
	imul_reg8l r5
imul_dl:
	imul_reg8l r6
imul_bl:
	imul_reg8l r7
imul_ah:
	imul_reg8h r4
imul_ch:
	imul_reg8h r5
imul_dh:
	imul_reg8h r6
imul_bh:
	imul_reg8h r7


// --- DIV r/m8 ---
// Numerator is always AX, the result goes to AL and the remainder to AH.
// All flags are undeterminate.

	.global	div_r0_bp_b
div_r0_bp_b:
div_b_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	div_r0_b
div_r0_b:
div_b_r0high:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .div_b_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.div_b_RAM:
	ldrb	r2, [r2]				// Load byte
div_reg8_by_r2_subroutine:
#if SOFTWARE_DIV
	//-------
	// Software division routine. Algorithm taken from
	// "http://www.peter-cockerell.net/aalp/html/ch-6.html"
	// 	r0 = div (result)
	// 	r1 = mod (result)
	// 	r2 = rhs
	// 	r3 = lhs
	//	r4 = count
	//-------
	teq  	r2, #0    				// Trap div by zero
	beq		.div8_by_zero			// division by zero!!
	push	{r4}
	movs	r3, eax, lsl #16
	mov  	r1, #0    				// Init remainder
	mov  	r0, #0    				// and result
	mov  	r4, #16    				// Set up count
	bmi		2f						// Skip first loop if highest bit of r3 set
1:	subs 	r4, r4, #1  			// Get first 1 bit of lhs
	beq		3f    					// into bit 31. Return if 0
	movs 	r3, r3, ASL #1
	bpl  	1b
2:	movs 	r3, r3, ASL #1  		// Get next bit into...
	adc  	r1, r1, r1   			// r1 for trial subtract
	cmp  	r1, r2    				// Can we subtract?
	subcs 	r1, r1, r2   			// Yes, so do
	adc  	r0, r0, r0   			// Shift carry into result
	subs 	r4, r4, #1  			// Next loop
	bne  	2b
3:	pop		{r4}
	cmp		r0, #0x100				// Is the result >= 256?
	bhs		.div8_by_zero			// Yep, overflow!
	lsr		eax, #16
	orr		eax, r0, eax, lsl #16
	orr		eax, r1, lsl #8
	b		loop					// Go back to loop
#else
	mov		r0, #0x280
	orr		r0, #0x04000000			// #define REG_DIVCNT			(*(vu16*)(0x04000280))
	cmp		r2, #0
	beq		.div8_by_zero			// Division by zero!! (See F7 opcode handler)
	mov		r1, #0
	strh	r1, [r0]				// REG_DIVCNT = DIV_32_32 = 0
	mov		r1, eax, lsl #16
	lsr		r1, #16
	str		r1, [r0, #0x10]			// #define REG_DIV_NUMER_L		(*(vs32*) (0x04000290)),	REG_DIV_NUMER_L = num
	str		r2, [r0, #0x18]			// #define REG_DIV_DENOM_L		(*(vs32*) (0x04000298)),	REG_DIV_DENOM_L = den
1:	ldrh	r1, [r0]				// while(REG_DIVCNT & DIV_BUSY)
	tst		r1, #0x8000
	bne		1b
	ldr		r2,[r0, #0x20]			// #define REG_DIV_RESULT_L		(*(vs32*) (0x040002A0)),	r4 (AL) is the result of the division
	cmp		r2, #0x100
	bhs		.div8_by_zero			// If result is >= 256, divide overflow! (See F7 opcode handler)
	ldr		r1,[r0, #0x28]			// #define REG_DIVREM_RESULT_L	(*(vs32*) (0x040002A8)),	r1 (AH) is the remainder of the division
	lsr		eax, #16
	orr		eax, r2, eax, lsl #16
	orr		eax, r1, lsl #8			// AX = AH<<8|AL
	b		loop
#endif

// -- div [idx] --

div_b_bxsi:
	add		r0, r7, r10
	b		div_b_r0high
div_b_bxdi:
	add		r0, r7, r11
	b		div_b_r0high
div_b_bpsi:
	add		r0, r9, r10
	b		div_b_r0_bp
div_b_bpdi:
	add		r0, r9, r11
	b		div_b_r0_bp
div_siidx_b:
	mov		r0, r10
	b		div_b_r0high
div_diidx_b:
	mov		r0, r11
	b		div_b_r0high
div_b_disp16:
	r0_from_disp16
	b		div_b_r0high
div_bxidx_b:
	mov		r0, r7
	b		div_b_r0high

// -- div [idx+disp8] --

div_b_bxsid8:
	r0_from_bxidxdisp8 r10
	b		div_b_r0high
div_b_bxdid8:
	r0_from_bxidxdisp8 r11
	b		div_b_r0high
div_b_bpsid8:
	r0_from_bpidxdisp8 r10
	b		div_b_r0_bp
div_b_bpdid8:
	r0_from_bpidxdisp8 r11
	b		div_b_r0_bp
div_sidisp8_b:
	r0_from_idx_disp8 r10
	b		div_b_r0high
div_didisp8_b:
	r0_from_idx_disp8 r11
	b		div_b_r0high
div_bpdisp8_b:
	r0_from_idx_disp8 r9
	b		div_b_r0_bp
div_bxdisp8_b:
	r0_from_idx_disp8 r7
	b		div_b_r0high

// -- div [idx+disp16] --

div_b_bxsid16:
	r0_from_bxidxdisp16 r10
	b		div_b_r0high
div_b_bxdid16:
	r0_from_bxidxdisp16 r11
	b		div_b_r0high
div_b_bpsid16:
	r0_from_bpidxdisp16  r10
	b		div_b_r0_bp
div_b_bpdid16:
	r0_from_bpidxdisp16 r11
	b		div_b_r0_bp
div_b_sidisp16:
	r0_from_idx_disp16 r10
	b		div_b_r0high
div_b_didisp16:
	r0_from_idx_disp16 r11
	b		div_b_r0high
div_b_bpdisp16:
	r0_from_idx_disp16 r9
	b		div_b_r0_bp
div_b_bxdisp16:
	r0_from_idx_disp16 r7
	b		div_b_r0high

// -- div register --

.macro div_reg8l reg
	and		r2, \reg, #0xFF			// r2 = UNSIGNED register value
	b		div_reg8_by_r2_subroutine
.endm
.macro div_reg8h reg
	mov		r2, \reg, lsr #8		// r2 = UNSIGNED register value
	and		r2, #0xFF
	b		div_reg8_by_r2_subroutine
.endm

div_al:
	div_reg8l r4
div_cl:
	div_reg8l r5
div_dl:
	div_reg8l r6
div_bl:
	div_reg8l r7

div_ah:
	div_reg8h r4
div_ch:
	div_reg8h r5
div_dh:
	div_reg8h r6
div_bh:
	div_reg8h r7

// --- IDIV r/m8 ---
// Numerator is always AX, the result goes to AL and the remainder to AH.
// All flags are undeterminate.
//

	.global	idiv_r0_bp_b
idiv_r0_bp_b:
idiv_b_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	idiv_r0_b
idiv_r0_b:
idiv_b_r0high:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .idiv_b_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.idiv_b_RAM:
	ldrsb	r2, [r2]				// Load signed byte
idiv_reg8_by_r2_subroutine:
#if SOFTWARE_DIV
	//-------
	// Software division routine. Algorithm taken from
	// "http://www.peter-cockerell.net/aalp/html/ch-6.html"
	// 	r0 = div (result)
	// 	r1 = mod (result)
	// 	r2 = rhs
	// 	r3 = lhs
	//	r4 = count
	//-------
	teq  	r2, #0    				// Trap div by zero
	beq		.div8_by_zero			// division by zero!!
	push	{r4, r5}
	movs	r5, eax, lsl #16
	eor		r3, r5, r2
	lsr		r3, #31					// r3 lowest bit tells the sign of the result
	orrmi	r3, #2					// Mod sign should be negative if lhs is negative
	rsbmi	r5, #0					// Make lhs positive
	teq		r2, #0					// Is rhs negative?
	rsbmi	r2, #0					// If yes, make it positive
	mov  	r1, #0    				// Init remainder
	mov  	r0, #0    				// and result
	mov  	r4, #16    				// Set up count
1:	subs 	r4, r4, #1  			// Get first 1 bit of lhs
	beq		3f    					// into bit 31. Return if 0
	movs 	r5, r5, ASL #1
	bpl  	1b
2:	movs 	r5, r5, ASL #1  		// Get next bit into...
	adc  	r1, r1, r1   			// r1 for trial subtract
	cmp  	r1, r2    				// Can we subtract?
	subcs 	r1, r1, r2   			// Yes, so do
	adc  	r0, r0, r0   			// Shift carry into result
	subs 	r4, r4, #1  			// Next loop
	bne  	2b
3:	pop		{r4, r5}
	and		r2, r3, #1
	add		r2, #0x80
	cmp		r0, r2					// Is the result > 127 or < -128?
	bhs		.div8_by_zero			// Yep, overflow!
	tst		r3, #1					// Should we negate the result?
	rsbne	r0, #0					// Yep
	tst		r3, #2					// Should we negate the remainder?
	rsbne	r1, #0					// Yep
	and		r0, #0xFF
	and		r1, #0xFF
	lsr		eax, #16
	orr		eax, r0, eax, lsl #16
	orr		eax, r1, lsl #8
	b		loop					// Go back to loop
#else
	mov		r0, #0x280
	orr		r0, #0x04000000			// #define REG_DIVCNT			(*(vu16*)(0x04000280))
	cmp		r2, #0
	beq		.div8_by_zero			// Division by zero!!
	mov		r1, #0
	strh	r1, [r0]				// REG_DIVCNT = DIV_32_32 = 0
	mov		r1, eax, lsl #16
	asr		r1, #16					// r1 = SIGNED AX
	str		r1, [r0, #0x10]			// #define REG_DIV_NUMER_L		(*(vs32*) (0x04000290)),	REG_DIV_NUMER_L = num
	str		r2, [r0, #0x18]			// #define REG_DIV_DENOM_L		(*(vs32*) (0x04000298)),	REG_DIV_DENOM_L = den
1:	ldrh	r1, [r0]				// while(REG_DIVCNT & DIV_BUSY)
	tst		r1, #0x8000
	bne		1b
	ldr		r2,[r0, #0x20]			// #define REG_DIV_RESULT_L		(*(vs32*) (0x040002A0)),	r4 (AL) is the result of the division
	mov		r1, #0x80000000
	cmp		r2, #0x80
	bge		.div8_by_zero
	cmp		r2, r1, asr #24
	blt		.div8_by_zero
	ldr		r1,[r0, #0x28]			// #define REG_DIVREM_RESULT_L	(*(vs32*) (0x040002A8)),	r1 (AH) is the remainder of the division
	and		r2, #0xFF
	lsr		eax, #16
	orr		eax, r2, eax, lsl #16
	and		r1, #0xFF
	orr		eax, r1, lsl #8			// AX = AH<<8|AL
	b		loop
#endif

// -- idiv [idx] --

idiv_b_bxsi:
	add		r0, r7, r10
	b		idiv_b_r0high
idiv_b_bxdi:
	add		r0, r7, r11
	b		idiv_b_r0high
idiv_b_bpsi:
	add		r0, r9, r10
	b		idiv_b_r0_bp
idiv_b_bpdi:
	add		r0, r9, r11
	b		idiv_b_r0_bp
idiv_siidx_b:
	mov		r0, r10
	b		idiv_b_r0high
idiv_diidx_b:
	mov		r0, r11
	b		idiv_b_r0high
idiv_b_disp16:
	r0_from_disp16
	b		idiv_b_r0high
idiv_bxidx_b:
	mov		r0, r7
	b		idiv_b_r0high

// -- idiv [idx+disp8] --

idiv_b_bxsid8:
	r0_from_bxidxdisp8 r10
	b		idiv_b_r0high
idiv_b_bxdid8:
	r0_from_bxidxdisp8 r11
	b		idiv_b_r0high
idiv_b_bpsid8:
	r0_from_bpidxdisp8 r10
	b		idiv_b_r0_bp
idiv_b_bpdid8:
	r0_from_bpidxdisp8 r11
	b		idiv_b_r0_bp
idiv_sidisp8_b:
	r0_from_idx_disp8 r10
	b		idiv_b_r0high
idiv_didisp8_b:
	r0_from_idx_disp8 r11
	b		idiv_b_r0high
idiv_bpdisp8_b:
	r0_from_idx_disp8 r9
	b		idiv_b_r0_bp
idiv_bxdisp8_b:
	r0_from_idx_disp8 r7
	b		idiv_b_r0high

// -- idiv [idx+disp16] --

idiv_b_bxsid16:
	r0_from_bxidxdisp16 r10
	b		idiv_b_r0high
idiv_b_bxdid16:
	r0_from_bxidxdisp16 r11
	b		idiv_b_r0high
idiv_b_bpsid16:
	r0_from_bpidxdisp16  r10
	b		idiv_b_r0_bp
idiv_b_bpdid16:
	r0_from_bpidxdisp16 r11
	b		idiv_b_r0_bp
idiv_b_sidisp16:
	r0_from_idx_disp16 r10
	b		idiv_b_r0high
idiv_b_didisp16:
	r0_from_idx_disp16 r11
	b		idiv_b_r0high
idiv_b_bpdisp16:
	r0_from_idx_disp16 r9
	b		idiv_b_r0_bp
idiv_b_bxdisp16:
	r0_from_idx_disp16 r7
	b		idiv_b_r0high

.macro idiv_reg8l reg
	mov		r2, \reg, lsl #24		// r2 = SIGNED register value
	asr		r2, #24
	b		idiv_reg8_by_r2_subroutine
.endm
.macro idiv_reg8h reg
	mov		r2, \reg, lsl #16		// r2 = SIGNED register value
	asr		r2, #24
	b		idiv_reg8_by_r2_subroutine
.endm

idiv_al:
	idiv_reg8l r4
idiv_cl:
	idiv_reg8l r5
idiv_dl:
	idiv_reg8l r6
idiv_bl:
	idiv_reg8l r7

idiv_ah:
	idiv_reg8h r4
idiv_ch:
	idiv_reg8h r5
idiv_dh:
	idiv_reg8h r6
idiv_bh:
	idiv_reg8h r7
	
// ------------------- F7 = ??? r/m16 ----------------------------------
//
// All modrm variations supported!
//
op_f7:
	ldrb	r0,[r12],#1							// Load next opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8
// 0
	.word test_bxsi_imm16, test_bxdi_imm16, test_bpsi_imm16, test_bpdi_imm16, test_siidx_w, test_diidx_w, test_disp16_imm16, test_bxidx_w
	.word .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown
	.word not_w_bxsi, not_w_bxdi, not_w_bpsi, not_w_bpdi, not_siidx_w, not_diidx_w, not_w_disp16, not_bxidx_w
	.word neg_w_bxsi, neg_w_bxdi, neg_w_bpsi, neg_w_bpdi, neg_siidx_w, neg_diidx_w, neg_w_disp16, neg_bxidx_w
	.word mul_w_bxsi, mul_w_bxdi, mul_w_bpsi, mul_w_bpdi, mul_siidx_w, mul_diidx_w, mul_w_disp16, mul_bxidx_w
	.word imul_w_bxsi, imul_w_bxdi, imul_w_bpsi, imul_w_bpdi, imul_siidx_w, imul_diidx_w, imul_w_disp16, imul_bxidx_w
	.word div_w_bxsi, div_w_bxdi, div_w_bpsi, div_w_bpdi, div_siidx_w, div_diidx_w, div_w_disp16, div_bxidx_w
	.word idiv_w_bxsi, idiv_w_bxdi, idiv_w_bpsi, idiv_w_bpdi, idiv_siidx_w, idiv_diidx_w, idiv_w_disp16, idiv_bxidx_w
//0x40
	.word test_bxsid8_imm16, test_bxdid8_imm16, test_bpsid8_imm16, test_bpdid8_imm16, test_sidisp8_w, test_didisp8_w, test_bpdisp8_w, test_bxdisp8_w
	.word .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown, .unknown
	.word not_w_bxsid8, not_w_bxdid8, not_w_bpsid8, not_w_bpdid8, not_sidisp8_w, not_didisp8_w, not_bpdisp8_w, not_bxdisp8_w
	.word neg_w_bxsid8, neg_w_bxdid8, neg_w_bpsid8, neg_w_bpdid8, neg_sidisp8_w, neg_didisp8_w, neg_bpdisp8_w, neg_bxdisp8_w
	.word mul_w_bxsid8, mul_w_bxdid8, mul_w_bpsid8, mul_w_bpdid8, mul_sidisp8_w, mul_didisp8_w, mul_bpdisp8_w, mul_bxdisp8_w
	.word imul_w_bxsid8, imul_w_bxdid8, imul_w_bpsid8, imul_w_bpdid8, imul_sidisp8_w, imul_didisp8_w, imul_bpdisp8_w, imul_bxdisp8_w
	.word div_w_bxsid8, div_w_bxdid8, div_w_bpsid8, div_w_bpdid8, div_sidisp8_w, div_didisp8_w, div_bpdisp8_w, div_bxdisp8_w
	.word idiv_w_bxsid8, idiv_w_bxdid8, idiv_w_bpsid8, idiv_w_bpdid8, idiv_sidisp8_w, idiv_didisp8_w, idiv_bpdisp8_w, idiv_bxdisp8_w
//0x80
	.word test_bxsid16_imm16, test_bxdid16_imm16, test_bpsid16_imm16, test_bpdid16_imm16, test_sidisp16_imm16, test_didisp16_imm16, test_bpdisp16_imm16, test_bxdisp16_imm16
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word not_w_bxsid16, not_w_bxdid16, not_w_bpsid16, not_w_bpdid16, not_w_sidisp16, not_w_didisp16, not_w_bpdisp16, not_w_bxdisp16
	.word neg_w_bxsid16, neg_w_bxdid16, neg_w_bpsid16, neg_w_bpdid16, neg_w_sidisp16, neg_w_didisp16, neg_w_bpdisp16, neg_w_bxdisp16
	.word mul_w_bxsid16, mul_w_bxdid16, mul_w_bpsid16, mul_w_bpdid16, mul_w_sidisp16, mul_w_didisp16, mul_w_bpdisp16, mul_w_bxdisp16
	.word imul_w_bxsid16, imul_w_bxdid16, imul_w_bpsid16, imul_w_bpdid16, imul_w_sidisp16, imul_w_didisp16, imul_w_bpdisp16, imul_w_bxdisp16
	.word div_w_bxsid16, div_w_bxdid16, div_w_bpsid16, div_w_bpdid16, div_w_sidisp16, div_w_didisp16, div_w_bpdisp16, div_w_bxdisp16
	.word idiv_w_bxsid16, idiv_w_bxdid16, idiv_w_bpsid16, idiv_w_bpdid16, idiv_w_sidisp16, idiv_w_didisp16, idiv_w_bpdisp16, idiv_w_bxdisp16
//0xc0 = mod = 11b => register operand
// TEST r16,imm16
	.word test_ax_imm16, test_cx_imm16, test_dx_imm16, test_bx_imm16, test_sp_imm16, test_bp_imm16, test_si_imm16, test_di_imm16
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
// NOT r16
	.word not_ax, not_cx, not_dx, not_bx, not_sp, not_bp, not_si, not_di
// NEG r16
	.word neg_ax, neg_cx, neg_dx, neg_bx, neg_sp, neg_bp, neg_si, neg_di
// MUL r16
	.word mul_ax, mul_cx, mul_dx, mul_bx, mul_sp, mul_bp, mul_si, mul_di
// IMUL r16
	.word imul_ax, imul_cx, imul_dx, imul_bx, imul_sp, imul_bp, imul_si, imul_di
// DIV r16
	.word div_ax, div_cx, div_dx, div_bx, div_sp, div_bp, div_si, div_di
// IDIV r16
	.word idiv_ax, idiv_cx, idiv_dx, idiv_bx, idiv_sp, idiv_bp, idiv_si, idiv_di

	.global test_siidx_w, test_diidx_w, test_bxidx_w
	.global not_siidx_w, not_diidx_w, not_bxidx_w
	.global neg_siidx_w, neg_diidx_w, neg_bxidx_w
	.global mul_siidx_w, mul_diidx_w, mul_bxidx_w
	.global imul_siidx_w, imul_diidx_w, imul_bxidx_w
	.global div_siidx_w, div_diidx_w, div_bxidx_w
	.global idiv_siidx_w, idiv_diidx_w, idiv_bxidx_w

	.global test_sidisp8_w, test_didisp8_w, test_bpdisp8_w, test_bxdisp8_w
	.global not_sidisp8_w, not_didisp8_w, not_bpdisp8_w, not_bxdisp8_w
	.global neg_sidisp8_w, neg_didisp8_w, neg_bpdisp8_w, neg_bxdisp8_w
	.global mul_sidisp8_w, mul_didisp8_w, mul_bpdisp8_w, mul_bxdisp8_w
	.global imul_sidisp8_w, imul_didisp8_w, imul_bpdisp8_w, imul_bxdisp8_w
	.global div_sidisp8_w, div_didisp8_w, div_bpdisp8_w, div_bxdisp8_w
	.global idiv_sidisp8_w, idiv_didisp8_w, idiv_bpdisp8_w, idiv_bxdisp8_w

	.global test_ax_imm16, test_cx_imm16, test_dx_imm16, test_bx_imm16, test_sp_imm16, test_bp_imm16, test_si_imm16, test_di_imm16
	.global not_ax, not_cx, not_dx, not_bx, not_sp, not_bp, not_si, not_di
	.global neg_ax, neg_cx, neg_dx, neg_bx, neg_sp, neg_bp, neg_si, neg_di
	.global mul_ax, mul_cx, mul_dx, mul_bx, mul_sp, mul_bp, mul_si, mul_di
	.global imul_ax, imul_cx, imul_dx, imul_bx, imul_sp, imul_bp, imul_si, imul_di
	.global div_ax, div_cx, div_dx, div_bx, div_sp, div_bp, div_si, div_di
	.global idiv_ax, idiv_cx, idiv_dx, idiv_bx, idiv_sp, idiv_bp, idiv_si, idiv_di

// --- TEST r/m16, imm16 --

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	test_r0_bp_w
test_r0_bp_w:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	test_r0_w
test_r0_w:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .test_RAM_imm16 test_EGA_r2_imm16 test_MODEX_r2_imm16
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.test_RAM_imm16:
	// ----- Get the word from RAM into r0 -----
	ldrb	r0, [r2]
	ldrb	r1, [r2, #1]
	ldrb	r2, [r12], #1
	orr		r0, r1, lsl #8
	// ----- Get the imm16 value into high halfword of r2 -----
	ldrb	r1, [r12], #1
	lsl		r2, #16
	orr		r2, r1, lsl #24
	// ----- Finally test the values -----
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	tst		r2, r0, lsl #16
	b		loop

	.text
	.align 2

// -- TEST [idx] --

test_bxsi_imm16:
	add		r0, r7, r10
	b		test_r0_w
test_bxdi_imm16:
	add		r0, r7, r11
	b		test_r0_w
test_bpsi_imm16:
	add		r0, r9, r10
	b		test_r0_bp_w
test_bpdi_imm16:
	add		r0, r9, r11
	b		test_r0_bp_w
test_siidx_w:
	mov		r0, r10
	b		test_r0_w
test_diidx_w:
	mov		r0, r11
	b		test_r0_w
test_disp16_imm16:
	r0_from_disp16
	b		test_r0_w
test_bxidx_w:
	mov		r0, r7
	b		test_r0_w

// -- TEST [idx+disp8] --

test_bxsid8_imm16:
	r0_from_bxidxdisp8 r10
	b		test_r0_w
test_bxdid8_imm16:
	r0_from_bxidxdisp8 r11
	b		test_r0_w
test_bpsid8_imm16:
	r0_from_bpidxdisp8 r10
	b		test_r0_bp_w
test_bpdid8_imm16:
	r0_from_bpidxdisp8 r11
	b		test_r0_bp_w
test_sidisp8_w:
	r0_from_idx_disp8 r10
	b		test_r0_w
test_didisp8_w:
	r0_from_idx_disp8 r11
	b		test_r0_w
test_bpdisp8_w:
	r0_from_idx_disp8 r9
	b		test_r0_bp_w
test_bxdisp8_w:
	r0_from_idx_disp8 r7
	b		test_r0_w

// -- TEST [idx+disp16] --

test_bxsid16_imm16:
	r0_from_bxidxdisp16 r10
	b		test_r0_w
test_bxdid16_imm16:
	r0_from_bxidxdisp16 r11
	b		test_r0_w
test_bpsid16_imm16:
	r0_from_bpidxdisp16  r10
	b		test_r0_bp_w
test_bpdid16_imm16:
	r0_from_bpidxdisp16 r11
	b		test_r0_bp_w
test_sidisp16_imm16:
	r0_from_idx_disp16 r10
	b		test_r0_w
test_didisp16_imm16:
	r0_from_idx_disp16 r11
	b		test_r0_w
test_bpdisp16_imm16:
	r0_from_idx_disp16 r9
	b		test_r0_bp_w
test_bxdisp16_imm16:
	r0_from_idx_disp16 r7
	b		test_r0_w

// -- TEST reg16, imm16 --

.macro test_reg16_imm16 reg
	ldrb	r0, [r12], #1
	ldrb	r1, [r12], #1
	msr		cpsr_f,#0				// Clear all flags (especially C and O)
	orr		r0, r1, lsl #8
	mov		r1, \reg, lsl #16
	tst		r1, r0, lsl #16
	b		loop
.endm

test_ax_imm16:
	test_reg16_imm16 r4
test_cx_imm16:
	test_reg16_imm16 r5
test_dx_imm16:
	test_reg16_imm16 r6
test_bx_imm16:
	test_reg16_imm16 r7
test_sp_imm16:
	test_reg16_imm16 r8
test_bp_imm16:
	test_reg16_imm16 r9
test_si_imm16:
	test_reg16_imm16 r10
test_di_imm16:
	test_reg16_imm16 r11

// --- NOT r/m16 ---

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	not_r0_bp_w
not_r0_bp_w:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	not_r0_w
not_r0_w:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .not_w_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.not_w_RAM:
	ldrb	r0, [r2]
	ldrb	r1, [r2, #1]
	mvn		r0, r0
	mvn		r1, r1
	strb	r0, [r2]
	strb	r1, [r2, #1]
	b		loop

	.text
	.align 2

// -- not [idx] --

not_w_bxsi:
	add		r0, r7, r10
	b		not_r0_w
not_w_bxdi:
	add		r0, r7, r11
	b		not_r0_w
not_w_bpsi:
	add		r0, r9, r10
	b		not_r0_bp_w
not_w_bpdi:
	add		r0, r9, r11
	b		not_r0_bp_w
not_siidx_w:
	mov		r0, r10
	b		not_r0_w
not_diidx_w:
	mov		r0, r11
	b		not_r0_w
not_w_disp16:
	r0_from_disp16
	b		not_r0_w
not_bxidx_w:
	mov		r0, r7
	b		not_r0_w

// -- not [idx+disp8] --

not_w_bxsid8:
	r0_from_bxidxdisp8 r10
	b		not_r0_w
not_w_bxdid8:
	r0_from_bxidxdisp8 r11
	b		not_r0_w
not_w_bpsid8:
	r0_from_bpidxdisp8 r10
	b		not_r0_bp_w
not_w_bpdid8:
	r0_from_bpidxdisp8 r11
	b		not_r0_bp_w
not_sidisp8_w:
	r0_from_idx_disp8 r10
	b		not_r0_w
not_didisp8_w:
	r0_from_idx_disp8 r11
	b		not_r0_w
not_bpdisp8_w:
	r0_from_idx_disp8 r9
	b		not_r0_bp_w
not_bxdisp8_w:
	r0_from_idx_disp8 r7
	b		not_r0_w

// -- not [idx+disp16] --

not_w_bxsid16:
	r0_from_bxidxdisp16 r10
	b		not_r0_w
not_w_bxdid16:
	r0_from_bxidxdisp16 r11
	b		not_r0_w
not_w_bpsid16:
	r0_from_bpidxdisp16  r10
	b		not_r0_bp_w
not_w_bpdid16:
	r0_from_bpidxdisp16 r11
	b		not_r0_bp_w
not_w_sidisp16:
	r0_from_idx_disp16 r10
	b		not_r0_w
not_w_didisp16:
	r0_from_idx_disp16 r11
	b		not_r0_w
not_w_bpdisp16:
	r0_from_idx_disp16 r9
	b		not_r0_bp_w
not_w_bxdisp16:
	r0_from_idx_disp16 r7
	b		not_r0_w

.macro not_reg16 reg
	mvn		r0, \reg
	lsr		\reg, #16
	orr		\reg, r0, lsl #16
	ror		\reg, #16
	b		loop
.endm

not_ax:
	not_reg16 r4
not_cx:
	not_reg16 r5
not_dx:
	not_reg16 r6
not_bx:
	not_reg16 r7
not_sp:
	not_reg16 r8
not_bp:
	not_reg16 r9
not_si:
	not_reg16 r10
not_di:
	not_reg16 r11

// --- NEG r/m16 ---

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	neg_r0_bp_w
neg_r0_bp_w:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	neg_r0_w
neg_r0_w:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .neg_w_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.neg_w_RAM:
	ldrb	r0, [r2]
	ldrb	r1, [r2, #1]
	lsl		r0, #16
	orr		r0, r1, lsl #24
	rsbs	r0, #0					// reg = 0 - reg, setting flags
	lsr		r0, #16
	strb	r0,[r2]					// Save low byte
	lsr		r0, #8
	strb	r0,[r2, #1]				// Save high byte
	b		complement_carry

	.text
	.align 2

// -- neg [idx] --

neg_w_bxsi:
	add		r0, r7, r10
	b		neg_r0_w
neg_w_bxdi:
	add		r0, r7, r11
	b		neg_r0_w
neg_w_bpsi:
	add		r0, r9, r10
	b		neg_r0_bp_w
neg_w_bpdi:
	add		r0, r9, r11
	b		neg_r0_bp_w
neg_siidx_w:
	mov		r0, r10
	b		neg_r0_w
neg_diidx_w:
	mov		r0, r11
	b		neg_r0_w
neg_w_disp16:
	r0_from_disp16
	b		neg_r0_w
neg_bxidx_w:
	mov		r0, r7
	b		neg_r0_w

// -- neg [idx+disp8] --

neg_w_bxsid8:
	r0_from_bxidxdisp8 r10
	b		neg_r0_w
neg_w_bxdid8:
	r0_from_bxidxdisp8 r11
	b		neg_r0_w
neg_w_bpsid8:
	r0_from_bpidxdisp8 r10
	b		neg_r0_bp_w
neg_w_bpdid8:
	r0_from_bpidxdisp8 r11
	b		neg_r0_bp_w
neg_sidisp8_w:
	r0_from_idx_disp8 r10
	b		neg_r0_w
neg_didisp8_w:
	r0_from_idx_disp8 r11
	b		neg_r0_w
neg_bpdisp8_w:
	r0_from_idx_disp8 r9
	b		neg_r0_bp_w
neg_bxdisp8_w:
	r0_from_idx_disp8 r7
	b		neg_r0_w

// -- neg [idx+disp16] --

neg_w_bxsid16:
	r0_from_bxidxdisp16 r10
	b		neg_r0_w
neg_w_bxdid16:
	r0_from_bxidxdisp16 r11
	b		neg_r0_w
neg_w_bpsid16:
	r0_from_bpidxdisp16  r10
	b		neg_r0_bp_w
neg_w_bpdid16:
	r0_from_bpidxdisp16 r11
	b		neg_r0_bp_w
neg_w_sidisp16:
	r0_from_idx_disp16 r10
	b		neg_r0_w
neg_w_didisp16:
	r0_from_idx_disp16 r11
	b		neg_r0_w
neg_w_bpdisp16:
	r0_from_idx_disp16 r9
	b		neg_r0_bp_w
neg_w_bxdisp16:
	r0_from_idx_disp16 r7
	b		neg_r0_w
	
.macro neg_reg16 reg
	lsl		r0, \reg, #16
	eor		\reg, r0, lsr #16
	rsbs	r0, #0				// reg = 0 - reg, setting flags
	orr		\reg, r0, lsr #16
	b		complement_carry
.endm

neg_ax:
	neg_reg16 r4
neg_cx:
	neg_reg16 r5
neg_dx:
	neg_reg16 r6
neg_bx:
	neg_reg16 r7
neg_sp:
	neg_reg16 r8
neg_bp:
	neg_reg16 r9
neg_si:
	neg_reg16 r10
neg_di:
	neg_reg16 r11

// --- MUL r/m16 ---
// One of the operands is always AX and the result goes to DX:AX
// Carry and Overflow are set if DX != 0, other flags are undeterminate

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	mul_r0_bp_w
mul_r0_bp_w:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	mul_r0_w
mul_r0_w:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .mul_w_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.mul_w_RAM:
	ldrb	r0, [r2]
	ldrb	r1, [r2, #1]
	msr		cpsr_f,#0				// Clear all flags
	orr		r0, r1, lsl #8
	mov		r1, eax, lsl #16
	lsr		eax, #16
	lsr		edx, #16
	lsr		r1, #16
	mul		r2, r0, r1
	movs	r1, r2, lsr #16			// r1 = new DX value
	msrne	cpsr_f,#0x30000000		// Set Carry and Overflow flags if it is != 0
	orr		edx, r1, edx, lsl #16
	orr		eax, r2, lsl #16
	ror		eax, #16
	b		loop

	.text
	.align 2

// -- mul [idx] --

mul_w_bxsi:
	add		r0, r7, r10
	b		mul_r0_w
mul_w_bxdi:
	add		r0, r7, r11
	b		mul_r0_w
mul_w_bpsi:
	add		r0, r9, r10
	b		mul_r0_bp_w
mul_w_bpdi:
	add		r0, r9, r11
	b		mul_r0_bp_w
mul_siidx_w:
	mov		r0, r10
	b		mul_r0_w
mul_diidx_w:
	mov		r0, r11
	b		mul_r0_w
mul_w_disp16:
	r0_from_disp16
	b		mul_r0_w
mul_bxidx_w:
	mov		r0, r7
	b		mul_r0_w

// -- mul [idx+disp8] --

mul_w_bxsid8:
	r0_from_bxidxdisp8 r10
	b		mul_r0_w
mul_w_bxdid8:
	r0_from_bxidxdisp8 r11
	b		mul_r0_w
mul_w_bpsid8:
	r0_from_bpidxdisp8 r10
	b		mul_r0_bp_w
mul_w_bpdid8:
	r0_from_bpidxdisp8 r11
	b		mul_r0_bp_w
mul_sidisp8_w:
	r0_from_idx_disp8 r10
	b		mul_r0_w
mul_didisp8_w:
	r0_from_idx_disp8 r11
	b		mul_r0_w
mul_bpdisp8_w:
	r0_from_idx_disp8 r9
	b		mul_r0_bp_w
mul_bxdisp8_w:
	r0_from_idx_disp8 r7
	b		mul_r0_w

// -- mul [idx+disp16] --

mul_w_bxsid16:
	r0_from_bxidxdisp16 r10
	b		mul_r0_w
mul_w_bxdid16:
	r0_from_bxidxdisp16 r11
	b		mul_r0_w
mul_w_bpsid16:
	r0_from_bpidxdisp16  r10
	b		mul_r0_bp_w
mul_w_bpdid16:
	r0_from_bpidxdisp16 r11
	b		mul_r0_bp_w
mul_w_sidisp16:
	r0_from_idx_disp16 r10
	b		mul_r0_w
mul_w_didisp16:
	r0_from_idx_disp16 r11
	b		mul_r0_w
mul_w_bpdisp16:
	r0_from_idx_disp16 r9
	b		mul_r0_bp_w
mul_w_bxdisp16:
	r0_from_idx_disp16 r7
	b		mul_r0_w

// -- mul registers --

.macro mul_reg16 reg
	msr		cpsr_f,#0				// Clear all flags
	mov		r0, \reg, lsl #16
	mov		r1, eax, lsl #16
	lsr		eax, #16
	lsr		edx, #16
	lsr		r0, #16
	lsr		r1, #16
	mul		r2, r0, r1
	movs	r1, r2, lsr #16			// r1 = new DX value
	msrne	cpsr_f,#0x30000000		// Set Carry and Overflow flags if it is != 0
	orr		edx, r1, edx, lsl #16
	orr		eax, r2, lsl #16
	ror		eax, #16
	b		loop
.endm

mul_ax:
	mul_reg16 r4
mul_cx:
	mul_reg16 r5
mul_dx:
	mul_reg16 r6
mul_bx:
	mul_reg16 r7
mul_sp:
	mul_reg16 r8
mul_bp:
	mul_reg16 r9
mul_si:
	mul_reg16 r10
mul_di:
	mul_reg16 r11

// --- IMUL r/m16 ---
// One of the operands is always AX and the result goes to DX:AX
// TODO! Overflow and Carry flag handling

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	imul_r0_bp_w
imul_r0_bp_w:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	imul_r0_w
imul_r0_w:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .imul_w_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.imul_w_RAM:
	ldrb	r0, [r2]
	ldrsb	r1, [r2, #1]			// Get high byte
	mov		r2, eax, lsl #16
	lsr		eax, #16
	lsr		edx, #16
	asr		r2, #16					// r2 = SIGNED AX value
	orr		r0, r1, lsl #8			// r0 = SIGNED halfword
	mul		r1, r0, r2
	mov		r0, r1, lsr #16
	orr		edx, r0, edx, lsl #16
	orr		eax, r1, lsl #16
	ror		eax, #16
	b		loop

	.text
	.align 2

// -- imul [idx] --

imul_w_bxsi:
	add		r0, r7, r10
	b		imul_r0_w
imul_w_bxdi:
	add		r0, r7, r11
	b		imul_r0_w
imul_w_bpsi:
	add		r0, r9, r10
	b		imul_r0_bp_w
imul_w_bpdi:
	add		r0, r9, r11
	b		imul_r0_bp_w
imul_siidx_w:
	mov		r0, r10
	b		imul_r0_w
imul_diidx_w:
	mov		r0, r11
	b		imul_r0_w
imul_w_disp16:
	r0_from_disp16
	b		imul_r0_w
imul_bxidx_w:
	mov		r0, r7
	b		imul_r0_w

// -- imul [idx+disp8] --

imul_w_bxsid8:
	r0_from_bxidxdisp8 r10
	b		imul_r0_w
imul_w_bxdid8:
	r0_from_bxidxdisp8 r11
	b		imul_r0_w
imul_w_bpsid8:
	r0_from_bpidxdisp8 r10
	b		imul_r0_bp_w
imul_w_bpdid8:
	r0_from_bpidxdisp8 r11
	b		imul_r0_bp_w
imul_sidisp8_w:
	r0_from_idx_disp8 r10
	b		imul_r0_w
imul_didisp8_w:
	r0_from_idx_disp8 r11
	b		imul_r0_w
imul_bpdisp8_w:
	r0_from_idx_disp8 r9
	b		imul_r0_bp_w
imul_bxdisp8_w:
	r0_from_idx_disp8 r7
	b		imul_r0_w

// -- imul [idx+disp16] --

imul_w_bxsid16:
	r0_from_bxidxdisp16 r10
	b		imul_r0_w
imul_w_bxdid16:
	r0_from_bxidxdisp16 r11
	b		imul_r0_w
imul_w_bpsid16:
	r0_from_bpidxdisp16  r10
	b		imul_r0_bp_w
imul_w_bpdid16:
	r0_from_bpidxdisp16 r11
	b		imul_r0_bp_w
imul_w_sidisp16:
	r0_from_idx_disp16 r10
	b		imul_r0_w
imul_w_didisp16:
	r0_from_idx_disp16 r11
	b		imul_r0_w
imul_w_bpdisp16:
	r0_from_idx_disp16 r9
	b		imul_r0_bp_w
imul_w_bxdisp16:
	r0_from_idx_disp16 r7
	b		imul_r0_w

// -- imul registers --

.macro imul_reg16 reg
	mov		r0, \reg, lsl #16
	mov		r2, eax, lsl #16
	lsr		eax, #16
	lsr		edx, #16
	asr		r0, #16					// r0 = SIGNED reg value
	asr		r2, #16					// r2 = SIGNED AX value
	mul		r1, r0, r2
	mov		r0, r1, lsr #16
	orr		edx, r0, edx, lsl #16
	orr		eax, r1, lsl #16
	ror		eax, #16
	b		loop
.endm

imul_ax:
	imul_reg16 r4
imul_cx:
	imul_reg16 r5
imul_dx:
	imul_reg16 r6
imul_bx:
	imul_reg16 r7
imul_sp:
	imul_reg16 r8
imul_bp:
	imul_reg16 r9
imul_si:
	imul_reg16 r10
imul_di:
	imul_reg16 r11

// --- DIV r/m16 ---
// Numerator is always DX:AX, the result goes to AX and the remainder to DX.
// All flags are undeterminate.
//
// INT 00 C - CPU-generated - DIVIDE ERROR
//
// Desc: Generated if the divisor of a DIV or IDIV instruction is zero or the quotient overflows the result register
//		DX and AX will be unchanged. 
//
// Notes: On an 8086/8088, the return address points to the following instruction.
//		 On an 80286+, the return address points to the divide instruction.
//		 An 8086/8088 will generate this interrupt if the result of a division is 80h (byte) or 8000h (word) 
//

	.global	div_r0_bp_w
div_r0_bp_w:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	div_r0_w
div_r0_w:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .div_w_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.div_w_RAM:
	ldrb	r0, [r2]
	ldrb	r1, [r2, #1]			// Get high byte
	orr		r2, r0, r1, lsl #8		// r2 = UNSIGNED halfword
div_reg16_by_r2_subroutine:
#if SOFTWARE_DIV
	//-------
	// Software division routine. Algorithm taken from
	// "http://www.peter-cockerell.net/aalp/html/ch-6.html"
	// 	r0 = div (result)
	// 	r1 = mod (result)
	// 	r2 = rhs
	// 	r3 = lhs
	//	r4 = count
	//-------
	teq  	r2, #0    				// Trap div by zero
	beq		.div16_by_zero			// division by zero!!
	push	{r4}
	mov		r3, eax, lsl #16
	mov		r1, edx, lsl #16		// r1 = DX in high 16 bits, low 16 bits = 0
	orrs	r3, r1, r3, lsr #16		// r3 = DX:AX = lhs
	mov  	r1, #0    				// Init remainder
	mov  	r0, #0    				// and result
	mov  	r4, #32    				// Set up count
	bmi		2f						// If highest bit of r3 set, skip the first loop
1:	subs 	r4, r4, #1  			// Get first 1 bit of lhs
	beq		3f    					// into bit 31. Return if 0
	movs 	r3, r3, ASL #1
	bpl  	1b
2:	movs 	r3, r3, ASL #1  		// Get next bit into...
	adc  	r1, r1, r1   			// r1 for trial subtract
	cmp  	r1, r2    				// Can we subtract?
	subcs 	r1, r1, r2   			// Yes, so do
	adc  	r0, r0, r0   			// Shift carry into result
	subs 	r4, r4, #1  			// Next loop
	bne  	2b
3:	pop		{r4}
	cmp		r0, #0x10000			// Is the result >= 65536?
	bhs		.div16_by_zero			// Yep, overflow!
	lsr		eax, #16
	lsr		edx, #16
	orr		eax, r0, eax, lsl #16
	orr		edx, r1, edx, lsl #16
	b		loop					// Go back to loop
#else
	//-------
	// Nintendo DS division, using the math coprocessor
	//-------
	mov		r0, #0x280
	orr		r0, #0x04000000			// #define REG_DIVCNT			(*(vu16*)(0x04000280))
	cmp		r2, #0
	beq		.div16_by_zero			// Division by zero!!
	mov		r3, eax, lsl #16
	movs	r1, edx, lsl #16		// r1 = DX in high 16 bits, low 16 bits = 0
	bmi		.div16_slow				// If DX >= 0x8000 use the slower 64bit/32bit divide
	strh	r1, [r0]				// REG_DIVCNT = DIV_32_32 = 0
	orr		r1, r3, lsr #16			// r1 = DX:AX
	str		r1, [r0, #0x10]			// #define REG_DIV_NUMER_L		(*(vs32*) (0x04000290)),	REG_DIV_NUMER_L = num
	str		r2, [r0, #0x18]			// #define REG_DIV_DENOM_L		(*(vs32*) (0x04000298)),	REG_DIV_DENOM_L = den
1:	ldrh	r1, [r0]				// while(REG_DIVCNT & DIV_BUSY)
	tst		r1, #0x8000
	bne		1b
	ldr		r2,[r0, #0x20]			// #define REG_DIV_RESULT_L		(*(vs32*) (0x040002A0)),	r2 is the result of the division
	cmp		r2, #0x10000			// Is the result >= 65536?
	bhs		.div16_by_zero			// Yep, overflow!
	ldr		r0,[r0, #0x28]			// #define REG_DIVREM_RESULT_L	(*(vs32*) (0x040002A8)),	r0 is the remainder of the division
	lsr		eax, #16
	lsr		edx, #16
	orr		eax, r2, eax, lsl #16
	orr		edx, r0, edx, lsl #16
	b		loop					// Go back to loop
.div16_slow:
	orr		r3, r1, r3, lsr #16		// r3 = DX:AX
	mov		r1, #1
	strh	r1, [r0]				// REG_DIVCNT = DIV_64_32 = 1
	mov		r1, #0
	str		r3, [r0, #0x10]			// #define REG_DIV_NUMER_L		(*(vs32*) (0x04000290)),	REG_DIV_NUMER_L = num
	str		r1, [r0, #0x14]			// #define REG_DIV_NUMER_H		(*(vs32*) (0x04000294)),	REG_DIV_NUMER_H = 0
	str		r2, [r0, #0x18]			// #define REG_DIV_DENOM_L		(*(vs32*) (0x04000298)),	REG_DIV_DENOM_L = den
	b		1b
#endif
	
#define CPU_INT_EXCEPTION		0x2
	
	//-------
	// Handle divide by zero (= divide overflow)
	//-------
	.global	div32_by_zero
div32_by_zero:
.div16_by_zero:
.div8_by_zero:
	ldr		r12, [sp, #SP_EX_CSIP]	// Get the starting address of this opcode
	ldrb	r3, [sp, #SP_CPU_CR0]	// Get the lowest byte of cpu_cr0
	sub		r12, #1					// Count the actual opcode itself as well.
	//-------
	// If in prot mode, generate EXCEPTION(0)
	//-------
	tst		r3, #1					// Are we in protected mode (or in VM mode)?
	movne	r0, #0
	movne	r1, #CPU_INT_EXCEPTION
	movne	r2, #0
	bne		exception_cont_r0r1r2
	//-------
	// Real mode, call the INT00 vector
	//-------
	push_flags_16 r0 r2 r3
	mov		r2, #0
	calc_linear_address_r2
	ldr		r2,[r2]					// Get interrupt vector address, high halfword = segment, low halfword = offset
	// ----- Then store current CS:IP to stack
	ldr		r0, [sp, #SP_CS_VALUE]	// r0 = Current logical CS
	push_hword r0 r1 r3
	ldr		r1, [sp, #SP_PHYS_CS]	// r1 = Current physical CS
	sub		r1, r12, r1				// r1 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	push_hword r1 r0 r3
	// ----- Then get new logical IP (zero-extended) to r12
	mov		r12, r2, lsl #16
	// ----- Then get new logical CS (zero-extended) to r0
	mov		r0, r2, lsr #16			// Now r0 = new logical CS
	// ----- Then save the new logical CS
	mov		r2, r0, lsl #REAL_SEGMENT_SHIFT
	str		r0, [sp, #SP_CS_VALUE]
	str		r2, [sp, #SP_CS_BASE]
	// ----- And finally calculate new physical IP
	calc_linear_address_r2
	str		r2,[sp, #SP_PHYS_CS]	// Store new physical CS into stack
	add		r12, r2, r12, lsr #16	// r12 = new physical CS:IP = physical base + new IP + (new CS << 4)
	b		loop

// -- div [idx] --

div_w_bxsi:
	add		r0, r7, r10
	b		div_r0_w
div_w_bxdi:
	add		r0, r7, r11
	b		div_r0_w
div_w_bpsi:
	add		r0, r9, r10
	b		div_r0_bp_w
div_w_bpdi:
	add		r0, r9, r11
	b		div_r0_bp_w
div_siidx_w:
	mov		r0, r10
	b		div_r0_w
div_diidx_w:
	mov		r0, r11
	b		div_r0_w
div_w_disp16:
	r0_from_disp16
	b		div_r0_w
div_bxidx_w:
	mov		r0, r7
	b		div_r0_w

// -- div [idx+disp8] --

div_w_bxsid8:
	r0_from_bxidxdisp8 r10
	b		div_r0_w
div_w_bxdid8:
	r0_from_bxidxdisp8 r11
	b		div_r0_w
div_w_bpsid8:
	r0_from_bpidxdisp8 r10
	b		div_r0_bp_w
div_w_bpdid8:
	r0_from_bpidxdisp8 r11
	b		div_r0_bp_w
div_sidisp8_w:
	r0_from_idx_disp8 r10
	b		div_r0_w
div_didisp8_w:
	r0_from_idx_disp8 r11
	b		div_r0_w
div_bpdisp8_w:
	r0_from_idx_disp8 r9
	b		div_r0_bp_w
div_bxdisp8_w:
	r0_from_idx_disp8 r7
	b		div_r0_w

// -- div [idx+disp16] --

div_w_bxsid16:
	r0_from_bxidxdisp16 r10
	b		div_r0_w
div_w_bxdid16:
	r0_from_bxidxdisp16 r11
	b		div_r0_w
div_w_bpsid16:
	r0_from_bpidxdisp16  r10
	b		div_r0_bp_w
div_w_bpdid16:
	r0_from_bpidxdisp16 r11
	b		div_r0_bp_w
div_w_sidisp16:
	r0_from_idx_disp16 r10
	b		div_r0_w
div_w_didisp16:
	r0_from_idx_disp16 r11
	b		div_r0_w
div_w_bpdisp16:
	r0_from_idx_disp16 r9
	b		div_r0_bp_w
div_w_bxdisp16:
	r0_from_idx_disp16 r7
	b		div_r0_w

// -- div register --
	
.macro div_reg16 reg
	mov		r2, \reg, lsl #16		// r2 = UNSIGNED register value
	lsr		r2, #16
	b		div_reg16_by_r2_subroutine
.endm

div_ax:
	div_reg16 r4
div_cx:
	div_reg16 r5
div_dx:
	div_reg16 r6
div_bx:
	div_reg16 r7
div_sp:
	div_reg16 r8
div_bp:
	div_reg16 r9
div_si:
	div_reg16 r10
div_di:
	div_reg16 r11

// --- IDIV r/m16 ---
// Numerator is always DX:AX, the result goes to AX and the remainder to DX.
// All flags are undeterminate.
//
// INT 00 C - CPU-generated - DIVIDE ERROR
//
// Desc: Generated if the divisor of a DIV or IDIV instruction is zero or the quotient overflows the result register
//		DX and AX will be unchanged. 
//
// Notes: On an 8086/8088, the return address points to the following instruction.
//		 On an 80286+, the return address points to the divide instruction.
//		 An 8086/8088 will generate this interrupt if the result of a division is 80h (byte) or 8000h (word) 
//
	.global	idiv_r0_bp_w
idiv_r0_bp_w:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	idiv_r0_w
idiv_r0_w:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .idiv_w_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.idiv_w_RAM:
	ldrb	r0,[r2]					// Get low byte
	ldrsb	r1,[r2, #1]				// Get signed high byte
	orr		r2, r0, r1, lsl #8		// r2 = SIGNED halfword
idiv_reg16_by_r2_subroutine:
#if SOFTWARE_DIV
	//-------
	// Software division routine. Algorithm taken from
	// "http://www.peter-cockerell.net/aalp/html/ch-6.html"
	// 	r0 = div (result)
	// 	r1 = mod (result)
	// 	r2 = rhs
	//	r3 = signs (bit 0 = div sign, bit 1 = mod sign)
	//	r4 = count
	// 	r5 = lhs
	//-------
	teq  	r2, #0    				// Trap div by zero
	beq		.div16_by_zero			// division by zero!!
	push	{r4, r5}
	mov		r5, eax, lsl #16
	mov		r1, edx, lsl #16		// r1 = DX in high 16 bits, low 16 bits = 0
	orrs	r5, r1, r5, lsr #16		// r5 = DX:AX = lhs, sign flag set if negative
	eor		r3, r5, r2
	lsr		r3, #31					// r3 lowest bit tells the sign of the result
	orrmi	r3, #2					// Mod sign should be negative if lhs is negative
	rsbmi	r5, #0					// Make lhs positive
	teq		r2, #0					// Is rhs negative?
	rsbmi	r2, #0					// If yes, make it positive
	mov  	r1, #0    				// Init remainder
	mov  	r0, #0    				// and result
	mov  	r4, #32    				// Set up count
1:	subs 	r4, r4, #1  			// Get first 1 bit of lhs
	beq		3f    					// into bit 31. Return if 0
	movs 	r5, r5, ASL #1
	bpl  	1b
2:	movs 	r5, r5, ASL #1  		// Get next bit into...
	adc  	r1, r1, r1   			// r1 for trial subtract
	cmp  	r1, r2    				// Can we subtract?
	subcs 	r1, r1, r2   			// Yes, so do
	adc  	r0, r0, r0   			// Shift carry into result
	subs 	r4, r4, #1  			// Next loop
	bne  	2b
3:	pop		{r4, r5}
	and		r2, r3, #1
	add		r2, #0x8000
	cmp		r0, r2					// Is the result > 32767 or < -32768?
	bhs		.div16_by_zero			// Yep, overflow!
	lsr		eax, #16
	lsr		edx, #16
	tst		r3, #1					// Should we negate the result?
	rsbne	r0, #0					// Yep
	tst		r3, #2					// Should we negate the remainder?
	rsbne	r1, #0					// Yep
	orr		eax, r0, lsl #16
	orr		edx, r1, lsl #16
	ror		eax, #16
	ror		edx, #16
	b		loop					// Go back to loop
#else
	mov		r0, #0x280
	orr		r0, #0x04000000			// #define REG_DIVCNT			(*(vu16*)(0x04000280))
	cmp		r2, #0
	beq		.div16_by_zero			// Division by zero!!
	mov		r3, eax, lsl #16
	mov		r1, edx, lsl #16		// r1 = DX in high 16 bits, low 16 bits = 0
	strh	r1, [r0]				// REG_DIVCNT = DIV_32_32 = 0
	orr		r1, r3, lsr #16			// r1 = DX:AX
	str		r1, [r0, #0x10]			// #define REG_DIV_NUMER_L		(*(vs32*) (0x04000290)),	REG_DIV_NUMER_L = num
	str		r2, [r0, #0x18]			// #define REG_DIV_DENOM_L		(*(vs32*) (0x04000298)),	REG_DIV_DENOM_L = den
1:	ldrh	r1, [r0]				// while(REG_DIVCNT & DIV_BUSY)
	tst		r1, #0x8000
	bne		1b
	ldr		r2,[r0, #0x20]			// #define REG_DIV_RESULT_L		(*(vs32*) (0x040002A0)),	r2 is the result of the division
	cmp		r2, #0x8000				// Is the result >= 32768?
	bge		.div16_by_zero			// Yep, overflow!
	mov		r1, #0x80000000
	cmp		r2, r1, asr #16			// Is the result < -32768?
	blt		.div16_by_zero			// Yep, overflow!
	ldr		r0,[r0, #0x28]			// #define REG_DIVREM_RESULT_L	(*(vs32*) (0x040002A8)),	r0 is the remainder of the division
	lsr		eax, #16
	lsr		edx, #16
	orr		eax, r2, lsl #16
	orr		edx, r0, lsl #16
	ror		eax, #16
	ror		edx, #16
	b		loop					// Go back to loop
#endif

// -- idiv [idx] --

idiv_w_bxsi:
	add		r0, r7, r10
	b		idiv_r0_w
idiv_w_bxdi:
	add		r0, r7, r11
	b		idiv_r0_w
idiv_w_bpsi:
	add		r0, r9, r10
	b		idiv_r0_bp_w
idiv_w_bpdi:
	add		r0, r9, r11
	b		idiv_r0_bp_w
idiv_siidx_w:
	mov		r0, r10
	b		idiv_r0_w
idiv_diidx_w:
	mov		r0, r11
	b		idiv_r0_w
idiv_w_disp16:
	r0_from_disp16
	b		idiv_r0_w
idiv_bxidx_w:
	mov		r0, r7
	b		idiv_r0_w

// -- idiv [idx+disp8] --

idiv_w_bxsid8:
	r0_from_bxidxdisp8 r10
	b		idiv_r0_w
idiv_w_bxdid8:
	r0_from_bxidxdisp8 r11
	b		idiv_r0_w
idiv_w_bpsid8:
	r0_from_bpidxdisp8 r10
	b		idiv_r0_bp_w
idiv_w_bpdid8:
	r0_from_bpidxdisp8 r11
	b		idiv_r0_bp_w
idiv_sidisp8_w:
	r0_from_idx_disp8 r10
	b		idiv_r0_w
idiv_didisp8_w:
	r0_from_idx_disp8 r11
	b		idiv_r0_w
idiv_bpdisp8_w:
	r0_from_idx_disp8 r9
	b		idiv_r0_bp_w
idiv_bxdisp8_w:
	r0_from_idx_disp8 r7
	b		idiv_r0_w

// -- idiv [idx+disp16] --

idiv_w_bxsid16:
	r0_from_bxidxdisp16 r10
	b		idiv_r0_w
idiv_w_bxdid16:
	r0_from_bxidxdisp16 r11
	b		idiv_r0_w
idiv_w_bpsid16:
	r0_from_bpidxdisp16  r10
	b		idiv_r0_bp_w
idiv_w_bpdid16:
	r0_from_bpidxdisp16 r11
	b		idiv_r0_bp_w
idiv_w_sidisp16:
	r0_from_idx_disp16 r10
	b		idiv_r0_w
idiv_w_didisp16:
	r0_from_idx_disp16 r11
	b		idiv_r0_w
idiv_w_bpdisp16:
	r0_from_idx_disp16 r9
	b		idiv_r0_bp_w
idiv_w_bxdisp16:
	r0_from_idx_disp16 r7
	b		idiv_r0_w

// -- idiv register --

.macro idiv_reg16 reg
	mov		r2, \reg, lsl #16		// r2 = SIGNED register value
	asr		r2, #16
	b		idiv_reg16_by_r2_subroutine
.endm

idiv_ax:
	idiv_reg16 r4
idiv_cx:
	idiv_reg16 r5
idiv_dx:
	idiv_reg16 r6
idiv_bx:
	idiv_reg16 r7
idiv_sp:
	idiv_reg16 r8
idiv_bp:
	idiv_reg16 r9
idiv_si:
	idiv_reg16 r10
idiv_di:
	idiv_reg16 r11

.ltorg								// Dump the current literal pool here

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	
	
// ------------------- F8 = CLC ----------------------------------------
op_f8:
	mrs		r0, cpsr				// Save current flags to r0
	bic		r0, #0x20000000			// Clear the Carry flag
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0

// ------------------- F9 = STC ----------------------------------------
op_f9:
	mrs		r0, cpsr				// Save current flags to r0
	orr		r0, #0x20000000			// Set the Carry flag
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0
	
// ------------------- FA = CLI ----------------------------------------
// op_fa_CLI: see "pic.s"
//
	
// ------------------- FB = STI ----------------------------------------
// op_fb_STI: see "pic.s"
//
	
// ------------------- FC = CLD ----------------------------------------
// Clear Direction Flag. Here we fix all the function pointers for the
// functions that use the direction flag (so that the functions themselves
// do not have to check the flag). CLD/STD are executed much less frequently
// than the functions themselves.

op_fc:
	ldr		r1,[sp, #SP_FLAGS]		// Get the EXTRAFLAGS value
	bic		r1,#FLAG_DF				// Clear the "Direction" bit
	str		r1,[sp, #SP_FLAGS]		// Save the EXTRAFLAGS value
	b		loop

// ------------------- FD = STD ----------------------------------------
// Set Direction Flag. Here we fix all the function pointers for the
// functions that use the direction flag (so that the functions themselves
// do not have to check the flag). CLD/STD are executed much less frequently
// than the functions themselves.
//
op_fd:
	ldr		r1,[sp, #SP_FLAGS]		// Get the EXTRAFLAGS value
	orr		r1,#FLAG_DF				// Set the "Direction" bit
	str		r1,[sp, #SP_FLAGS]		// Save the EXTRAFLAGS value
	b		loop

.ltorg								// Dump the current literal pool here

	.text
	.align 2
	
// ------------------- FE = INC/DEC r/m8 -------------------------------
// INC x is like ADD x,1, except the Carry flag is not changed.
//
// All modrm variations supported!
//
	.global	op_fe
op_fe:
	ldrb	r0,[r12],#1							// Load next opcode byte to r0, increment r12 by 1
	ldr		r3, [sp, #SP_MASK_16]				// Use 16-bit memory address masking
	ldr		pc,[pc, r0, lsl #2]					// Jump to the handler
	.word	0									// Dummy word to align the table to PC+8

// 0
	.word inc_byte_bxsi, inc_byte_bxdi, inc_byte_bpsi, inc_byte_bpdi, inc_byte_siidx_, inc_byte_diidx_, inc_byte_disp16, inc_byte_bxidx_
	.word dec_byte_bxsi, dec_byte_bxdi, dec_byte_bpsi, dec_byte_bpdi, dec_byte_siidx_, dec_byte_diidx_, dec_byte_disp16, dec_byte_bxidx_
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word op_fe_callback, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
//0x40
	.word inc_byte_bxsid8, inc_byte_bxdid8, inc_byte_bpsid8, inc_byte_bpdid8, inc_byte_sidisp8_, inc_byte_didisp8_, inc_byte_bpdisp8_, inc_byte_bxdisp8_
	.word dec_byte_bxsid8, dec_byte_bxdid8, dec_byte_bpsid8, dec_byte_bpdid8, dec_byte_sidisp8_, dec_byte_didisp8_, dec_byte_bpdisp8_, dec_byte_bxdisp8_
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
//0x80
	.word inc_byte_bxsid16, inc_byte_bxdid16, inc_byte_bpsid16, inc_byte_bpdid16, inc_byte_sidisp16, inc_byte_didisp16, inc_byte_bpdisp16, inc_byte_bxdisp16
	.word dec_byte_bxsid16, dec_byte_bxdid16, dec_byte_bpsid16, dec_byte_bpdid16, dec_byte_sidisp16, dec_byte_didisp16, dec_byte_bpdisp16, dec_byte_bxdisp16
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
//0xc0 = mod = 11b => register operand
// INC reg8
	.word inc_al, inc_cl, inc_dl, inc_bl, inc_ah, inc_ch, inc_dh, inc_bh
// DEC reg8
	.word dec_al, dec_cl, dec_dl, dec_bl, dec_ah, dec_ch, dec_dh, dec_bh
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1

	.global inc_byte_siidx_, inc_byte_diidx_, inc_byte_bxidx_
	.global dec_byte_siidx_, dec_byte_diidx_, dec_byte_bxidx_
	.global inc_byte_sidisp8_, inc_byte_didisp8_, inc_byte_bpdisp8_, inc_byte_bxdisp8_
	.global dec_byte_sidisp8_, dec_byte_didisp8_, dec_byte_bpdisp8_, dec_byte_bxdisp8_

	.global inc_al, inc_cl, inc_dl, inc_bl, inc_ah, inc_ch, inc_dh, inc_bh
	.global dec_al, dec_cl, dec_dl, dec_bl, dec_ah, dec_ch, dec_dh, dec_bh

// ----- INC -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	inc_byte_bp_r0
inc_byte_bp_r0:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	inc_byte_r0
inc_byte_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .inc_byte_RAM inc_byte_EGA_r2 inc_byte_MODEX_r2
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.inc_byte_RAM:
	ldrb	r1,[r2]					// Get byte from RAM
	mrs		r0,cpsr					// Get original flags to r0.
	lsl		r1, #24
	adds	r1, #0x01000000			// Add 1 to the high byte
	lsr		r1, #24
	strb	r1,[r2]					// Save low byte
	// ----- Fix the Carry flag
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Only the original Carry flag bit
	bic		r1, #0x20000000			// r1 = New flags with Carry cleared
	orr		r0, r1					// r0 = new flags + original Carry flag
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0

	.text
	.align 2

// --- INC [idx] ---

inc_byte_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		inc_byte_r0
inc_byte_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		inc_byte_r0
inc_byte_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		inc_byte_bp_r0
inc_byte_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		inc_byte_bp_r0
inc_byte_siidx_:
	mov		r0, r10
	b		inc_byte_r0
inc_byte_diidx_:
	mov		r0, r11
	b		inc_byte_r0
inc_byte_disp16:
	r0_from_disp16
	b		inc_byte_r0
inc_byte_bxidx_:
	mov		r0, r7
	b		inc_byte_r0

// --- INC [idx+disp8] ---

inc_byte_bxsid8:
	r0_from_bxidxdisp8 r10
	b		inc_byte_r0
inc_byte_bxdid8:
	r0_from_bxidxdisp8 r11
	b		inc_byte_r0
inc_byte_bpsid8:
	r0_from_bpidxdisp8 r10
	b		inc_byte_bp_r0
inc_byte_bpdid8:
	r0_from_bpidxdisp8 r11
	b		inc_byte_bp_r0
inc_byte_sidisp8_:
	r0_from_idx_disp8 r10
	b		inc_byte_r0
inc_byte_didisp8_:
	r0_from_idx_disp8 r11
	b		inc_byte_r0
inc_byte_bpdisp8_:
	r0_from_idx_disp8 r9
	b		inc_byte_bp_r0
inc_byte_bxdisp8_:
	r0_from_idx_disp8 r7
	b		inc_byte_r0

// --- INC [idx+disp16] ---

inc_byte_bxsid16:
	r0_from_bxidxdisp16 r10
	b		inc_byte_r0
inc_byte_bxdid16:
	r0_from_bxidxdisp16 r11
	b		inc_byte_r0
inc_byte_bpsid16:
	r0_from_bpidxdisp16 r10
	b		inc_byte_bp_r0
inc_byte_bpdid16:
	r0_from_bpidxdisp16 r11
	b		inc_byte_bp_r0
inc_byte_sidisp16:
	r0_from_idx_disp16 r10
	b		inc_byte_r0
inc_byte_didisp16:
	r0_from_idx_disp16 r11
	b		inc_byte_r0
inc_byte_bpdisp16:
	r0_from_idx_disp16 r9
	b		inc_byte_bp_r0
inc_byte_bxdisp16:
	r0_from_idx_disp16 r7
	b		inc_byte_r0

// --- INC reg8 ---

.macro inc_reg8l reg
	// ----- Save the current flags (namely Carry)
	mrs		r0,cpsr					// r0 = Current flags
	// ----- Perform the INC reg8l operation
	mov		r1, \reg, lsl #24
	adds	r1, #0x01000000			// Perform the INC using the highest byte and setting flags
	bic		\reg, #0xFF
	orr		\reg, r1, lsr #24
	// ----- Restore the Carry flag
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Original Carry flag
	bic		r1, #0x20000000			// r1 = All but the carry flag
	orr		r0, r1					// r0 = new flags
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0
.endm

.macro inc_reg8h reg
	// ----- Save the current flags (namely Carry)
	mrs		r0,cpsr					// r0 = Current flags
	// ----- Perform the INC reg8h operation
	mov		r1, \reg, lsl #16
	and		r1, #0xFF000000
	adds	r1, #0x01000000			// Perform the INC using the highest byte and setting flags
	bic		\reg, #0xFF00
	orr		\reg, r1, lsr #16
	// ----- Restore the Carry flag
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Original Carry flag
	bic		r1, #0x20000000			// r1 = All but the carry flag
	orr		r0, r1					// r0 = new flags
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0
.endm

inc_al:
	inc_reg8l r4
inc_cl:
	inc_reg8l r5
inc_dl:
	inc_reg8l r6
inc_bl:
	inc_reg8l r7
inc_ah:
	inc_reg8h r4
inc_ch:
	inc_reg8h r5
inc_dh:
	inc_reg8h r6
inc_bh:
	inc_reg8h r7

// ----- DEC -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global dec_byte_bp_r0
dec_byte_bp_r0:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	dec_byte_r0
dec_byte_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .dec_byte_RAM dec_byte_EGA_r2 dec_byte_MODEX_r2
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.dec_byte_RAM:
	ldrb	r1,[r2]					// Get byte from RAM
	mrs		r0,cpsr					// Get original flags to r0.
	lsl		r1, #24
	subs	r1, #0x01000000			// Add 1 to the high byte
	lsr		r1, #24
	strb	r1,[r2]					// Save low byte
	// ----- Fix the Carry flag
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Only the original Carry flag bit
	bic		r1, #0x20000000			// r1 = New flags with Carry cleared
	orr		r0, r1					// r0 = new flags + original Carry flag
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0

	.text
	.align 2

// --- DEC [idx] ---

dec_byte_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		dec_byte_r0
dec_byte_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		dec_byte_r0
dec_byte_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		dec_byte_bp_r0
dec_byte_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		dec_byte_bp_r0
dec_byte_siidx_:
	mov		r0, r10
	b		dec_byte_r0
dec_byte_diidx_:
	mov		r0, r11
	b		dec_byte_r0
dec_byte_disp16:
	r0_from_disp16
	b		dec_byte_r0
dec_byte_bxidx_:
	mov		r0, r7
	b		dec_byte_r0

// --- DEC [idx+disp8] ---

dec_byte_bxsid8:
	r0_from_bxidxdisp8 r10
	b		dec_byte_r0
dec_byte_bxdid8:
	r0_from_bxidxdisp8 r11
	b		dec_byte_r0
dec_byte_bpsid8:
	r0_from_bpidxdisp8 r10
	b		dec_byte_bp_r0
dec_byte_bpdid8:
	r0_from_bpidxdisp8 r11
	b		dec_byte_bp_r0
dec_byte_sidisp8_:
	r0_from_idx_disp8 r10
	b		dec_byte_r0
dec_byte_didisp8_:
	r0_from_idx_disp8 r11
	b		dec_byte_r0
dec_byte_bpdisp8_:
	r0_from_idx_disp8 r9
	b		dec_byte_bp_r0
dec_byte_bxdisp8_:
	r0_from_idx_disp8 r7
	b		dec_byte_r0

// --- DEC [idx+disp16] ---

dec_byte_bxsid16:
	r0_from_bxidxdisp16 r10
	b		dec_byte_r0
dec_byte_bxdid16:
	r0_from_bxidxdisp16 r11
	b		dec_byte_r0
dec_byte_bpsid16:
	r0_from_bpidxdisp16 r10
	b		dec_byte_bp_r0
dec_byte_bpdid16:
	r0_from_bpidxdisp16 r11
	b		dec_byte_bp_r0
dec_byte_sidisp16:
	r0_from_idx_disp16 r10
	b		dec_byte_r0
dec_byte_didisp16:
	r0_from_idx_disp16 r11
	b		dec_byte_r0
dec_byte_bpdisp16:
	r0_from_idx_disp16 r9
	b		dec_byte_bp_r0
dec_byte_bxdisp16:
	r0_from_idx_disp16 r7
	b		dec_byte_r0

// --- DEC reg8 ---

.macro dec_reg8l reg
	// ----- Save the current flags (namely Carry)
	mrs		r0,cpsr					// r0 = Current flags
	// ----- Perform the dec reg8l operation
	mov		r1, \reg, lsl #24
	subs	r1, #0x01000000			// Perform the dec using the highest byte and setting flags
	bic		\reg, #0xFF
	orr		\reg, r1, lsr #24
	// ----- Restore the Carry flag
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Original Carry flag
	bic		r1, #0x20000000			// r1 = All but the carry flag
	orr		r0, r1					// r0 = new flags
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0
.endm

.macro dec_reg8h reg
	// ----- Save the current flags (namely Carry)
	mrs		r0,cpsr					// r0 = Current flags
	// ----- Perform the dec reg8h operation
	mov		r1, \reg, lsl #16
	and		r1, #0xFF000000
	subs	r1, #0x01000000			// Perform the dec using the highest byte and setting flags
	bic		\reg, #0xFF00
	orr		\reg, r1, lsr #16
	// ----- Restore the Carry flag
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Original Carry flag
	bic		r1, #0x20000000			// r1 = All but the carry flag
	orr		r0, r1					// r0 = new flags
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0
.endm

dec_al:
	dec_reg8l r4
dec_cl:
	dec_reg8l r5
dec_dl:
	dec_reg8l r6
dec_bl:
	dec_reg8l r7
dec_ah:
	dec_reg8h r4
dec_ch:
	dec_reg8h r5
dec_dh:
	dec_reg8h r6
dec_bh:
	dec_reg8h r7

// ------------------- FF = INC/DEC/CALL/JMP/PUSH ----------------------
//
// All modrm variations supported!
//
	.global	op_ff
op_ff:
	modrm_jump_16
// 0 (idx only)
	.word inc_word_bxsi, inc_word_bxdi, inc_word_bpsi, inc_word_bpdi, inc_word_siidx, inc_word_diidx, inc_word_disp16, inc_word_bxidx
	.word dec_word_bxsi, dec_word_bxdi, dec_word_bpsi, dec_word_bpdi, dec_word_siidx, dec_word_diidx, dec_word_disp16, dec_word_bxidx
	.word call_near_bxsi, call_near_bxdi, call_near_bpsi, call_near_bpdi, call_near_siidx, call_near_diidx, call_near_disp16, call_near_bxidx
	.word call_far_bxsi, call_far_bxdi, call_far_bpsi, call_far_bpdi, call_far_siidx, call_far_diidx, call_far_disp16, call_far_bxidx
	.word jmp_near_bxsi, jmp_near_bxdi, jmp_near_bpsi, jmp_near_bpdi, jmp_near_siidx, jmp_near_diidx, jmp_near_disp16, jmp_near_bxidx
	.word jmp_far_bxsi, jmp_far_bxdi, jmp_far_bpsi, jmp_far_bpdi, jmp_far_siidx, jmp_far_diidx, jmp_far_disp16, jmp_far_bxidx
	.word push_bxsi, push_bxdi, push_bpsi, push_bpdi, push_word_siidx, push_word_diidx, push_disp16, push_word_bxidx
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
//0x40 (+disp8)
	.word inc_word_bxsid8, inc_word_bxdid8, inc_word_bpsid8, inc_word_bpdid8, inc_word_sidisp8, inc_word_didisp8, inc_word_bpdisp8, inc_word_bxdisp8
	.word dec_word_bxsid8, dec_word_bxdid8, dec_word_bpsid8, dec_word_bpdid8, dec_word_sidisp8, dec_word_didisp8, dec_word_bpdisp8, dec_word_bxdisp8
	.word call_near_bxsid8, call_near_bxdid8, call_near_bpsid8, call_near_bpdid8, call_near_sidisp8, call_near_didisp8, call_near_bpdisp8, call_near_bxdisp8
	.word call_far_bxsid8, call_far_bxdid8, call_far_bpsid8, call_far_bpdid8, call_far_sidisp8, call_far_didisp8, call_far_bpdisp8, call_far_bxdisp8
	.word jmp_near_bxsid8, jmp_near_bxdid8, jmp_near_bpsid8, jmp_near_bpdid8, jmp_near_sidisp8, jmp_near_didisp8, jmp_near_bpdisp8, jmp_near_bxdisp8
	.word jmp_far_bxsid8, jmp_far_bxdid8, jmp_far_bpsid8, jmp_far_bpdid8, jmp_far_sidisp8, jmp_far_didisp8, jmp_far_bpdisp8, jmp_far_bxdisp8
	.word push_bxsid8, push_bxdid8, push_bpsid8, push_bpdid8, push_word_sidisp8, push_word_didisp8, push_word_bpdisp8, push_word_bxdisp8
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
//0x80
	.word inc_word_bxsid16, inc_word_bxdid16, inc_word_bpsid16, inc_word_bpdid16, inc_word_sidisp16, inc_word_didisp16, inc_word_bpdisp16, inc_word_bxdisp16
	.word dec_word_bxsid16, dec_word_bxdid16, dec_word_bpsid16, dec_word_bpdid16, dec_word_sidisp16, dec_word_didisp16, dec_word_bpdisp16, dec_word_bxdisp16
	.word call_near_bxsid16, call_near_bxdid16, call_near_bpsid16, call_near_bpdid16, call_near_sidisp16, call_near_didisp16, call_near_bpdisp16, call_near_bxdisp16
	.word call_far_bxsid16, call_far_bxdid16, call_far_bpsid16, call_far_bpdid16, call_far_sidisp16, call_far_didisp16, call_far_bpdisp16, call_far_bxdisp16
	.word jmp_near_bxsid16, jmp_near_bxdid16, jmp_near_bpsid16, jmp_near_bpdid16, jmp_near_sidisp16, jmp_near_didisp16, jmp_near_bpdisp16, jmp_near_bxdisp16
	.word jmp_far_bxsid16, jmp_far_bxdid16, jmp_far_bpsid16, jmp_far_bpdid16, jmp_far_sidisp16, jmp_far_didisp16, jmp_far_bpdisp16, jmp_far_bxdisp16
	.word push_bxsid16, push_bxdid16, push_bpsid16, push_bpdid16, push_sidisp16, push_didisp16, push_bpdisp16, push_bxdisp16
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
//0xC0
	.word op_40, op_41, op_42, op_43, op_44, op_45, op_46, op_47		// INC AX ... INC DI
	.word op_48, op_49, op_4a, op_4b, op_4c, op_4d, op_4e, op_4f		// DEC AX ... DEC DI
	.word call_near_ax, call_near_cx, call_near_dx, call_near_bx, call_near_sp, call_near_bp, call_near_si, call_near_di
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word jmp_near_ax, jmp_near_cx, jmp_near_dx, jmp_near_bx, jmp_near_sp, jmp_near_bp, jmp_near_si, jmp_near_di
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1
	.word op_50, op_51, op_52, op_53, op_54, op_55, op_56, op_57		// PUSH AX ... PUSH DI
	.word .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1, .unknown_back1

	.ltorg

	.global inc_word_bxsi, inc_word_bxdi, inc_word_bpsi, inc_word_bpdi, inc_word_siidx, inc_word_diidx, inc_word_disp16, inc_word_bxidx
	.global dec_word_bxsi, dec_word_bxdi, dec_word_bpsi, dec_word_bpdi, dec_word_siidx, dec_word_diidx, dec_word_disp16, dec_word_bxidx
	.global call_near_bxsi, call_near_bxdi, call_near_bpsi, call_near_bpdi, call_near_siidx, call_near_diidx, call_near_disp16, call_near_bxidx
	.global call_far_bxsi, call_far_bxdi, call_far_bpsi, call_far_bpdi, call_far_siidx, call_far_diidx, call_far_disp16, call_far_bxidx
	.global jmp_near_bxsi, jmp_near_bxdi, jmp_near_bpsi, jmp_near_bpdi, jmp_near_siidx, jmp_near_diidx, jmp_near_disp16, jmp_near_bxidx
	.global push_bxsi, push_bxdi, push_bpsi, push_bpdi, push_word_siidx, push_word_diidx, push_disp16, push_word_bxidx
	.global inc_word_bxsid8, inc_word_bxdid8, inc_word_bpsid8, inc_word_bpdid8, inc_word_sidisp8, inc_word_didisp8, inc_word_bpdisp8, inc_word_bxdisp8
	.global dec_word_bxsid8, dec_word_bxdid8, dec_word_bpsid8, dec_word_bpdid8, dec_word_sidisp8, dec_word_didisp8, dec_word_bpdisp8, dec_word_bxdisp8
	.global call_near_bxsid8, call_near_bxdid8, call_near_bpsid8, call_near_bpdid8, call_near_sidisp8, call_near_didisp8, call_near_bpdisp8, call_near_bxdisp8
	.global call_far_bxsid8, call_far_bxdid8, call_far_bpsid8, call_far_bpdid8, call_far_sidisp8, call_far_didisp8, call_far_bpdisp8, call_far_bxdisp8
	.global jmp_near_bxsid8, jmp_near_bxdid8, jmp_near_bpsid8, jmp_near_bpdid8, jmp_near_sidisp8, jmp_near_didisp8, jmp_near_bpdisp8, jmp_near_bxdisp8
	.global push_bxsid8, push_bxdid8, push_bpsid8, push_bpdid8, push_word_sidisp8, push_word_didisp8, push_word_bpdisp8, push_word_bxdisp8
	.global inc_word_bxsid16, inc_word_bxdid16, inc_word_bpsid16, inc_word_bpdid16, inc_word_sidisp16, inc_word_didisp16, inc_word_bpdisp16, inc_word_bxdisp16
	.global dec_word_bxsid16, dec_word_bxdid16, dec_word_bpsid16, dec_word_bpdid16, dec_word_sidisp16, dec_word_didisp16, dec_word_bpdisp16, dec_word_bxdisp16
	.global call_near_bxsid16, call_near_bxdid16, call_near_bpsid16, call_near_bpdid16, call_near_sidisp16, call_near_didisp16, call_near_bpdisp16, call_near_bxdisp16
	.global jmp_near_bxsid16, jmp_near_bxdid16, jmp_near_bpsid16, jmp_near_bpdid16, jmp_near_sidisp16, jmp_near_didisp16, jmp_near_bpdisp16, jmp_near_bxdisp16
	.global push_bxsid16, push_bxdid16, push_bpsid16, push_bpdid16, push_sidisp16, push_didisp16, push_bpdisp16, push_bxdisp16
	.global op_40, op_41, op_42, op_43, op_44, op_45, op_46, op_47		// INC AX ... INC DI
	.global op_48, op_49, op_4a, op_4b, op_4c, op_4d, op_4e, op_4f		// DEC AX ... DEC DI
	.global call_near_ax, call_near_cx, call_near_dx, call_near_bx, call_near_sp, call_near_bp, call_near_si, call_near_di
	.global jmp_near_ax, jmp_near_cx, jmp_near_dx, jmp_near_bx, jmp_near_sp, jmp_near_bp, jmp_near_si, jmp_near_di
	.global op_50, op_51, op_52, op_53, op_54, op_55, op_56, op_57		// PUSH AX ... PUSH DI

// ----- INC -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	inc_word_r0_bp
inc_word_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	inc_word_r0
inc_word_r0:
	mem_handler_jump_r0r3 .inc_word_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.inc_word_RAM:
	ldrb	r0,[r2]					// Get low byte
	ldrb	r1,[r2, #1]				// Get high byte
	lsl		r0, #16
	orr		r1, r0, r1, lsl #24		// r1 = low byte | (high byte << 8) = the value to increment
	mrs		r0,cpsr					// Get original flags to r0.
	adds	r1, #0x00010000			// Add 1 to the value
	lsr		r1, #16
	strb	r1,[r2]					// Save low byte
	lsr		r1, #8
	strb	r1,[r2, #1]				// Save high byte
	// ----- Fix the Carry flag
	mrs		r1,cpsr					// r1 = Flags after the increment
	and		r0, #0x20000000			// r0 = Only the original Carry flag bit
	bic		r1, #0x20000000			// r1 = New flags with Carry cleared
	orr		r0, r1					// r0 = new flags + original Carry flag
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0

	.text
	.align 2
	
inc_word_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		inc_word_r0
inc_word_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		inc_word_r0
inc_word_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		inc_word_r0_bp
inc_word_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		inc_word_r0_bp
inc_word_siidx:
	mov		r0, r10
	b		inc_word_r0
inc_word_diidx:
	mov		r0, r11
	b		inc_word_r0
inc_word_disp16:
	r0_from_disp16
	b		inc_word_r0
inc_word_bxidx:
	mov		r0, r7
	b		inc_word_r0

inc_word_bxsid8:
	r0_from_bxidxdisp8 r10
	b		inc_word_r0
inc_word_bxdid8:
	r0_from_bxidxdisp8 r11
	b		inc_word_r0
inc_word_bpsid8:
	r0_from_bpidxdisp8 r10
	b		inc_word_r0_bp
inc_word_bpdid8:
	r0_from_bpidxdisp8 r11
	b		inc_word_r0_bp
inc_word_sidisp8:
	r0_from_idx_disp8 r10
	b		inc_word_r0
inc_word_didisp8:
	r0_from_idx_disp8 r11
	b		inc_word_r0
inc_word_bpdisp8:
	r0_from_idx_disp8 r9
	b		inc_word_r0_bp
inc_word_bxdisp8:
	r0_from_idx_disp8 r7
	b		inc_word_r0

inc_word_bxsid16:
	r0_from_bxidxdisp16 r10
	b		inc_word_r0
inc_word_bxdid16:
	r0_from_bxidxdisp16 r11
	b		inc_word_r0
inc_word_bpsid16:
	r0_from_bpidxdisp16 r10
	b		inc_word_r0_bp
inc_word_bpdid16:
	r0_from_bpidxdisp16 r11
	b		inc_word_r0_bp
inc_word_sidisp16:
	r0_from_idx_disp16 r10
	b		inc_word_r0
inc_word_didisp16:
	r0_from_idx_disp16 r11
	b		inc_word_r0
inc_word_bpdisp16:
	r0_from_idx_disp16 r9
	b		inc_word_r0_bp
inc_word_bxdisp16:
	r0_from_idx_disp16 r7
	b		inc_word_r0

// ----- DEC -----

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	dec_word_r0_bp
dec_word_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	dec_word_r0
dec_word_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .dec_word_RAM dec_word_EGA bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.dec_word_RAM:
	ldrb	r0,[r2]					// Get low byte
	ldrb	r1,[r2, #1]				// Get high byte
	lsl		r0, #16
	orr		r1, r0, r1, lsl #24		// r1 = low byte | (high byte << 8) = the value to decrement
	mrs		r0,cpsr					// Get original flags to r0.
	subs	r1, #0x00010000			// Sub 1 from the value
	lsr		r1, #16
	strb	r1,[r2]					// Save low byte
	lsr		r1, #8
	strb	r1,[r2, #1]				// Save high byte
	// ----- Fix the Carry flag
	mrs		r1,cpsr					// r1 = Flags after subtraction
	and		r0, #0x20000000			// r0 = Only the original Carry flag bit
	bic		r1, #0x20000000			// r1 = New flags with Carry cleared
	orr		r0, r1					// r0 = new flags + original Carry flag
	b		restore_flags_from_r0	// Jump back to loop, setting the flags from r0

	.text
	.align 2
	
dec_word_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		dec_word_r0
dec_word_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		dec_word_r0
dec_word_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		dec_word_r0_bp
dec_word_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		dec_word_r0_bp
dec_word_siidx:
	mov		r0, r10
	b		dec_word_r0
dec_word_diidx:
	mov		r0, r11
	b		dec_word_r0
dec_word_disp16:
	r0_from_disp16
	b		dec_word_r0
dec_word_bxidx:
	mov		r0, r7
	b		dec_word_r0

dec_word_bxsid8:
	r0_from_bxidxdisp8 r10
	b		dec_word_r0
dec_word_bxdid8:
	r0_from_bxidxdisp8 r11
	b		dec_word_r0
dec_word_bpsid8:
	r0_from_bpidxdisp8 r10
	b		dec_word_r0_bp
dec_word_bpdid8:
	r0_from_bpidxdisp8 r11
	b		dec_word_r0_bp
dec_word_sidisp8:
	r0_from_idx_disp8 r10
	b		dec_word_r0
dec_word_didisp8:
	r0_from_idx_disp8 r11
	b		dec_word_r0
dec_word_bpdisp8:
	r0_from_idx_disp8 r9
	b		dec_word_r0_bp
dec_word_bxdisp8:
	r0_from_idx_disp8 r7
	b		dec_word_r0

dec_word_bxsid16:
	r0_from_bxidxdisp16 r10
	b		dec_word_r0
dec_word_bxdid16:
	r0_from_bxidxdisp16 r11
	b		dec_word_r0
dec_word_bpsid16:
	r0_from_bpidxdisp16 r10
	b		dec_word_r0_bp
dec_word_bpdid16:
	r0_from_bpidxdisp16 r11
	b		dec_word_r0_bp
dec_word_sidisp16:
	r0_from_idx_disp16 r10
	b		dec_word_r0
dec_word_didisp16:
	r0_from_idx_disp16 r11
	b		dec_word_r0
dec_word_bpdisp16:
	r0_from_idx_disp16 r9
	b		dec_word_r0_bp
dec_word_bxdisp16:
	r0_from_idx_disp16 r7
	b		dec_word_r0


// --- CALL NEAR [address] ---

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	call_near_r0_bp
call_near_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	call_near_r0
call_near_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .call_near_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.call_near_RAM:
	ldrb	r0,[r2]					// Get low byte
	ldrb	r2,[r2, #1]
	ldr		r1,[sp, #SP_PHYS_CS]	// Get current physical CS from stack
	orr		r0, r2, lsl #8			// Now r0 = new logical IP
	sub		r2, r12, r1				// r2 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	add		r12, r1, r0				// New physical IP = physical CS:0000 + new logical IP
	push_hword r2 r0 r1
	b		loop

	.text
	.align 2

	.global	call_near_bxsi
call_near_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		call_near_r0
call_near_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		call_near_r0
call_near_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		call_near_r0_bp
call_near_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		call_near_r0_bp
call_near_siidx:
	mov		r0, r10
	b		call_near_r0
call_near_diidx:
	mov		r0, r11
	b		call_near_r0
call_near_disp16:
	r0_from_disp16
	b		call_near_r0
call_near_bxidx:
	mov		r0, r7
	b		call_near_r0

call_near_bxsid8:
	r0_from_bxidxdisp8 r10
	b		call_near_r0
call_near_bxdid8:
	r0_from_bxidxdisp8 r11
	b		call_near_r0
call_near_bpsid8:
	r0_from_bpidxdisp8 r10
	b		call_near_r0_bp
call_near_bpdid8:
	r0_from_bpidxdisp8 r11
	b		call_near_r0_bp
call_near_sidisp8:
	r0_from_idx_disp8 r10
	b		call_near_r0
call_near_didisp8:
	r0_from_idx_disp8 r11
	b		call_near_r0
call_near_bpdisp8:
	r0_from_idx_disp8 r9
	b		call_near_r0_bp
call_near_bxdisp8:
	r0_from_idx_disp8 r7
	b		call_near_r0

call_near_bxsid16:
	r0_from_bxidxdisp16 r10
	b		call_near_r0
call_near_bxdid16:
	r0_from_bxidxdisp16 r11
	b		call_near_r0
call_near_bpsid16:
	r0_from_bpidxdisp16 r10
	b		call_near_r0_bp
call_near_bpdid16:
	r0_from_bpidxdisp16 r11
	b		call_near_r0_bp
call_near_sidisp16:
	r0_from_idx_disp16 r10
	b		call_near_r0
call_near_didisp16:
	r0_from_idx_disp16 r11
	b		call_near_r0
call_near_bpdisp16:
	r0_from_idx_disp16 r9
	b		call_near_r0_bp
call_near_bxdisp16:
	r0_from_idx_disp16 r7
	b		call_near_r0

.macro call_near_reg16 reg
	ldr		r1,[sp, #SP_PHYS_CS]	// Get current physical CS from stack
	sub		r2, r12, r1				// r2 = Current physical IP  - (physical base + (CS << 4)) = Current logical IP
	mov		r0, \reg, lsl #16		// Before push, in case the opcode is "call near sp" (very unlikely!)
	add		r12, r1, r0, lsr #16	// New PC = physical base + (CS<<4) + new logical IP
	push_hword r2, r0, r1
	b		loop
.endm

call_near_ax:
	call_near_reg16 r4
call_near_cx:
	call_near_reg16 r5
call_near_dx:
	call_near_reg16 r6
call_near_bx:
	call_near_reg16 r7
call_near_sp:
	call_near_reg16 r8
call_near_bp:
	call_near_reg16 r9
call_near_si:
	call_near_reg16 r10
call_near_di:
	call_near_reg16 r11

// --- CALL FAR [address] ---

	.global	call_far_r0_bp
call_far_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	call_far_r0
call_far_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .call_far_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.call_far_RAM:
	mov		r0, #16
	str		r0, [sp, #SP_FREE3]		// Save the flag telling this is a USE16 call far
	//-------
	// First get the call target :
	//	r1 = new IP (offset)
	//	r2 = new CS (segment)
	//-------
	ldrb	r0,[r2]
	ldrb	r1,[r2, #1]
	ldrb	r3,[r2, #3]
	ldrb	r2,[r2, #2]
	orr		r1, r0, r1, lsl #8		// r1 = new logical IP
	orr		r2, r3, lsl #8			// r2 = new CS value
	b		cpu_call_far_r1r2		// Jump to common handling for both real and protected mode.

call_far_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		call_far_r0
call_far_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		call_far_r0
call_far_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		call_far_r0_bp
call_far_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		call_far_r0_bp
call_far_siidx:
	mov		r0, r10
	b		call_far_r0
call_far_diidx:
	mov		r0, r11
	b		call_far_r0
call_far_disp16:
	r0_from_disp16
	b		call_far_r0
call_far_bxidx:
	mov		r0, r7
	b		call_far_r0

call_far_bxsid8:
	r0_from_bxidxdisp8 r10
	b		call_far_r0
call_far_bxdid8:
	r0_from_bxidxdisp8 r11
	b		call_far_r0
call_far_bpsid8:
	r0_from_bpidxdisp8 r10
	b		call_far_r0_bp
call_far_bpdid8:
	r0_from_bpidxdisp8 r11
	b		call_far_r0_bp
call_far_sidisp8:
	r0_from_idx_disp8 r10
	b		call_far_r0
call_far_didisp8:
	r0_from_idx_disp8 r11
	b		call_far_r0
call_far_bpdisp8:
	r0_from_idx_disp8 r9
	b		call_far_r0_bp
call_far_bxdisp8:
	r0_from_idx_disp8 r7
	b		call_far_r0

call_far_bxsid16:
	r0_from_bxidxdisp16 r10
	b		call_far_r0
call_far_bxdid16:
	r0_from_bxidxdisp16 r11
	b		call_far_r0
call_far_bpsid16:
	r0_from_bpidxdisp16 r10
	b		call_far_r0_bp
call_far_bpdid16:
	r0_from_bpidxdisp16 r11
	b		call_far_r0_bp
call_far_sidisp16:
	r0_from_idx_disp16 r10
	b		call_far_r0
call_far_didisp16:
	r0_from_idx_disp16 r11
	b		call_far_r0
call_far_bpdisp16:
	r0_from_idx_disp16 r9
	b		call_far_r0_bp
call_far_bxdisp16:
	r0_from_idx_disp16 r7
	b		call_far_r0

// --- JMP NEAR [address] ---

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	jmp_near_r0_bp
jmp_near_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	jmp_near_r0
jmp_near_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .jmp_near_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.jmp_near_RAM:
	ldrb	r0,[r2]					// Get low byte
	ldrb	r2,[r2, #1]
	ldr		r1,[sp, #SP_PHYS_CS]	// Get current physical CS from stack
	orr		r0, r2, lsl #8			// Now r0 = new logical IP
	// ----- Then calculate the current logical IP
	add		r12, r1, r0				// New PC = physical base + (CS<<4) + new logical IP
	b		loop

	.text
	.align 2

jmp_near_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		jmp_near_r0
jmp_near_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		jmp_near_r0
jmp_near_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		jmp_near_r0_bp
jmp_near_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		jmp_near_r0_bp
jmp_near_siidx:
	mov		r0, r10
	b		jmp_near_r0
jmp_near_diidx:
	mov		r0, r11
	b		jmp_near_r0
jmp_near_disp16:
	r0_from_disp16
	b		jmp_near_r0
jmp_near_bxidx:
	mov		r0, r7
	b		jmp_near_r0

jmp_near_bxsid8:
	r0_from_bxidxdisp8 r10
	b		jmp_near_r0
jmp_near_bxdid8:
	r0_from_bxidxdisp8 r11
	b		jmp_near_r0
jmp_near_bpsid8:
	r0_from_bpidxdisp8 r10
	b		jmp_near_r0_bp
jmp_near_bpdid8:
	r0_from_bpidxdisp8 r11
	b		jmp_near_r0_bp
jmp_near_sidisp8:
	r0_from_idx_disp8 r10
	b		jmp_near_r0
jmp_near_didisp8:
	r0_from_idx_disp8 r11
	b		jmp_near_r0
jmp_near_bpdisp8:
	r0_from_idx_disp8 r9
	b		jmp_near_r0_bp
jmp_near_bxdisp8:
	r0_from_idx_disp8 r7
	b		jmp_near_r0

jmp_near_bxsid16:
	r0_from_bxidxdisp16 r10
	b		jmp_near_r0
jmp_near_bxdid16:
	r0_from_bxidxdisp16 r11
	b		jmp_near_r0
jmp_near_bpsid16:
	r0_from_bpidxdisp16 r10
	b		jmp_near_r0_bp
jmp_near_bpdid16:
	r0_from_bpidxdisp16 r11
	b		jmp_near_r0_bp
jmp_near_sidisp16:
	r0_from_idx_disp16 r10
	b		jmp_near_r0
jmp_near_didisp16:
	r0_from_idx_disp16 r11
	b		jmp_near_r0
jmp_near_bpdisp16:
	r0_from_idx_disp16 r9
	b		jmp_near_r0_bp
jmp_near_bxdisp16:
	r0_from_idx_disp16 r7
	b		jmp_near_r0

.macro jmp_near_reg16 reg
	ldr		r1,[sp, #SP_PHYS_CS]	// Get current physical CS from stack
	mov		r0, \reg, lsl #16
	add		r12, r1, r0, lsr #16	// New PC = physical base + (CS<<4) + new logical IP
	b		loop
.endm

jmp_near_ax:
	jmp_near_reg16 r4
jmp_near_cx:
	jmp_near_reg16 r5
jmp_near_dx:
	jmp_near_reg16 r6
jmp_near_bx:
	jmp_near_reg16 r7
jmp_near_sp:
	jmp_near_reg16 r8
jmp_near_bp:
	jmp_near_reg16 r9
jmp_near_si:
	jmp_near_reg16 r10
jmp_near_di:
	jmp_near_reg16 r11

// --- JMP FAR [address] ---

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	jmp_far_r0_bp
jmp_far_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	jmp_far_r0
jmp_far_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .jmp_far_RAM bad_EGA_opcode bad_MODEX_opcode
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.jmp_far_RAM:
	//-------
	// First get the jump target :
	//	r1 = new IP (offset)
	//	r2 = new CS (segment)
	//-------
	ldrb	r0,[r2]
	ldrb	r1,[r2, #1]
	ldrb	r3,[r2, #3]
	ldrb	r2,[r2, #2]
	orr		r1, r0, r1, lsl #8		// r1 = new logical IP
	orr		r2, r3, lsl #8			// r2 = new CS value
	b		cpu_jmp_far_r1r2		// Jump to common handling for both real and protected mode.

	.text
	.align 2

jmp_far_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		jmp_far_r0
jmp_far_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		jmp_far_r0
jmp_far_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		jmp_far_r0_bp
jmp_far_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		jmp_far_r0_bp
jmp_far_siidx:
	mov		r0, r10
	b		jmp_far_r0
jmp_far_diidx:
	mov		r0, r11
	b		jmp_far_r0
jmp_far_disp16:
	r0_from_disp16
	b		jmp_far_r0
jmp_far_bxidx:
	mov		r0, r7
	b		jmp_far_r0

jmp_far_bxsid8:
	r0_from_bxidxdisp8 r10
	b		jmp_far_r0
jmp_far_bxdid8:
	r0_from_bxidxdisp8 r11
	b		jmp_far_r0
jmp_far_bpsid8:
	r0_from_bpidxdisp8 r10
	b		jmp_far_r0_bp
jmp_far_bpdid8:
	r0_from_bpidxdisp8 r11
	b		jmp_far_r0_bp
jmp_far_sidisp8:
	r0_from_idx_disp8 r10
	b		jmp_far_r0
jmp_far_didisp8:
	r0_from_idx_disp8 r11
	b		jmp_far_r0
jmp_far_bpdisp8:
	r0_from_idx_disp8 r9
	b		jmp_far_r0_bp
jmp_far_bxdisp8:
	r0_from_idx_disp8 r7
	b		jmp_far_r0

jmp_far_bxsid16:
	r0_from_bxidxdisp16 r10
	b		jmp_far_r0
jmp_far_bxdid16:
	r0_from_bxidxdisp16 r11
	b		jmp_far_r0
jmp_far_bpsid16:
	r0_from_bpidxdisp16 r10
	b		jmp_far_r0_bp
jmp_far_bpdid16:
	r0_from_bpidxdisp16 r11
	b		jmp_far_r0_bp
jmp_far_sidisp16:
	r0_from_idx_disp16 r10
	b		jmp_far_r0
jmp_far_didisp16:
	r0_from_idx_disp16 r11
	b		jmp_far_r0
jmp_far_bpdisp16:
	r0_from_idx_disp16 r9
	b		jmp_far_r0_bp
jmp_far_bxdisp16:
	r0_from_idx_disp16 r7
	b		jmp_far_r0


// --- PUSH ---

#if !USE_SEIBUSPI
	.section .itcm, "ax", %progbits
	.align	2
#endif	

	.global	push_word_r0_bp
push_word_r0_bp:
	//-------
	// Setup the correct segment when indexing by BP register.
	//-------
	mem_handler_bp
	.global	push_word_r0
push_word_r0:
	//-------
	// Calculate and jump to correct memory access handler.
	//-------
	mem_handler_jump_r0r3 .push_RAM push_EGA_r2 push_MODEX_r2
	//-------
	// Memory location in normal RAM.
	// On input:
	//	r2 = physical memory address
	//-------
.push_RAM:
	ldrb	r0,[r2]					// Get low byte
	ldrb	r1,[r2, #1]				// Load high byte to r1
	push_low_hi r0 r1 r2 r3
	b		loop

	.text
	.align 2

push_bxsi:
	add		r0, r7, r10				// r0 = BX+SI
	b		push_word_r0
push_bxdi:
	add		r0, r7, r11				// r0 = BX+DI
	b		push_word_r0
push_bpsi:
	add		r0, r9, r10				// r0 = BP+SI
	b		push_word_r0_bp
push_bpdi:
	add		r0, r9, r11				// r0 = BP+DI
	b		push_word_r0_bp
push_word_siidx:
	mov		r0, r10
	b		push_word_r0
push_word_diidx:
	mov		r0, r11
	b		push_word_r0
push_disp16:
	r0_from_disp16
	b		push_word_r0
push_word_bxidx:
	mov		r0, r7
	b		push_word_r0

push_bxsid8:
	r0_from_bxidxdisp8 r10
	b		push_word_r0
push_bxdid8:
	r0_from_bxidxdisp8 r11
	b		push_word_r0
push_bpsid8:
	r0_from_bpidxdisp8 r10
	b		push_word_r0_bp
push_bpdid8:
	r0_from_bpidxdisp8 r11
	b		push_word_r0_bp
push_word_sidisp8:
	r0_from_idx_disp8 r10
	b		push_word_r0
push_word_didisp8:
	r0_from_idx_disp8 r11
	b		push_word_r0
push_word_bpdisp8:
	r0_from_idx_disp8 r9
	b		push_word_r0_bp
push_word_bxdisp8:
	r0_from_idx_disp8 r7
	b		push_word_r0

push_bxsid16:
	r0_from_bxidxdisp16 r10
	b		push_word_r0
push_bxdid16:
	r0_from_bxidxdisp16 r11
	b		push_word_r0
push_bpsid16:
	r0_from_bpidxdisp16 r10
	b		push_word_r0_bp
push_bpdid16:
	r0_from_bpidxdisp16 r11
	b		push_word_r0_bp
push_sidisp16:
	r0_from_idx_disp16 r10
	b		push_word_r0
push_didisp16:
	r0_from_idx_disp16 r11
	b		push_word_r0
push_bpdisp16:
	r0_from_idx_disp16 r9
	b		push_word_r0_bp
push_bxdisp16:
	r0_from_idx_disp16 r7
	b		push_word_r0

	.global	ccnt_enable
ccnt_enable:
	mov		r0, #1						// Enable all counters
	mcr		p15, 0, r0, c15, c12, 0
	bx		lr

	.global	ccnt_read
ccnt_read:
	mrc		p15, 0, r0, c15, c12, 1
	bx		lr

// =================== Opcode tables etc ===============================

	.data
	.align 2

	.global	EMSPageTable
EMSPageTable:
	.word	EMSPageStatic

	.global IRQFlagAddr
IRQFlagAddr:
	.word	0
FrameCounter:
	.word 	0
TestData:
	.word	0
	.global	BreakReason
BreakReason:						// Reason for breaking into debugger (0 = NULL = unknown opcode)
	.word	0
	.global	TrapFlag				// Also used from "pic.s"
TrapFlag:
	.word	0
	
	// ----- Jump table for opcode handler and IRQ handler

	.global op_00, op_01, op_02, op_03, op_04, op_05, op_06, op_07
	.global op_08, op_09, op_0a, op_0b, op_0c, op_0d, op_0e, op_0f
	.global op_10, op_11, op_12, op_13, op_14, op_15, op_16, op_17
	.global op_18, op_19, op_1a, op_1b, op_1c, op_1d, op_1e, op_1f
	.global op_20, op_21, op_22, op_23, op_24, op_25, op_26_USE16_r, op_27
	.global op_28, op_29, op_2a, op_2b, op_2c, op_2d, op_2e_USE16_r, op_2f
	.global op_30, op_31, op_32, op_33, op_34, op_35, op_36_USE16_r, op_37
	.global op_38, op_39, op_3a, op_3b, op_3c, op_3d, op_3e_USE16_r, op_3f
// 0x40
	.global op_40, op_41, op_42, op_43, op_44, op_45, op_46, op_47
	.global op_48, op_49, op_4a, op_4b, op_4c, op_4d, op_4e, op_4f
	.global op_50, op_51, op_52, op_53, op_54, op_55, op_56, op_57
	.global op_60, op_61, .unknown, .unknown, op_64_USE16_r, op_65_USE16_r
	.global op_68, op_69, op_6a, op_6b, op_6c_insb, .unknown, op_6e_outsb, .unknown
	.global op_70, op_71, op_72, op_73, op_74, op_75, op_76, op_77
	.global op_78, op_79, op_7a, op_7b, op_7c, op_7d, op_7e, op_7f
// 0x80
	.global op_80, op_81, op_82, op_83, op_84, op_85, op_86, op_87
	.global op_88, op_89, op_8a, op_8b, op_8c_r, op_8d, op_8f
	.global loop, xchg_ax_cx, xchg_ax_dx, xchg_ax_bx, xchg_ax_sp, xchg_ax_bp, xchg_ax_si, xchg_ax_di
	.global op_98, op_99, op_9a, loop, op_9c, op_9d, op_9e, op_9f
	.global op_a0, op_a1, op_a2, op_a3 
	.global op_a8, op_a9
	.global op_b0, op_b1, op_b2, op_b3, op_b4, op_b5, op_b6, op_b7
// 0xC0
	.global op_c0, op_c1, op_c2, op_c3, op_c4, op_c5, op_c6, op_c7
	.global op_c8, op_c9, op_ca, op_cb_r, .unknown, op_cd, op_ce, op_cf_r
	.global op_d0, op_d1, op_d2, op_d3, op_d4, op_d5, op_d6, op_d7
	.global	op_d8, op_d9, op_da, op_db, op_dc, op_dd, op_de, op_df
	.global op_e0, op_e1, op_e2, op_e3 
	.global op_e8_rel16, op_e9_rel16, op_ea, op_eb
	.global .unknown, .unknown, op_f2, op_f3, op_f4, op_f5, op_f6, op_f7
	.global op_f8, op_f9, op_fa_CLI, op_fb_STI, op_fc, op_fd, op_fe, op_ff


	.global EMSPageStatic
EMSPageStatic:
	.space	4*4*(16+1)

	//-------
	// Potential reasons for breaking into the debugger
	//-------
	.global BRUnsOP
BRUnsOP:
	.ascii	"Unsupported opcode!"
	.byte	0x0a, 0

	.global BRUnsJPO
BRUnsJPO:
	.ascii	"Unhandled JPO opcode!"
	.byte	0x0a, 0

	.global BRUnsJPE
BRUnsJPE:
	.ascii	"Unhandled JPE opcode!"
	.byte	0x0a, 0

	.global BRUnsEGA
BRUnsEGA:
	.ascii	"Unsupported EGA opcode!"
	.byte	0x0a, 0

	.global BRUnsMODEX
BRUnsMODEX:
	.ascii	"Unsupported Mode-X opcode!"
	.byte	0x0a, 0

BRUnsINT:
	.ascii	"Unsupported INT "
	.global	BRUnsIntCode
BRUnsIntCode:
	.ascii	"XX call!"
	.byte	0x0a, 0

BRMemWatch:
	.ascii	"Memory/register watch trap"
	.byte	0x0a, 0

	.global	BRUns386Op
BRUns386Op:
	.ascii	"386 opcodes not supported!"
	.byte	0x0a, 0

	.global	BRUnsXMS
BRUnsXMS:
	.ascii	"Unsupported XMS call!"
	.byte	0x0a, 0

	.align 2
	.global	eiptrace
eiptrace:
	.space	4*32

	.global profcounts
profcounts:	
	.space	4*256
	
